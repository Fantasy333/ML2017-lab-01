{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  1 :    Loss_Train:  [[ 98497.10224306]]    Loss_Validation:  [[ 35914.42793409]]\n",
      "Loop  2 :    Loss_Train:  [[ 79378.55410535]]    Loss_Validation:  [[ 29023.68739909]]\n",
      "Loop  3 :    Loss_Train:  [[ 64646.96319788]]    Loss_Validation:  [[ 23691.19070642]]\n",
      "Loop  4 :    Loss_Train:  [[ 53287.22123212]]    Loss_Validation:  [[ 19559.50642044]]\n",
      "Loop  5 :    Loss_Train:  [[ 44519.44617324]]    Loss_Validation:  [[ 16353.6166197]]\n",
      "Loop  6 :    Loss_Train:  [[ 37744.44647248]]    Loss_Validation:  [[ 13861.86339584]]\n",
      "Loop  7 :    Loss_Train:  [[ 32501.83186289]]    Loss_Validation:  [[ 11921.30686134]]\n",
      "Loop  8 :    Loss_Train:  [[ 28437.83776066]]    Loss_Validation:  [[ 10406.47244144]]\n",
      "Loop  9 :    Loss_Train:  [[ 25280.61054737]]    Loss_Validation:  [[ 9220.70219613]]\n",
      "Loop  10 :    Loss_Train:  [[ 22821.22347415]]    Loss_Validation:  [[ 8289.50694156]]\n",
      "Loop  11 :    Loss_Train:  [[ 20899.09421803]]    Loss_Validation:  [[ 7555.45575918]]\n",
      "Loop  12 :    Loss_Train:  [[ 19390.78333891]]    Loss_Validation:  [[ 6974.24688167]]\n",
      "Loop  13 :    Loss_Train:  [[ 18201.38961888]]    Loss_Validation:  [[ 6511.68644615]]\n",
      "Loop  14 :    Loss_Train:  [[ 17257.94009366]]    Loss_Validation:  [[ 6141.36497964]]\n",
      "Loop  15 :    Loss_Train:  [[ 16504.31224257]]    Loss_Validation:  [[ 5842.87016561]]\n",
      "Loop  16 :    Loss_Train:  [[ 15897.33307093]]    Loss_Validation:  [[ 5600.41183912]]\n",
      "Loop  17 :    Loss_Train:  [[ 15403.78220724]]    Loss_Validation:  [[ 5401.76388907]]\n",
      "Loop  18 :    Loss_Train:  [[ 14998.08941904]]    Loss_Validation:  [[ 5237.44981797]]\n",
      "Loop  19 :    Loss_Train:  [[ 14660.56555587]]    Loss_Validation:  [[ 5100.11566717]]\n",
      "Loop  20 :    Loss_Train:  [[ 14376.04326063]]    Loss_Validation:  [[ 4984.04704392]]\n",
      "Loop  21 :    Loss_Train:  [[ 14132.83246483]]    Loss_Validation:  [[ 4884.79699655]]\n",
      "Loop  22 :    Loss_Train:  [[ 13921.91770795]]    Loss_Validation:  [[ 4798.89917568]]\n",
      "Loop  23 :    Loss_Train:  [[ 13736.34123787]]    Loss_Validation:  [[ 4723.64662945]]\n",
      "Loop  24 :    Loss_Train:  [[ 13570.72884322]]    Loss_Validation:  [[ 4656.9211226]]\n",
      "Loop  25 :    Loss_Train:  [[ 13420.92534888]]    Loss_Validation:  [[ 4597.06135947]]\n",
      "Loop  26 :    Loss_Train:  [[ 13283.71437204]]    Loss_Validation:  [[ 4542.76117385]]\n",
      "Loop  27 :    Loss_Train:  [[ 13156.60282468]]    Loss_Validation:  [[ 4492.99081048]]\n",
      "Loop  28 :    Loss_Train:  [[ 13037.65517144]]    Loss_Validation:  [[ 4446.93600799]]\n",
      "Loop  29 :    Loss_Train:  [[ 12925.36592589]]    Loss_Validation:  [[ 4403.95081207]]\n",
      "Loop  30 :    Loss_Train:  [[ 12818.56153744]]    Loss_Validation:  [[ 4363.52098444]]\n",
      "Loop  31 :    Loss_Train:  [[ 12716.32487065]]    Loss_Validation:  [[ 4325.23559382]]\n",
      "Loop  32 :    Loss_Train:  [[ 12617.93705378]]    Loss_Validation:  [[ 4288.76492971]]\n",
      "Loop  33 :    Loss_Train:  [[ 12522.83268317]]    Loss_Validation:  [[ 4253.8433058]]\n",
      "Loop  34 :    Loss_Train:  [[ 12430.56529909]]    Loss_Validation:  [[ 4220.25564821]]\n",
      "Loop  35 :    Loss_Train:  [[ 12340.78076301]]    Loss_Validation:  [[ 4187.8270164]]\n",
      "Loop  36 :    Loss_Train:  [[ 12253.19671438]]    Loss_Validation:  [[ 4156.41439877]]\n",
      "Loop  37 :    Loss_Train:  [[ 12167.58670672]]    Loss_Validation:  [[ 4125.90027495]]\n",
      "Loop  38 :    Loss_Train:  [[ 12083.76794641]]    Loss_Validation:  [[ 4096.18755206]]\n",
      "Loop  39 :    Loss_Train:  [[ 12001.59180644]]    Loss_Validation:  [[ 4067.19557129]]\n",
      "Loop  40 :    Loss_Train:  [[ 11920.93647845]]    Loss_Validation:  [[ 4038.85694939]]\n",
      "Loop  41 :    Loss_Train:  [[ 11841.70127367]]    Loss_Validation:  [[ 4011.11507303]]\n",
      "Loop  42 :    Loss_Train:  [[ 11763.80219562]]    Loss_Validation:  [[ 3983.92210441]]\n",
      "Loop  43 :    Loss_Train:  [[ 11687.16849504]]    Loss_Validation:  [[ 3957.23738841]]\n",
      "Loop  44 :    Loss_Train:  [[ 11611.73998355]]    Loss_Validation:  [[ 3931.02617556]]\n",
      "Loop  45 :    Loss_Train:  [[ 11537.46493424]]    Loss_Validation:  [[ 3905.25859445]]\n",
      "Loop  46 :    Loss_Train:  [[ 11464.29843673]]    Loss_Validation:  [[ 3879.90882142]]\n",
      "Loop  47 :    Loss_Train:  [[ 11392.20110459]]    Loss_Validation:  [[ 3854.95440689]]\n",
      "Loop  48 :    Loss_Train:  [[ 11321.1380563]]    Loss_Validation:  [[ 3830.37572646]]\n",
      "Loop  49 :    Loss_Train:  [[ 11251.07810898]]    Loss_Validation:  [[ 3806.1555318]]\n",
      "Loop  50 :    Loss_Train:  [[ 11181.99313798]]    Loss_Validation:  [[ 3782.27858146]]\n",
      "Loop  51 :    Loss_Train:  [[ 11113.85756585]]    Loss_Validation:  [[ 3758.73133617]]\n",
      "Loop  52 :    Loss_Train:  [[ 11046.64795278]]    Loss_Validation:  [[ 3735.50170621]]\n",
      "Loop  53 :    Loss_Train:  [[ 10980.34266653]]    Loss_Validation:  [[ 3712.57884113]]\n",
      "Loop  54 :    Loss_Train:  [[ 10914.92161504]]    Loss_Validation:  [[ 3689.95295387]]\n",
      "Loop  55 :    Loss_Train:  [[ 10850.36602858]]    Loss_Validation:  [[ 3667.61517321]]\n",
      "Loop  56 :    Loss_Train:  [[ 10786.65828111]]    Loss_Validation:  [[ 3645.55741936]]\n",
      "Loop  57 :    Loss_Train:  [[ 10723.78174296]]    Loss_Validation:  [[ 3623.77229882]]\n",
      "Loop  58 :    Loss_Train:  [[ 10661.7206585]]    Loss_Validation:  [[ 3602.25301504]]\n",
      "Loop  59 :    Loss_Train:  [[ 10600.46004398]]    Loss_Validation:  [[ 3580.9932924]]\n",
      "Loop  60 :    Loss_Train:  [[ 10539.98560153]]    Loss_Validation:  [[ 3559.98731123]]\n",
      "Loop  61 :    Loss_Train:  [[ 10480.28364648]]    Loss_Validation:  [[ 3539.22965216]]\n",
      "Loop  62 :    Loss_Train:  [[ 10421.34104542]]    Loss_Validation:  [[ 3518.71524822]]\n",
      "Loop  63 :    Loss_Train:  [[ 10363.1451631]]    Loss_Validation:  [[ 3498.43934369]]\n",
      "Loop  64 :    Loss_Train:  [[ 10305.68381677]]    Loss_Validation:  [[ 3478.39745845]]\n",
      "Loop  65 :    Loss_Train:  [[ 10248.94523654]]    Loss_Validation:  [[ 3458.58535718]]\n",
      "Loop  66 :    Loss_Train:  [[ 10192.91803089]]    Loss_Validation:  [[ 3438.99902261]]\n",
      "Loop  67 :    Loss_Train:  [[ 10137.59115652]]    Loss_Validation:  [[ 3419.63463229]]\n",
      "Loop  68 :    Loss_Train:  [[ 10082.95389176]]    Loss_Validation:  [[ 3400.48853834]]\n",
      "Loop  69 :    Loss_Train:  [[ 10028.99581324]]    Loss_Validation:  [[ 3381.55724977]]\n",
      "Loop  70 :    Loss_Train:  [[ 9975.70677504]]    Loss_Validation:  [[ 3362.8374171]]\n",
      "Loop  71 :    Loss_Train:  [[ 9923.07689033]]    Loss_Validation:  [[ 3344.32581874]]\n",
      "Loop  72 :    Loss_Train:  [[ 9871.09651483]]    Loss_Validation:  [[ 3326.01934924]]\n",
      "Loop  73 :    Loss_Train:  [[ 9819.75623208]]    Loss_Validation:  [[ 3307.91500882]]\n",
      "Loop  74 :    Loss_Train:  [[ 9769.04684024]]    Loss_Validation:  [[ 3290.00989423]]\n",
      "Loop  75 :    Loss_Train:  [[ 9718.95934012]]    Loss_Validation:  [[ 3272.30119066]]\n",
      "Loop  76 :    Loss_Train:  [[ 9669.48492448]]    Loss_Validation:  [[ 3254.78616466]]\n",
      "Loop  77 :    Loss_Train:  [[ 9620.61496824]]    Loss_Validation:  [[ 3237.46215781]]\n",
      "Loop  78 :    Loss_Train:  [[ 9572.34101967]]    Loss_Validation:  [[ 3220.32658116]]\n",
      "Loop  79 :    Loss_Train:  [[ 9524.65479238]]    Loss_Validation:  [[ 3203.37691029]]\n",
      "Loop  80 :    Loss_Train:  [[ 9477.54815797]]    Loss_Validation:  [[ 3186.61068095]]\n",
      "Loop  81 :    Loss_Train:  [[ 9431.01313938]]    Loss_Validation:  [[ 3170.0254851]]\n",
      "Loop  82 :    Loss_Train:  [[ 9385.04190473]]    Loss_Validation:  [[ 3153.6189675]]\n",
      "Loop  83 :    Loss_Train:  [[ 9339.62676175]]    Loss_Validation:  [[ 3137.38882252]]\n",
      "Loop  84 :    Loss_Train:  [[ 9294.76015259]]    Loss_Validation:  [[ 3121.33279146]]\n",
      "Loop  85 :    Loss_Train:  [[ 9250.43464906]]    Loss_Validation:  [[ 3105.44865995]]\n",
      "Loop  86 :    Loss_Train:  [[ 9206.64294827]]    Loss_Validation:  [[ 3089.73425581]]\n",
      "Loop  87 :    Loss_Train:  [[ 9163.37786854]]    Loss_Validation:  [[ 3074.18744693]]\n",
      "Loop  88 :    Loss_Train:  [[ 9120.6323456]]    Loss_Validation:  [[ 3058.80613956]]\n",
      "Loop  89 :    Loss_Train:  [[ 9078.39942916]]    Loss_Validation:  [[ 3043.58827654]]\n",
      "Loop  90 :    Loss_Train:  [[ 9036.67227956]]    Loss_Validation:  [[ 3028.53183591]]\n",
      "Loop  91 :    Loss_Train:  [[ 8995.44416477]]    Loss_Validation:  [[ 3013.63482947]]\n",
      "Loop  92 :    Loss_Train:  [[ 8954.70845749]]    Loss_Validation:  [[ 2998.89530159]]\n",
      "Loop  93 :    Loss_Train:  [[ 8914.45863253]]    Loss_Validation:  [[ 2984.31132803]]\n",
      "Loop  94 :    Loss_Train:  [[ 8874.68826422]]    Loss_Validation:  [[ 2969.88101493]]\n",
      "Loop  95 :    Loss_Train:  [[ 8835.39102406]]    Loss_Validation:  [[ 2955.60249783]]\n",
      "Loop  96 :    Loss_Train:  [[ 8796.56067849]]    Loss_Validation:  [[ 2941.47394078]]\n",
      "Loop  97 :    Loss_Train:  [[ 8758.19108674]]    Loss_Validation:  [[ 2927.49353554]]\n",
      "Loop  98 :    Loss_Train:  [[ 8720.27619882]]    Loss_Validation:  [[ 2913.65950078]]\n",
      "Loop  99 :    Loss_Train:  [[ 8682.81005363]]    Loss_Validation:  [[ 2899.97008142]]\n",
      "Loop  100 :    Loss_Train:  [[ 8645.78677707]]    Loss_Validation:  [[ 2886.42354792]]\n",
      "Loop  101 :    Loss_Train:  [[ 8609.20058035]]    Loss_Validation:  [[ 2873.01819567]]\n",
      "Loop  102 :    Loss_Train:  [[ 8573.04575831]]    Loss_Validation:  [[ 2859.75234443]]\n",
      "Loop  103 :    Loss_Train:  [[ 8537.31668779]]    Loss_Validation:  [[ 2846.62433774]]\n",
      "Loop  104 :    Loss_Train:  [[ 8502.00782616]]    Loss_Validation:  [[ 2833.63254241]]\n",
      "Loop  105 :    Loss_Train:  [[ 8467.11370977]]    Loss_Validation:  [[ 2820.77534805]]\n",
      "Loop  106 :    Loss_Train:  [[ 8432.62895257]]    Loss_Validation:  [[ 2808.05116658]]\n",
      "Loop  107 :    Loss_Train:  [[ 8398.54824473]]    Loss_Validation:  [[ 2795.45843177]]\n",
      "Loop  108 :    Loss_Train:  [[ 8364.86635134]]    Loss_Validation:  [[ 2782.99559884]]\n",
      "Loop  109 :    Loss_Train:  [[ 8331.57811106]]    Loss_Validation:  [[ 2770.66114404]]\n",
      "Loop  110 :    Loss_Train:  [[ 8298.67843496]]    Loss_Validation:  [[ 2758.45356425]]\n",
      "Loop  111 :    Loss_Train:  [[ 8266.16230525]]    Loss_Validation:  [[ 2746.37137662]]\n",
      "Loop  112 :    Loss_Train:  [[ 8234.02477416]]    Loss_Validation:  [[ 2734.41311818]]\n",
      "Loop  113 :    Loss_Train:  [[ 8202.26096277]]    Loss_Validation:  [[ 2722.57734554]]\n",
      "Loop  114 :    Loss_Train:  [[ 8170.8660599]]    Loss_Validation:  [[ 2710.86263448]]\n",
      "Loop  115 :    Loss_Train:  [[ 8139.83532107]]    Loss_Validation:  [[ 2699.2675797]]\n",
      "Loop  116 :    Loss_Train:  [[ 8109.1640674]]    Loss_Validation:  [[ 2687.79079445]]\n",
      "Loop  117 :    Loss_Train:  [[ 8078.84768462]]    Loss_Validation:  [[ 2676.43091026]]\n",
      "Loop  118 :    Loss_Train:  [[ 8048.88162206]]    Loss_Validation:  [[ 2665.18657658]]\n",
      "Loop  119 :    Loss_Train:  [[ 8019.26139165]]    Loss_Validation:  [[ 2654.05646059]]\n",
      "Loop  120 :    Loss_Train:  [[ 7989.98256701]]    Loss_Validation:  [[ 2643.03924683]]\n",
      "Loop  121 :    Loss_Train:  [[ 7961.04078245]]    Loss_Validation:  [[ 2632.13363695]]\n",
      "Loop  122 :    Loss_Train:  [[ 7932.4317321]]    Loss_Validation:  [[ 2621.33834947]]\n",
      "Loop  123 :    Loss_Train:  [[ 7904.15116901]]    Loss_Validation:  [[ 2610.65211948]]\n",
      "Loop  124 :    Loss_Train:  [[ 7876.19490424]]    Loss_Validation:  [[ 2600.07369842]]\n",
      "Loop  125 :    Loss_Train:  [[ 7848.55880603]]    Loss_Validation:  [[ 2589.60185381]]\n",
      "Loop  126 :    Loss_Train:  [[ 7821.23879892]]    Loss_Validation:  [[ 2579.235369]]\n",
      "Loop  127 :    Loss_Train:  [[ 7794.23086295]]    Loss_Validation:  [[ 2568.97304295]]\n",
      "Loop  128 :    Loss_Train:  [[ 7767.53103283]]    Loss_Validation:  [[ 2558.81368998]]\n",
      "Loop  129 :    Loss_Train:  [[ 7741.13539714]]    Loss_Validation:  [[ 2548.75613957]]\n",
      "Loop  130 :    Loss_Train:  [[ 7715.04009754]]    Loss_Validation:  [[ 2538.79923608]]\n",
      "Loop  131 :    Loss_Train:  [[ 7689.24132801]]    Loss_Validation:  [[ 2528.9418386]]\n",
      "Loop  132 :    Loss_Train:  [[ 7663.73533406]]    Loss_Validation:  [[ 2519.18282068]]\n",
      "Loop  133 :    Loss_Train:  [[ 7638.51841205]]    Loss_Validation:  [[ 2509.52107017]]\n",
      "Loop  134 :    Loss_Train:  [[ 7613.58690837]]    Loss_Validation:  [[ 2499.95548894]]\n",
      "Loop  135 :    Loss_Train:  [[ 7588.93721877]]    Loss_Validation:  [[ 2490.48499276]]\n",
      "Loop  136 :    Loss_Train:  [[ 7564.56578767]]    Loss_Validation:  [[ 2481.10851104]]\n",
      "Loop  137 :    Loss_Train:  [[ 7540.46910739]]    Loss_Validation:  [[ 2471.82498665]]\n",
      "Loop  138 :    Loss_Train:  [[ 7516.64371755]]    Loss_Validation:  [[ 2462.63337576]]\n",
      "Loop  139 :    Loss_Train:  [[ 7493.0862043]]    Loss_Validation:  [[ 2453.5326476]]\n",
      "Loop  140 :    Loss_Train:  [[ 7469.79319976]]    Loss_Validation:  [[ 2444.5217843]]\n",
      "Loop  141 :    Loss_Train:  [[ 7446.76138128]]    Loss_Validation:  [[ 2435.59978072]]\n",
      "Loop  142 :    Loss_Train:  [[ 7423.98747082]]    Loss_Validation:  [[ 2426.76564425]]\n",
      "Loop  143 :    Loss_Train:  [[ 7401.46823436]]    Loss_Validation:  [[ 2418.01839464]]\n",
      "Loop  144 :    Loss_Train:  [[ 7379.20048121]]    Loss_Validation:  [[ 2409.35706384]]\n",
      "Loop  145 :    Loss_Train:  [[ 7357.18106342]]    Loss_Validation:  [[ 2400.7806958]]\n",
      "Loop  146 :    Loss_Train:  [[ 7335.40687521]]    Loss_Validation:  [[ 2392.28834633]]\n",
      "Loop  147 :    Loss_Train:  [[ 7313.87485232]]    Loss_Validation:  [[ 2383.87908293]]\n",
      "Loop  148 :    Loss_Train:  [[ 7292.58197145]]    Loss_Validation:  [[ 2375.55198462]]\n",
      "Loop  149 :    Loss_Train:  [[ 7271.52524969]]    Loss_Validation:  [[ 2367.30614178]]\n",
      "Loop  150 :    Loss_Train:  [[ 7250.70174394]]    Loss_Validation:  [[ 2359.14065602]]\n",
      "Loop  151 :    Loss_Train:  [[ 7230.10855033]]    Loss_Validation:  [[ 2351.05463997]]\n",
      "Loop  152 :    Loss_Train:  [[ 7209.74280372]]    Loss_Validation:  [[ 2343.0472172]]\n",
      "Loop  153 :    Loss_Train:  [[ 7189.6016771]]    Loss_Validation:  [[ 2335.11752201]]\n",
      "Loop  154 :    Loss_Train:  [[ 7169.68238109]]    Loss_Validation:  [[ 2327.26469932]]\n",
      "Loop  155 :    Loss_Train:  [[ 7149.98216339]]    Loss_Validation:  [[ 2319.48790449]]\n",
      "Loop  156 :    Loss_Train:  [[ 7130.4983083]]    Loss_Validation:  [[ 2311.78630324]]\n",
      "Loop  157 :    Loss_Train:  [[ 7111.22813614]]    Loss_Validation:  [[ 2304.15907142]]\n",
      "Loop  158 :    Loss_Train:  [[ 7092.16900281]]    Loss_Validation:  [[ 2296.60539497]]\n",
      "Loop  159 :    Loss_Train:  [[ 7073.31829926]]    Loss_Validation:  [[ 2289.12446971]]\n",
      "Loop  160 :    Loss_Train:  [[ 7054.67345102]]    Loss_Validation:  [[ 2281.71550123]]\n",
      "Loop  161 :    Loss_Train:  [[ 7036.2319177]]    Loss_Validation:  [[ 2274.37770478]]\n",
      "Loop  162 :    Loss_Train:  [[ 7017.9911925]]    Loss_Validation:  [[ 2267.11030512]]\n",
      "Loop  163 :    Loss_Train:  [[ 6999.94880178]]    Loss_Validation:  [[ 2259.91253638]]\n",
      "Loop  164 :    Loss_Train:  [[ 6982.1023046]]    Loss_Validation:  [[ 2252.78364195]]\n",
      "Loop  165 :    Loss_Train:  [[ 6964.4492922]]    Loss_Validation:  [[ 2245.72287437]]\n",
      "Loop  166 :    Loss_Train:  [[ 6946.98738764]]    Loss_Validation:  [[ 2238.72949519]]\n",
      "Loop  167 :    Loss_Train:  [[ 6929.7142453]]    Loss_Validation:  [[ 2231.80277484]]\n",
      "Loop  168 :    Loss_Train:  [[ 6912.62755045]]    Loss_Validation:  [[ 2224.94199254]]\n",
      "Loop  169 :    Loss_Train:  [[ 6895.72501885]]    Loss_Validation:  [[ 2218.14643617]]\n",
      "Loop  170 :    Loss_Train:  [[ 6879.00439629]]    Loss_Validation:  [[ 2211.41540214]]\n",
      "Loop  171 :    Loss_Train:  [[ 6862.46345822]]    Loss_Validation:  [[ 2204.7481953]]\n",
      "Loop  172 :    Loss_Train:  [[ 6846.10000929]]    Loss_Validation:  [[ 2198.14412882]]\n",
      "Loop  173 :    Loss_Train:  [[ 6829.91188298]]    Loss_Validation:  [[ 2191.60252409]]\n",
      "Loop  174 :    Loss_Train:  [[ 6813.89694117]]    Loss_Validation:  [[ 2185.12271059]]\n",
      "Loop  175 :    Loss_Train:  [[ 6798.05307381]]    Loss_Validation:  [[ 2178.70402579]]\n",
      "Loop  176 :    Loss_Train:  [[ 6782.37819845]]    Loss_Validation:  [[ 2172.34581508]]\n",
      "Loop  177 :    Loss_Train:  [[ 6766.87025991]]    Loss_Validation:  [[ 2166.0474316]]\n",
      "Loop  178 :    Loss_Train:  [[ 6751.5272299]]    Loss_Validation:  [[ 2159.80823621]]\n",
      "Loop  179 :    Loss_Train:  [[ 6736.34710663]]    Loss_Validation:  [[ 2153.62759733]]\n",
      "Loop  180 :    Loss_Train:  [[ 6721.32791446]]    Loss_Validation:  [[ 2147.50489089]]\n",
      "Loop  181 :    Loss_Train:  [[ 6706.46770356]]    Loss_Validation:  [[ 2141.43950019]]\n",
      "Loop  182 :    Loss_Train:  [[ 6691.7645495]]    Loss_Validation:  [[ 2135.43081584]]\n",
      "Loop  183 :    Loss_Train:  [[ 6677.21655294]]    Loss_Validation:  [[ 2129.47823563]]\n",
      "Loop  184 :    Loss_Train:  [[ 6662.8218393]]    Loss_Validation:  [[ 2123.58116448]]\n",
      "Loop  185 :    Loss_Train:  [[ 6648.57855836]]    Loss_Validation:  [[ 2117.73901429]]\n",
      "Loop  186 :    Loss_Train:  [[ 6634.484884]]    Loss_Validation:  [[ 2111.95120392]]\n",
      "Loop  187 :    Loss_Train:  [[ 6620.53901382]]    Loss_Validation:  [[ 2106.21715905]]\n",
      "Loop  188 :    Loss_Train:  [[ 6606.73916882]]    Loss_Validation:  [[ 2100.53631209]]\n",
      "Loop  189 :    Loss_Train:  [[ 6593.08359309]]    Loss_Validation:  [[ 2094.90810212]]\n",
      "Loop  190 :    Loss_Train:  [[ 6579.57055351]]    Loss_Validation:  [[ 2089.33197481]]\n",
      "Loop  191 :    Loss_Train:  [[ 6566.19833939]]    Loss_Validation:  [[ 2083.8073823]]\n",
      "Loop  192 :    Loss_Train:  [[ 6552.96526222]]    Loss_Validation:  [[ 2078.33378313]]\n",
      "Loop  193 :    Loss_Train:  [[ 6539.86965533]]    Loss_Validation:  [[ 2072.91064218]]\n",
      "Loop  194 :    Loss_Train:  [[ 6526.90987359]]    Loss_Validation:  [[ 2067.53743057]]\n",
      "Loop  195 :    Loss_Train:  [[ 6514.08429316]]    Loss_Validation:  [[ 2062.21362558]]\n",
      "Loop  196 :    Loss_Train:  [[ 6501.39131113]]    Loss_Validation:  [[ 2056.93871056]]\n",
      "Loop  197 :    Loss_Train:  [[ 6488.8293453]]    Loss_Validation:  [[ 2051.7121749]]\n",
      "Loop  198 :    Loss_Train:  [[ 6476.39683387]]    Loss_Validation:  [[ 2046.5335139]]\n",
      "Loop  199 :    Loss_Train:  [[ 6464.09223513]]    Loss_Validation:  [[ 2041.40222871]]\n",
      "Loop  200 :    Loss_Train:  [[ 6451.91402727]]    Loss_Validation:  [[ 2036.31782627]]\n",
      "Loop  201 :    Loss_Train:  [[ 6439.86070801]]    Loss_Validation:  [[ 2031.27981923]]\n",
      "Loop  202 :    Loss_Train:  [[ 6427.93079443]]    Loss_Validation:  [[ 2026.28772587]]\n",
      "Loop  203 :    Loss_Train:  [[ 6416.12282263]]    Loss_Validation:  [[ 2021.34107005]]\n",
      "Loop  204 :    Loss_Train:  [[ 6404.43534751]]    Loss_Validation:  [[ 2016.43938109]]\n",
      "Loop  205 :    Loss_Train:  [[ 6392.86694252]]    Loss_Validation:  [[ 2011.58219378]]\n",
      "Loop  206 :    Loss_Train:  [[ 6381.41619938]]    Loss_Validation:  [[ 2006.76904822]]\n",
      "Loop  207 :    Loss_Train:  [[ 6370.08172785]]    Loss_Validation:  [[ 2001.99948983]]\n",
      "Loop  208 :    Loss_Train:  [[ 6358.86215551]]    Loss_Validation:  [[ 1997.27306925]]\n",
      "Loop  209 :    Loss_Train:  [[ 6347.75612746]]    Loss_Validation:  [[ 1992.58934226]]\n",
      "Loop  210 :    Loss_Train:  [[ 6336.76230615]]    Loss_Validation:  [[ 1987.94786976]]\n",
      "Loop  211 :    Loss_Train:  [[ 6325.87937108]]    Loss_Validation:  [[ 1983.34821764]]\n",
      "Loop  212 :    Loss_Train:  [[ 6315.10601863]]    Loss_Validation:  [[ 1978.7899568]]\n",
      "Loop  213 :    Loss_Train:  [[ 6304.4409618]]    Loss_Validation:  [[ 1974.272663]]\n",
      "Loop  214 :    Loss_Train:  [[ 6293.88292999]]    Loss_Validation:  [[ 1969.79591689]]\n",
      "Loop  215 :    Loss_Train:  [[ 6283.43066876]]    Loss_Validation:  [[ 1965.35930385]]\n",
      "Loop  216 :    Loss_Train:  [[ 6273.08293967]]    Loss_Validation:  [[ 1960.96241402]]\n",
      "Loop  217 :    Loss_Train:  [[ 6262.83851999]]    Loss_Validation:  [[ 1956.60484219]]\n",
      "Loop  218 :    Loss_Train:  [[ 6252.69620255]]    Loss_Validation:  [[ 1952.28618777]]\n",
      "Loop  219 :    Loss_Train:  [[ 6242.65479551]]    Loss_Validation:  [[ 1948.00605468]]\n",
      "Loop  220 :    Loss_Train:  [[ 6232.71312213]]    Loss_Validation:  [[ 1943.76405138]]\n",
      "Loop  221 :    Loss_Train:  [[ 6222.8700206]]    Loss_Validation:  [[ 1939.55979074]]\n",
      "Loop  222 :    Loss_Train:  [[ 6213.12434383]]    Loss_Validation:  [[ 1935.39289001]]\n",
      "Loop  223 :    Loss_Train:  [[ 6203.47495925]]    Loss_Validation:  [[ 1931.26297077]]\n",
      "Loop  224 :    Loss_Train:  [[ 6193.92074862]]    Loss_Validation:  [[ 1927.16965889]]\n",
      "Loop  225 :    Loss_Train:  [[ 6184.46060782]]    Loss_Validation:  [[ 1923.11258445]]\n",
      "Loop  226 :    Loss_Train:  [[ 6175.09344668]]    Loss_Validation:  [[ 1919.09138168]]\n",
      "Loop  227 :    Loss_Train:  [[ 6165.81818881]]    Loss_Validation:  [[ 1915.10568896]]\n",
      "Loop  228 :    Loss_Train:  [[ 6156.63377136]]    Loss_Validation:  [[ 1911.15514872]]\n",
      "Loop  229 :    Loss_Train:  [[ 6147.5391449]]    Loss_Validation:  [[ 1907.23940741]]\n",
      "Loop  230 :    Loss_Train:  [[ 6138.53327321]]    Loss_Validation:  [[ 1903.35811545]]\n",
      "Loop  231 :    Loss_Train:  [[ 6129.6151331]]    Loss_Validation:  [[ 1899.51092716]]\n",
      "Loop  232 :    Loss_Train:  [[ 6120.78371424]]    Loss_Validation:  [[ 1895.69750078]]\n",
      "Loop  233 :    Loss_Train:  [[ 6112.03801902]]    Loss_Validation:  [[ 1891.91749831]]\n",
      "Loop  234 :    Loss_Train:  [[ 6103.37706232]]    Loss_Validation:  [[ 1888.17058558]]\n",
      "Loop  235 :    Loss_Train:  [[ 6094.79987141]]    Loss_Validation:  [[ 1884.45643212]]\n",
      "Loop  236 :    Loss_Train:  [[ 6086.30548573]]    Loss_Validation:  [[ 1880.77471116]]\n",
      "Loop  237 :    Loss_Train:  [[ 6077.89295676]]    Loss_Validation:  [[ 1877.12509957]]\n",
      "Loop  238 :    Loss_Train:  [[ 6069.56134785]]    Loss_Validation:  [[ 1873.50727781]]\n",
      "Loop  239 :    Loss_Train:  [[ 6061.30973406]]    Loss_Validation:  [[ 1869.92092988]]\n",
      "Loop  240 :    Loss_Train:  [[ 6053.13720202]]    Loss_Validation:  [[ 1866.36574333]]\n",
      "Loop  241 :    Loss_Train:  [[ 6045.04284976]]    Loss_Validation:  [[ 1862.84140913]]\n",
      "Loop  242 :    Loss_Train:  [[ 6037.02578657]]    Loss_Validation:  [[ 1859.34762171]]\n",
      "Loop  243 :    Loss_Train:  [[ 6029.08513282]]    Loss_Validation:  [[ 1855.88407886]]\n",
      "Loop  244 :    Loss_Train:  [[ 6021.22001986]]    Loss_Validation:  [[ 1852.45048173]]\n",
      "Loop  245 :    Loss_Train:  [[ 6013.42958986]]    Loss_Validation:  [[ 1849.04653475]]\n",
      "Loop  246 :    Loss_Train:  [[ 6005.71299565]]    Loss_Validation:  [[ 1845.67194563]]\n",
      "Loop  247 :    Loss_Train:  [[ 5998.06940058]]    Loss_Validation:  [[ 1842.3264253]]\n",
      "Loop  248 :    Loss_Train:  [[ 5990.49797842]]    Loss_Validation:  [[ 1839.00968787]]\n",
      "Loop  249 :    Loss_Train:  [[ 5982.99791315]]    Loss_Validation:  [[ 1835.7214506]]\n",
      "Loop  250 :    Loss_Train:  [[ 5975.56839892]]    Loss_Validation:  [[ 1832.46143385]]\n",
      "Loop  251 :    Loss_Train:  [[ 5968.20863982]]    Loss_Validation:  [[ 1829.22936104]]\n",
      "Loop  252 :    Loss_Train:  [[ 5960.91784982]]    Loss_Validation:  [[ 1826.02495866]]\n",
      "Loop  253 :    Loss_Train:  [[ 5953.69525261]]    Loss_Validation:  [[ 1822.84795617]]\n",
      "Loop  254 :    Loss_Train:  [[ 5946.54008147]]    Loss_Validation:  [[ 1819.69808598]]\n",
      "Loop  255 :    Loss_Train:  [[ 5939.45157916]]    Loss_Validation:  [[ 1816.57508346]]\n",
      "Loop  256 :    Loss_Train:  [[ 5932.42899777]]    Loss_Validation:  [[ 1813.47868683]]\n",
      "Loop  257 :    Loss_Train:  [[ 5925.47159862]]    Loss_Validation:  [[ 1810.4086372]]\n",
      "Loop  258 :    Loss_Train:  [[ 5918.57865216]]    Loss_Validation:  [[ 1807.36467849]]\n",
      "Loop  259 :    Loss_Train:  [[ 5911.74943778]]    Loss_Validation:  [[ 1804.34655741]]\n",
      "Loop  260 :    Loss_Train:  [[ 5904.98324376]]    Loss_Validation:  [[ 1801.3540234]]\n",
      "Loop  261 :    Loss_Train:  [[ 5898.27936713]]    Loss_Validation:  [[ 1798.38682867]]\n",
      "Loop  262 :    Loss_Train:  [[ 5891.63711353]]    Loss_Validation:  [[ 1795.44472808]]\n",
      "Loop  263 :    Loss_Train:  [[ 5885.05579717]]    Loss_Validation:  [[ 1792.52747916]]\n",
      "Loop  264 :    Loss_Train:  [[ 5878.53474063]]    Loss_Validation:  [[ 1789.63484207]]\n",
      "Loop  265 :    Loss_Train:  [[ 5872.0732748]]    Loss_Validation:  [[ 1786.76657957]]\n",
      "Loop  266 :    Loss_Train:  [[ 5865.67073877]]    Loss_Validation:  [[ 1783.92245697]]\n",
      "Loop  267 :    Loss_Train:  [[ 5859.32647971]]    Loss_Validation:  [[ 1781.10224212]]\n",
      "Loop  268 :    Loss_Train:  [[ 5853.03985279]]    Loss_Validation:  [[ 1778.30570537]]\n",
      "Loop  269 :    Loss_Train:  [[ 5846.81022102]]    Loss_Validation:  [[ 1775.53261956]]\n",
      "Loop  270 :    Loss_Train:  [[ 5840.63695522]]    Loss_Validation:  [[ 1772.78275996]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  271 :    Loss_Train:  [[ 5834.51943386]]    Loss_Validation:  [[ 1770.05590425]]\n",
      "Loop  272 :    Loss_Train:  [[ 5828.45704299]]    Loss_Validation:  [[ 1767.35183253]]\n",
      "Loop  273 :    Loss_Train:  [[ 5822.44917615]]    Loss_Validation:  [[ 1764.67032722]]\n",
      "Loop  274 :    Loss_Train:  [[ 5816.49523424]]    Loss_Validation:  [[ 1762.01117309]]\n",
      "Loop  275 :    Loss_Train:  [[ 5810.59462545]]    Loss_Validation:  [[ 1759.37415723]]\n",
      "Loop  276 :    Loss_Train:  [[ 5804.74676514]]    Loss_Validation:  [[ 1756.75906897]]\n",
      "Loop  277 :    Loss_Train:  [[ 5798.95107581]]    Loss_Validation:  [[ 1754.16569993]]\n",
      "Loop  278 :    Loss_Train:  [[ 5793.20698691]]    Loss_Validation:  [[ 1751.59384394]]\n",
      "Loop  279 :    Loss_Train:  [[ 5787.51393484]]    Loss_Validation:  [[ 1749.043297]]\n",
      "Loop  280 :    Loss_Train:  [[ 5781.87136281]]    Loss_Validation:  [[ 1746.51385734]]\n",
      "Loop  281 :    Loss_Train:  [[ 5776.27872076]]    Loss_Validation:  [[ 1744.00532528]]\n",
      "Loop  282 :    Loss_Train:  [[ 5770.7354653]]    Loss_Validation:  [[ 1741.5175033]]\n",
      "Loop  283 :    Loss_Train:  [[ 5765.24105956]]    Loss_Validation:  [[ 1739.05019596]]\n",
      "Loop  284 :    Loss_Train:  [[ 5759.7949732]]    Loss_Validation:  [[ 1736.6032099]]\n",
      "Loop  285 :    Loss_Train:  [[ 5754.39668223]]    Loss_Validation:  [[ 1734.17635381]]\n",
      "Loop  286 :    Loss_Train:  [[ 5749.04566901]]    Loss_Validation:  [[ 1731.76943839]]\n",
      "Loop  287 :    Loss_Train:  [[ 5743.7414221]]    Loss_Validation:  [[ 1729.38227636]]\n",
      "Loop  288 :    Loss_Train:  [[ 5738.48343622]]    Loss_Validation:  [[ 1727.01468242]]\n",
      "Loop  289 :    Loss_Train:  [[ 5733.27121218]]    Loss_Validation:  [[ 1724.6664732]]\n",
      "Loop  290 :    Loss_Train:  [[ 5728.10425675]]    Loss_Validation:  [[ 1722.33746729]]\n",
      "Loop  291 :    Loss_Train:  [[ 5722.98208264]]    Loss_Validation:  [[ 1720.02748518]]\n",
      "Loop  292 :    Loss_Train:  [[ 5717.90420841]]    Loss_Validation:  [[ 1717.73634924]]\n",
      "Loop  293 :    Loss_Train:  [[ 5712.87015835]]    Loss_Validation:  [[ 1715.46388372]]\n",
      "Loop  294 :    Loss_Train:  [[ 5707.87946248]]    Loss_Validation:  [[ 1713.2099147]]\n",
      "Loop  295 :    Loss_Train:  [[ 5702.93165643]]    Loss_Validation:  [[ 1710.9742701]]\n",
      "Loop  296 :    Loss_Train:  [[ 5698.02628135]]    Loss_Validation:  [[ 1708.75677964]]\n",
      "Loop  297 :    Loss_Train:  [[ 5693.16288391]]    Loss_Validation:  [[ 1706.5572748]]\n",
      "Loop  298 :    Loss_Train:  [[ 5688.34101615]]    Loss_Validation:  [[ 1704.37558884]]\n",
      "Loop  299 :    Loss_Train:  [[ 5683.56023547]]    Loss_Validation:  [[ 1702.21155677]]\n",
      "Loop  300 :    Loss_Train:  [[ 5678.82010453]]    Loss_Validation:  [[ 1700.06501531]]\n",
      "Loop  301 :    Loss_Train:  [[ 5674.1201912]]    Loss_Validation:  [[ 1697.93580286]]\n",
      "Loop  302 :    Loss_Train:  [[ 5669.46006847]]    Loss_Validation:  [[ 1695.82375954]]\n",
      "Loop  303 :    Loss_Train:  [[ 5664.83931443]]    Loss_Validation:  [[ 1693.72872712]]\n",
      "Loop  304 :    Loss_Train:  [[ 5660.25751213]]    Loss_Validation:  [[ 1691.65054899]]\n",
      "Loop  305 :    Loss_Train:  [[ 5655.71424962]]    Loss_Validation:  [[ 1689.58907019]]\n",
      "Loop  306 :    Loss_Train:  [[ 5651.20911978]]    Loss_Validation:  [[ 1687.54413736]]\n",
      "Loop  307 :    Loss_Train:  [[ 5646.74172034]]    Loss_Validation:  [[ 1685.51559873]]\n",
      "Loop  308 :    Loss_Train:  [[ 5642.31165378]]    Loss_Validation:  [[ 1683.50330409]]\n",
      "Loop  309 :    Loss_Train:  [[ 5637.91852725]]    Loss_Validation:  [[ 1681.50710479]]\n",
      "Loop  310 :    Loss_Train:  [[ 5633.56195258]]    Loss_Validation:  [[ 1679.52685372]]\n",
      "Loop  311 :    Loss_Train:  [[ 5629.24154615]]    Loss_Validation:  [[ 1677.56240527]]\n",
      "Loop  312 :    Loss_Train:  [[ 5624.95692887]]    Loss_Validation:  [[ 1675.61361534]]\n",
      "Loop  313 :    Loss_Train:  [[ 5620.7077261]]    Loss_Validation:  [[ 1673.68034132]]\n",
      "Loop  314 :    Loss_Train:  [[ 5616.49356763]]    Loss_Validation:  [[ 1671.76244204]]\n",
      "Loop  315 :    Loss_Train:  [[ 5612.31408758]]    Loss_Validation:  [[ 1669.85977781]]\n",
      "Loop  316 :    Loss_Train:  [[ 5608.16892438]]    Loss_Validation:  [[ 1667.97221036]]\n",
      "Loop  317 :    Loss_Train:  [[ 5604.0577207]]    Loss_Validation:  [[ 1666.09960282]]\n",
      "Loop  318 :    Loss_Train:  [[ 5599.98012339]]    Loss_Validation:  [[ 1664.24181976]]\n",
      "Loop  319 :    Loss_Train:  [[ 5595.93578344]]    Loss_Validation:  [[ 1662.39872708]]\n",
      "Loop  320 :    Loss_Train:  [[ 5591.92435593]]    Loss_Validation:  [[ 1660.57019211]]\n",
      "Loop  321 :    Loss_Train:  [[ 5587.94549996]]    Loss_Validation:  [[ 1658.75608348]]\n",
      "Loop  322 :    Loss_Train:  [[ 5583.99887863]]    Loss_Validation:  [[ 1656.95627119]]\n",
      "Loop  323 :    Loss_Train:  [[ 5580.08415896]]    Loss_Validation:  [[ 1655.17062656]]\n",
      "Loop  324 :    Loss_Train:  [[ 5576.20101185]]    Loss_Validation:  [[ 1653.39902221]]\n",
      "Loop  325 :    Loss_Train:  [[ 5572.34911203]]    Loss_Validation:  [[ 1651.64133206]]\n",
      "Loop  326 :    Loss_Train:  [[ 5568.52813804]]    Loss_Validation:  [[ 1649.8974313]]\n",
      "Loop  327 :    Loss_Train:  [[ 5564.73777214]]    Loss_Validation:  [[ 1648.16719639]]\n",
      "Loop  328 :    Loss_Train:  [[ 5560.97770027]]    Loss_Validation:  [[ 1646.45050506]]\n",
      "Loop  329 :    Loss_Train:  [[ 5557.24761203]]    Loss_Validation:  [[ 1644.74723625]]\n",
      "Loop  330 :    Loss_Train:  [[ 5553.54720064]]    Loss_Validation:  [[ 1643.05727012]]\n",
      "Loop  331 :    Loss_Train:  [[ 5549.87616283]]    Loss_Validation:  [[ 1641.38048807]]\n",
      "Loop  332 :    Loss_Train:  [[ 5546.23419888]]    Loss_Validation:  [[ 1639.71677268]]\n",
      "Loop  333 :    Loss_Train:  [[ 5542.6210125]]    Loss_Validation:  [[ 1638.06600769]]\n",
      "Loop  334 :    Loss_Train:  [[ 5539.03631087]]    Loss_Validation:  [[ 1636.42807805]]\n",
      "Loop  335 :    Loss_Train:  [[ 5535.47980451]]    Loss_Validation:  [[ 1634.80286985]]\n",
      "Loop  336 :    Loss_Train:  [[ 5531.9512073]]    Loss_Validation:  [[ 1633.1902703]]\n",
      "Loop  337 :    Loss_Train:  [[ 5528.45023641]]    Loss_Validation:  [[ 1631.59016778]]\n",
      "Loop  338 :    Loss_Train:  [[ 5524.97661227]]    Loss_Validation:  [[ 1630.00245176]]\n",
      "Loop  339 :    Loss_Train:  [[ 5521.53005852]]    Loss_Validation:  [[ 1628.42701283]]\n",
      "Loop  340 :    Loss_Train:  [[ 5518.11030198]]    Loss_Validation:  [[ 1626.86374267]]\n",
      "Loop  341 :    Loss_Train:  [[ 5514.71707261]]    Loss_Validation:  [[ 1625.31253404]]\n",
      "Loop  342 :    Loss_Train:  [[ 5511.35010347]]    Loss_Validation:  [[ 1623.77328077]]\n",
      "Loop  343 :    Loss_Train:  [[ 5508.00913065]]    Loss_Validation:  [[ 1622.24587776]]\n",
      "Loop  344 :    Loss_Train:  [[ 5504.69389331]]    Loss_Validation:  [[ 1620.73022094]]\n",
      "Loop  345 :    Loss_Train:  [[ 5501.40413356]]    Loss_Validation:  [[ 1619.22620727]]\n",
      "Loop  346 :    Loss_Train:  [[ 5498.13959647]]    Loss_Validation:  [[ 1617.73373475]]\n",
      "Loop  347 :    Loss_Train:  [[ 5494.90003001]]    Loss_Validation:  [[ 1616.2527024]]\n",
      "Loop  348 :    Loss_Train:  [[ 5491.68518504]]    Loss_Validation:  [[ 1614.78301021]]\n",
      "Loop  349 :    Loss_Train:  [[ 5488.49481526]]    Loss_Validation:  [[ 1613.32455918]]\n",
      "Loop  350 :    Loss_Train:  [[ 5485.32867714]]    Loss_Validation:  [[ 1611.87725129]]\n",
      "Loop  351 :    Loss_Train:  [[ 5482.18652997]]    Loss_Validation:  [[ 1610.44098948]]\n",
      "Loop  352 :    Loss_Train:  [[ 5479.06813575]]    Loss_Validation:  [[ 1609.01567767]]\n",
      "Loop  353 :    Loss_Train:  [[ 5475.97325918]]    Loss_Validation:  [[ 1607.60122069]]\n",
      "Loop  354 :    Loss_Train:  [[ 5472.90166763]]    Loss_Validation:  [[ 1606.19752433]]\n",
      "Loop  355 :    Loss_Train:  [[ 5469.85313112]]    Loss_Validation:  [[ 1604.80449532]]\n",
      "Loop  356 :    Loss_Train:  [[ 5466.82742226]]    Loss_Validation:  [[ 1603.42204127]]\n",
      "Loop  357 :    Loss_Train:  [[ 5463.82431624]]    Loss_Validation:  [[ 1602.05007073]]\n",
      "Loop  358 :    Loss_Train:  [[ 5460.84359078]]    Loss_Validation:  [[ 1600.68849314]]\n",
      "Loop  359 :    Loss_Train:  [[ 5457.88502612]]    Loss_Validation:  [[ 1599.3372188]]\n",
      "Loop  360 :    Loss_Train:  [[ 5454.94840498]]    Loss_Validation:  [[ 1597.99615894]]\n",
      "Loop  361 :    Loss_Train:  [[ 5452.03351252]]    Loss_Validation:  [[ 1596.6652256]]\n",
      "Loop  362 :    Loss_Train:  [[ 5449.14013632]]    Loss_Validation:  [[ 1595.34433172]]\n",
      "Loop  363 :    Loss_Train:  [[ 5446.26806635]]    Loss_Validation:  [[ 1594.03339107]]\n",
      "Loop  364 :    Loss_Train:  [[ 5443.41709495]]    Loss_Validation:  [[ 1592.73231827]]\n",
      "Loop  365 :    Loss_Train:  [[ 5440.58701677]]    Loss_Validation:  [[ 1591.44102877]]\n",
      "Loop  366 :    Loss_Train:  [[ 5437.77762879]]    Loss_Validation:  [[ 1590.15943882]]\n",
      "Loop  367 :    Loss_Train:  [[ 5434.98873023]]    Loss_Validation:  [[ 1588.88746553]]\n",
      "Loop  368 :    Loss_Train:  [[ 5432.2201226]]    Loss_Validation:  [[ 1587.62502676]]\n",
      "Loop  369 :    Loss_Train:  [[ 5429.47160959]]    Loss_Validation:  [[ 1586.37204121]]\n",
      "Loop  370 :    Loss_Train:  [[ 5426.7429971]]    Loss_Validation:  [[ 1585.12842834]]\n",
      "Loop  371 :    Loss_Train:  [[ 5424.03409321]]    Loss_Validation:  [[ 1583.8941084]]\n",
      "Loop  372 :    Loss_Train:  [[ 5421.34470811]]    Loss_Validation:  [[ 1582.66900241]]\n",
      "Loop  373 :    Loss_Train:  [[ 5418.67465412]]    Loss_Validation:  [[ 1581.45303215]]\n",
      "Loop  374 :    Loss_Train:  [[ 5416.02374565]]    Loss_Validation:  [[ 1580.24612015]]\n",
      "Loop  375 :    Loss_Train:  [[ 5413.39179918]]    Loss_Validation:  [[ 1579.0481897]]\n",
      "Loop  376 :    Loss_Train:  [[ 5410.77863321]]    Loss_Validation:  [[ 1577.85916481]]\n",
      "Loop  377 :    Loss_Train:  [[ 5408.18406826]]    Loss_Validation:  [[ 1576.67897023]]\n",
      "Loop  378 :    Loss_Train:  [[ 5405.60792685]]    Loss_Validation:  [[ 1575.50753143]]\n",
      "Loop  379 :    Loss_Train:  [[ 5403.05003345]]    Loss_Validation:  [[ 1574.34477461]]\n",
      "Loop  380 :    Loss_Train:  [[ 5400.51021448]]    Loss_Validation:  [[ 1573.19062664]]\n",
      "Loop  381 :    Loss_Train:  [[ 5397.98829828]]    Loss_Validation:  [[ 1572.04501512]]\n",
      "Loop  382 :    Loss_Train:  [[ 5395.48411508]]    Loss_Validation:  [[ 1570.90786834]]\n",
      "Loop  383 :    Loss_Train:  [[ 5392.99749698]]    Loss_Validation:  [[ 1569.77911527]]\n",
      "Loop  384 :    Loss_Train:  [[ 5390.52827793]]    Loss_Validation:  [[ 1568.65868554]]\n",
      "Loop  385 :    Loss_Train:  [[ 5388.07629373]]    Loss_Validation:  [[ 1567.54650948]]\n",
      "Loop  386 :    Loss_Train:  [[ 5385.64138194]]    Loss_Validation:  [[ 1566.44251806]]\n",
      "Loop  387 :    Loss_Train:  [[ 5383.22338195]]    Loss_Validation:  [[ 1565.34664292]]\n",
      "Loop  388 :    Loss_Train:  [[ 5380.82213489]]    Loss_Validation:  [[ 1564.25881634]]\n",
      "Loop  389 :    Loss_Train:  [[ 5378.43748363]]    Loss_Validation:  [[ 1563.17897126]]\n",
      "Loop  390 :    Loss_Train:  [[ 5376.06927277]]    Loss_Validation:  [[ 1562.10704122]]\n",
      "Loop  391 :    Loss_Train:  [[ 5373.7173486]]    Loss_Validation:  [[ 1561.04296043]]\n",
      "Loop  392 :    Loss_Train:  [[ 5371.3815591]]    Loss_Validation:  [[ 1559.98666369]]\n",
      "Loop  393 :    Loss_Train:  [[ 5369.06175391]]    Loss_Validation:  [[ 1558.93808644]]\n",
      "Loop  394 :    Loss_Train:  [[ 5366.75778429]]    Loss_Validation:  [[ 1557.8971647]]\n",
      "Loop  395 :    Loss_Train:  [[ 5364.46950314]]    Loss_Validation:  [[ 1556.86383513]]\n",
      "Loop  396 :    Loss_Train:  [[ 5362.19676496]]    Loss_Validation:  [[ 1555.83803496]]\n",
      "Loop  397 :    Loss_Train:  [[ 5359.93942583]]    Loss_Validation:  [[ 1554.81970201]]\n",
      "Loop  398 :    Loss_Train:  [[ 5357.69734338]]    Loss_Validation:  [[ 1553.8087747]]\n",
      "Loop  399 :    Loss_Train:  [[ 5355.47037681]]    Loss_Validation:  [[ 1552.80519201]]\n",
      "Loop  400 :    Loss_Train:  [[ 5353.25838683]]    Loss_Validation:  [[ 1551.80889351]]\n",
      "Loop  401 :    Loss_Train:  [[ 5351.06123565]]    Loss_Validation:  [[ 1550.81981932]]\n",
      "Loop  402 :    Loss_Train:  [[ 5348.87878699]]    Loss_Validation:  [[ 1549.83791013]]\n",
      "Loop  403 :    Loss_Train:  [[ 5346.71090602]]    Loss_Validation:  [[ 1548.86310718]]\n",
      "Loop  404 :    Loss_Train:  [[ 5344.5574594]]    Loss_Validation:  [[ 1547.89535226]]\n",
      "Loop  405 :    Loss_Train:  [[ 5342.41831519]]    Loss_Validation:  [[ 1546.9345877]]\n",
      "Loop  406 :    Loss_Train:  [[ 5340.29334289]]    Loss_Validation:  [[ 1545.98075637]]\n",
      "Loop  407 :    Loss_Train:  [[ 5338.18241341]]    Loss_Validation:  [[ 1545.03380166]]\n",
      "Loop  408 :    Loss_Train:  [[ 5336.08539902]]    Loss_Validation:  [[ 1544.09366752]]\n",
      "Loop  409 :    Loss_Train:  [[ 5334.0021734]]    Loss_Validation:  [[ 1543.16029837]]\n",
      "Loop  410 :    Loss_Train:  [[ 5331.93261156]]    Loss_Validation:  [[ 1542.23363919]]\n",
      "Loop  411 :    Loss_Train:  [[ 5329.87658985]]    Loss_Validation:  [[ 1541.31363545]]\n",
      "Loop  412 :    Loss_Train:  [[ 5327.83398595]]    Loss_Validation:  [[ 1540.40023312]]\n",
      "Loop  413 :    Loss_Train:  [[ 5325.80467884]]    Loss_Validation:  [[ 1539.49337867]]\n",
      "Loop  414 :    Loss_Train:  [[ 5323.78854881]]    Loss_Validation:  [[ 1538.59301908]]\n",
      "Loop  415 :    Loss_Train:  [[ 5321.78547741]]    Loss_Validation:  [[ 1537.6991018]]\n",
      "Loop  416 :    Loss_Train:  [[ 5319.79534745]]    Loss_Validation:  [[ 1536.81157478]]\n",
      "Loop  417 :    Loss_Train:  [[ 5317.81804301]]    Loss_Validation:  [[ 1535.93038644]]\n",
      "Loop  418 :    Loss_Train:  [[ 5315.85344938]]    Loss_Validation:  [[ 1535.05548568]]\n",
      "Loop  419 :    Loss_Train:  [[ 5313.90145307]]    Loss_Validation:  [[ 1534.18682185]]\n",
      "Loop  420 :    Loss_Train:  [[ 5311.96194182]]    Loss_Validation:  [[ 1533.3243448]]\n",
      "Loop  421 :    Loss_Train:  [[ 5310.03480452]]    Loss_Validation:  [[ 1532.4680048]]\n",
      "Loop  422 :    Loss_Train:  [[ 5308.11993127]]    Loss_Validation:  [[ 1531.6177526]]\n",
      "Loop  423 :    Loss_Train:  [[ 5306.21721331]]    Loss_Validation:  [[ 1530.77353939]]\n",
      "Loop  424 :    Loss_Train:  [[ 5304.32654305]]    Loss_Validation:  [[ 1529.93531683]]\n",
      "Loop  425 :    Loss_Train:  [[ 5302.44781402]]    Loss_Validation:  [[ 1529.10303698]]\n",
      "Loop  426 :    Loss_Train:  [[ 5300.58092088]]    Loss_Validation:  [[ 1528.27665237]]\n",
      "Loop  427 :    Loss_Train:  [[ 5298.72575939]]    Loss_Validation:  [[ 1527.45611594]]\n",
      "Loop  428 :    Loss_Train:  [[ 5296.88222642]]    Loss_Validation:  [[ 1526.64138107]]\n",
      "Loop  429 :    Loss_Train:  [[ 5295.05021991]]    Loss_Validation:  [[ 1525.83240158]]\n",
      "Loop  430 :    Loss_Train:  [[ 5293.22963887]]    Loss_Validation:  [[ 1525.02913166]]\n",
      "Loop  431 :    Loss_Train:  [[ 5291.4203834]]    Loss_Validation:  [[ 1524.23152597]]\n",
      "Loop  432 :    Loss_Train:  [[ 5289.6223546]]    Loss_Validation:  [[ 1523.43953955]]\n",
      "Loop  433 :    Loss_Train:  [[ 5287.83545464]]    Loss_Validation:  [[ 1522.65312784]]\n",
      "Loop  434 :    Loss_Train:  [[ 5286.05958669]]    Loss_Validation:  [[ 1521.87224671]]\n",
      "Loop  435 :    Loss_Train:  [[ 5284.29465495]]    Loss_Validation:  [[ 1521.09685242]]\n",
      "Loop  436 :    Loss_Train:  [[ 5282.5405646]]    Loss_Validation:  [[ 1520.3269016]]\n",
      "Loop  437 :    Loss_Train:  [[ 5280.79722183]]    Loss_Validation:  [[ 1519.5623513]]\n",
      "Loop  438 :    Loss_Train:  [[ 5279.06453378]]    Loss_Validation:  [[ 1518.80315893]]\n",
      "Loop  439 :    Loss_Train:  [[ 5277.34240857]]    Loss_Validation:  [[ 1518.04928232]]\n",
      "Loop  440 :    Loss_Train:  [[ 5275.63075528]]    Loss_Validation:  [[ 1517.30067965]]\n",
      "Loop  441 :    Loss_Train:  [[ 5273.92948391]]    Loss_Validation:  [[ 1516.55730947]]\n",
      "Loop  442 :    Loss_Train:  [[ 5272.23850542]]    Loss_Validation:  [[ 1515.81913072]]\n",
      "Loop  443 :    Loss_Train:  [[ 5270.55773166]]    Loss_Validation:  [[ 1515.08610269]]\n",
      "Loop  444 :    Loss_Train:  [[ 5268.88707542]]    Loss_Validation:  [[ 1514.35818506]]\n",
      "Loop  445 :    Loss_Train:  [[ 5267.22645038]]    Loss_Validation:  [[ 1513.63533785]]\n",
      "Loop  446 :    Loss_Train:  [[ 5265.5757711]]    Loss_Validation:  [[ 1512.91752144]]\n",
      "Loop  447 :    Loss_Train:  [[ 5263.93495303]]    Loss_Validation:  [[ 1512.20469655]]\n",
      "Loop  448 :    Loss_Train:  [[ 5262.30391248]]    Loss_Validation:  [[ 1511.49682427]]\n",
      "Loop  449 :    Loss_Train:  [[ 5260.68256664]]    Loss_Validation:  [[ 1510.79386604]]\n",
      "Loop  450 :    Loss_Train:  [[ 5259.07083353]]    Loss_Validation:  [[ 1510.09578361]]\n",
      "Loop  451 :    Loss_Train:  [[ 5257.46863202]]    Loss_Validation:  [[ 1509.40253911]]\n",
      "Loop  452 :    Loss_Train:  [[ 5255.8758818]]    Loss_Validation:  [[ 1508.71409498]]\n",
      "Loop  453 :    Loss_Train:  [[ 5254.2925034]]    Loss_Validation:  [[ 1508.03041399]]\n",
      "Loop  454 :    Loss_Train:  [[ 5252.71841814]]    Loss_Validation:  [[ 1507.35145925]]\n",
      "Loop  455 :    Loss_Train:  [[ 5251.15354816]]    Loss_Validation:  [[ 1506.6771942]]\n",
      "Loop  456 :    Loss_Train:  [[ 5249.59781638]]    Loss_Validation:  [[ 1506.00758259]]\n",
      "Loop  457 :    Loss_Train:  [[ 5248.05114651]]    Loss_Validation:  [[ 1505.3425885]]\n",
      "Loop  458 :    Loss_Train:  [[ 5246.51346305]]    Loss_Validation:  [[ 1504.68217632]]\n",
      "Loop  459 :    Loss_Train:  [[ 5244.98469125]]    Loss_Validation:  [[ 1504.02631075]]\n",
      "Loop  460 :    Loss_Train:  [[ 5243.46475711]]    Loss_Validation:  [[ 1503.3749568]]\n",
      "Loop  461 :    Loss_Train:  [[ 5241.9535874]]    Loss_Validation:  [[ 1502.72807981]]\n",
      "Loop  462 :    Loss_Train:  [[ 5240.45110962]]    Loss_Validation:  [[ 1502.08564538]]\n",
      "Loop  463 :    Loss_Train:  [[ 5238.957252]]    Loss_Validation:  [[ 1501.44761946]]\n",
      "Loop  464 :    Loss_Train:  [[ 5237.47194352]]    Loss_Validation:  [[ 1500.81396826]]\n",
      "Loop  465 :    Loss_Train:  [[ 5235.99511383]]    Loss_Validation:  [[ 1500.18465831]]\n",
      "Loop  466 :    Loss_Train:  [[ 5234.52669333]]    Loss_Validation:  [[ 1499.55965642]]\n",
      "Loop  467 :    Loss_Train:  [[ 5233.0666131]]    Loss_Validation:  [[ 1498.93892968]]\n",
      "Loop  468 :    Loss_Train:  [[ 5231.61480491]]    Loss_Validation:  [[ 1498.32244548]]\n",
      "Loop  469 :    Loss_Train:  [[ 5230.17120124]]    Loss_Validation:  [[ 1497.7101715]]\n",
      "Loop  470 :    Loss_Train:  [[ 5228.73573521]]    Loss_Validation:  [[ 1497.10207569]]\n",
      "Loop  471 :    Loss_Train:  [[ 5227.30834063]]    Loss_Validation:  [[ 1496.49812628]]\n",
      "Loop  472 :    Loss_Train:  [[ 5225.88895198]]    Loss_Validation:  [[ 1495.89829178]]\n",
      "Loop  473 :    Loss_Train:  [[ 5224.47750437]]    Loss_Validation:  [[ 1495.30254096]]\n",
      "Loop  474 :    Loss_Train:  [[ 5223.07393358]]    Loss_Validation:  [[ 1494.71084287]]\n",
      "Loop  475 :    Loss_Train:  [[ 5221.67817602]]    Loss_Validation:  [[ 1494.12316682]]\n",
      "Loop  476 :    Loss_Train:  [[ 5220.29016873]]    Loss_Validation:  [[ 1493.53948241]]\n",
      "Loop  477 :    Loss_Train:  [[ 5218.90984938]]    Loss_Validation:  [[ 1492.95975947]]\n",
      "Loop  478 :    Loss_Train:  [[ 5217.53715627]]    Loss_Validation:  [[ 1492.38396811]]\n",
      "Loop  479 :    Loss_Train:  [[ 5216.17202828]]    Loss_Validation:  [[ 1491.81207869]]\n",
      "Loop  480 :    Loss_Train:  [[ 5214.81440492]]    Loss_Validation:  [[ 1491.24406182]]\n",
      "Loop  481 :    Loss_Train:  [[ 5213.4642263]]    Loss_Validation:  [[ 1490.67988837]]\n",
      "Loop  482 :    Loss_Train:  [[ 5212.12143311]]    Loss_Validation:  [[ 1490.11952946]]\n",
      "Loop  483 :    Loss_Train:  [[ 5210.78596663]]    Loss_Validation:  [[ 1489.56295646]]\n",
      "Loop  484 :    Loss_Train:  [[ 5209.45776872]]    Loss_Validation:  [[ 1489.01014097]]\n",
      "Loop  485 :    Loss_Train:  [[ 5208.13678181]]    Loss_Validation:  [[ 1488.46105485]]\n",
      "Loop  486 :    Loss_Train:  [[ 5206.82294889]]    Loss_Validation:  [[ 1487.91567019]]\n",
      "Loop  487 :    Loss_Train:  [[ 5205.51621353]]    Loss_Validation:  [[ 1487.37395932]]\n",
      "Loop  488 :    Loss_Train:  [[ 5204.21651982]]    Loss_Validation:  [[ 1486.83589482]]\n",
      "Loop  489 :    Loss_Train:  [[ 5202.92381242]]    Loss_Validation:  [[ 1486.30144947]]\n",
      "Loop  490 :    Loss_Train:  [[ 5201.63803654]]    Loss_Validation:  [[ 1485.77059632]]\n",
      "Loop  491 :    Loss_Train:  [[ 5200.35913791]]    Loss_Validation:  [[ 1485.24330863]]\n",
      "Loop  492 :    Loss_Train:  [[ 5199.08706278]]    Loss_Validation:  [[ 1484.71955988]]\n",
      "Loop  493 :    Loss_Train:  [[ 5197.82175795]]    Loss_Validation:  [[ 1484.19932379]]\n",
      "Loop  494 :    Loss_Train:  [[ 5196.56317071]]    Loss_Validation:  [[ 1483.68257429]]\n",
      "Loop  495 :    Loss_Train:  [[ 5195.31124889]]    Loss_Validation:  [[ 1483.16928554]]\n",
      "Loop  496 :    Loss_Train:  [[ 5194.0659408]]    Loss_Validation:  [[ 1482.65943192]]\n",
      "Loop  497 :    Loss_Train:  [[ 5192.82719527]]    Loss_Validation:  [[ 1482.15298801]]\n",
      "Loop  498 :    Loss_Train:  [[ 5191.59496161]]    Loss_Validation:  [[ 1481.64992862]]\n",
      "Loop  499 :    Loss_Train:  [[ 5190.36918963]]    Loss_Validation:  [[ 1481.15022877]]\n",
      "Loop  500 :    Loss_Train:  [[ 5189.14982963]]    Loss_Validation:  [[ 1480.65386368]]\n",
      "Loop  501 :    Loss_Train:  [[ 5187.93683238]]    Loss_Validation:  [[ 1480.1608088]]\n",
      "Loop  502 :    Loss_Train:  [[ 5186.73014913]]    Loss_Validation:  [[ 1479.67103977]]\n",
      "Loop  503 :    Loss_Train:  [[ 5185.52973159]]    Loss_Validation:  [[ 1479.18453242]]\n",
      "Loop  504 :    Loss_Train:  [[ 5184.33553193]]    Loss_Validation:  [[ 1478.70126281]]\n",
      "Loop  505 :    Loss_Train:  [[ 5183.1475028]]    Loss_Validation:  [[ 1478.22120719]]\n",
      "Loop  506 :    Loss_Train:  [[ 5181.9655973]]    Loss_Validation:  [[ 1477.74434201]]\n",
      "Loop  507 :    Loss_Train:  [[ 5180.78976895]]    Loss_Validation:  [[ 1477.27064391]]\n",
      "Loop  508 :    Loss_Train:  [[ 5179.61997175]]    Loss_Validation:  [[ 1476.80008973]]\n",
      "Loop  509 :    Loss_Train:  [[ 5178.45616012]]    Loss_Validation:  [[ 1476.33265651]]\n",
      "Loop  510 :    Loss_Train:  [[ 5177.29828891]]    Loss_Validation:  [[ 1475.86832146]]\n",
      "Loop  511 :    Loss_Train:  [[ 5176.14631342]]    Loss_Validation:  [[ 1475.407062]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  512 :    Loss_Train:  [[ 5175.00018935]]    Loss_Validation:  [[ 1474.94885574]]\n",
      "Loop  513 :    Loss_Train:  [[ 5173.85987285]]    Loss_Validation:  [[ 1474.49368045]]\n",
      "Loop  514 :    Loss_Train:  [[ 5172.72532046]]    Loss_Validation:  [[ 1474.04151411]]\n",
      "Loop  515 :    Loss_Train:  [[ 5171.59648914]]    Loss_Validation:  [[ 1473.59233487]]\n",
      "Loop  516 :    Loss_Train:  [[ 5170.47333626]]    Loss_Validation:  [[ 1473.14612106]]\n",
      "Loop  517 :    Loss_Train:  [[ 5169.35581959]]    Loss_Validation:  [[ 1472.70285121]]\n",
      "Loop  518 :    Loss_Train:  [[ 5168.2438973]]    Loss_Validation:  [[ 1472.26250399]]\n",
      "Loop  519 :    Loss_Train:  [[ 5167.13752795]]    Loss_Validation:  [[ 1471.82505828]]\n",
      "Loop  520 :    Loss_Train:  [[ 5166.03667049]]    Loss_Validation:  [[ 1471.39049312]]\n",
      "Loop  521 :    Loss_Train:  [[ 5164.94128427]]    Loss_Validation:  [[ 1470.95878771]]\n",
      "Loop  522 :    Loss_Train:  [[ 5163.851329]]    Loss_Validation:  [[ 1470.52992144]]\n",
      "Loop  523 :    Loss_Train:  [[ 5162.76676478]]    Loss_Validation:  [[ 1470.10387387]]\n",
      "Loop  524 :    Loss_Train:  [[ 5161.68755207]]    Loss_Validation:  [[ 1469.68062471]]\n",
      "Loop  525 :    Loss_Train:  [[ 5160.61365173]]    Loss_Validation:  [[ 1469.26015385]]\n",
      "Loop  526 :    Loss_Train:  [[ 5159.54502495]]    Loss_Validation:  [[ 1468.84244134]]\n",
      "Loop  527 :    Loss_Train:  [[ 5158.4816333]]    Loss_Validation:  [[ 1468.4274674]]\n",
      "Loop  528 :    Loss_Train:  [[ 5157.42343871]]    Loss_Validation:  [[ 1468.01521241]]\n",
      "Loop  529 :    Loss_Train:  [[ 5156.37040344]]    Loss_Validation:  [[ 1467.60565689]]\n",
      "Loop  530 :    Loss_Train:  [[ 5155.32249014]]    Loss_Validation:  [[ 1467.19878154]]\n",
      "Loop  531 :    Loss_Train:  [[ 5154.27966178]]    Loss_Validation:  [[ 1466.79456722]]\n",
      "Loop  532 :    Loss_Train:  [[ 5153.24188167]]    Loss_Validation:  [[ 1466.39299493]]\n",
      "Loop  533 :    Loss_Train:  [[ 5152.20911346]]    Loss_Validation:  [[ 1465.99404583]]\n",
      "Loop  534 :    Loss_Train:  [[ 5151.18132116]]    Loss_Validation:  [[ 1465.59770125]]\n",
      "Loop  535 :    Loss_Train:  [[ 5150.15846908]]    Loss_Validation:  [[ 1465.20394264]]\n",
      "Loop  536 :    Loss_Train:  [[ 5149.14052188]]    Loss_Validation:  [[ 1464.81275162]]\n",
      "Loop  537 :    Loss_Train:  [[ 5148.12744453]]    Loss_Validation:  [[ 1464.42410995]]\n",
      "Loop  538 :    Loss_Train:  [[ 5147.11920233]]    Loss_Validation:  [[ 1464.03799956]]\n",
      "Loop  539 :    Loss_Train:  [[ 5146.11576089]]    Loss_Validation:  [[ 1463.6544025]]\n",
      "Loop  540 :    Loss_Train:  [[ 5145.11708616]]    Loss_Validation:  [[ 1463.27330096]]\n",
      "Loop  541 :    Loss_Train:  [[ 5144.12314437]]    Loss_Validation:  [[ 1462.89467731]]\n",
      "Loop  542 :    Loss_Train:  [[ 5143.13390206]]    Loss_Validation:  [[ 1462.51851402]]\n",
      "Loop  543 :    Loss_Train:  [[ 5142.14932611]]    Loss_Validation:  [[ 1462.14479372]]\n",
      "Loop  544 :    Loss_Train:  [[ 5141.16938366]]    Loss_Validation:  [[ 1461.77349919]]\n",
      "Loop  545 :    Loss_Train:  [[ 5140.19404217]]    Loss_Validation:  [[ 1461.40461333]]\n",
      "Loop  546 :    Loss_Train:  [[ 5139.22326939]]    Loss_Validation:  [[ 1461.03811919]]\n",
      "Loop  547 :    Loss_Train:  [[ 5138.25703336]]    Loss_Validation:  [[ 1460.67399994]]\n",
      "Loop  548 :    Loss_Train:  [[ 5137.29530243]]    Loss_Validation:  [[ 1460.3122389]]\n",
      "Loop  549 :    Loss_Train:  [[ 5136.3380452]]    Loss_Validation:  [[ 1459.95281952]]\n",
      "Loop  550 :    Loss_Train:  [[ 5135.38523057]]    Loss_Validation:  [[ 1459.59572538]]\n",
      "Loop  551 :    Loss_Train:  [[ 5134.43682774]]    Loss_Validation:  [[ 1459.24094019]]\n",
      "Loop  552 :    Loss_Train:  [[ 5133.49280616]]    Loss_Validation:  [[ 1458.88844778]]\n",
      "Loop  553 :    Loss_Train:  [[ 5132.55313556]]    Loss_Validation:  [[ 1458.53823213]]\n",
      "Loop  554 :    Loss_Train:  [[ 5131.61778596]]    Loss_Validation:  [[ 1458.19027734]]\n",
      "Loop  555 :    Loss_Train:  [[ 5130.68672762]]    Loss_Validation:  [[ 1457.84456763]]\n",
      "Loop  556 :    Loss_Train:  [[ 5129.75993109]]    Loss_Validation:  [[ 1457.50108733]]\n",
      "Loop  557 :    Loss_Train:  [[ 5128.83736717]]    Loss_Validation:  [[ 1457.15982094]]\n",
      "Loop  558 :    Loss_Train:  [[ 5127.91900692]]    Loss_Validation:  [[ 1456.82075303]]\n",
      "Loop  559 :    Loss_Train:  [[ 5127.00482167]]    Loss_Validation:  [[ 1456.48386834]]\n",
      "Loop  560 :    Loss_Train:  [[ 5126.09478299]]    Loss_Validation:  [[ 1456.14915168]]\n",
      "Loop  561 :    Loss_Train:  [[ 5125.18886272]]    Loss_Validation:  [[ 1455.81658803]]\n",
      "Loop  562 :    Loss_Train:  [[ 5124.28703294]]    Loss_Validation:  [[ 1455.48616246]]\n",
      "Loop  563 :    Loss_Train:  [[ 5123.38926596]]    Loss_Validation:  [[ 1455.15786015]]\n",
      "Loop  564 :    Loss_Train:  [[ 5122.49553437]]    Loss_Validation:  [[ 1454.83166643]]\n",
      "Loop  565 :    Loss_Train:  [[ 5121.60581098]]    Loss_Validation:  [[ 1454.50756671]]\n",
      "Loop  566 :    Loss_Train:  [[ 5120.72006884]]    Loss_Validation:  [[ 1454.18554653]]\n",
      "Loop  567 :    Loss_Train:  [[ 5119.83828124]]    Loss_Validation:  [[ 1453.86559155]]\n",
      "Loop  568 :    Loss_Train:  [[ 5118.96042172]]    Loss_Validation:  [[ 1453.54768752]]\n",
      "Loop  569 :    Loss_Train:  [[ 5118.08646402]]    Loss_Validation:  [[ 1453.23182034]]\n",
      "Loop  570 :    Loss_Train:  [[ 5117.21638214]]    Loss_Validation:  [[ 1452.91797598]]\n",
      "Loop  571 :    Loss_Train:  [[ 5116.3501503]]    Loss_Validation:  [[ 1452.60614054]]\n",
      "Loop  572 :    Loss_Train:  [[ 5115.48774293]]    Loss_Validation:  [[ 1452.29630022]]\n",
      "Loop  573 :    Loss_Train:  [[ 5114.6291347]]    Loss_Validation:  [[ 1451.98844134]]\n",
      "Loop  574 :    Loss_Train:  [[ 5113.77430051]]    Loss_Validation:  [[ 1451.68255031]]\n",
      "Loop  575 :    Loss_Train:  [[ 5112.92321544]]    Loss_Validation:  [[ 1451.37861366]]\n",
      "Loop  576 :    Loss_Train:  [[ 5112.07585483]]    Loss_Validation:  [[ 1451.07661802]]\n",
      "Loop  577 :    Loss_Train:  [[ 5111.23219421]]    Loss_Validation:  [[ 1450.77655012]]\n",
      "Loop  578 :    Loss_Train:  [[ 5110.39220932]]    Loss_Validation:  [[ 1450.4783968]]\n",
      "Loop  579 :    Loss_Train:  [[ 5109.55587612]]    Loss_Validation:  [[ 1450.18214499]]\n",
      "Loop  580 :    Loss_Train:  [[ 5108.72317079]]    Loss_Validation:  [[ 1449.88778174]]\n",
      "Loop  581 :    Loss_Train:  [[ 5107.89406968]]    Loss_Validation:  [[ 1449.59529417]]\n",
      "Loop  582 :    Loss_Train:  [[ 5107.06854937]]    Loss_Validation:  [[ 1449.30466953]]\n",
      "Loop  583 :    Loss_Train:  [[ 5106.24658664]]    Loss_Validation:  [[ 1449.01589516]]\n",
      "Loop  584 :    Loss_Train:  [[ 5105.42815846]]    Loss_Validation:  [[ 1448.72895849]]\n",
      "Loop  585 :    Loss_Train:  [[ 5104.613242]]    Loss_Validation:  [[ 1448.44384705]]\n",
      "Loop  586 :    Loss_Train:  [[ 5103.80181464]]    Loss_Validation:  [[ 1448.16054847]]\n",
      "Loop  587 :    Loss_Train:  [[ 5102.99385393]]    Loss_Validation:  [[ 1447.87905046]]\n",
      "Loop  588 :    Loss_Train:  [[ 5102.18933762]]    Loss_Validation:  [[ 1447.59934085]]\n",
      "Loop  589 :    Loss_Train:  [[ 5101.38824366]]    Loss_Validation:  [[ 1447.32140754]]\n",
      "Loop  590 :    Loss_Train:  [[ 5100.59055018]]    Loss_Validation:  [[ 1447.04523853]]\n",
      "Loop  591 :    Loss_Train:  [[ 5099.7962355]]    Loss_Validation:  [[ 1446.77082193]]\n",
      "Loop  592 :    Loss_Train:  [[ 5099.0052781]]    Loss_Validation:  [[ 1446.49814591]]\n",
      "Loop  593 :    Loss_Train:  [[ 5098.21765668]]    Loss_Validation:  [[ 1446.22719874]]\n",
      "Loop  594 :    Loss_Train:  [[ 5097.4333501]]    Loss_Validation:  [[ 1445.9579688]]\n",
      "Loop  595 :    Loss_Train:  [[ 5096.6523374]]    Loss_Validation:  [[ 1445.69044454]]\n",
      "Loop  596 :    Loss_Train:  [[ 5095.87459779]]    Loss_Validation:  [[ 1445.42461449]]\n",
      "Loop  597 :    Loss_Train:  [[ 5095.10011067]]    Loss_Validation:  [[ 1445.16046728]]\n",
      "Loop  598 :    Loss_Train:  [[ 5094.3288556]]    Loss_Validation:  [[ 1444.89799163]]\n",
      "Loop  599 :    Loss_Train:  [[ 5093.56081232]]    Loss_Validation:  [[ 1444.63717634]]\n",
      "Loop  600 :    Loss_Train:  [[ 5092.79596074]]    Loss_Validation:  [[ 1444.3780103]]\n",
      "Loop  601 :    Loss_Train:  [[ 5092.03428093]]    Loss_Validation:  [[ 1444.12048246]]\n",
      "Loop  602 :    Loss_Train:  [[ 5091.27575314]]    Loss_Validation:  [[ 1443.86458189]]\n",
      "Loop  603 :    Loss_Train:  [[ 5090.52035776]]    Loss_Validation:  [[ 1443.61029772]]\n",
      "Loop  604 :    Loss_Train:  [[ 5089.76807538]]    Loss_Validation:  [[ 1443.35761916]]\n",
      "Loop  605 :    Loss_Train:  [[ 5089.01888671]]    Loss_Validation:  [[ 1443.10653552]]\n",
      "Loop  606 :    Loss_Train:  [[ 5088.27277266]]    Loss_Validation:  [[ 1442.85703618]]\n",
      "Loop  607 :    Loss_Train:  [[ 5087.52971426]]    Loss_Validation:  [[ 1442.60911058]]\n",
      "Loop  608 :    Loss_Train:  [[ 5086.78969274]]    Loss_Validation:  [[ 1442.36274828]]\n",
      "Loop  609 :    Loss_Train:  [[ 5086.05268944]]    Loss_Validation:  [[ 1442.11793889]]\n",
      "Loop  610 :    Loss_Train:  [[ 5085.31868588]]    Loss_Validation:  [[ 1441.8746721]]\n",
      "Loop  611 :    Loss_Train:  [[ 5084.58766374]]    Loss_Validation:  [[ 1441.63293768]]\n",
      "Loop  612 :    Loss_Train:  [[ 5083.85960482]]    Loss_Validation:  [[ 1441.39272549]]\n",
      "Loop  613 :    Loss_Train:  [[ 5083.13449111]]    Loss_Validation:  [[ 1441.15402545]]\n",
      "Loop  614 :    Loss_Train:  [[ 5082.4123047]]    Loss_Validation:  [[ 1440.91682755]]\n",
      "Loop  615 :    Loss_Train:  [[ 5081.69302787]]    Loss_Validation:  [[ 1440.68112188]]\n",
      "Loop  616 :    Loss_Train:  [[ 5080.97664301]]    Loss_Validation:  [[ 1440.44689858]]\n",
      "Loop  617 :    Loss_Train:  [[ 5080.26313269]]    Loss_Validation:  [[ 1440.21414788]]\n",
      "Loop  618 :    Loss_Train:  [[ 5079.55247959]]    Loss_Validation:  [[ 1439.98286006]]\n",
      "Loop  619 :    Loss_Train:  [[ 5078.84466655]]    Loss_Validation:  [[ 1439.7530255]]\n",
      "Loop  620 :    Loss_Train:  [[ 5078.13967654]]    Loss_Validation:  [[ 1439.52463463]]\n",
      "Loop  621 :    Loss_Train:  [[ 5077.43749266]]    Loss_Validation:  [[ 1439.29767797]]\n",
      "Loop  622 :    Loss_Train:  [[ 5076.73809817]]    Loss_Validation:  [[ 1439.07214609]]\n",
      "Loop  623 :    Loss_Train:  [[ 5076.04147646]]    Loss_Validation:  [[ 1438.84802964]]\n",
      "Loop  624 :    Loss_Train:  [[ 5075.34761102]]    Loss_Validation:  [[ 1438.62531935]]\n",
      "Loop  625 :    Loss_Train:  [[ 5074.65648552]]    Loss_Validation:  [[ 1438.40400599]]\n",
      "Loop  626 :    Loss_Train:  [[ 5073.96808374]]    Loss_Validation:  [[ 1438.18408043]]\n",
      "Loop  627 :    Loss_Train:  [[ 5073.28238959]]    Loss_Validation:  [[ 1437.96553359]]\n",
      "Loop  628 :    Loss_Train:  [[ 5072.5993871]]    Loss_Validation:  [[ 1437.74835646]]\n",
      "Loop  629 :    Loss_Train:  [[ 5071.91906045]]    Loss_Validation:  [[ 1437.53254009]]\n",
      "Loop  630 :    Loss_Train:  [[ 5071.24139393]]    Loss_Validation:  [[ 1437.31807561]]\n",
      "Loop  631 :    Loss_Train:  [[ 5070.56637195]]    Loss_Validation:  [[ 1437.1049542]]\n",
      "Loop  632 :    Loss_Train:  [[ 5069.89397907]]    Loss_Validation:  [[ 1436.89316712]]\n",
      "Loop  633 :    Loss_Train:  [[ 5069.22419995]]    Loss_Validation:  [[ 1436.68270568]]\n",
      "Loop  634 :    Loss_Train:  [[ 5068.55701938]]    Loss_Validation:  [[ 1436.47356126]]\n",
      "Loop  635 :    Loss_Train:  [[ 5067.89242226]]    Loss_Validation:  [[ 1436.26572531]]\n",
      "Loop  636 :    Loss_Train:  [[ 5067.23039363]]    Loss_Validation:  [[ 1436.05918932]]\n",
      "Loop  637 :    Loss_Train:  [[ 5066.57091864]]    Loss_Validation:  [[ 1435.85394488]]\n",
      "Loop  638 :    Loss_Train:  [[ 5065.91398253]]    Loss_Validation:  [[ 1435.6499836]]\n",
      "Loop  639 :    Loss_Train:  [[ 5065.2595707]]    Loss_Validation:  [[ 1435.44729718]]\n",
      "Loop  640 :    Loss_Train:  [[ 5064.60766864]]    Loss_Validation:  [[ 1435.24587736]]\n",
      "Loop  641 :    Loss_Train:  [[ 5063.95826196]]    Loss_Validation:  [[ 1435.04571597]]\n",
      "Loop  642 :    Loss_Train:  [[ 5063.31133638]]    Loss_Validation:  [[ 1434.84680486]]\n",
      "Loop  643 :    Loss_Train:  [[ 5062.66687773]]    Loss_Validation:  [[ 1434.64913597]]\n",
      "Loop  644 :    Loss_Train:  [[ 5062.02487195]]    Loss_Validation:  [[ 1434.45270129]]\n",
      "Loop  645 :    Loss_Train:  [[ 5061.38530511]]    Loss_Validation:  [[ 1434.25749286]]\n",
      "Loop  646 :    Loss_Train:  [[ 5060.74816335]]    Loss_Validation:  [[ 1434.06350278]]\n",
      "Loop  647 :    Loss_Train:  [[ 5060.11343295]]    Loss_Validation:  [[ 1433.87072322]]\n",
      "Loop  648 :    Loss_Train:  [[ 5059.48110029]]    Loss_Validation:  [[ 1433.6791464]]\n",
      "Loop  649 :    Loss_Train:  [[ 5058.85115184]]    Loss_Validation:  [[ 1433.48876458]]\n",
      "Loop  650 :    Loss_Train:  [[ 5058.2235742]]    Loss_Validation:  [[ 1433.29957009]]\n",
      "Loop  651 :    Loss_Train:  [[ 5057.59835405]]    Loss_Validation:  [[ 1433.11155533]]\n",
      "Loop  652 :    Loss_Train:  [[ 5056.97547817]]    Loss_Validation:  [[ 1432.92471273]]\n",
      "Loop  653 :    Loss_Train:  [[ 5056.35493348]]    Loss_Validation:  [[ 1432.73903478]]\n",
      "Loop  654 :    Loss_Train:  [[ 5055.73670695]]    Loss_Validation:  [[ 1432.55451403]]\n",
      "Loop  655 :    Loss_Train:  [[ 5055.12078569]]    Loss_Validation:  [[ 1432.37114309]]\n",
      "Loop  656 :    Loss_Train:  [[ 5054.50715689]]    Loss_Validation:  [[ 1432.1889146]]\n",
      "Loop  657 :    Loss_Train:  [[ 5053.89580783]]    Loss_Validation:  [[ 1432.00782128]]\n",
      "Loop  658 :    Loss_Train:  [[ 5053.2867259]]    Loss_Validation:  [[ 1431.82785588]]\n",
      "Loop  659 :    Loss_Train:  [[ 5052.67989859]]    Loss_Validation:  [[ 1431.64901122]]\n",
      "Loop  660 :    Loss_Train:  [[ 5052.07531348]]    Loss_Validation:  [[ 1431.47128015]]\n",
      "Loop  661 :    Loss_Train:  [[ 5051.47295824]]    Loss_Validation:  [[ 1431.29465559]]\n",
      "Loop  662 :    Loss_Train:  [[ 5050.87282063]]    Loss_Validation:  [[ 1431.1191305]]\n",
      "Loop  663 :    Loss_Train:  [[ 5050.27488851]]    Loss_Validation:  [[ 1430.9446979]]\n",
      "Loop  664 :    Loss_Train:  [[ 5049.67914984]]    Loss_Validation:  [[ 1430.77135086]]\n",
      "Loop  665 :    Loss_Train:  [[ 5049.08559265]]    Loss_Validation:  [[ 1430.59908247]]\n",
      "Loop  666 :    Loss_Train:  [[ 5048.49420507]]    Loss_Validation:  [[ 1430.42788592]]\n",
      "Loop  667 :    Loss_Train:  [[ 5047.90497534]]    Loss_Validation:  [[ 1430.2577544]]\n",
      "Loop  668 :    Loss_Train:  [[ 5047.31789175]]    Loss_Validation:  [[ 1430.08868117]]\n",
      "Loop  669 :    Loss_Train:  [[ 5046.7329427]]    Loss_Validation:  [[ 1429.92065955]]\n",
      "Loop  670 :    Loss_Train:  [[ 5046.15011667]]    Loss_Validation:  [[ 1429.75368288]]\n",
      "Loop  671 :    Loss_Train:  [[ 5045.56940224]]    Loss_Validation:  [[ 1429.58774456]]\n",
      "Loop  672 :    Loss_Train:  [[ 5044.99078805]]    Loss_Validation:  [[ 1429.42283805]]\n",
      "Loop  673 :    Loss_Train:  [[ 5044.41426285]]    Loss_Validation:  [[ 1429.25895684]]\n",
      "Loop  674 :    Loss_Train:  [[ 5043.83981546]]    Loss_Validation:  [[ 1429.09609446]]\n",
      "Loop  675 :    Loss_Train:  [[ 5043.26743478]]    Loss_Validation:  [[ 1428.93424451]]\n",
      "Loop  676 :    Loss_Train:  [[ 5042.6971098]]    Loss_Validation:  [[ 1428.7734006]]\n",
      "Loop  677 :    Loss_Train:  [[ 5042.12882959]]    Loss_Validation:  [[ 1428.61355642]]\n",
      "Loop  678 :    Loss_Train:  [[ 5041.56258329]]    Loss_Validation:  [[ 1428.45470569]]\n",
      "Loop  679 :    Loss_Train:  [[ 5040.99836014]]    Loss_Validation:  [[ 1428.29684217]]\n",
      "Loop  680 :    Loss_Train:  [[ 5040.43614944]]    Loss_Validation:  [[ 1428.13995966]]\n",
      "Loop  681 :    Loss_Train:  [[ 5039.87594058]]    Loss_Validation:  [[ 1427.98405201]]\n",
      "Loop  682 :    Loss_Train:  [[ 5039.31772303]]    Loss_Validation:  [[ 1427.82911313]]\n",
      "Loop  683 :    Loss_Train:  [[ 5038.76148631]]    Loss_Validation:  [[ 1427.67513695]]\n",
      "Loop  684 :    Loss_Train:  [[ 5038.20722006]]    Loss_Validation:  [[ 1427.52211744]]\n",
      "Loop  685 :    Loss_Train:  [[ 5037.65491397]]    Loss_Validation:  [[ 1427.37004862]]\n",
      "Loop  686 :    Loss_Train:  [[ 5037.10455779]]    Loss_Validation:  [[ 1427.21892456]]\n",
      "Loop  687 :    Loss_Train:  [[ 5036.55614139]]    Loss_Validation:  [[ 1427.06873937]]\n",
      "Loop  688 :    Loss_Train:  [[ 5036.00965466]]    Loss_Validation:  [[ 1426.91948718]]\n",
      "Loop  689 :    Loss_Train:  [[ 5035.4650876]]    Loss_Validation:  [[ 1426.77116218]]\n",
      "Loop  690 :    Loss_Train:  [[ 5034.92243027]]    Loss_Validation:  [[ 1426.6237586]]\n",
      "Loop  691 :    Loss_Train:  [[ 5034.3816728]]    Loss_Validation:  [[ 1426.4772707]]\n",
      "Loop  692 :    Loss_Train:  [[ 5033.8428054]]    Loss_Validation:  [[ 1426.33169279]]\n",
      "Loop  693 :    Loss_Train:  [[ 5033.30581833]]    Loss_Validation:  [[ 1426.18701922]]\n",
      "Loop  694 :    Loss_Train:  [[ 5032.77070196]]    Loss_Validation:  [[ 1426.04324436]]\n",
      "Loop  695 :    Loss_Train:  [[ 5032.23744667]]    Loss_Validation:  [[ 1425.90036265]]\n",
      "Loop  696 :    Loss_Train:  [[ 5031.70604297]]    Loss_Validation:  [[ 1425.75836853]]\n",
      "Loop  697 :    Loss_Train:  [[ 5031.17648139]]    Loss_Validation:  [[ 1425.61725653]]\n",
      "Loop  698 :    Loss_Train:  [[ 5030.64875256]]    Loss_Validation:  [[ 1425.47702116]]\n",
      "Loop  699 :    Loss_Train:  [[ 5030.12284715]]    Loss_Validation:  [[ 1425.337657]]\n",
      "Loop  700 :    Loss_Train:  [[ 5029.59875592]]    Loss_Validation:  [[ 1425.19915868]]\n",
      "Loop  701 :    Loss_Train:  [[ 5029.07646968]]    Loss_Validation:  [[ 1425.06152083]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  702 :    Loss_Train:  [[ 5028.55597931]]    Loss_Validation:  [[ 1424.92473815]]\n",
      "Loop  703 :    Loss_Train:  [[ 5028.03727576]]    Loss_Validation:  [[ 1424.78880535]]\n",
      "Loop  704 :    Loss_Train:  [[ 5027.52035002]]    Loss_Validation:  [[ 1424.65371721]]\n",
      "Loop  705 :    Loss_Train:  [[ 5027.00519319]]    Loss_Validation:  [[ 1424.5194685]]\n",
      "Loop  706 :    Loss_Train:  [[ 5026.49179638]]    Loss_Validation:  [[ 1424.38605407]]\n",
      "Loop  707 :    Loss_Train:  [[ 5025.98015079]]    Loss_Validation:  [[ 1424.25346877]]\n",
      "Loop  708 :    Loss_Train:  [[ 5025.47024768]]    Loss_Validation:  [[ 1424.12170752]]\n",
      "Loop  709 :    Loss_Train:  [[ 5024.96207838]]    Loss_Validation:  [[ 1423.99076524]]\n",
      "Loop  710 :    Loss_Train:  [[ 5024.45563425]]    Loss_Validation:  [[ 1423.86063691]]\n",
      "Loop  711 :    Loss_Train:  [[ 5023.95090675]]    Loss_Validation:  [[ 1423.73131753]]\n",
      "Loop  712 :    Loss_Train:  [[ 5023.44788736]]    Loss_Validation:  [[ 1423.60280213]]\n",
      "Loop  713 :    Loss_Train:  [[ 5022.94656764]]    Loss_Validation:  [[ 1423.47508581]]\n",
      "Loop  714 :    Loss_Train:  [[ 5022.44693922]]    Loss_Validation:  [[ 1423.34816364]]\n",
      "Loop  715 :    Loss_Train:  [[ 5021.94899376]]    Loss_Validation:  [[ 1423.22203079]]\n",
      "Loop  716 :    Loss_Train:  [[ 5021.452723]]    Loss_Validation:  [[ 1423.09668242]]\n",
      "Loop  717 :    Loss_Train:  [[ 5020.95811872]]    Loss_Validation:  [[ 1422.97211373]]\n",
      "Loop  718 :    Loss_Train:  [[ 5020.46517277]]    Loss_Validation:  [[ 1422.84831996]]\n",
      "Loop  719 :    Loss_Train:  [[ 5019.97387706]]    Loss_Validation:  [[ 1422.72529639]]\n",
      "Loop  720 :    Loss_Train:  [[ 5019.48422352]]    Loss_Validation:  [[ 1422.6030383]]\n",
      "Loop  721 :    Loss_Train:  [[ 5018.99620419]]    Loss_Validation:  [[ 1422.48154105]]\n",
      "Loop  722 :    Loss_Train:  [[ 5018.50981112]]    Loss_Validation:  [[ 1422.36079999]]\n",
      "Loop  723 :    Loss_Train:  [[ 5018.02503643]]    Loss_Validation:  [[ 1422.24081051]]\n",
      "Loop  724 :    Loss_Train:  [[ 5017.5418723]]    Loss_Validation:  [[ 1422.12156805]]\n",
      "Loop  725 :    Loss_Train:  [[ 5017.06031095]]    Loss_Validation:  [[ 1422.00306806]]\n",
      "Loop  726 :    Loss_Train:  [[ 5016.58034467]]    Loss_Validation:  [[ 1421.88530604]]\n",
      "Loop  727 :    Loss_Train:  [[ 5016.10196577]]    Loss_Validation:  [[ 1421.76827749]]\n",
      "Loop  728 :    Loss_Train:  [[ 5015.62516666]]    Loss_Validation:  [[ 1421.65197797]]\n",
      "Loop  729 :    Loss_Train:  [[ 5015.14993975]]    Loss_Validation:  [[ 1421.53640306]]\n",
      "Loop  730 :    Loss_Train:  [[ 5014.67627754]]    Loss_Validation:  [[ 1421.42154837]]\n",
      "Loop  731 :    Loss_Train:  [[ 5014.20417257]]    Loss_Validation:  [[ 1421.30740952]]\n",
      "Loop  732 :    Loss_Train:  [[ 5013.73361741]]    Loss_Validation:  [[ 1421.1939822]]\n",
      "Loop  733 :    Loss_Train:  [[ 5013.2646047]]    Loss_Validation:  [[ 1421.0812621]]\n",
      "Loop  734 :    Loss_Train:  [[ 5012.79712714]]    Loss_Validation:  [[ 1420.96924493]]\n",
      "Loop  735 :    Loss_Train:  [[ 5012.33117744]]    Loss_Validation:  [[ 1420.85792646]]\n",
      "Loop  736 :    Loss_Train:  [[ 5011.8667484]]    Loss_Validation:  [[ 1420.74730247]]\n",
      "Loop  737 :    Loss_Train:  [[ 5011.40383285]]    Loss_Validation:  [[ 1420.63736875]]\n",
      "Loop  738 :    Loss_Train:  [[ 5010.94242365]]    Loss_Validation:  [[ 1420.52812116]]\n",
      "Loop  739 :    Loss_Train:  [[ 5010.48251374]]    Loss_Validation:  [[ 1420.41955556]]\n",
      "Loop  740 :    Loss_Train:  [[ 5010.02409608]]    Loss_Validation:  [[ 1420.31166784]]\n",
      "Loop  741 :    Loss_Train:  [[ 5009.5671637]]    Loss_Validation:  [[ 1420.20445392]]\n",
      "Loop  742 :    Loss_Train:  [[ 5009.11170966]]    Loss_Validation:  [[ 1420.09790974]]\n",
      "Loop  743 :    Loss_Train:  [[ 5008.65772706]]    Loss_Validation:  [[ 1419.99203128]]\n",
      "Loop  744 :    Loss_Train:  [[ 5008.20520907]]    Loss_Validation:  [[ 1419.88681455]]\n",
      "Loop  745 :    Loss_Train:  [[ 5007.75414887]]    Loss_Validation:  [[ 1419.78225556]]\n",
      "Loop  746 :    Loss_Train:  [[ 5007.30453972]]    Loss_Validation:  [[ 1419.67835037]]\n",
      "Loop  747 :    Loss_Train:  [[ 5006.8563749]]    Loss_Validation:  [[ 1419.57509506]]\n",
      "Loop  748 :    Loss_Train:  [[ 5006.40964775]]    Loss_Validation:  [[ 1419.47248573]]\n",
      "Loop  749 :    Loss_Train:  [[ 5005.96435163]]    Loss_Validation:  [[ 1419.37051852]]\n",
      "Loop  750 :    Loss_Train:  [[ 5005.52047997]]    Loss_Validation:  [[ 1419.26918958]]\n",
      "Loop  751 :    Loss_Train:  [[ 5005.07802622]]    Loss_Validation:  [[ 1419.16849509]]\n",
      "Loop  752 :    Loss_Train:  [[ 5004.63698389]]    Loss_Validation:  [[ 1419.06843126]]\n",
      "Loop  753 :    Loss_Train:  [[ 5004.19734653]]    Loss_Validation:  [[ 1418.96899433]]\n",
      "Loop  754 :    Loss_Train:  [[ 5003.75910772]]    Loss_Validation:  [[ 1418.87018053]]\n",
      "Loop  755 :    Loss_Train:  [[ 5003.32226108]]    Loss_Validation:  [[ 1418.77198617]]\n",
      "Loop  756 :    Loss_Train:  [[ 5002.88680029]]    Loss_Validation:  [[ 1418.67440754]]\n",
      "Loop  757 :    Loss_Train:  [[ 5002.45271906]]    Loss_Validation:  [[ 1418.57744097]]\n",
      "Loop  758 :    Loss_Train:  [[ 5002.02001113]]    Loss_Validation:  [[ 1418.48108282]]\n",
      "Loop  759 :    Loss_Train:  [[ 5001.58867029]]    Loss_Validation:  [[ 1418.38532945]]\n",
      "Loop  760 :    Loss_Train:  [[ 5001.15869038]]    Loss_Validation:  [[ 1418.29017729]]\n",
      "Loop  761 :    Loss_Train:  [[ 5000.73006525]]    Loss_Validation:  [[ 1418.19562273]]\n",
      "Loop  762 :    Loss_Train:  [[ 5000.30278882]]    Loss_Validation:  [[ 1418.10166225]]\n",
      "Loop  763 :    Loss_Train:  [[ 4999.87685504]]    Loss_Validation:  [[ 1418.0082923]]\n",
      "Loop  764 :    Loss_Train:  [[ 4999.45225788]]    Loss_Validation:  [[ 1417.91550938]]\n",
      "Loop  765 :    Loss_Train:  [[ 4999.02899137]]    Loss_Validation:  [[ 1417.82331]]\n",
      "Loop  766 :    Loss_Train:  [[ 4998.60704957]]    Loss_Validation:  [[ 1417.73169071]]\n",
      "Loop  767 :    Loss_Train:  [[ 4998.18642658]]    Loss_Validation:  [[ 1417.64064807]]\n",
      "Loop  768 :    Loss_Train:  [[ 4997.76711652]]    Loss_Validation:  [[ 1417.55017866]]\n",
      "Loop  769 :    Loss_Train:  [[ 4997.34911357]]    Loss_Validation:  [[ 1417.46027909]]\n",
      "Loop  770 :    Loss_Train:  [[ 4996.93241194]]    Loss_Validation:  [[ 1417.37094598]]\n",
      "Loop  771 :    Loss_Train:  [[ 4996.51700588]]    Loss_Validation:  [[ 1417.28217598]]\n",
      "Loop  772 :    Loss_Train:  [[ 4996.10288965]]    Loss_Validation:  [[ 1417.19396577]]\n",
      "Loop  773 :    Loss_Train:  [[ 4995.69005758]]    Loss_Validation:  [[ 1417.10631204]]\n",
      "Loop  774 :    Loss_Train:  [[ 4995.27850401]]    Loss_Validation:  [[ 1417.01921151]]\n",
      "Loop  775 :    Loss_Train:  [[ 4994.86822333]]    Loss_Validation:  [[ 1416.9326609]]\n",
      "Loop  776 :    Loss_Train:  [[ 4994.45920997]]    Loss_Validation:  [[ 1416.84665698]]\n",
      "Loop  777 :    Loss_Train:  [[ 4994.05145837]]    Loss_Validation:  [[ 1416.76119652]]\n",
      "Loop  778 :    Loss_Train:  [[ 4993.64496303]]    Loss_Validation:  [[ 1416.67627633]]\n",
      "Loop  779 :    Loss_Train:  [[ 4993.23971847]]    Loss_Validation:  [[ 1416.59189322]]\n",
      "Loop  780 :    Loss_Train:  [[ 4992.83571924]]    Loss_Validation:  [[ 1416.50804402]]\n",
      "Loop  781 :    Loss_Train:  [[ 4992.43295993]]    Loss_Validation:  [[ 1416.42472561]]\n",
      "Loop  782 :    Loss_Train:  [[ 4992.03143517]]    Loss_Validation:  [[ 1416.34193485]]\n",
      "Loop  783 :    Loss_Train:  [[ 4991.63113962]]    Loss_Validation:  [[ 1416.25966865]]\n",
      "Loop  784 :    Loss_Train:  [[ 4991.23206796]]    Loss_Validation:  [[ 1416.17792393]]\n",
      "Loop  785 :    Loss_Train:  [[ 4990.83421491]]    Loss_Validation:  [[ 1416.09669763]]\n",
      "Loop  786 :    Loss_Train:  [[ 4990.43757522]]    Loss_Validation:  [[ 1416.0159867]]\n",
      "Loop  787 :    Loss_Train:  [[ 4990.04214369]]    Loss_Validation:  [[ 1415.93578813]]\n",
      "Loop  788 :    Loss_Train:  [[ 4989.64791512]]    Loss_Validation:  [[ 1415.85609891]]\n",
      "Loop  789 :    Loss_Train:  [[ 4989.25488437]]    Loss_Validation:  [[ 1415.77691606]]\n",
      "Loop  790 :    Loss_Train:  [[ 4988.86304632]]    Loss_Validation:  [[ 1415.69823661]]\n",
      "Loop  791 :    Loss_Train:  [[ 4988.47239586]]    Loss_Validation:  [[ 1415.62005762]]\n",
      "Loop  792 :    Loss_Train:  [[ 4988.08292795]]    Loss_Validation:  [[ 1415.54237617]]\n",
      "Loop  793 :    Loss_Train:  [[ 4987.69463756]]    Loss_Validation:  [[ 1415.46518934]]\n",
      "Loop  794 :    Loss_Train:  [[ 4987.30751968]]    Loss_Validation:  [[ 1415.38849424]]\n",
      "Loop  795 :    Loss_Train:  [[ 4986.92156935]]    Loss_Validation:  [[ 1415.312288]]\n",
      "Loop  796 :    Loss_Train:  [[ 4986.53678162]]    Loss_Validation:  [[ 1415.23656778]]\n",
      "Loop  797 :    Loss_Train:  [[ 4986.15315159]]    Loss_Validation:  [[ 1415.16133073]]\n",
      "Loop  798 :    Loss_Train:  [[ 4985.77067438]]    Loss_Validation:  [[ 1415.08657403]]\n",
      "Loop  799 :    Loss_Train:  [[ 4985.38934513]]    Loss_Validation:  [[ 1415.0122949]]\n",
      "Loop  800 :    Loss_Train:  [[ 4985.00915903]]    Loss_Validation:  [[ 1414.93849054]]\n",
      "Loop  801 :    Loss_Train:  [[ 4984.63011127]]    Loss_Validation:  [[ 1414.8651582]]\n",
      "Loop  802 :    Loss_Train:  [[ 4984.25219709]]    Loss_Validation:  [[ 1414.79229512]]\n",
      "Loop  803 :    Loss_Train:  [[ 4983.87541175]]    Loss_Validation:  [[ 1414.71989858]]\n",
      "Loop  804 :    Loss_Train:  [[ 4983.49975055]]    Loss_Validation:  [[ 1414.64796586]]\n",
      "Loop  805 :    Loss_Train:  [[ 4983.1252088]]    Loss_Validation:  [[ 1414.57649428]]\n",
      "Loop  806 :    Loss_Train:  [[ 4982.75178184]]    Loss_Validation:  [[ 1414.50548114]]\n",
      "Loop  807 :    Loss_Train:  [[ 4982.37946505]]    Loss_Validation:  [[ 1414.4349238]]\n",
      "Loop  808 :    Loss_Train:  [[ 4982.00825382]]    Loss_Validation:  [[ 1414.36481961]]\n",
      "Loop  809 :    Loss_Train:  [[ 4981.63814359]]    Loss_Validation:  [[ 1414.29516593]]\n",
      "Loop  810 :    Loss_Train:  [[ 4981.2691298]]    Loss_Validation:  [[ 1414.22596016]]\n",
      "Loop  811 :    Loss_Train:  [[ 4980.90120793]]    Loss_Validation:  [[ 1414.1571997]]\n",
      "Loop  812 :    Loss_Train:  [[ 4980.5343735]]    Loss_Validation:  [[ 1414.08888198]]\n",
      "Loop  813 :    Loss_Train:  [[ 4980.16862203]]    Loss_Validation:  [[ 1414.02100443]]\n",
      "Loop  814 :    Loss_Train:  [[ 4979.80394907]]    Loss_Validation:  [[ 1413.9535645]]\n",
      "Loop  815 :    Loss_Train:  [[ 4979.44035022]]    Loss_Validation:  [[ 1413.88655967]]\n",
      "Loop  816 :    Loss_Train:  [[ 4979.07782107]]    Loss_Validation:  [[ 1413.81998742]]\n",
      "Loop  817 :    Loss_Train:  [[ 4978.71635727]]    Loss_Validation:  [[ 1413.75384524]]\n",
      "Loop  818 :    Loss_Train:  [[ 4978.35595447]]    Loss_Validation:  [[ 1413.68813066]]\n",
      "Loop  819 :    Loss_Train:  [[ 4977.99660836]]    Loss_Validation:  [[ 1413.62284122]]\n",
      "Loop  820 :    Loss_Train:  [[ 4977.63831464]]    Loss_Validation:  [[ 1413.55797444]]\n",
      "Loop  821 :    Loss_Train:  [[ 4977.28106905]]    Loss_Validation:  [[ 1413.49352791]]\n",
      "Loop  822 :    Loss_Train:  [[ 4976.92486734]]    Loss_Validation:  [[ 1413.42949919]]\n",
      "Loop  823 :    Loss_Train:  [[ 4976.56970529]]    Loss_Validation:  [[ 1413.36588588]]\n",
      "Loop  824 :    Loss_Train:  [[ 4976.21557872]]    Loss_Validation:  [[ 1413.30268558]]\n",
      "Loop  825 :    Loss_Train:  [[ 4975.86248344]]    Loss_Validation:  [[ 1413.23989593]]\n",
      "Loop  826 :    Loss_Train:  [[ 4975.51041532]]    Loss_Validation:  [[ 1413.17751455]]\n",
      "Loop  827 :    Loss_Train:  [[ 4975.15937022]]    Loss_Validation:  [[ 1413.11553909]]\n",
      "Loop  828 :    Loss_Train:  [[ 4974.80934405]]    Loss_Validation:  [[ 1413.05396723]]\n",
      "Loop  829 :    Loss_Train:  [[ 4974.46033273]]    Loss_Validation:  [[ 1412.99279665]]\n",
      "Loop  830 :    Loss_Train:  [[ 4974.1123322]]    Loss_Validation:  [[ 1412.93202504]]\n",
      "Loop  831 :    Loss_Train:  [[ 4973.76533843]]    Loss_Validation:  [[ 1412.8716501]]\n",
      "Loop  832 :    Loss_Train:  [[ 4973.41934742]]    Loss_Validation:  [[ 1412.81166957]]\n",
      "Loop  833 :    Loss_Train:  [[ 4973.07435518]]    Loss_Validation:  [[ 1412.75208118]]\n",
      "Loop  834 :    Loss_Train:  [[ 4972.73035773]]    Loss_Validation:  [[ 1412.69288268]]\n",
      "Loop  835 :    Loss_Train:  [[ 4972.38735114]]    Loss_Validation:  [[ 1412.63407184]]\n",
      "Loop  836 :    Loss_Train:  [[ 4972.04533149]]    Loss_Validation:  [[ 1412.57564643]]\n",
      "Loop  837 :    Loss_Train:  [[ 4971.70429488]]    Loss_Validation:  [[ 1412.51760425]]\n",
      "Loop  838 :    Loss_Train:  [[ 4971.36423743]]    Loss_Validation:  [[ 1412.45994311]]\n",
      "Loop  839 :    Loss_Train:  [[ 4971.02515529]]    Loss_Validation:  [[ 1412.40266083]]\n",
      "Loop  840 :    Loss_Train:  [[ 4970.68704461]]    Loss_Validation:  [[ 1412.34575523]]\n",
      "Loop  841 :    Loss_Train:  [[ 4970.34990159]]    Loss_Validation:  [[ 1412.28922416]]\n",
      "Loop  842 :    Loss_Train:  [[ 4970.01372244]]    Loss_Validation:  [[ 1412.23306549]]\n",
      "Loop  843 :    Loss_Train:  [[ 4969.67850338]]    Loss_Validation:  [[ 1412.17727709]]\n",
      "Loop  844 :    Loss_Train:  [[ 4969.34424066]]    Loss_Validation:  [[ 1412.12185683]]\n",
      "Loop  845 :    Loss_Train:  [[ 4969.01093055]]    Loss_Validation:  [[ 1412.06680263]]\n",
      "Loop  846 :    Loss_Train:  [[ 4968.67856934]]    Loss_Validation:  [[ 1412.0121124]]\n",
      "Loop  847 :    Loss_Train:  [[ 4968.34715334]]    Loss_Validation:  [[ 1411.95778404]]\n",
      "Loop  848 :    Loss_Train:  [[ 4968.01667888]]    Loss_Validation:  [[ 1411.90381551]]\n",
      "Loop  849 :    Loss_Train:  [[ 4967.68714232]]    Loss_Validation:  [[ 1411.85020476]]\n",
      "Loop  850 :    Loss_Train:  [[ 4967.35854001]]    Loss_Validation:  [[ 1411.79694974]]\n",
      "Loop  851 :    Loss_Train:  [[ 4967.03086835]]    Loss_Validation:  [[ 1411.74404842]]\n",
      "Loop  852 :    Loss_Train:  [[ 4966.70412376]]    Loss_Validation:  [[ 1411.69149881]]\n",
      "Loop  853 :    Loss_Train:  [[ 4966.37830265]]    Loss_Validation:  [[ 1411.63929888]]\n",
      "Loop  854 :    Loss_Train:  [[ 4966.05340147]]    Loss_Validation:  [[ 1411.58744666]]\n",
      "Loop  855 :    Loss_Train:  [[ 4965.7294167]]    Loss_Validation:  [[ 1411.53594017]]\n",
      "Loop  856 :    Loss_Train:  [[ 4965.40634481]]    Loss_Validation:  [[ 1411.48477745]]\n",
      "Loop  857 :    Loss_Train:  [[ 4965.08418232]]    Loss_Validation:  [[ 1411.43395653]]\n",
      "Loop  858 :    Loss_Train:  [[ 4964.76292574]]    Loss_Validation:  [[ 1411.38347549]]\n",
      "Loop  859 :    Loss_Train:  [[ 4964.44257162]]    Loss_Validation:  [[ 1411.33333238]]\n",
      "Loop  860 :    Loss_Train:  [[ 4964.12311652]]    Loss_Validation:  [[ 1411.28352529]]\n",
      "Loop  861 :    Loss_Train:  [[ 4963.80455701]]    Loss_Validation:  [[ 1411.23405232]]\n",
      "Loop  862 :    Loss_Train:  [[ 4963.48688969]]    Loss_Validation:  [[ 1411.18491157]]\n",
      "Loop  863 :    Loss_Train:  [[ 4963.17011118]]    Loss_Validation:  [[ 1411.13610116]]\n",
      "Loop  864 :    Loss_Train:  [[ 4962.85421811]]    Loss_Validation:  [[ 1411.08761921]]\n",
      "Loop  865 :    Loss_Train:  [[ 4962.53920713]]    Loss_Validation:  [[ 1411.03946387]]\n",
      "Loop  866 :    Loss_Train:  [[ 4962.22507491]]    Loss_Validation:  [[ 1410.99163329]]\n",
      "Loop  867 :    Loss_Train:  [[ 4961.91181813]]    Loss_Validation:  [[ 1410.94412562]]\n",
      "Loop  868 :    Loss_Train:  [[ 4961.5994335]]    Loss_Validation:  [[ 1410.89693904]]\n",
      "Loop  869 :    Loss_Train:  [[ 4961.28791774]]    Loss_Validation:  [[ 1410.85007173]]\n",
      "Loop  870 :    Loss_Train:  [[ 4960.97726758]]    Loss_Validation:  [[ 1410.80352189]]\n",
      "Loop  871 :    Loss_Train:  [[ 4960.66747978]]    Loss_Validation:  [[ 1410.75728773]]\n",
      "Loop  872 :    Loss_Train:  [[ 4960.35855112]]    Loss_Validation:  [[ 1410.71136745]]\n",
      "Loop  873 :    Loss_Train:  [[ 4960.05047837]]    Loss_Validation:  [[ 1410.66575929]]\n",
      "Loop  874 :    Loss_Train:  [[ 4959.74325834]]    Loss_Validation:  [[ 1410.62046149]]\n",
      "Loop  875 :    Loss_Train:  [[ 4959.43688787]]    Loss_Validation:  [[ 1410.57547229]]\n",
      "Loop  876 :    Loss_Train:  [[ 4959.13136377]]    Loss_Validation:  [[ 1410.53078995]]\n",
      "Loop  877 :    Loss_Train:  [[ 4958.82668292]]    Loss_Validation:  [[ 1410.48641273]]\n",
      "Loop  878 :    Loss_Train:  [[ 4958.52284217]]    Loss_Validation:  [[ 1410.44233893]]\n",
      "Loop  879 :    Loss_Train:  [[ 4958.21983842]]    Loss_Validation:  [[ 1410.39856683]]\n",
      "Loop  880 :    Loss_Train:  [[ 4957.91766857]]    Loss_Validation:  [[ 1410.35509472]]\n",
      "Loop  881 :    Loss_Train:  [[ 4957.61632954]]    Loss_Validation:  [[ 1410.31192092]]\n",
      "Loop  882 :    Loss_Train:  [[ 4957.31581826]]    Loss_Validation:  [[ 1410.26904375]]\n",
      "Loop  883 :    Loss_Train:  [[ 4957.01613168]]    Loss_Validation:  [[ 1410.22646153]]\n",
      "Loop  884 :    Loss_Train:  [[ 4956.71726678]]    Loss_Validation:  [[ 1410.18417262]]\n",
      "Loop  885 :    Loss_Train:  [[ 4956.41922052]]    Loss_Validation:  [[ 1410.14217535]]\n",
      "Loop  886 :    Loss_Train:  [[ 4956.12198991]]    Loss_Validation:  [[ 1410.10046809]]\n",
      "Loop  887 :    Loss_Train:  [[ 4955.82557196]]    Loss_Validation:  [[ 1410.0590492]]\n",
      "Loop  888 :    Loss_Train:  [[ 4955.5299637]]    Loss_Validation:  [[ 1410.01791707]]\n",
      "Loop  889 :    Loss_Train:  [[ 4955.23516216]]    Loss_Validation:  [[ 1409.97707008]]\n",
      "Loop  890 :    Loss_Train:  [[ 4954.94116441]]    Loss_Validation:  [[ 1409.93650664]]\n",
      "Loop  891 :    Loss_Train:  [[ 4954.64796752]]    Loss_Validation:  [[ 1409.89622514]]\n",
      "Loop  892 :    Loss_Train:  [[ 4954.35556858]]    Loss_Validation:  [[ 1409.85622401]]\n",
      "Loop  893 :    Loss_Train:  [[ 4954.06396468]]    Loss_Validation:  [[ 1409.81650167]]\n",
      "Loop  894 :    Loss_Train:  [[ 4953.77315295]]    Loss_Validation:  [[ 1409.77705656]]\n",
      "Loop  895 :    Loss_Train:  [[ 4953.48313051]]    Loss_Validation:  [[ 1409.73788713]]\n",
      "Loop  896 :    Loss_Train:  [[ 4953.1938945]]    Loss_Validation:  [[ 1409.69899182]]\n",
      "Loop  897 :    Loss_Train:  [[ 4952.9054421]]    Loss_Validation:  [[ 1409.6603691]]\n",
      "Loop  898 :    Loss_Train:  [[ 4952.61777047]]    Loss_Validation:  [[ 1409.62201744]]\n",
      "Loop  899 :    Loss_Train:  [[ 4952.3308768]]    Loss_Validation:  [[ 1409.58393533]]\n",
      "Loop  900 :    Loss_Train:  [[ 4952.04475829]]    Loss_Validation:  [[ 1409.54612125]]\n",
      "Loop  901 :    Loss_Train:  [[ 4951.75941215]]    Loss_Validation:  [[ 1409.50857371]]\n",
      "Loop  902 :    Loss_Train:  [[ 4951.47483563]]    Loss_Validation:  [[ 1409.4712912]]\n",
      "Loop  903 :    Loss_Train:  [[ 4951.19102595]]    Loss_Validation:  [[ 1409.43427226]]\n",
      "Loop  904 :    Loss_Train:  [[ 4950.90798037]]    Loss_Validation:  [[ 1409.39751539]]\n",
      "Loop  905 :    Loss_Train:  [[ 4950.62569618]]    Loss_Validation:  [[ 1409.36101914]]\n",
      "Loop  906 :    Loss_Train:  [[ 4950.34417064]]    Loss_Validation:  [[ 1409.32478206]]\n",
      "Loop  907 :    Loss_Train:  [[ 4950.06340106]]    Loss_Validation:  [[ 1409.28880268]]\n",
      "Loop  908 :    Loss_Train:  [[ 4949.78338475]]    Loss_Validation:  [[ 1409.25307957]]\n",
      "Loop  909 :    Loss_Train:  [[ 4949.50411902]]    Loss_Validation:  [[ 1409.2176113]]\n",
      "Loop  910 :    Loss_Train:  [[ 4949.22560123]]    Loss_Validation:  [[ 1409.18239645]]\n",
      "Loop  911 :    Loss_Train:  [[ 4948.94782871]]    Loss_Validation:  [[ 1409.14743359]]\n",
      "Loop  912 :    Loss_Train:  [[ 4948.67079883]]    Loss_Validation:  [[ 1409.11272133]]\n",
      "Loop  913 :    Loss_Train:  [[ 4948.39450896]]    Loss_Validation:  [[ 1409.07825826]]\n",
      "Loop  914 :    Loss_Train:  [[ 4948.1189565]]    Loss_Validation:  [[ 1409.04404299]]\n",
      "Loop  915 :    Loss_Train:  [[ 4947.84413884]]    Loss_Validation:  [[ 1409.01007415]]\n",
      "Loop  916 :    Loss_Train:  [[ 4947.5700534]]    Loss_Validation:  [[ 1408.97635035]]\n",
      "Loop  917 :    Loss_Train:  [[ 4947.2966976]]    Loss_Validation:  [[ 1408.94287022]]\n",
      "Loop  918 :    Loss_Train:  [[ 4947.02406889]]    Loss_Validation:  [[ 1408.90963242]]\n",
      "Loop  919 :    Loss_Train:  [[ 4946.75216471]]    Loss_Validation:  [[ 1408.87663559]]\n",
      "Loop  920 :    Loss_Train:  [[ 4946.48098252]]    Loss_Validation:  [[ 1408.84387839]]\n",
      "Loop  921 :    Loss_Train:  [[ 4946.2105198]]    Loss_Validation:  [[ 1408.81135948]]\n",
      "Loop  922 :    Loss_Train:  [[ 4945.94077404]]    Loss_Validation:  [[ 1408.77907754]]\n",
      "Loop  923 :    Loss_Train:  [[ 4945.67174274]]    Loss_Validation:  [[ 1408.74703124]]\n",
      "Loop  924 :    Loss_Train:  [[ 4945.40342341]]    Loss_Validation:  [[ 1408.71521928]]\n",
      "Loop  925 :    Loss_Train:  [[ 4945.13581357]]    Loss_Validation:  [[ 1408.68364034]]\n",
      "Loop  926 :    Loss_Train:  [[ 4944.86891076]]    Loss_Validation:  [[ 1408.65229314]]\n",
      "Loop  927 :    Loss_Train:  [[ 4944.60271252]]    Loss_Validation:  [[ 1408.62117638]]\n",
      "Loop  928 :    Loss_Train:  [[ 4944.33721641]]    Loss_Validation:  [[ 1408.59028879]]\n",
      "Loop  929 :    Loss_Train:  [[ 4944.07242001]]    Loss_Validation:  [[ 1408.55962908]]\n",
      "Loop  930 :    Loss_Train:  [[ 4943.80832089]]    Loss_Validation:  [[ 1408.52919599]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  931 :    Loss_Train:  [[ 4943.54491665]]    Loss_Validation:  [[ 1408.49898826]]\n",
      "Loop  932 :    Loss_Train:  [[ 4943.28220489]]    Loss_Validation:  [[ 1408.46900464]]\n",
      "Loop  933 :    Loss_Train:  [[ 4943.02018323]]    Loss_Validation:  [[ 1408.43924389]]\n",
      "Loop  934 :    Loss_Train:  [[ 4942.7588493]]    Loss_Validation:  [[ 1408.40970476]]\n",
      "Loop  935 :    Loss_Train:  [[ 4942.49820072]]    Loss_Validation:  [[ 1408.38038603]]\n",
      "Loop  936 :    Loss_Train:  [[ 4942.23823516]]    Loss_Validation:  [[ 1408.35128646]]\n",
      "Loop  937 :    Loss_Train:  [[ 4941.97895027]]    Loss_Validation:  [[ 1408.32240485]]\n",
      "Loop  938 :    Loss_Train:  [[ 4941.72034372]]    Loss_Validation:  [[ 1408.29373998]]\n",
      "Loop  939 :    Loss_Train:  [[ 4941.4624132]]    Loss_Validation:  [[ 1408.26529066]]\n",
      "Loop  940 :    Loss_Train:  [[ 4941.20515639]]    Loss_Validation:  [[ 1408.23705568]]\n",
      "Loop  941 :    Loss_Train:  [[ 4940.94857101]]    Loss_Validation:  [[ 1408.20903386]]\n",
      "Loop  942 :    Loss_Train:  [[ 4940.69265476]]    Loss_Validation:  [[ 1408.18122401]]\n",
      "Loop  943 :    Loss_Train:  [[ 4940.43740537]]    Loss_Validation:  [[ 1408.15362496]]\n",
      "Loop  944 :    Loss_Train:  [[ 4940.18282058]]    Loss_Validation:  [[ 1408.12623554]]\n",
      "Loop  945 :    Loss_Train:  [[ 4939.92889813]]    Loss_Validation:  [[ 1408.09905459]]\n",
      "Loop  946 :    Loss_Train:  [[ 4939.67563578]]    Loss_Validation:  [[ 1408.07208095]]\n",
      "Loop  947 :    Loss_Train:  [[ 4939.42303129]]    Loss_Validation:  [[ 1408.04531347]]\n",
      "Loop  948 :    Loss_Train:  [[ 4939.17108244]]    Loss_Validation:  [[ 1408.01875102]]\n",
      "Loop  949 :    Loss_Train:  [[ 4938.91978702]]    Loss_Validation:  [[ 1407.99239245]]\n",
      "Loop  950 :    Loss_Train:  [[ 4938.66914283]]    Loss_Validation:  [[ 1407.96623664]]\n",
      "Loop  951 :    Loss_Train:  [[ 4938.41914768]]    Loss_Validation:  [[ 1407.94028246]]\n",
      "Loop  952 :    Loss_Train:  [[ 4938.16979937]]    Loss_Validation:  [[ 1407.9145288]]\n",
      "Loop  953 :    Loss_Train:  [[ 4937.92109574]]    Loss_Validation:  [[ 1407.88897455]]\n",
      "Loop  954 :    Loss_Train:  [[ 4937.67303463]]    Loss_Validation:  [[ 1407.8636186]]\n",
      "Loop  955 :    Loss_Train:  [[ 4937.42561388]]    Loss_Validation:  [[ 1407.83845986]]\n",
      "Loop  956 :    Loss_Train:  [[ 4937.17883135]]    Loss_Validation:  [[ 1407.81349724]]\n",
      "Loop  957 :    Loss_Train:  [[ 4936.9326849]]    Loss_Validation:  [[ 1407.78872964]]\n",
      "Loop  958 :    Loss_Train:  [[ 4936.68717242]]    Loss_Validation:  [[ 1407.764156]]\n",
      "Loop  959 :    Loss_Train:  [[ 4936.44229179]]    Loss_Validation:  [[ 1407.73977524]]\n",
      "Loop  960 :    Loss_Train:  [[ 4936.1980409]]    Loss_Validation:  [[ 1407.71558629]]\n",
      "Loop  961 :    Loss_Train:  [[ 4935.95441767]]    Loss_Validation:  [[ 1407.69158809]]\n",
      "Loop  962 :    Loss_Train:  [[ 4935.71141999]]    Loss_Validation:  [[ 1407.66777959]]\n",
      "Loop  963 :    Loss_Train:  [[ 4935.46904581]]    Loss_Validation:  [[ 1407.64415974]]\n",
      "Loop  964 :    Loss_Train:  [[ 4935.22729304]]    Loss_Validation:  [[ 1407.62072749]]\n",
      "Loop  965 :    Loss_Train:  [[ 4934.98615964]]    Loss_Validation:  [[ 1407.59748182]]\n",
      "Loop  966 :    Loss_Train:  [[ 4934.74564355]]    Loss_Validation:  [[ 1407.57442168]]\n",
      "Loop  967 :    Loss_Train:  [[ 4934.50574274]]    Loss_Validation:  [[ 1407.55154606]]\n",
      "Loop  968 :    Loss_Train:  [[ 4934.26645518]]    Loss_Validation:  [[ 1407.52885393]]\n",
      "Loop  969 :    Loss_Train:  [[ 4934.02777884]]    Loss_Validation:  [[ 1407.50634429]]\n",
      "Loop  970 :    Loss_Train:  [[ 4933.78971172]]    Loss_Validation:  [[ 1407.48401612]]\n",
      "Loop  971 :    Loss_Train:  [[ 4933.5522518]]    Loss_Validation:  [[ 1407.46186842]]\n",
      "Loop  972 :    Loss_Train:  [[ 4933.3153971]]    Loss_Validation:  [[ 1407.43990019]]\n",
      "Loop  973 :    Loss_Train:  [[ 4933.07914563]]    Loss_Validation:  [[ 1407.41811045]]\n",
      "Loop  974 :    Loss_Train:  [[ 4932.84349542]]    Loss_Validation:  [[ 1407.39649822]]\n",
      "Loop  975 :    Loss_Train:  [[ 4932.60844449]]    Loss_Validation:  [[ 1407.3750625]]\n",
      "Loop  976 :    Loss_Train:  [[ 4932.37399089]]    Loss_Validation:  [[ 1407.35380232]]\n",
      "Loop  977 :    Loss_Train:  [[ 4932.14013267]]    Loss_Validation:  [[ 1407.33271673]]\n",
      "Loop  978 :    Loss_Train:  [[ 4931.90686788]]    Loss_Validation:  [[ 1407.31180474]]\n",
      "Loop  979 :    Loss_Train:  [[ 4931.67419459]]    Loss_Validation:  [[ 1407.29106542]]\n",
      "Loop  980 :    Loss_Train:  [[ 4931.44211088]]    Loss_Validation:  [[ 1407.2704978]]\n",
      "Loop  981 :    Loss_Train:  [[ 4931.21061483]]    Loss_Validation:  [[ 1407.25010093]]\n",
      "Loop  982 :    Loss_Train:  [[ 4930.97970453]]    Loss_Validation:  [[ 1407.22987388]]\n",
      "Loop  983 :    Loss_Train:  [[ 4930.74937809]]    Loss_Validation:  [[ 1407.20981571]]\n",
      "Loop  984 :    Loss_Train:  [[ 4930.5196336]]    Loss_Validation:  [[ 1407.18992549]]\n",
      "Loop  985 :    Loss_Train:  [[ 4930.2904692]]    Loss_Validation:  [[ 1407.17020229]]\n",
      "Loop  986 :    Loss_Train:  [[ 4930.061883]]    Loss_Validation:  [[ 1407.15064519]]\n",
      "Loop  987 :    Loss_Train:  [[ 4929.83387313]]    Loss_Validation:  [[ 1407.13125327]]\n",
      "Loop  988 :    Loss_Train:  [[ 4929.60643774]]    Loss_Validation:  [[ 1407.11202563]]\n",
      "Loop  989 :    Loss_Train:  [[ 4929.37957497]]    Loss_Validation:  [[ 1407.09296135]]\n",
      "Loop  990 :    Loss_Train:  [[ 4929.15328299]]    Loss_Validation:  [[ 1407.07405955]]\n",
      "Loop  991 :    Loss_Train:  [[ 4928.92755996]]    Loss_Validation:  [[ 1407.05531932]]\n",
      "Loop  992 :    Loss_Train:  [[ 4928.70240405]]    Loss_Validation:  [[ 1407.03673977]]\n",
      "Loop  993 :    Loss_Train:  [[ 4928.47781345]]    Loss_Validation:  [[ 1407.01832002]]\n",
      "Loop  994 :    Loss_Train:  [[ 4928.25378633]]    Loss_Validation:  [[ 1407.00005919]]\n",
      "Loop  995 :    Loss_Train:  [[ 4928.03032091]]    Loss_Validation:  [[ 1406.9819564]]\n",
      "Loop  996 :    Loss_Train:  [[ 4927.80741538]]    Loss_Validation:  [[ 1406.96401078]]\n",
      "Loop  997 :    Loss_Train:  [[ 4927.58506795]]    Loss_Validation:  [[ 1406.94622146]]\n",
      "Loop  998 :    Loss_Train:  [[ 4927.36327685]]    Loss_Validation:  [[ 1406.92858759]]\n",
      "Loop  999 :    Loss_Train:  [[ 4927.14204029]]    Loss_Validation:  [[ 1406.91110831]]\n",
      "Loop  1000 :    Loss_Train:  [[ 4926.92135653]]    Loss_Validation:  [[ 1406.89378276]]\n",
      "Loop  1001 :    Loss_Train:  [[ 4926.70122379]]    Loss_Validation:  [[ 1406.8766101]]\n",
      "Loop  1002 :    Loss_Train:  [[ 4926.48164033]]    Loss_Validation:  [[ 1406.85958949]]\n",
      "Loop  1003 :    Loss_Train:  [[ 4926.26260441]]    Loss_Validation:  [[ 1406.84272009]]\n",
      "Loop  1004 :    Loss_Train:  [[ 4926.04411429]]    Loss_Validation:  [[ 1406.82600107]]\n",
      "Loop  1005 :    Loss_Train:  [[ 4925.82616824]]    Loss_Validation:  [[ 1406.80943159]]\n",
      "Loop  1006 :    Loss_Train:  [[ 4925.60876454]]    Loss_Validation:  [[ 1406.79301085]]\n",
      "Loop  1007 :    Loss_Train:  [[ 4925.39190148]]    Loss_Validation:  [[ 1406.776738]]\n",
      "Loop  1008 :    Loss_Train:  [[ 4925.17557735]]    Loss_Validation:  [[ 1406.76061226]]\n",
      "Loop  1009 :    Loss_Train:  [[ 4924.95979045]]    Loss_Validation:  [[ 1406.74463279]]\n",
      "Loop  1010 :    Loss_Train:  [[ 4924.7445391]]    Loss_Validation:  [[ 1406.7287988]]\n",
      "Loop  1011 :    Loss_Train:  [[ 4924.52982159]]    Loss_Validation:  [[ 1406.71310949]]\n",
      "Loop  1012 :    Loss_Train:  [[ 4924.31563627]]    Loss_Validation:  [[ 1406.69756406]]\n",
      "Loop  1013 :    Loss_Train:  [[ 4924.10198146]]    Loss_Validation:  [[ 1406.68216171]]\n",
      "Loop  1014 :    Loss_Train:  [[ 4923.88885548]]    Loss_Validation:  [[ 1406.66690167]]\n",
      "Loop  1015 :    Loss_Train:  [[ 4923.67625669]]    Loss_Validation:  [[ 1406.65178314]]\n",
      "Loop  1016 :    Loss_Train:  [[ 4923.46418344]]    Loss_Validation:  [[ 1406.63680535]]\n",
      "Loop  1017 :    Loss_Train:  [[ 4923.25263408]]    Loss_Validation:  [[ 1406.62196752]]\n",
      "Loop  1018 :    Loss_Train:  [[ 4923.04160698]]    Loss_Validation:  [[ 1406.60726888]]\n",
      "Loop  1019 :    Loss_Train:  [[ 4922.83110051]]    Loss_Validation:  [[ 1406.59270866]]\n",
      "Loop  1020 :    Loss_Train:  [[ 4922.62111304]]    Loss_Validation:  [[ 1406.57828612]]\n",
      "Loop  1021 :    Loss_Train:  [[ 4922.41164296]]    Loss_Validation:  [[ 1406.56400047]]\n",
      "Loop  1022 :    Loss_Train:  [[ 4922.20268865]]    Loss_Validation:  [[ 1406.54985098]]\n",
      "Loop  1023 :    Loss_Train:  [[ 4921.99424853]]    Loss_Validation:  [[ 1406.53583689]]\n",
      "Loop  1024 :    Loss_Train:  [[ 4921.78632098]]    Loss_Validation:  [[ 1406.52195746]]\n",
      "Loop  1025 :    Loss_Train:  [[ 4921.57890442]]    Loss_Validation:  [[ 1406.50821194]]\n",
      "Loop  1026 :    Loss_Train:  [[ 4921.37199728]]    Loss_Validation:  [[ 1406.4945996]]\n",
      "Loop  1027 :    Loss_Train:  [[ 4921.16559796]]    Loss_Validation:  [[ 1406.4811197]]\n",
      "Loop  1028 :    Loss_Train:  [[ 4920.9597049]]    Loss_Validation:  [[ 1406.46777152]]\n",
      "Loop  1029 :    Loss_Train:  [[ 4920.75431654]]    Loss_Validation:  [[ 1406.45455434]]\n",
      "Loop  1030 :    Loss_Train:  [[ 4920.54943132]]    Loss_Validation:  [[ 1406.44146741]]\n",
      "Loop  1031 :    Loss_Train:  [[ 4920.34504769]]    Loss_Validation:  [[ 1406.42851005]]\n",
      "Loop  1032 :    Loss_Train:  [[ 4920.14116411]]    Loss_Validation:  [[ 1406.41568152]]\n",
      "Loop  1033 :    Loss_Train:  [[ 4919.93777903]]    Loss_Validation:  [[ 1406.40298111]]\n",
      "Loop  1034 :    Loss_Train:  [[ 4919.73489092]]    Loss_Validation:  [[ 1406.39040814]]\n",
      "Loop  1035 :    Loss_Train:  [[ 4919.53249826]]    Loss_Validation:  [[ 1406.37796188]]\n",
      "Loop  1036 :    Loss_Train:  [[ 4919.33059953]]    Loss_Validation:  [[ 1406.36564165]]\n",
      "Loop  1037 :    Loss_Train:  [[ 4919.12919322]]    Loss_Validation:  [[ 1406.35344674]]\n",
      "Loop  1038 :    Loss_Train:  [[ 4918.92827782]]    Loss_Validation:  [[ 1406.34137648]]\n",
      "Loop  1039 :    Loss_Train:  [[ 4918.72785182]]    Loss_Validation:  [[ 1406.32943017]]\n",
      "Loop  1040 :    Loss_Train:  [[ 4918.52791373]]    Loss_Validation:  [[ 1406.31760712]]\n",
      "Loop  1041 :    Loss_Train:  [[ 4918.32846206]]    Loss_Validation:  [[ 1406.30590667]]\n",
      "Loop  1042 :    Loss_Train:  [[ 4918.12949533]]    Loss_Validation:  [[ 1406.29432814]]\n",
      "Loop  1043 :    Loss_Train:  [[ 4917.93101207]]    Loss_Validation:  [[ 1406.28287084]]\n",
      "Loop  1044 :    Loss_Train:  [[ 4917.73301079]]    Loss_Validation:  [[ 1406.27153413]]\n",
      "Loop  1045 :    Loss_Train:  [[ 4917.53549004]]    Loss_Validation:  [[ 1406.26031732]]\n",
      "Loop  1046 :    Loss_Train:  [[ 4917.33844836]]    Loss_Validation:  [[ 1406.24921977]]\n",
      "Loop  1047 :    Loss_Train:  [[ 4917.14188428]]    Loss_Validation:  [[ 1406.2382408]]\n",
      "Loop  1048 :    Loss_Train:  [[ 4916.94579637]]    Loss_Validation:  [[ 1406.22737978]]\n",
      "Loop  1049 :    Loss_Train:  [[ 4916.75018318]]    Loss_Validation:  [[ 1406.21663605]]\n",
      "Loop  1050 :    Loss_Train:  [[ 4916.55504328]]    Loss_Validation:  [[ 1406.20600896]]\n",
      "Loop  1051 :    Loss_Train:  [[ 4916.36037523]]    Loss_Validation:  [[ 1406.19549787]]\n",
      "Loop  1052 :    Loss_Train:  [[ 4916.16617761]]    Loss_Validation:  [[ 1406.18510214]]\n",
      "Loop  1053 :    Loss_Train:  [[ 4915.972449]]    Loss_Validation:  [[ 1406.17482113]]\n",
      "Loop  1054 :    Loss_Train:  [[ 4915.77918798]]    Loss_Validation:  [[ 1406.16465422]]\n",
      "Loop  1055 :    Loss_Train:  [[ 4915.58639315]]    Loss_Validation:  [[ 1406.15460077]]\n",
      "Loop  1056 :    Loss_Train:  [[ 4915.39406311]]    Loss_Validation:  [[ 1406.14466015]]\n",
      "Loop  1057 :    Loss_Train:  [[ 4915.20219646]]    Loss_Validation:  [[ 1406.13483175]]\n",
      "Loop  1058 :    Loss_Train:  [[ 4915.0107918]]    Loss_Validation:  [[ 1406.12511495]]\n",
      "Loop  1059 :    Loss_Train:  [[ 4914.81984775]]    Loss_Validation:  [[ 1406.11550912]]\n",
      "Loop  1060 :    Loss_Train:  [[ 4914.62936293]]    Loss_Validation:  [[ 1406.10601366]]\n",
      "Loop  1061 :    Loss_Train:  [[ 4914.43933597]]    Loss_Validation:  [[ 1406.09662796]]\n",
      "Loop  1062 :    Loss_Train:  [[ 4914.24976549]]    Loss_Validation:  [[ 1406.08735141]]\n",
      "Loop  1063 :    Loss_Train:  [[ 4914.06065013]]    Loss_Validation:  [[ 1406.07818341]]\n",
      "Loop  1064 :    Loss_Train:  [[ 4913.87198853]]    Loss_Validation:  [[ 1406.06912337]]\n",
      "Loop  1065 :    Loss_Train:  [[ 4913.68377934]]    Loss_Validation:  [[ 1406.06017067]]\n",
      "Loop  1066 :    Loss_Train:  [[ 4913.49602121]]    Loss_Validation:  [[ 1406.05132474]]\n",
      "Loop  1067 :    Loss_Train:  [[ 4913.30871279]]    Loss_Validation:  [[ 1406.04258498]]\n",
      "Loop  1068 :    Loss_Train:  [[ 4913.12185275]]    Loss_Validation:  [[ 1406.03395081]]\n",
      "Loop  1069 :    Loss_Train:  [[ 4912.93543975]]    Loss_Validation:  [[ 1406.02542164]]\n",
      "Loop  1070 :    Loss_Train:  [[ 4912.74947247]]    Loss_Validation:  [[ 1406.01699689]]\n",
      "Loop  1071 :    Loss_Train:  [[ 4912.56394959]]    Loss_Validation:  [[ 1406.00867599]]\n",
      "Loop  1072 :    Loss_Train:  [[ 4912.37886978]]    Loss_Validation:  [[ 1406.00045836]]\n",
      "Loop  1073 :    Loss_Train:  [[ 4912.19423173]]    Loss_Validation:  [[ 1405.99234343]]\n",
      "Loop  1074 :    Loss_Train:  [[ 4912.01003414]]    Loss_Validation:  [[ 1405.98433064]]\n",
      "Loop  1075 :    Loss_Train:  [[ 4911.8262757]]    Loss_Validation:  [[ 1405.97641941]]\n",
      "Loop  1076 :    Loss_Train:  [[ 4911.64295512]]    Loss_Validation:  [[ 1405.96860919]]\n",
      "Loop  1077 :    Loss_Train:  [[ 4911.46007111]]    Loss_Validation:  [[ 1405.96089942]]\n",
      "Loop  1078 :    Loss_Train:  [[ 4911.27762237]]    Loss_Validation:  [[ 1405.95328954]]\n",
      "Loop  1079 :    Loss_Train:  [[ 4911.09560763]]    Loss_Validation:  [[ 1405.945779]]\n",
      "Loop  1080 :    Loss_Train:  [[ 4910.91402561]]    Loss_Validation:  [[ 1405.93836725]]\n",
      "Loop  1081 :    Loss_Train:  [[ 4910.73287503]]    Loss_Validation:  [[ 1405.93105374]]\n",
      "Loop  1082 :    Loss_Train:  [[ 4910.55215463]]    Loss_Validation:  [[ 1405.92383794]]\n",
      "Loop  1083 :    Loss_Train:  [[ 4910.37186314]]    Loss_Validation:  [[ 1405.91671929]]\n",
      "Loop  1084 :    Loss_Train:  [[ 4910.19199931]]    Loss_Validation:  [[ 1405.90969727]]\n",
      "Loop  1085 :    Loss_Train:  [[ 4910.01256188]]    Loss_Validation:  [[ 1405.90277133]]\n",
      "Loop  1086 :    Loss_Train:  [[ 4909.83354961]]    Loss_Validation:  [[ 1405.89594094]]\n",
      "Loop  1087 :    Loss_Train:  [[ 4909.65496125]]    Loss_Validation:  [[ 1405.88920558]]\n",
      "Loop  1088 :    Loss_Train:  [[ 4909.47679556]]    Loss_Validation:  [[ 1405.88256471]]\n",
      "Loop  1089 :    Loss_Train:  [[ 4909.29905131]]    Loss_Validation:  [[ 1405.87601782]]\n",
      "Loop  1090 :    Loss_Train:  [[ 4909.12172726]]    Loss_Validation:  [[ 1405.86956438]]\n",
      "Loop  1091 :    Loss_Train:  [[ 4908.9448222]]    Loss_Validation:  [[ 1405.86320388]]\n",
      "Loop  1092 :    Loss_Train:  [[ 4908.76833491]]    Loss_Validation:  [[ 1405.8569358]]\n",
      "Loop  1093 :    Loss_Train:  [[ 4908.59226415]]    Loss_Validation:  [[ 1405.85075962]]\n",
      "Loop  1094 :    Loss_Train:  [[ 4908.41660874]]    Loss_Validation:  [[ 1405.84467484]]\n",
      "Loop  1095 :    Loss_Train:  [[ 4908.24136745]]    Loss_Validation:  [[ 1405.83868095]]\n",
      "Loop  1096 :    Loss_Train:  [[ 4908.06653909]]    Loss_Validation:  [[ 1405.83277745]]\n",
      "Loop  1097 :    Loss_Train:  [[ 4907.89212246]]    Loss_Validation:  [[ 1405.82696383]]\n",
      "Loop  1098 :    Loss_Train:  [[ 4907.71811637]]    Loss_Validation:  [[ 1405.82123959]]\n",
      "Loop  1099 :    Loss_Train:  [[ 4907.54451962]]    Loss_Validation:  [[ 1405.81560424]]\n",
      "Loop  1100 :    Loss_Train:  [[ 4907.37133104]]    Loss_Validation:  [[ 1405.81005729]]\n",
      "Loop  1101 :    Loss_Train:  [[ 4907.19854944]]    Loss_Validation:  [[ 1405.80459824]]\n",
      "Loop  1102 :    Loss_Train:  [[ 4907.02617365]]    Loss_Validation:  [[ 1405.7992266]]\n",
      "Loop  1103 :    Loss_Train:  [[ 4906.8542025]]    Loss_Validation:  [[ 1405.79394189]]\n",
      "Loop  1104 :    Loss_Train:  [[ 4906.68263482]]    Loss_Validation:  [[ 1405.78874363]]\n",
      "Loop  1105 :    Loss_Train:  [[ 4906.51146945]]    Loss_Validation:  [[ 1405.78363133]]\n",
      "Loop  1106 :    Loss_Train:  [[ 4906.34070522]]    Loss_Validation:  [[ 1405.77860451]]\n",
      "Loop  1107 :    Loss_Train:  [[ 4906.170341]]    Loss_Validation:  [[ 1405.77366271]]\n",
      "Loop  1108 :    Loss_Train:  [[ 4906.00037562]]    Loss_Validation:  [[ 1405.76880544]]\n",
      "Loop  1109 :    Loss_Train:  [[ 4905.83080795]]    Loss_Validation:  [[ 1405.76403224]]\n",
      "Loop  1110 :    Loss_Train:  [[ 4905.66163684]]    Loss_Validation:  [[ 1405.75934264]]\n",
      "Loop  1111 :    Loss_Train:  [[ 4905.49286115]]    Loss_Validation:  [[ 1405.75473617]]\n",
      "Loop  1112 :    Loss_Train:  [[ 4905.32447975]]    Loss_Validation:  [[ 1405.75021237]]\n",
      "Loop  1113 :    Loss_Train:  [[ 4905.15649152]]    Loss_Validation:  [[ 1405.74577078]]\n",
      "Loop  1114 :    Loss_Train:  [[ 4904.98889533]]    Loss_Validation:  [[ 1405.74141094]]\n",
      "Loop  1115 :    Loss_Train:  [[ 4904.82169006]]    Loss_Validation:  [[ 1405.73713239]]\n",
      "Loop  1116 :    Loss_Train:  [[ 4904.6548746]]    Loss_Validation:  [[ 1405.73293468]]\n",
      "Loop  1117 :    Loss_Train:  [[ 4904.48844782]]    Loss_Validation:  [[ 1405.72881736]]\n",
      "Loop  1118 :    Loss_Train:  [[ 4904.32240863]]    Loss_Validation:  [[ 1405.72477999]]\n",
      "Loop  1119 :    Loss_Train:  [[ 4904.15675593]]    Loss_Validation:  [[ 1405.7208221]]\n",
      "Loop  1120 :    Loss_Train:  [[ 4903.9914886]]    Loss_Validation:  [[ 1405.71694327]]\n",
      "Loop  1121 :    Loss_Train:  [[ 4903.82660556]]    Loss_Validation:  [[ 1405.71314305]]\n",
      "Loop  1122 :    Loss_Train:  [[ 4903.66210572]]    Loss_Validation:  [[ 1405.709421]]\n",
      "Loop  1123 :    Loss_Train:  [[ 4903.49798798]]    Loss_Validation:  [[ 1405.70577668]]\n",
      "Loop  1124 :    Loss_Train:  [[ 4903.33425126]]    Loss_Validation:  [[ 1405.70220965]]\n",
      "Loop  1125 :    Loss_Train:  [[ 4903.17089449]]    Loss_Validation:  [[ 1405.6987195]]\n",
      "Loop  1126 :    Loss_Train:  [[ 4903.00791659]]    Loss_Validation:  [[ 1405.69530578]]\n",
      "Loop  1127 :    Loss_Train:  [[ 4902.84531648]]    Loss_Validation:  [[ 1405.69196806]]\n",
      "Loop  1128 :    Loss_Train:  [[ 4902.6830931]]    Loss_Validation:  [[ 1405.68870593]]\n",
      "Loop  1129 :    Loss_Train:  [[ 4902.52124538]]    Loss_Validation:  [[ 1405.68551896]]\n",
      "Loop  1130 :    Loss_Train:  [[ 4902.35977226]]    Loss_Validation:  [[ 1405.68240673]]\n",
      "Loop  1131 :    Loss_Train:  [[ 4902.19867269]]    Loss_Validation:  [[ 1405.67936881]]\n",
      "Loop  1132 :    Loss_Train:  [[ 4902.03794562]]    Loss_Validation:  [[ 1405.6764048]]\n",
      "Loop  1133 :    Loss_Train:  [[ 4901.87758999]]    Loss_Validation:  [[ 1405.67351428]]\n",
      "Loop  1134 :    Loss_Train:  [[ 4901.71760476]]    Loss_Validation:  [[ 1405.67069683]]\n",
      "Loop  1135 :    Loss_Train:  [[ 4901.55798889]]    Loss_Validation:  [[ 1405.66795204]]\n",
      "Loop  1136 :    Loss_Train:  [[ 4901.39874134]]    Loss_Validation:  [[ 1405.66527952]]\n",
      "Loop  1137 :    Loss_Train:  [[ 4901.23986108]]    Loss_Validation:  [[ 1405.66267885]]\n",
      "Loop  1138 :    Loss_Train:  [[ 4901.08134707]]    Loss_Validation:  [[ 1405.66014962]]\n",
      "Loop  1139 :    Loss_Train:  [[ 4900.92319829]]    Loss_Validation:  [[ 1405.65769144]]\n",
      "Loop  1140 :    Loss_Train:  [[ 4900.76541373]]    Loss_Validation:  [[ 1405.65530391]]\n",
      "Loop  1141 :    Loss_Train:  [[ 4900.60799235]]    Loss_Validation:  [[ 1405.65298663]]\n",
      "Loop  1142 :    Loss_Train:  [[ 4900.45093314]]    Loss_Validation:  [[ 1405.6507392]]\n",
      "Loop  1143 :    Loss_Train:  [[ 4900.2942351]]    Loss_Validation:  [[ 1405.64856123]]\n",
      "Loop  1144 :    Loss_Train:  [[ 4900.1378972]]    Loss_Validation:  [[ 1405.64645234]]\n",
      "Loop  1145 :    Loss_Train:  [[ 4899.98191846]]    Loss_Validation:  [[ 1405.64441212]]\n",
      "Loop  1146 :    Loss_Train:  [[ 4899.82629786]]    Loss_Validation:  [[ 1405.6424402]]\n",
      "Loop  1147 :    Loss_Train:  [[ 4899.67103442]]    Loss_Validation:  [[ 1405.64053619]]\n",
      "Loop  1148 :    Loss_Train:  [[ 4899.51612712]]    Loss_Validation:  [[ 1405.63869971]]\n",
      "Loop  1149 :    Loss_Train:  [[ 4899.361575]]    Loss_Validation:  [[ 1405.63693037]]\n",
      "Loop  1150 :    Loss_Train:  [[ 4899.20737705]]    Loss_Validation:  [[ 1405.6352278]]\n",
      "Loop  1151 :    Loss_Train:  [[ 4899.05353229]]    Loss_Validation:  [[ 1405.63359161]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  1152 :    Loss_Train:  [[ 4898.90003975]]    Loss_Validation:  [[ 1405.63202145]]\n",
      "Loop  1153 :    Loss_Train:  [[ 4898.74689845]]    Loss_Validation:  [[ 1405.63051692]]\n",
      "Loop  1154 :    Loss_Train:  [[ 4898.59410741]]    Loss_Validation:  [[ 1405.62907766]]\n",
      "Loop  1155 :    Loss_Train:  [[ 4898.44166567]]    Loss_Validation:  [[ 1405.62770331]]\n",
      "Loop  1156 :    Loss_Train:  [[ 4898.28957225]]    Loss_Validation:  [[ 1405.62639348]]\n",
      "Loop  1157 :    Loss_Train:  [[ 4898.13782621]]    Loss_Validation:  [[ 1405.62514783]]\n",
      "Loop  1158 :    Loss_Train:  [[ 4897.98642656]]    Loss_Validation:  [[ 1405.62396598]]\n",
      "Loop  1159 :    Loss_Train:  [[ 4897.83537237]]    Loss_Validation:  [[ 1405.62284758]]\n",
      "Loop  1160 :    Loss_Train:  [[ 4897.68466267]]    Loss_Validation:  [[ 1405.62179226]]\n",
      "Loop  1161 :    Loss_Train:  [[ 4897.53429653]]    Loss_Validation:  [[ 1405.62079967]]\n",
      "Loop  1162 :    Loss_Train:  [[ 4897.38427298]]    Loss_Validation:  [[ 1405.61986944]]\n",
      "Loop  1163 :    Loss_Train:  [[ 4897.23459109]]    Loss_Validation:  [[ 1405.61900124]]\n",
      "Loop  1164 :    Loss_Train:  [[ 4897.08524992]]    Loss_Validation:  [[ 1405.6181947]]\n",
      "Loop  1165 :    Loss_Train:  [[ 4896.93624853]]    Loss_Validation:  [[ 1405.61744947]]\n",
      "Loop  1166 :    Loss_Train:  [[ 4896.787586]]    Loss_Validation:  [[ 1405.61676521]]\n",
      "Loop  1167 :    Loss_Train:  [[ 4896.63926138]]    Loss_Validation:  [[ 1405.61614157]]\n",
      "Loop  1168 :    Loss_Train:  [[ 4896.49127376]]    Loss_Validation:  [[ 1405.6155782]]\n",
      "Loop  1169 :    Loss_Train:  [[ 4896.3436222]]    Loss_Validation:  [[ 1405.61507476]]\n",
      "Loop  1170 :    Loss_Train:  [[ 4896.1963058]]    Loss_Validation:  [[ 1405.61463091]]\n",
      "Loop  1171 :    Loss_Train:  [[ 4896.04932363]]    Loss_Validation:  [[ 1405.61424632]]\n",
      "Loop  1172 :    Loss_Train:  [[ 4895.90267478]]    Loss_Validation:  [[ 1405.61392064]]\n",
      "Loop  1173 :    Loss_Train:  [[ 4895.75635833]]    Loss_Validation:  [[ 1405.61365353]]\n",
      "Loop  1174 :    Loss_Train:  [[ 4895.61037339]]    Loss_Validation:  [[ 1405.61344467]]\n",
      "Loop  1175 :    Loss_Train:  [[ 4895.46471904]]    Loss_Validation:  [[ 1405.61329371]]\n",
      "Loop  1176 :    Loss_Train:  [[ 4895.31939439]]    Loss_Validation:  [[ 1405.61320034]]\n",
      "Loop  1177 :    Loss_Train:  [[ 4895.17439854]]    Loss_Validation:  [[ 1405.61316421]]\n",
      "Loop  1178 :    Loss_Train:  [[ 4895.02973058]]    Loss_Validation:  [[ 1405.61318501]]\n",
      "Loop  1179 :    Loss_Train:  [[ 4894.88538964]]    Loss_Validation:  [[ 1405.61326241]]\n",
      "Loop  1180 :    Loss_Train:  [[ 4894.74137482]]    Loss_Validation:  [[ 1405.61339608]]\n",
      "Loop  1181 :    Loss_Train:  [[ 4894.59768524]]    Loss_Validation:  [[ 1405.6135857]]\n",
      "Loop  1182 :    Loss_Train:  [[ 4894.45432]]    Loss_Validation:  [[ 1405.61383096]]\n",
      "Loop  1183 :    Loss_Train:  [[ 4894.31127824]]    Loss_Validation:  [[ 1405.61413152]]\n",
      "Loop  1184 :    Loss_Train:  [[ 4894.16855908]]    Loss_Validation:  [[ 1405.61448708]]\n",
      "Loop  1185 :    Loss_Train:  [[ 4894.02616163]]    Loss_Validation:  [[ 1405.61489732]]\n",
      "Loop  1186 :    Loss_Train:  [[ 4893.88408504]]    Loss_Validation:  [[ 1405.61536193]]\n",
      "Loop  1187 :    Loss_Train:  [[ 4893.74232843]]    Loss_Validation:  [[ 1405.61588058]]\n",
      "Loop  1188 :    Loss_Train:  [[ 4893.60089094]]    Loss_Validation:  [[ 1405.61645298]]\n",
      "Loop  1189 :    Loss_Train:  [[ 4893.45977171]]    Loss_Validation:  [[ 1405.61707882]]\n",
      "Loop  1190 :    Loss_Train:  [[ 4893.31896987]]    Loss_Validation:  [[ 1405.61775778]]\n",
      "Loop  1191 :    Loss_Train:  [[ 4893.17848458]]    Loss_Validation:  [[ 1405.61848955]]\n",
      "Loop  1192 :    Loss_Train:  [[ 4893.03831497]]    Loss_Validation:  [[ 1405.61927385]]\n",
      "Loop  1193 :    Loss_Train:  [[ 4892.8984602]]    Loss_Validation:  [[ 1405.62011036]]\n",
      "Loop  1194 :    Loss_Train:  [[ 4892.75891943]]    Loss_Validation:  [[ 1405.62099877]]\n",
      "Loop  1195 :    Loss_Train:  [[ 4892.61969179]]    Loss_Validation:  [[ 1405.6219388]]\n",
      "Loop  1196 :    Loss_Train:  [[ 4892.48077646]]    Loss_Validation:  [[ 1405.62293015]]\n",
      "Loop  1197 :    Loss_Train:  [[ 4892.3421726]]    Loss_Validation:  [[ 1405.62397251]]\n",
      "Loop  1198 :    Loss_Train:  [[ 4892.20387936]]    Loss_Validation:  [[ 1405.6250656]]\n",
      "Loop  1199 :    Loss_Train:  [[ 4892.06589592]]    Loss_Validation:  [[ 1405.62620911]]\n",
      "Loop  1200 :    Loss_Train:  [[ 4891.92822145]]    Loss_Validation:  [[ 1405.62740276]]\n",
      "Loop  1201 :    Loss_Train:  [[ 4891.79085511]]    Loss_Validation:  [[ 1405.62864626]]\n",
      "Loop  1202 :    Loss_Train:  [[ 4891.65379609]]    Loss_Validation:  [[ 1405.62993932]]\n",
      "Loop  1203 :    Loss_Train:  [[ 4891.51704356]]    Loss_Validation:  [[ 1405.63128164]]\n",
      "Loop  1204 :    Loss_Train:  [[ 4891.3805967]]    Loss_Validation:  [[ 1405.63267296]]\n",
      "Loop  1205 :    Loss_Train:  [[ 4891.24445469]]    Loss_Validation:  [[ 1405.63411297]]\n",
      "Loop  1206 :    Loss_Train:  [[ 4891.10861673]]    Loss_Validation:  [[ 1405.6356014]]\n",
      "Loop  1207 :    Loss_Train:  [[ 4890.97308199]]    Loss_Validation:  [[ 1405.63713796]]\n",
      "Loop  1208 :    Loss_Train:  [[ 4890.83784968]]    Loss_Validation:  [[ 1405.63872238]]\n",
      "Loop  1209 :    Loss_Train:  [[ 4890.70291898]]    Loss_Validation:  [[ 1405.64035438]]\n",
      "Loop  1210 :    Loss_Train:  [[ 4890.56828909]]    Loss_Validation:  [[ 1405.64203368]]\n",
      "Loop  1211 :    Loss_Train:  [[ 4890.43395922]]    Loss_Validation:  [[ 1405.64376]]\n",
      "Loop  1212 :    Loss_Train:  [[ 4890.29992856]]    Loss_Validation:  [[ 1405.64553307]]\n",
      "Loop  1213 :    Loss_Train:  [[ 4890.16619632]]    Loss_Validation:  [[ 1405.64735262]]\n",
      "Loop  1214 :    Loss_Train:  [[ 4890.03276171]]    Loss_Validation:  [[ 1405.64921838]]\n",
      "Loop  1215 :    Loss_Train:  [[ 4889.89962393]]    Loss_Validation:  [[ 1405.65113007]]\n",
      "Loop  1216 :    Loss_Train:  [[ 4889.76678221]]    Loss_Validation:  [[ 1405.65308743]]\n",
      "Loop  1217 :    Loss_Train:  [[ 4889.63423575]]    Loss_Validation:  [[ 1405.65509018]]\n",
      "Loop  1218 :    Loss_Train:  [[ 4889.50198377]]    Loss_Validation:  [[ 1405.65713807]]\n",
      "Loop  1219 :    Loss_Train:  [[ 4889.3700255]]    Loss_Validation:  [[ 1405.65923083]]\n",
      "Loop  1220 :    Loss_Train:  [[ 4889.23836016]]    Loss_Validation:  [[ 1405.6613682]]\n",
      "Loop  1221 :    Loss_Train:  [[ 4889.10698697]]    Loss_Validation:  [[ 1405.66354991]]\n",
      "Loop  1222 :    Loss_Train:  [[ 4888.97590516]]    Loss_Validation:  [[ 1405.6657757]]\n",
      "Loop  1223 :    Loss_Train:  [[ 4888.84511396]]    Loss_Validation:  [[ 1405.66804532]]\n",
      "Loop  1224 :    Loss_Train:  [[ 4888.71461261]]    Loss_Validation:  [[ 1405.6703585]]\n",
      "Loop  1225 :    Loss_Train:  [[ 4888.58440034]]    Loss_Validation:  [[ 1405.67271499]]\n",
      "Loop  1226 :    Loss_Train:  [[ 4888.45447639]]    Loss_Validation:  [[ 1405.67511454]]\n",
      "Loop  1227 :    Loss_Train:  [[ 4888.32484001]]    Loss_Validation:  [[ 1405.67755689]]\n",
      "Loop  1228 :    Loss_Train:  [[ 4888.19549042]]    Loss_Validation:  [[ 1405.68004179]]\n",
      "Loop  1229 :    Loss_Train:  [[ 4888.06642689]]    Loss_Validation:  [[ 1405.68256899]]\n",
      "Loop  1230 :    Loss_Train:  [[ 4887.93764866]]    Loss_Validation:  [[ 1405.68513823]]\n",
      "Loop  1231 :    Loss_Train:  [[ 4887.80915497]]    Loss_Validation:  [[ 1405.68774927]]\n",
      "Loop  1232 :    Loss_Train:  [[ 4887.68094509]]    Loss_Validation:  [[ 1405.69040186]]\n",
      "Loop  1233 :    Loss_Train:  [[ 4887.55301827]]    Loss_Validation:  [[ 1405.69309576]]\n",
      "Loop  1234 :    Loss_Train:  [[ 4887.42537376]]    Loss_Validation:  [[ 1405.69583072]]\n",
      "Loop  1235 :    Loss_Train:  [[ 4887.29801083]]    Loss_Validation:  [[ 1405.6986065]]\n",
      "Loop  1236 :    Loss_Train:  [[ 4887.17092875]]    Loss_Validation:  [[ 1405.70142285]]\n",
      "Loop  1237 :    Loss_Train:  [[ 4887.04412676]]    Loss_Validation:  [[ 1405.70427953]]\n",
      "Loop  1238 :    Loss_Train:  [[ 4886.91760415]]    Loss_Validation:  [[ 1405.70717631]]\n",
      "Loop  1239 :    Loss_Train:  [[ 4886.79136019]]    Loss_Validation:  [[ 1405.71011294]]\n",
      "Loop  1240 :    Loss_Train:  [[ 4886.66539414]]    Loss_Validation:  [[ 1405.71308919]]\n",
      "Loop  1241 :    Loss_Train:  [[ 4886.53970528]]    Loss_Validation:  [[ 1405.71610482]]\n",
      "Loop  1242 :    Loss_Train:  [[ 4886.41429289]]    Loss_Validation:  [[ 1405.7191596]]\n",
      "Loop  1243 :    Loss_Train:  [[ 4886.28915625]]    Loss_Validation:  [[ 1405.72225329]]\n",
      "Loop  1244 :    Loss_Train:  [[ 4886.16429463]]    Loss_Validation:  [[ 1405.72538566]]\n",
      "Loop  1245 :    Loss_Train:  [[ 4886.03970733]]    Loss_Validation:  [[ 1405.72855648]]\n",
      "Loop  1246 :    Loss_Train:  [[ 4885.91539363]]    Loss_Validation:  [[ 1405.73176552]]\n",
      "Loop  1247 :    Loss_Train:  [[ 4885.79135282]]    Loss_Validation:  [[ 1405.73501255]]\n",
      "Loop  1248 :    Loss_Train:  [[ 4885.66758419]]    Loss_Validation:  [[ 1405.73829734]]\n",
      "Loop  1249 :    Loss_Train:  [[ 4885.54408703]]    Loss_Validation:  [[ 1405.74161966]]\n",
      "Loop  1250 :    Loss_Train:  [[ 4885.42086065]]    Loss_Validation:  [[ 1405.7449793]]\n",
      "Loop  1251 :    Loss_Train:  [[ 4885.29790433]]    Loss_Validation:  [[ 1405.74837602]]\n",
      "Loop  1252 :    Loss_Train:  [[ 4885.17521737]]    Loss_Validation:  [[ 1405.7518096]]\n",
      "Loop  1253 :    Loss_Train:  [[ 4885.05279909]]    Loss_Validation:  [[ 1405.75527983]]\n",
      "Loop  1254 :    Loss_Train:  [[ 4884.93064878]]    Loss_Validation:  [[ 1405.75878647]]\n",
      "Loop  1255 :    Loss_Train:  [[ 4884.80876575]]    Loss_Validation:  [[ 1405.76232931]]\n",
      "Loop  1256 :    Loss_Train:  [[ 4884.68714931]]    Loss_Validation:  [[ 1405.76590813]]\n",
      "Loop  1257 :    Loss_Train:  [[ 4884.56579878]]    Loss_Validation:  [[ 1405.76952272]]\n",
      "Loop  1258 :    Loss_Train:  [[ 4884.44471345]]    Loss_Validation:  [[ 1405.77317285]]\n",
      "Loop  1259 :    Loss_Train:  [[ 4884.32389266]]    Loss_Validation:  [[ 1405.77685832]]\n",
      "Loop  1260 :    Loss_Train:  [[ 4884.20333572]]    Loss_Validation:  [[ 1405.7805789]]\n",
      "Loop  1261 :    Loss_Train:  [[ 4884.08304195]]    Loss_Validation:  [[ 1405.78433439]]\n",
      "Loop  1262 :    Loss_Train:  [[ 4883.96301067]]    Loss_Validation:  [[ 1405.78812457]]\n",
      "Loop  1263 :    Loss_Train:  [[ 4883.8432412]]    Loss_Validation:  [[ 1405.79194923]]\n",
      "Loop  1264 :    Loss_Train:  [[ 4883.72373288]]    Loss_Validation:  [[ 1405.79580817]]\n",
      "Loop  1265 :    Loss_Train:  [[ 4883.60448502]]    Loss_Validation:  [[ 1405.79970117]]\n",
      "Loop  1266 :    Loss_Train:  [[ 4883.48549697]]    Loss_Validation:  [[ 1405.80362802]]\n",
      "Loop  1267 :    Loss_Train:  [[ 4883.36676805]]    Loss_Validation:  [[ 1405.80758852]]\n",
      "Loop  1268 :    Loss_Train:  [[ 4883.2482976]]    Loss_Validation:  [[ 1405.81158247]]\n",
      "Loop  1269 :    Loss_Train:  [[ 4883.13008496]]    Loss_Validation:  [[ 1405.81560965]]\n",
      "Loop  1270 :    Loss_Train:  [[ 4883.01212946]]    Loss_Validation:  [[ 1405.81966987]]\n",
      "Loop  1271 :    Loss_Train:  [[ 4882.89443045]]    Loss_Validation:  [[ 1405.82376292]]\n",
      "Loop  1272 :    Loss_Train:  [[ 4882.77698727]]    Loss_Validation:  [[ 1405.8278886]]\n",
      "Loop  1273 :    Loss_Train:  [[ 4882.65979927]]    Loss_Validation:  [[ 1405.83204672]]\n",
      "Loop  1274 :    Loss_Train:  [[ 4882.54286579]]    Loss_Validation:  [[ 1405.83623707]]\n",
      "Loop  1275 :    Loss_Train:  [[ 4882.42618618]]    Loss_Validation:  [[ 1405.84045945]]\n",
      "Loop  1276 :    Loss_Train:  [[ 4882.3097598]]    Loss_Validation:  [[ 1405.84471366]]\n",
      "Loop  1277 :    Loss_Train:  [[ 4882.19358599]]    Loss_Validation:  [[ 1405.84899952]]\n",
      "Loop  1278 :    Loss_Train:  [[ 4882.07766412]]    Loss_Validation:  [[ 1405.85331682]]\n",
      "Loop  1279 :    Loss_Train:  [[ 4881.96199355]]    Loss_Validation:  [[ 1405.85766537]]\n",
      "Loop  1280 :    Loss_Train:  [[ 4881.84657362]]    Loss_Validation:  [[ 1405.86204498]]\n",
      "Loop  1281 :    Loss_Train:  [[ 4881.73140371]]    Loss_Validation:  [[ 1405.86645545]]\n",
      "Loop  1282 :    Loss_Train:  [[ 4881.61648317]]    Loss_Validation:  [[ 1405.8708966]]\n",
      "Loop  1283 :    Loss_Train:  [[ 4881.50181137]]    Loss_Validation:  [[ 1405.87536823]]\n",
      "Loop  1284 :    Loss_Train:  [[ 4881.38738769]]    Loss_Validation:  [[ 1405.87987016]]\n",
      "Loop  1285 :    Loss_Train:  [[ 4881.27321149]]    Loss_Validation:  [[ 1405.88440218]]\n",
      "Loop  1286 :    Loss_Train:  [[ 4881.15928214]]    Loss_Validation:  [[ 1405.88896413]]\n",
      "Loop  1287 :    Loss_Train:  [[ 4881.04559901]]    Loss_Validation:  [[ 1405.89355581]]\n",
      "Loop  1288 :    Loss_Train:  [[ 4880.93216149]]    Loss_Validation:  [[ 1405.89817704]]\n",
      "Loop  1289 :    Loss_Train:  [[ 4880.81896894]]    Loss_Validation:  [[ 1405.90282762]]\n",
      "Loop  1290 :    Loss_Train:  [[ 4880.70602075]]    Loss_Validation:  [[ 1405.90750739]]\n",
      "Loop  1291 :    Loss_Train:  [[ 4880.59331631]]    Loss_Validation:  [[ 1405.91221615]]\n",
      "Loop  1292 :    Loss_Train:  [[ 4880.48085498]]    Loss_Validation:  [[ 1405.91695372]]\n",
      "Loop  1293 :    Loss_Train:  [[ 4880.36863616]]    Loss_Validation:  [[ 1405.92171992]]\n",
      "Loop  1294 :    Loss_Train:  [[ 4880.25665924]]    Loss_Validation:  [[ 1405.92651458]]\n",
      "Loop  1295 :    Loss_Train:  [[ 4880.1449236]]    Loss_Validation:  [[ 1405.93133751]]\n",
      "Loop  1296 :    Loss_Train:  [[ 4880.03342864]]    Loss_Validation:  [[ 1405.93618854]]\n",
      "Loop  1297 :    Loss_Train:  [[ 4879.92217374]]    Loss_Validation:  [[ 1405.94106748]]\n",
      "Loop  1298 :    Loss_Train:  [[ 4879.81115831]]    Loss_Validation:  [[ 1405.94597417]]\n",
      "Loop  1299 :    Loss_Train:  [[ 4879.70038174]]    Loss_Validation:  [[ 1405.95090842]]\n",
      "Loop  1300 :    Loss_Train:  [[ 4879.58984342]]    Loss_Validation:  [[ 1405.95587007]]\n",
      "Loop  1301 :    Loss_Train:  [[ 4879.47954276]]    Loss_Validation:  [[ 1405.96085893]]\n",
      "Loop  1302 :    Loss_Train:  [[ 4879.36947917]]    Loss_Validation:  [[ 1405.96587484]]\n",
      "Loop  1303 :    Loss_Train:  [[ 4879.25965203]]    Loss_Validation:  [[ 1405.97091763]]\n",
      "Loop  1304 :    Loss_Train:  [[ 4879.15006077]]    Loss_Validation:  [[ 1405.97598712]]\n",
      "Loop  1305 :    Loss_Train:  [[ 4879.04070478]]    Loss_Validation:  [[ 1405.98108314]]\n",
      "Loop  1306 :    Loss_Train:  [[ 4878.93158348]]    Loss_Validation:  [[ 1405.98620552]]\n",
      "Loop  1307 :    Loss_Train:  [[ 4878.82269628]]    Loss_Validation:  [[ 1405.9913541]]\n",
      "Loop  1308 :    Loss_Train:  [[ 4878.71404259]]    Loss_Validation:  [[ 1405.99652871]]\n",
      "Loop  1309 :    Loss_Train:  [[ 4878.60562183]]    Loss_Validation:  [[ 1406.00172918]]\n",
      "Loop  1310 :    Loss_Train:  [[ 4878.49743341]]    Loss_Validation:  [[ 1406.00695535]]\n",
      "Loop  1311 :    Loss_Train:  [[ 4878.38947675]]    Loss_Validation:  [[ 1406.01220705]]\n",
      "Loop  1312 :    Loss_Train:  [[ 4878.28175127]]    Loss_Validation:  [[ 1406.01748411]]\n",
      "Loop  1313 :    Loss_Train:  [[ 4878.17425639]]    Loss_Validation:  [[ 1406.02278638]]\n",
      "Loop  1314 :    Loss_Train:  [[ 4878.06699154]]    Loss_Validation:  [[ 1406.02811369]]\n",
      "Loop  1315 :    Loss_Train:  [[ 4877.95995615]]    Loss_Validation:  [[ 1406.03346588]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  1316 :    Loss_Train:  [[ 4877.85314963]]    Loss_Validation:  [[ 1406.03884278]]\n",
      "Loop  1317 :    Loss_Train:  [[ 4877.74657143]]    Loss_Validation:  [[ 1406.04424425]]\n",
      "Loop  1318 :    Loss_Train:  [[ 4877.64022096]]    Loss_Validation:  [[ 1406.04967011]]\n",
      "Loop  1319 :    Loss_Train:  [[ 4877.53409766]]    Loss_Validation:  [[ 1406.05512022]]\n",
      "Loop  1320 :    Loss_Train:  [[ 4877.42820098]]    Loss_Validation:  [[ 1406.06059441]]\n",
      "Loop  1321 :    Loss_Train:  [[ 4877.32253033]]    Loss_Validation:  [[ 1406.06609253]]\n",
      "Loop  1322 :    Loss_Train:  [[ 4877.21708517]]    Loss_Validation:  [[ 1406.07161442]]\n",
      "Loop  1323 :    Loss_Train:  [[ 4877.11186492]]    Loss_Validation:  [[ 1406.07715992]]\n",
      "Loop  1324 :    Loss_Train:  [[ 4877.00686903]]    Loss_Validation:  [[ 1406.08272889]]\n",
      "Loop  1325 :    Loss_Train:  [[ 4876.90209695]]    Loss_Validation:  [[ 1406.08832117]]\n",
      "Loop  1326 :    Loss_Train:  [[ 4876.79754812]]    Loss_Validation:  [[ 1406.0939366]]\n",
      "Loop  1327 :    Loss_Train:  [[ 4876.69322198]]    Loss_Validation:  [[ 1406.09957504]]\n",
      "Loop  1328 :    Loss_Train:  [[ 4876.58911798]]    Loss_Validation:  [[ 1406.10523632]]\n",
      "Loop  1329 :    Loss_Train:  [[ 4876.48523557]]    Loss_Validation:  [[ 1406.11092031]]\n",
      "Loop  1330 :    Loss_Train:  [[ 4876.3815742]]    Loss_Validation:  [[ 1406.11662686]]\n",
      "Loop  1331 :    Loss_Train:  [[ 4876.27813333]]    Loss_Validation:  [[ 1406.1223558]]\n",
      "Loop  1332 :    Loss_Train:  [[ 4876.17491241]]    Loss_Validation:  [[ 1406.128107]]\n",
      "Loop  1333 :    Loss_Train:  [[ 4876.07191089]]    Loss_Validation:  [[ 1406.13388031]]\n",
      "Loop  1334 :    Loss_Train:  [[ 4875.96912824]]    Loss_Validation:  [[ 1406.13967558]]\n",
      "Loop  1335 :    Loss_Train:  [[ 4875.86656391]]    Loss_Validation:  [[ 1406.14549267]]\n",
      "Loop  1336 :    Loss_Train:  [[ 4875.76421736]]    Loss_Validation:  [[ 1406.15133143]]\n",
      "Loop  1337 :    Loss_Train:  [[ 4875.66208806]]    Loss_Validation:  [[ 1406.15719171]]\n",
      "Loop  1338 :    Loss_Train:  [[ 4875.56017546]]    Loss_Validation:  [[ 1406.16307337]]\n",
      "Loop  1339 :    Loss_Train:  [[ 4875.45847905]]    Loss_Validation:  [[ 1406.16897628]]\n",
      "Loop  1340 :    Loss_Train:  [[ 4875.35699827]]    Loss_Validation:  [[ 1406.17490028]]\n",
      "Loop  1341 :    Loss_Train:  [[ 4875.25573261]]    Loss_Validation:  [[ 1406.18084524]]\n",
      "Loop  1342 :    Loss_Train:  [[ 4875.15468153]]    Loss_Validation:  [[ 1406.18681101]]\n",
      "Loop  1343 :    Loss_Train:  [[ 4875.05384451]]    Loss_Validation:  [[ 1406.19279746]]\n",
      "Loop  1344 :    Loss_Train:  [[ 4874.95322102]]    Loss_Validation:  [[ 1406.19880444]]\n",
      "Loop  1345 :    Loss_Train:  [[ 4874.85281053]]    Loss_Validation:  [[ 1406.20483182]]\n",
      "Loop  1346 :    Loss_Train:  [[ 4874.75261252]]    Loss_Validation:  [[ 1406.21087946]]\n",
      "Loop  1347 :    Loss_Train:  [[ 4874.65262646]]    Loss_Validation:  [[ 1406.21694722]]\n",
      "Loop  1348 :    Loss_Train:  [[ 4874.55285185]]    Loss_Validation:  [[ 1406.22303497]]\n",
      "Loop  1349 :    Loss_Train:  [[ 4874.45328816]]    Loss_Validation:  [[ 1406.22914257]]\n",
      "Loop  1350 :    Loss_Train:  [[ 4874.35393488]]    Loss_Validation:  [[ 1406.23526988]]\n",
      "Loop  1351 :    Loss_Train:  [[ 4874.25479148]]    Loss_Validation:  [[ 1406.24141677]]\n",
      "Loop  1352 :    Loss_Train:  [[ 4874.15585745]]    Loss_Validation:  [[ 1406.24758311]]\n",
      "Loop  1353 :    Loss_Train:  [[ 4874.05713229]]    Loss_Validation:  [[ 1406.25376876]]\n",
      "Loop  1354 :    Loss_Train:  [[ 4873.95861548]]    Loss_Validation:  [[ 1406.25997359]]\n",
      "Loop  1355 :    Loss_Train:  [[ 4873.86030651]]    Loss_Validation:  [[ 1406.26619747]]\n",
      "Loop  1356 :    Loss_Train:  [[ 4873.76220488]]    Loss_Validation:  [[ 1406.27244027]]\n",
      "Loop  1357 :    Loss_Train:  [[ 4873.66431007]]    Loss_Validation:  [[ 1406.27870186]]\n",
      "Loop  1358 :    Loss_Train:  [[ 4873.56662159]]    Loss_Validation:  [[ 1406.28498211]]\n",
      "Loop  1359 :    Loss_Train:  [[ 4873.46913892]]    Loss_Validation:  [[ 1406.29128088]]\n",
      "Loop  1360 :    Loss_Train:  [[ 4873.37186158]]    Loss_Validation:  [[ 1406.29759806]]\n",
      "Loop  1361 :    Loss_Train:  [[ 4873.27478905]]    Loss_Validation:  [[ 1406.30393351]]\n",
      "Loop  1362 :    Loss_Train:  [[ 4873.17792084]]    Loss_Validation:  [[ 1406.31028711]]\n",
      "Loop  1363 :    Loss_Train:  [[ 4873.08125645]]    Loss_Validation:  [[ 1406.31665872]]\n",
      "Loop  1364 :    Loss_Train:  [[ 4872.98479539]]    Loss_Validation:  [[ 1406.32304823]]\n",
      "Loop  1365 :    Loss_Train:  [[ 4872.88853715]]    Loss_Validation:  [[ 1406.32945551]]\n",
      "Loop  1366 :    Loss_Train:  [[ 4872.79248126]]    Loss_Validation:  [[ 1406.33588043]]\n",
      "Loop  1367 :    Loss_Train:  [[ 4872.69662721]]    Loss_Validation:  [[ 1406.34232287]]\n",
      "Loop  1368 :    Loss_Train:  [[ 4872.60097452]]    Loss_Validation:  [[ 1406.34878271]]\n",
      "Loop  1369 :    Loss_Train:  [[ 4872.5055227]]    Loss_Validation:  [[ 1406.35525983]]\n",
      "Loop  1370 :    Loss_Train:  [[ 4872.41027125]]    Loss_Validation:  [[ 1406.3617541]]\n",
      "Loop  1371 :    Loss_Train:  [[ 4872.3152197]]    Loss_Validation:  [[ 1406.36826539]]\n",
      "Loop  1372 :    Loss_Train:  [[ 4872.22036756]]    Loss_Validation:  [[ 1406.3747936]]\n",
      "Loop  1373 :    Loss_Train:  [[ 4872.12571435]]    Loss_Validation:  [[ 1406.3813386]]\n",
      "Loop  1374 :    Loss_Train:  [[ 4872.03125958]]    Loss_Validation:  [[ 1406.38790027]]\n",
      "Loop  1375 :    Loss_Train:  [[ 4871.93700278]]    Loss_Validation:  [[ 1406.39447849]]\n",
      "Loop  1376 :    Loss_Train:  [[ 4871.84294346]]    Loss_Validation:  [[ 1406.40107315]]\n",
      "Loop  1377 :    Loss_Train:  [[ 4871.74908116]]    Loss_Validation:  [[ 1406.40768412]]\n",
      "Loop  1378 :    Loss_Train:  [[ 4871.65541538]]    Loss_Validation:  [[ 1406.41431129]]\n",
      "Loop  1379 :    Loss_Train:  [[ 4871.56194567]]    Loss_Validation:  [[ 1406.42095455]]\n",
      "Loop  1380 :    Loss_Train:  [[ 4871.46867153]]    Loss_Validation:  [[ 1406.42761377]]\n",
      "Loop  1381 :    Loss_Train:  [[ 4871.37559252]]    Loss_Validation:  [[ 1406.43428884]]\n",
      "Loop  1382 :    Loss_Train:  [[ 4871.28270814]]    Loss_Validation:  [[ 1406.44097965]]\n",
      "Loop  1383 :    Loss_Train:  [[ 4871.19001794]]    Loss_Validation:  [[ 1406.44768608]]\n",
      "Loop  1384 :    Loss_Train:  [[ 4871.09752145]]    Loss_Validation:  [[ 1406.45440802]]\n",
      "Loop  1385 :    Loss_Train:  [[ 4871.00521819]]    Loss_Validation:  [[ 1406.46114535]]\n",
      "Loop  1386 :    Loss_Train:  [[ 4870.91310771]]    Loss_Validation:  [[ 1406.46789797]]\n",
      "Loop  1387 :    Loss_Train:  [[ 4870.82118954]]    Loss_Validation:  [[ 1406.47466576]]\n",
      "Loop  1388 :    Loss_Train:  [[ 4870.72946322]]    Loss_Validation:  [[ 1406.48144862]]\n",
      "Loop  1389 :    Loss_Train:  [[ 4870.63792829]]    Loss_Validation:  [[ 1406.48824642]]\n",
      "Loop  1390 :    Loss_Train:  [[ 4870.54658428]]    Loss_Validation:  [[ 1406.49505906]]\n",
      "Loop  1391 :    Loss_Train:  [[ 4870.45543075]]    Loss_Validation:  [[ 1406.50188643]]\n",
      "Loop  1392 :    Loss_Train:  [[ 4870.36446722]]    Loss_Validation:  [[ 1406.50872843]]\n",
      "Loop  1393 :    Loss_Train:  [[ 4870.27369326]]    Loss_Validation:  [[ 1406.51558493]]\n",
      "Loop  1394 :    Loss_Train:  [[ 4870.18310839]]    Loss_Validation:  [[ 1406.52245584]]\n",
      "Loop  1395 :    Loss_Train:  [[ 4870.09271218]]    Loss_Validation:  [[ 1406.52934105]]\n",
      "Loop  1396 :    Loss_Train:  [[ 4870.00250416]]    Loss_Validation:  [[ 1406.53624045]]\n",
      "Loop  1397 :    Loss_Train:  [[ 4869.91248389]]    Loss_Validation:  [[ 1406.54315394]]\n",
      "Loop  1398 :    Loss_Train:  [[ 4869.82265091]]    Loss_Validation:  [[ 1406.5500814]]\n",
      "Loop  1399 :    Loss_Train:  [[ 4869.73300479]]    Loss_Validation:  [[ 1406.55702274]]\n",
      "Loop  1400 :    Loss_Train:  [[ 4869.64354507]]    Loss_Validation:  [[ 1406.56397785]]\n",
      "Loop  1401 :    Loss_Train:  [[ 4869.55427131]]    Loss_Validation:  [[ 1406.57094662]]\n",
      "Loop  1402 :    Loss_Train:  [[ 4869.46518306]]    Loss_Validation:  [[ 1406.57792896]]\n",
      "Loop  1403 :    Loss_Train:  [[ 4869.37627989]]    Loss_Validation:  [[ 1406.58492475]]\n",
      "Loop  1404 :    Loss_Train:  [[ 4869.28756134]]    Loss_Validation:  [[ 1406.5919339]]\n",
      "Loop  1405 :    Loss_Train:  [[ 4869.19902699]]    Loss_Validation:  [[ 1406.5989563]]\n",
      "Loop  1406 :    Loss_Train:  [[ 4869.11067638]]    Loss_Validation:  [[ 1406.60599186]]\n",
      "Loop  1407 :    Loss_Train:  [[ 4869.02250909]]    Loss_Validation:  [[ 1406.61304047]]\n",
      "Loop  1408 :    Loss_Train:  [[ 4868.93452467]]    Loss_Validation:  [[ 1406.62010203]]\n",
      "Loop  1409 :    Loss_Train:  [[ 4868.8467227]]    Loss_Validation:  [[ 1406.62717644]]\n",
      "Loop  1410 :    Loss_Train:  [[ 4868.75910273]]    Loss_Validation:  [[ 1406.63426361]]\n",
      "Loop  1411 :    Loss_Train:  [[ 4868.67166433]]    Loss_Validation:  [[ 1406.64136343]]\n",
      "Loop  1412 :    Loss_Train:  [[ 4868.58440708]]    Loss_Validation:  [[ 1406.6484758]]\n",
      "Loop  1413 :    Loss_Train:  [[ 4868.49733054]]    Loss_Validation:  [[ 1406.65560063]]\n",
      "Loop  1414 :    Loss_Train:  [[ 4868.41043429]]    Loss_Validation:  [[ 1406.66273782]]\n",
      "Loop  1415 :    Loss_Train:  [[ 4868.32371789]]    Loss_Validation:  [[ 1406.66988728]]\n",
      "Loop  1416 :    Loss_Train:  [[ 4868.23718092]]    Loss_Validation:  [[ 1406.6770489]]\n",
      "Loop  1417 :    Loss_Train:  [[ 4868.15082295]]    Loss_Validation:  [[ 1406.68422259]]\n",
      "Loop  1418 :    Loss_Train:  [[ 4868.06464357]]    Loss_Validation:  [[ 1406.69140826]]\n",
      "Loop  1419 :    Loss_Train:  [[ 4867.97864234]]    Loss_Validation:  [[ 1406.6986058]]\n",
      "Loop  1420 :    Loss_Train:  [[ 4867.89281884]]    Loss_Validation:  [[ 1406.70581514]]\n",
      "Loop  1421 :    Loss_Train:  [[ 4867.80717266]]    Loss_Validation:  [[ 1406.71303617]]\n",
      "Loop  1422 :    Loss_Train:  [[ 4867.72170337]]    Loss_Validation:  [[ 1406.72026879]]\n",
      "Loop  1423 :    Loss_Train:  [[ 4867.63641056]]    Loss_Validation:  [[ 1406.72751292]]\n",
      "Loop  1424 :    Loss_Train:  [[ 4867.55129381]]    Loss_Validation:  [[ 1406.73476847]]\n",
      "Loop  1425 :    Loss_Train:  [[ 4867.4663527]]    Loss_Validation:  [[ 1406.74203534]]\n",
      "Loop  1426 :    Loss_Train:  [[ 4867.38158683]]    Loss_Validation:  [[ 1406.74931344]]\n",
      "Loop  1427 :    Loss_Train:  [[ 4867.29699576]]    Loss_Validation:  [[ 1406.75660267]]\n",
      "Loop  1428 :    Loss_Train:  [[ 4867.2125791]]    Loss_Validation:  [[ 1406.76390296]]\n",
      "Loop  1429 :    Loss_Train:  [[ 4867.12833643]]    Loss_Validation:  [[ 1406.7712142]]\n",
      "Loop  1430 :    Loss_Train:  [[ 4867.04426735]]    Loss_Validation:  [[ 1406.77853631]]\n",
      "Loop  1431 :    Loss_Train:  [[ 4866.96037143]]    Loss_Validation:  [[ 1406.78586921]]\n",
      "Loop  1432 :    Loss_Train:  [[ 4866.87664828]]    Loss_Validation:  [[ 1406.79321279]]\n",
      "Loop  1433 :    Loss_Train:  [[ 4866.79309749]]    Loss_Validation:  [[ 1406.80056697]]\n",
      "Loop  1434 :    Loss_Train:  [[ 4866.70971866]]    Loss_Validation:  [[ 1406.80793167]]\n",
      "Loop  1435 :    Loss_Train:  [[ 4866.62651137]]    Loss_Validation:  [[ 1406.8153068]]\n",
      "Loop  1436 :    Loss_Train:  [[ 4866.54347523]]    Loss_Validation:  [[ 1406.82269227]]\n",
      "Loop  1437 :    Loss_Train:  [[ 4866.46060983]]    Loss_Validation:  [[ 1406.83008799]]\n",
      "Loop  1438 :    Loss_Train:  [[ 4866.37791477]]    Loss_Validation:  [[ 1406.83749388]]\n",
      "Loop  1439 :    Loss_Train:  [[ 4866.29538966]]    Loss_Validation:  [[ 1406.84490985]]\n",
      "Loop  1440 :    Loss_Train:  [[ 4866.21303409]]    Loss_Validation:  [[ 1406.85233582]]\n",
      "Loop  1441 :    Loss_Train:  [[ 4866.13084766]]    Loss_Validation:  [[ 1406.8597717]]\n",
      "Loop  1442 :    Loss_Train:  [[ 4866.04882999]]    Loss_Validation:  [[ 1406.86721741]]\n",
      "Loop  1443 :    Loss_Train:  [[ 4865.96698067]]    Loss_Validation:  [[ 1406.87467286]]\n",
      "Loop  1444 :    Loss_Train:  [[ 4865.88529932]]    Loss_Validation:  [[ 1406.88213798]]\n",
      "Loop  1445 :    Loss_Train:  [[ 4865.80378553]]    Loss_Validation:  [[ 1406.88961267]]\n",
      "Loop  1446 :    Loss_Train:  [[ 4865.72243892]]    Loss_Validation:  [[ 1406.89709686]]\n",
      "Loop  1447 :    Loss_Train:  [[ 4865.64125909]]    Loss_Validation:  [[ 1406.90459046]]\n",
      "Loop  1448 :    Loss_Train:  [[ 4865.56024565]]    Loss_Validation:  [[ 1406.9120934]]\n",
      "Loop  1449 :    Loss_Train:  [[ 4865.47939822]]    Loss_Validation:  [[ 1406.91960558]]\n",
      "Loop  1450 :    Loss_Train:  [[ 4865.39871641]]    Loss_Validation:  [[ 1406.92712693]]\n",
      "Loop  1451 :    Loss_Train:  [[ 4865.31819984]]    Loss_Validation:  [[ 1406.93465737]]\n",
      "Loop  1452 :    Loss_Train:  [[ 4865.2378481]]    Loss_Validation:  [[ 1406.94219682]]\n",
      "Loop  1453 :    Loss_Train:  [[ 4865.15766083]]    Loss_Validation:  [[ 1406.9497452]]\n",
      "Loop  1454 :    Loss_Train:  [[ 4865.07763764]]    Loss_Validation:  [[ 1406.95730244]]\n",
      "Loop  1455 :    Loss_Train:  [[ 4864.99777814]]    Loss_Validation:  [[ 1406.96486844]]\n",
      "Loop  1456 :    Loss_Train:  [[ 4864.91808196]]    Loss_Validation:  [[ 1406.97244313]]\n",
      "Loop  1457 :    Loss_Train:  [[ 4864.83854872]]    Loss_Validation:  [[ 1406.98002644]]\n",
      "Loop  1458 :    Loss_Train:  [[ 4864.75917802]]    Loss_Validation:  [[ 1406.98761829]]\n",
      "Loop  1459 :    Loss_Train:  [[ 4864.67996951]]    Loss_Validation:  [[ 1406.9952186]]\n",
      "Loop  1460 :    Loss_Train:  [[ 4864.60092279]]    Loss_Validation:  [[ 1407.00282729]]\n",
      "Loop  1461 :    Loss_Train:  [[ 4864.5220375]]    Loss_Validation:  [[ 1407.01044428]]\n",
      "Loop  1462 :    Loss_Train:  [[ 4864.44331326]]    Loss_Validation:  [[ 1407.01806951]]\n",
      "Loop  1463 :    Loss_Train:  [[ 4864.3647497]]    Loss_Validation:  [[ 1407.0257029]]\n",
      "Loop  1464 :    Loss_Train:  [[ 4864.28634643]]    Loss_Validation:  [[ 1407.03334436]]\n",
      "Loop  1465 :    Loss_Train:  [[ 4864.2081031]]    Loss_Validation:  [[ 1407.04099383]]\n",
      "Loop  1466 :    Loss_Train:  [[ 4864.13001932]]    Loss_Validation:  [[ 1407.04865123]]\n",
      "Loop  1467 :    Loss_Train:  [[ 4864.05209474]]    Loss_Validation:  [[ 1407.05631649]]\n",
      "Loop  1468 :    Loss_Train:  [[ 4863.97432898]]    Loss_Validation:  [[ 1407.06398953]]\n",
      "Loop  1469 :    Loss_Train:  [[ 4863.89672167]]    Loss_Validation:  [[ 1407.07167029]]\n",
      "Loop  1470 :    Loss_Train:  [[ 4863.81927244]]    Loss_Validation:  [[ 1407.07935867]]\n",
      "Loop  1471 :    Loss_Train:  [[ 4863.74198094]]    Loss_Validation:  [[ 1407.08705463]]\n",
      "Loop  1472 :    Loss_Train:  [[ 4863.66484679]]    Loss_Validation:  [[ 1407.09475807]]\n",
      "Loop  1473 :    Loss_Train:  [[ 4863.58786963]]    Loss_Validation:  [[ 1407.10246894]]\n",
      "Loop  1474 :    Loss_Train:  [[ 4863.5110491]]    Loss_Validation:  [[ 1407.11018715]]\n",
      "Loop  1475 :    Loss_Train:  [[ 4863.43438484]]    Loss_Validation:  [[ 1407.11791265]]\n",
      "Loop  1476 :    Loss_Train:  [[ 4863.35787649]]    Loss_Validation:  [[ 1407.12564535]]\n",
      "Loop  1477 :    Loss_Train:  [[ 4863.28152368]]    Loss_Validation:  [[ 1407.13338519]]\n",
      "Loop  1478 :    Loss_Train:  [[ 4863.20532606]]    Loss_Validation:  [[ 1407.14113209]]\n",
      "Loop  1479 :    Loss_Train:  [[ 4863.12928327]]    Loss_Validation:  [[ 1407.148886]]\n",
      "Loop  1480 :    Loss_Train:  [[ 4863.05339495]]    Loss_Validation:  [[ 1407.15664683]]\n",
      "Loop  1481 :    Loss_Train:  [[ 4862.97766075]]    Loss_Validation:  [[ 1407.16441452]]\n",
      "Loop  1482 :    Loss_Train:  [[ 4862.90208031]]    Loss_Validation:  [[ 1407.17218901]]\n",
      "Loop  1483 :    Loss_Train:  [[ 4862.82665328]]    Loss_Validation:  [[ 1407.17997021]]\n",
      "Loop  1484 :    Loss_Train:  [[ 4862.75137931]]    Loss_Validation:  [[ 1407.18775808]]\n",
      "Loop  1485 :    Loss_Train:  [[ 4862.67625804]]    Loss_Validation:  [[ 1407.19555253]]\n",
      "Loop  1486 :    Loss_Train:  [[ 4862.60128912]]    Loss_Validation:  [[ 1407.2033535]]\n",
      "Loop  1487 :    Loss_Train:  [[ 4862.5264722]]    Loss_Validation:  [[ 1407.21116092]]\n",
      "Loop  1488 :    Loss_Train:  [[ 4862.45180694]]    Loss_Validation:  [[ 1407.21897473]]\n",
      "Loop  1489 :    Loss_Train:  [[ 4862.37729298]]    Loss_Validation:  [[ 1407.22679487]]\n",
      "Loop  1490 :    Loss_Train:  [[ 4862.30292997]]    Loss_Validation:  [[ 1407.23462126]]\n",
      "Loop  1491 :    Loss_Train:  [[ 4862.22871758]]    Loss_Validation:  [[ 1407.24245384]]\n",
      "Loop  1492 :    Loss_Train:  [[ 4862.15465545]]    Loss_Validation:  [[ 1407.25029255]]\n",
      "Loop  1493 :    Loss_Train:  [[ 4862.08074325]]    Loss_Validation:  [[ 1407.25813732]]\n",
      "Loop  1494 :    Loss_Train:  [[ 4862.00698062]]    Loss_Validation:  [[ 1407.26598808]]\n",
      "Loop  1495 :    Loss_Train:  [[ 4861.93336723]]    Loss_Validation:  [[ 1407.27384478]]\n",
      "Loop  1496 :    Loss_Train:  [[ 4861.85990273]]    Loss_Validation:  [[ 1407.28170734]]\n",
      "Loop  1497 :    Loss_Train:  [[ 4861.78658678]]    Loss_Validation:  [[ 1407.28957571]]\n",
      "Loop  1498 :    Loss_Train:  [[ 4861.71341905]]    Loss_Validation:  [[ 1407.29744983]]\n",
      "Loop  1499 :    Loss_Train:  [[ 4861.64039919]]    Loss_Validation:  [[ 1407.30532962]]\n",
      "Loop  1500 :    Loss_Train:  [[ 4861.56752686]]    Loss_Validation:  [[ 1407.31321504]]\n",
      "Loop  1501 :    Loss_Train:  [[ 4861.49480173]]    Loss_Validation:  [[ 1407.321106]]\n",
      "Loop  1502 :    Loss_Train:  [[ 4861.42222347]]    Loss_Validation:  [[ 1407.32900247]]\n",
      "Loop  1503 :    Loss_Train:  [[ 4861.34979173]]    Loss_Validation:  [[ 1407.33690436]]\n",
      "Loop  1504 :    Loss_Train:  [[ 4861.27750619]]    Loss_Validation:  [[ 1407.34481163]]\n",
      "Loop  1505 :    Loss_Train:  [[ 4861.20536651]]    Loss_Validation:  [[ 1407.3527242]]\n",
      "Loop  1506 :    Loss_Train:  [[ 4861.13337235]]    Loss_Validation:  [[ 1407.36064203]]\n",
      "Loop  1507 :    Loss_Train:  [[ 4861.06152339]]    Loss_Validation:  [[ 1407.36856505]]\n",
      "Loop  1508 :    Loss_Train:  [[ 4860.98981929]]    Loss_Validation:  [[ 1407.3764932]]\n",
      "Loop  1509 :    Loss_Train:  [[ 4860.91825973]]    Loss_Validation:  [[ 1407.38442642]]\n",
      "Loop  1510 :    Loss_Train:  [[ 4860.84684437]]    Loss_Validation:  [[ 1407.39236465]]\n",
      "Loop  1511 :    Loss_Train:  [[ 4860.77557289]]    Loss_Validation:  [[ 1407.40030783]]\n",
      "Loop  1512 :    Loss_Train:  [[ 4860.70444496]]    Loss_Validation:  [[ 1407.40825591]]\n",
      "Loop  1513 :    Loss_Train:  [[ 4860.63346026]]    Loss_Validation:  [[ 1407.41620883]]\n",
      "Loop  1514 :    Loss_Train:  [[ 4860.56261845]]    Loss_Validation:  [[ 1407.42416652]]\n",
      "Loop  1515 :    Loss_Train:  [[ 4860.49191922]]    Loss_Validation:  [[ 1407.43212893]]\n",
      "Loop  1516 :    Loss_Train:  [[ 4860.42136223]]    Loss_Validation:  [[ 1407.44009601]]\n",
      "Loop  1517 :    Loss_Train:  [[ 4860.35094718]]    Loss_Validation:  [[ 1407.4480677]]\n",
      "Loop  1518 :    Loss_Train:  [[ 4860.28067373]]    Loss_Validation:  [[ 1407.45604393]]\n",
      "Loop  1519 :    Loss_Train:  [[ 4860.21054156]]    Loss_Validation:  [[ 1407.46402466]]\n",
      "Loop  1520 :    Loss_Train:  [[ 4860.14055036]]    Loss_Validation:  [[ 1407.47200982]]\n",
      "Loop  1521 :    Loss_Train:  [[ 4860.0706998]]    Loss_Validation:  [[ 1407.47999937]]\n",
      "Loop  1522 :    Loss_Train:  [[ 4860.00098956]]    Loss_Validation:  [[ 1407.48799324]]\n",
      "Loop  1523 :    Loss_Train:  [[ 4859.93141934]]    Loss_Validation:  [[ 1407.49599138]]\n",
      "Loop  1524 :    Loss_Train:  [[ 4859.8619888]]    Loss_Validation:  [[ 1407.50399374]]\n",
      "Loop  1525 :    Loss_Train:  [[ 4859.79269764]]    Loss_Validation:  [[ 1407.51200026]]\n",
      "Loop  1526 :    Loss_Train:  [[ 4859.72354554]]    Loss_Validation:  [[ 1407.52001089]]\n",
      "Loop  1527 :    Loss_Train:  [[ 4859.65453219]]    Loss_Validation:  [[ 1407.52802556]]\n",
      "Loop  1528 :    Loss_Train:  [[ 4859.58565727]]    Loss_Validation:  [[ 1407.53604424]]\n",
      "Loop  1529 :    Loss_Train:  [[ 4859.51692046]]    Loss_Validation:  [[ 1407.54406686]]\n",
      "Loop  1530 :    Loss_Train:  [[ 4859.44832147]]    Loss_Validation:  [[ 1407.55209338]]\n",
      "Loop  1531 :    Loss_Train:  [[ 4859.37985997]]    Loss_Validation:  [[ 1407.56012373]]\n",
      "Loop  1532 :    Loss_Train:  [[ 4859.31153565]]    Loss_Validation:  [[ 1407.56815787]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  1533 :    Loss_Train:  [[ 4859.24334821]]    Loss_Validation:  [[ 1407.57619575]]\n",
      "Loop  1534 :    Loss_Train:  [[ 4859.17529734]]    Loss_Validation:  [[ 1407.5842373]]\n",
      "Loop  1535 :    Loss_Train:  [[ 4859.10738274]]    Loss_Validation:  [[ 1407.59228249]]\n",
      "Loop  1536 :    Loss_Train:  [[ 4859.03960408]]    Loss_Validation:  [[ 1407.60033125]]\n",
      "Loop  1537 :    Loss_Train:  [[ 4858.97196107]]    Loss_Validation:  [[ 1407.60838354]]\n",
      "Loop  1538 :    Loss_Train:  [[ 4858.9044534]]    Loss_Validation:  [[ 1407.61643931]]\n",
      "Loop  1539 :    Loss_Train:  [[ 4858.83708077]]    Loss_Validation:  [[ 1407.62449851]]\n",
      "Loop  1540 :    Loss_Train:  [[ 4858.76984288]]    Loss_Validation:  [[ 1407.63256107]]\n",
      "Loop  1541 :    Loss_Train:  [[ 4858.70273941]]    Loss_Validation:  [[ 1407.64062697]]\n",
      "Loop  1542 :    Loss_Train:  [[ 4858.63577007]]    Loss_Validation:  [[ 1407.64869613]]\n",
      "Loop  1543 :    Loss_Train:  [[ 4858.56893456]]    Loss_Validation:  [[ 1407.65676853]]\n",
      "Loop  1544 :    Loss_Train:  [[ 4858.50223258]]    Loss_Validation:  [[ 1407.6648441]]\n",
      "Loop  1545 :    Loss_Train:  [[ 4858.43566383]]    Loss_Validation:  [[ 1407.67292279]]\n",
      "Loop  1546 :    Loss_Train:  [[ 4858.369228]]    Loss_Validation:  [[ 1407.68100456]]\n",
      "Loop  1547 :    Loss_Train:  [[ 4858.3029248]]    Loss_Validation:  [[ 1407.68908937]]\n",
      "Loop  1548 :    Loss_Train:  [[ 4858.23675393]]    Loss_Validation:  [[ 1407.69717715]]\n",
      "Loop  1549 :    Loss_Train:  [[ 4858.1707151]]    Loss_Validation:  [[ 1407.70526787]]\n",
      "Loop  1550 :    Loss_Train:  [[ 4858.10480801]]    Loss_Validation:  [[ 1407.71336147]]\n",
      "Loop  1551 :    Loss_Train:  [[ 4858.03903237]]    Loss_Validation:  [[ 1407.7214579]]\n",
      "Loop  1552 :    Loss_Train:  [[ 4857.97338788]]    Loss_Validation:  [[ 1407.72955713]]\n",
      "Loop  1553 :    Loss_Train:  [[ 4857.90787424]]    Loss_Validation:  [[ 1407.7376591]]\n",
      "Loop  1554 :    Loss_Train:  [[ 4857.84249117]]    Loss_Validation:  [[ 1407.74576376]]\n",
      "Loop  1555 :    Loss_Train:  [[ 4857.77723837]]    Loss_Validation:  [[ 1407.75387108]]\n",
      "Loop  1556 :    Loss_Train:  [[ 4857.71211555]]    Loss_Validation:  [[ 1407.761981]]\n",
      "Loop  1557 :    Loss_Train:  [[ 4857.64712242]]    Loss_Validation:  [[ 1407.77009347]]\n",
      "Loop  1558 :    Loss_Train:  [[ 4857.5822587]]    Loss_Validation:  [[ 1407.77820846]]\n",
      "Loop  1559 :    Loss_Train:  [[ 4857.51752408]]    Loss_Validation:  [[ 1407.78632591]]\n",
      "Loop  1560 :    Loss_Train:  [[ 4857.4529183]]    Loss_Validation:  [[ 1407.79444578]]\n",
      "Loop  1561 :    Loss_Train:  [[ 4857.38844104]]    Loss_Validation:  [[ 1407.80256802]]\n",
      "Loop  1562 :    Loss_Train:  [[ 4857.32409204]]    Loss_Validation:  [[ 1407.8106926]]\n",
      "Loop  1563 :    Loss_Train:  [[ 4857.259871]]    Loss_Validation:  [[ 1407.81881946]]\n",
      "Loop  1564 :    Loss_Train:  [[ 4857.19577765]]    Loss_Validation:  [[ 1407.82694856]]\n",
      "Loop  1565 :    Loss_Train:  [[ 4857.13181168]]    Loss_Validation:  [[ 1407.83507986]]\n",
      "Loop  1566 :    Loss_Train:  [[ 4857.06797283]]    Loss_Validation:  [[ 1407.84321331]]\n",
      "Loop  1567 :    Loss_Train:  [[ 4857.0042608]]    Loss_Validation:  [[ 1407.85134887]]\n",
      "Loop  1568 :    Loss_Train:  [[ 4856.94067533]]    Loss_Validation:  [[ 1407.8594865]]\n",
      "Loop  1569 :    Loss_Train:  [[ 4856.87721611]]    Loss_Validation:  [[ 1407.86762615]]\n",
      "Loop  1570 :    Loss_Train:  [[ 4856.81388288]]    Loss_Validation:  [[ 1407.87576777]]\n",
      "Loop  1571 :    Loss_Train:  [[ 4856.75067535]]    Loss_Validation:  [[ 1407.88391134]]\n",
      "Loop  1572 :    Loss_Train:  [[ 4856.68759325]]    Loss_Validation:  [[ 1407.8920568]]\n",
      "Loop  1573 :    Loss_Train:  [[ 4856.6246363]]    Loss_Validation:  [[ 1407.90020411]]\n",
      "Loop  1574 :    Loss_Train:  [[ 4856.56180421]]    Loss_Validation:  [[ 1407.90835323]]\n",
      "Loop  1575 :    Loss_Train:  [[ 4856.49909671]]    Loss_Validation:  [[ 1407.91650412]]\n",
      "Loop  1576 :    Loss_Train:  [[ 4856.43651353]]    Loss_Validation:  [[ 1407.92465673]]\n",
      "Loop  1577 :    Loss_Train:  [[ 4856.37405438]]    Loss_Validation:  [[ 1407.93281103]]\n",
      "Loop  1578 :    Loss_Train:  [[ 4856.311719]]    Loss_Validation:  [[ 1407.94096698]]\n",
      "Loop  1579 :    Loss_Train:  [[ 4856.24950711]]    Loss_Validation:  [[ 1407.94912453]]\n",
      "Loop  1580 :    Loss_Train:  [[ 4856.18741843]]    Loss_Validation:  [[ 1407.95728363]]\n",
      "Loop  1581 :    Loss_Train:  [[ 4856.1254527]]    Loss_Validation:  [[ 1407.96544427]]\n",
      "Loop  1582 :    Loss_Train:  [[ 4856.06360964]]    Loss_Validation:  [[ 1407.97360638]]\n",
      "Loop  1583 :    Loss_Train:  [[ 4856.00188898]]    Loss_Validation:  [[ 1407.98176993]]\n",
      "Loop  1584 :    Loss_Train:  [[ 4855.94029045]]    Loss_Validation:  [[ 1407.98993489]]\n",
      "Loop  1585 :    Loss_Train:  [[ 4855.87881378]]    Loss_Validation:  [[ 1407.9981012]]\n",
      "Loop  1586 :    Loss_Train:  [[ 4855.81745869]]    Loss_Validation:  [[ 1408.00626884]]\n",
      "Loop  1587 :    Loss_Train:  [[ 4855.75622493]]    Loss_Validation:  [[ 1408.01443777]]\n",
      "Loop  1588 :    Loss_Train:  [[ 4855.69511222]]    Loss_Validation:  [[ 1408.02260793]]\n",
      "Loop  1589 :    Loss_Train:  [[ 4855.63412029]]    Loss_Validation:  [[ 1408.03077931]]\n",
      "Loop  1590 :    Loss_Train:  [[ 4855.57324889]]    Loss_Validation:  [[ 1408.03895185]]\n",
      "Loop  1591 :    Loss_Train:  [[ 4855.51249774]]    Loss_Validation:  [[ 1408.04712551]]\n",
      "Loop  1592 :    Loss_Train:  [[ 4855.45186657]]    Loss_Validation:  [[ 1408.05530027]]\n",
      "Loop  1593 :    Loss_Train:  [[ 4855.39135513]]    Loss_Validation:  [[ 1408.06347608]]\n",
      "Loop  1594 :    Loss_Train:  [[ 4855.33096315]]    Loss_Validation:  [[ 1408.07165291]]\n",
      "Loop  1595 :    Loss_Train:  [[ 4855.27069036]]    Loss_Validation:  [[ 1408.07983071]]\n",
      "Loop  1596 :    Loss_Train:  [[ 4855.21053651]]    Loss_Validation:  [[ 1408.08800945]]\n",
      "Loop  1597 :    Loss_Train:  [[ 4855.15050133]]    Loss_Validation:  [[ 1408.0961891]]\n",
      "Loop  1598 :    Loss_Train:  [[ 4855.09058457]]    Loss_Validation:  [[ 1408.10436961]]\n",
      "Loop  1599 :    Loss_Train:  [[ 4855.03078595]]    Loss_Validation:  [[ 1408.11255095]]\n",
      "Loop  1600 :    Loss_Train:  [[ 4854.97110522]]    Loss_Validation:  [[ 1408.12073308]]\n",
      "Loop  1601 :    Loss_Train:  [[ 4854.91154213]]    Loss_Validation:  [[ 1408.12891597]]\n",
      "Loop  1602 :    Loss_Train:  [[ 4854.8520964]]    Loss_Validation:  [[ 1408.13709958]]\n",
      "Loop  1603 :    Loss_Train:  [[ 4854.7927678]]    Loss_Validation:  [[ 1408.14528388]]\n",
      "Loop  1604 :    Loss_Train:  [[ 4854.73355605]]    Loss_Validation:  [[ 1408.15346882]]\n",
      "Loop  1605 :    Loss_Train:  [[ 4854.6744609]]    Loss_Validation:  [[ 1408.16165438]]\n",
      "Loop  1606 :    Loss_Train:  [[ 4854.6154821]]    Loss_Validation:  [[ 1408.16984051]]\n",
      "Loop  1607 :    Loss_Train:  [[ 4854.55661938]]    Loss_Validation:  [[ 1408.17802718]]\n",
      "Loop  1608 :    Loss_Train:  [[ 4854.49787251]]    Loss_Validation:  [[ 1408.18621437]]\n",
      "Loop  1609 :    Loss_Train:  [[ 4854.43924121]]    Loss_Validation:  [[ 1408.19440202]]\n",
      "Loop  1610 :    Loss_Train:  [[ 4854.38072525]]    Loss_Validation:  [[ 1408.20259012]]\n",
      "Loop  1611 :    Loss_Train:  [[ 4854.32232436]]    Loss_Validation:  [[ 1408.21077862]]\n",
      "Loop  1612 :    Loss_Train:  [[ 4854.26403829]]    Loss_Validation:  [[ 1408.21896749]]\n",
      "Loop  1613 :    Loss_Train:  [[ 4854.2058668]]    Loss_Validation:  [[ 1408.22715669]]\n",
      "Loop  1614 :    Loss_Train:  [[ 4854.14780963]]    Loss_Validation:  [[ 1408.2353462]]\n",
      "Loop  1615 :    Loss_Train:  [[ 4854.08986653]]    Loss_Validation:  [[ 1408.24353597]]\n",
      "Loop  1616 :    Loss_Train:  [[ 4854.03203725]]    Loss_Validation:  [[ 1408.25172598]]\n",
      "Loop  1617 :    Loss_Train:  [[ 4853.97432155]]    Loss_Validation:  [[ 1408.25991619]]\n",
      "Loop  1618 :    Loss_Train:  [[ 4853.91671918]]    Loss_Validation:  [[ 1408.26810657]]\n",
      "Loop  1619 :    Loss_Train:  [[ 4853.85922988]]    Loss_Validation:  [[ 1408.27629709]]\n",
      "Loop  1620 :    Loss_Train:  [[ 4853.80185341]]    Loss_Validation:  [[ 1408.28448771]]\n",
      "Loop  1621 :    Loss_Train:  [[ 4853.74458953]]    Loss_Validation:  [[ 1408.2926784]]\n",
      "Loop  1622 :    Loss_Train:  [[ 4853.68743798]]    Loss_Validation:  [[ 1408.30086912]]\n",
      "Loop  1623 :    Loss_Train:  [[ 4853.63039853]]    Loss_Validation:  [[ 1408.30905986]]\n",
      "Loop  1624 :    Loss_Train:  [[ 4853.57347093]]    Loss_Validation:  [[ 1408.31725057]]\n",
      "Loop  1625 :    Loss_Train:  [[ 4853.51665494]]    Loss_Validation:  [[ 1408.32544122]]\n",
      "Loop  1626 :    Loss_Train:  [[ 4853.45995031]]    Loss_Validation:  [[ 1408.33363178]]\n",
      "Loop  1627 :    Loss_Train:  [[ 4853.4033568]]    Loss_Validation:  [[ 1408.34182222]]\n",
      "Loop  1628 :    Loss_Train:  [[ 4853.34687416]]    Loss_Validation:  [[ 1408.35001251]]\n",
      "Loop  1629 :    Loss_Train:  [[ 4853.29050217]]    Loss_Validation:  [[ 1408.35820261]]\n",
      "Loop  1630 :    Loss_Train:  [[ 4853.23424057]]    Loss_Validation:  [[ 1408.3663925]]\n",
      "Loop  1631 :    Loss_Train:  [[ 4853.17808912]]    Loss_Validation:  [[ 1408.37458215]]\n",
      "Loop  1632 :    Loss_Train:  [[ 4853.1220476]]    Loss_Validation:  [[ 1408.38277152]]\n",
      "Loop  1633 :    Loss_Train:  [[ 4853.06611575]]    Loss_Validation:  [[ 1408.39096059]]\n",
      "Loop  1634 :    Loss_Train:  [[ 4853.01029334]]    Loss_Validation:  [[ 1408.39914931]]\n",
      "Loop  1635 :    Loss_Train:  [[ 4852.95458013]]    Loss_Validation:  [[ 1408.40733768]]\n",
      "Loop  1636 :    Loss_Train:  [[ 4852.89897588]]    Loss_Validation:  [[ 1408.41552565]]\n",
      "Loop  1637 :    Loss_Train:  [[ 4852.84348037]]    Loss_Validation:  [[ 1408.42371319]]\n",
      "Loop  1638 :    Loss_Train:  [[ 4852.78809334]]    Loss_Validation:  [[ 1408.43190027]]\n",
      "Loop  1639 :    Loss_Train:  [[ 4852.73281457]]    Loss_Validation:  [[ 1408.44008688]]\n",
      "Loop  1640 :    Loss_Train:  [[ 4852.67764383]]    Loss_Validation:  [[ 1408.44827296]]\n",
      "Loop  1641 :    Loss_Train:  [[ 4852.62258087]]    Loss_Validation:  [[ 1408.45645851]]\n",
      "Loop  1642 :    Loss_Train:  [[ 4852.56762546]]    Loss_Validation:  [[ 1408.46464348]]\n",
      "Loop  1643 :    Loss_Train:  [[ 4852.51277738]]    Loss_Validation:  [[ 1408.47282786]]\n",
      "Loop  1644 :    Loss_Train:  [[ 4852.45803638]]    Loss_Validation:  [[ 1408.4810116]]\n",
      "Loop  1645 :    Loss_Train:  [[ 4852.40340225]]    Loss_Validation:  [[ 1408.48919469]]\n",
      "Loop  1646 :    Loss_Train:  [[ 4852.34887473]]    Loss_Validation:  [[ 1408.49737709]]\n",
      "Loop  1647 :    Loss_Train:  [[ 4852.29445362]]    Loss_Validation:  [[ 1408.50555878]]\n",
      "Loop  1648 :    Loss_Train:  [[ 4852.24013866]]    Loss_Validation:  [[ 1408.51373972]]\n",
      "Loop  1649 :    Loss_Train:  [[ 4852.18592965]]    Loss_Validation:  [[ 1408.5219199]]\n",
      "Loop  1650 :    Loss_Train:  [[ 4852.13182633]]    Loss_Validation:  [[ 1408.53009927]]\n",
      "Loop  1651 :    Loss_Train:  [[ 4852.0778285]]    Loss_Validation:  [[ 1408.53827783]]\n",
      "Loop  1652 :    Loss_Train:  [[ 4852.02393592]]    Loss_Validation:  [[ 1408.54645553]]\n",
      "Loop  1653 :    Loss_Train:  [[ 4851.97014836]]    Loss_Validation:  [[ 1408.55463235]]\n",
      "Loop  1654 :    Loss_Train:  [[ 4851.91646559]]    Loss_Validation:  [[ 1408.56280827]]\n",
      "Loop  1655 :    Loss_Train:  [[ 4851.8628874]]    Loss_Validation:  [[ 1408.57098325]]\n",
      "Loop  1656 :    Loss_Train:  [[ 4851.80941355]]    Loss_Validation:  [[ 1408.57915728]]\n",
      "Loop  1657 :    Loss_Train:  [[ 4851.75604382]]    Loss_Validation:  [[ 1408.58733032]]\n",
      "Loop  1658 :    Loss_Train:  [[ 4851.70277799]]    Loss_Validation:  [[ 1408.59550234]]\n",
      "Loop  1659 :    Loss_Train:  [[ 4851.64961583]]    Loss_Validation:  [[ 1408.60367333]]\n",
      "Loop  1660 :    Loss_Train:  [[ 4851.59655711]]    Loss_Validation:  [[ 1408.61184325]]\n",
      "Loop  1661 :    Loss_Train:  [[ 4851.54360162]]    Loss_Validation:  [[ 1408.62001208]]\n",
      "Loop  1662 :    Loss_Train:  [[ 4851.49074913]]    Loss_Validation:  [[ 1408.6281798]]\n",
      "Loop  1663 :    Loss_Train:  [[ 4851.43799943]]    Loss_Validation:  [[ 1408.63634637]]\n",
      "Loop  1664 :    Loss_Train:  [[ 4851.38535229]]    Loss_Validation:  [[ 1408.64451177]]\n",
      "Loop  1665 :    Loss_Train:  [[ 4851.33280748]]    Loss_Validation:  [[ 1408.65267598]]\n",
      "Loop  1666 :    Loss_Train:  [[ 4851.2803648]]    Loss_Validation:  [[ 1408.66083898]]\n",
      "Loop  1667 :    Loss_Train:  [[ 4851.22802401]]    Loss_Validation:  [[ 1408.66900073]]\n",
      "Loop  1668 :    Loss_Train:  [[ 4851.17578491]]    Loss_Validation:  [[ 1408.67716121]]\n",
      "Loop  1669 :    Loss_Train:  [[ 4851.12364727]]    Loss_Validation:  [[ 1408.6853204]]\n",
      "Loop  1670 :    Loss_Train:  [[ 4851.07161087]]    Loss_Validation:  [[ 1408.69347827]]\n",
      "Loop  1671 :    Loss_Train:  [[ 4851.01967551]]    Loss_Validation:  [[ 1408.7016348]]\n",
      "Loop  1672 :    Loss_Train:  [[ 4850.96784095]]    Loss_Validation:  [[ 1408.70978996]]\n",
      "Loop  1673 :    Loss_Train:  [[ 4850.91610699]]    Loss_Validation:  [[ 1408.71794374]]\n",
      "Loop  1674 :    Loss_Train:  [[ 4850.86447341]]    Loss_Validation:  [[ 1408.72609609]]\n",
      "Loop  1675 :    Loss_Train:  [[ 4850.81293999]]    Loss_Validation:  [[ 1408.73424701]]\n",
      "Loop  1676 :    Loss_Train:  [[ 4850.76150652]]    Loss_Validation:  [[ 1408.74239647]]\n",
      "Loop  1677 :    Loss_Train:  [[ 4850.71017279]]    Loss_Validation:  [[ 1408.75054444]]\n",
      "Loop  1678 :    Loss_Train:  [[ 4850.65893858]]    Loss_Validation:  [[ 1408.7586909]]\n",
      "Loop  1679 :    Loss_Train:  [[ 4850.60780368]]    Loss_Validation:  [[ 1408.76683583]]\n",
      "Loop  1680 :    Loss_Train:  [[ 4850.55676787]]    Loss_Validation:  [[ 1408.7749792]]\n",
      "Loop  1681 :    Loss_Train:  [[ 4850.50583095]]    Loss_Validation:  [[ 1408.783121]]\n",
      "Loop  1682 :    Loss_Train:  [[ 4850.4549927]]    Loss_Validation:  [[ 1408.79126119]]\n",
      "Loop  1683 :    Loss_Train:  [[ 4850.40425291]]    Loss_Validation:  [[ 1408.79939976]]\n",
      "Loop  1684 :    Loss_Train:  [[ 4850.35361138]]    Loss_Validation:  [[ 1408.80753667]]\n",
      "Loop  1685 :    Loss_Train:  [[ 4850.30306788]]    Loss_Validation:  [[ 1408.81567192]]\n",
      "Loop  1686 :    Loss_Train:  [[ 4850.25262222]]    Loss_Validation:  [[ 1408.82380548]]\n",
      "Loop  1687 :    Loss_Train:  [[ 4850.20227418]]    Loss_Validation:  [[ 1408.83193732]]\n",
      "Loop  1688 :    Loss_Train:  [[ 4850.15202356]]    Loss_Validation:  [[ 1408.84006742]]\n",
      "Loop  1689 :    Loss_Train:  [[ 4850.10187014]]    Loss_Validation:  [[ 1408.84819577]]\n",
      "Loop  1690 :    Loss_Train:  [[ 4850.05181372]]    Loss_Validation:  [[ 1408.85632233]]\n",
      "Loop  1691 :    Loss_Train:  [[ 4850.0018541]]    Loss_Validation:  [[ 1408.86444709]]\n",
      "Loop  1692 :    Loss_Train:  [[ 4849.95199106]]    Loss_Validation:  [[ 1408.87257003]]\n",
      "Loop  1693 :    Loss_Train:  [[ 4849.9022244]]    Loss_Validation:  [[ 1408.88069112]]\n",
      "Loop  1694 :    Loss_Train:  [[ 4849.85255392]]    Loss_Validation:  [[ 1408.88881034]]\n",
      "Loop  1695 :    Loss_Train:  [[ 4849.80297941]]    Loss_Validation:  [[ 1408.89692768]]\n",
      "Loop  1696 :    Loss_Train:  [[ 4849.75350066]]    Loss_Validation:  [[ 1408.9050431]]\n",
      "Loop  1697 :    Loss_Train:  [[ 4849.70411748]]    Loss_Validation:  [[ 1408.9131566]]\n",
      "Loop  1698 :    Loss_Train:  [[ 4849.65482965]]    Loss_Validation:  [[ 1408.92126814]]\n",
      "Loop  1699 :    Loss_Train:  [[ 4849.60563698]]    Loss_Validation:  [[ 1408.92937771]]\n",
      "Loop  1700 :    Loss_Train:  [[ 4849.55653927]]    Loss_Validation:  [[ 1408.93748529]]\n",
      "Loop  1701 :    Loss_Train:  [[ 4849.50753631]]    Loss_Validation:  [[ 1408.94559085]]\n",
      "Loop  1702 :    Loss_Train:  [[ 4849.45862789]]    Loss_Validation:  [[ 1408.95369438]]\n",
      "Loop  1703 :    Loss_Train:  [[ 4849.40981383]]    Loss_Validation:  [[ 1408.96179586]]\n",
      "Loop  1704 :    Loss_Train:  [[ 4849.36109391]]    Loss_Validation:  [[ 1408.96989526]]\n",
      "Loop  1705 :    Loss_Train:  [[ 4849.31246795]]    Loss_Validation:  [[ 1408.97799256]]\n",
      "Loop  1706 :    Loss_Train:  [[ 4849.26393574]]    Loss_Validation:  [[ 1408.98608776]]\n",
      "Loop  1707 :    Loss_Train:  [[ 4849.21549707]]    Loss_Validation:  [[ 1408.99418081]]\n",
      "Loop  1708 :    Loss_Train:  [[ 4849.16715176]]    Loss_Validation:  [[ 1409.00227172]]\n",
      "Loop  1709 :    Loss_Train:  [[ 4849.1188996]]    Loss_Validation:  [[ 1409.01036045]]\n",
      "Loop  1710 :    Loss_Train:  [[ 4849.0707404]]    Loss_Validation:  [[ 1409.01844699]]\n",
      "Loop  1711 :    Loss_Train:  [[ 4849.02267397]]    Loss_Validation:  [[ 1409.02653131]]\n",
      "Loop  1712 :    Loss_Train:  [[ 4848.97470009]]    Loss_Validation:  [[ 1409.03461341]]\n",
      "Loop  1713 :    Loss_Train:  [[ 4848.92681858]]    Loss_Validation:  [[ 1409.04269325]]\n",
      "Loop  1714 :    Loss_Train:  [[ 4848.87902925]]    Loss_Validation:  [[ 1409.05077083]]\n",
      "Loop  1715 :    Loss_Train:  [[ 4848.83133189]]    Loss_Validation:  [[ 1409.05884612]]\n",
      "Loop  1716 :    Loss_Train:  [[ 4848.78372631]]    Loss_Validation:  [[ 1409.0669191]]\n",
      "Loop  1717 :    Loss_Train:  [[ 4848.73621232]]    Loss_Validation:  [[ 1409.07498975]]\n",
      "Loop  1718 :    Loss_Train:  [[ 4848.68878973]]    Loss_Validation:  [[ 1409.08305806]]\n",
      "Loop  1719 :    Loss_Train:  [[ 4848.64145834]]    Loss_Validation:  [[ 1409.09112401]]\n",
      "Loop  1720 :    Loss_Train:  [[ 4848.59421795]]    Loss_Validation:  [[ 1409.09918757]]\n",
      "Loop  1721 :    Loss_Train:  [[ 4848.54706839]]    Loss_Validation:  [[ 1409.10724874]]\n",
      "Loop  1722 :    Loss_Train:  [[ 4848.50000945]]    Loss_Validation:  [[ 1409.11530749]]\n",
      "Loop  1723 :    Loss_Train:  [[ 4848.45304094]]    Loss_Validation:  [[ 1409.12336381]]\n",
      "Loop  1724 :    Loss_Train:  [[ 4848.40616267]]    Loss_Validation:  [[ 1409.13141767]]\n",
      "Loop  1725 :    Loss_Train:  [[ 4848.35937445]]    Loss_Validation:  [[ 1409.13946906]]\n",
      "Loop  1726 :    Loss_Train:  [[ 4848.3126761]]    Loss_Validation:  [[ 1409.14751797]]\n",
      "Loop  1727 :    Loss_Train:  [[ 4848.26606742]]    Loss_Validation:  [[ 1409.15556437]]\n",
      "Loop  1728 :    Loss_Train:  [[ 4848.21954822]]    Loss_Validation:  [[ 1409.16360824]]\n",
      "Loop  1729 :    Loss_Train:  [[ 4848.17311832]]    Loss_Validation:  [[ 1409.17164958]]\n",
      "Loop  1730 :    Loss_Train:  [[ 4848.12677752]]    Loss_Validation:  [[ 1409.17968835]]\n",
      "Loop  1731 :    Loss_Train:  [[ 4848.08052565]]    Loss_Validation:  [[ 1409.18772456]]\n",
      "Loop  1732 :    Loss_Train:  [[ 4848.0343625]]    Loss_Validation:  [[ 1409.19575817]]\n",
      "Loop  1733 :    Loss_Train:  [[ 4847.9882879]]    Loss_Validation:  [[ 1409.20378917]]\n",
      "Loop  1734 :    Loss_Train:  [[ 4847.94230166]]    Loss_Validation:  [[ 1409.21181755]]\n",
      "Loop  1735 :    Loss_Train:  [[ 4847.89640359]]    Loss_Validation:  [[ 1409.21984328]]\n",
      "Loop  1736 :    Loss_Train:  [[ 4847.85059351]]    Loss_Validation:  [[ 1409.22786636]]\n",
      "Loop  1737 :    Loss_Train:  [[ 4847.80487123]]    Loss_Validation:  [[ 1409.23588676]]\n",
      "Loop  1738 :    Loss_Train:  [[ 4847.75923657]]    Loss_Validation:  [[ 1409.24390447]]\n",
      "Loop  1739 :    Loss_Train:  [[ 4847.71368934]]    Loss_Validation:  [[ 1409.25191947]]\n",
      "Loop  1740 :    Loss_Train:  [[ 4847.66822936]]    Loss_Validation:  [[ 1409.25993175]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  1741 :    Loss_Train:  [[ 4847.62285645]]    Loss_Validation:  [[ 1409.26794129]]\n",
      "Loop  1742 :    Loss_Train:  [[ 4847.57757042]]    Loss_Validation:  [[ 1409.27594807]]\n",
      "Loop  1743 :    Loss_Train:  [[ 4847.53237109]]    Loss_Validation:  [[ 1409.28395208]]\n",
      "Loop  1744 :    Loss_Train:  [[ 4847.48725829]]    Loss_Validation:  [[ 1409.2919533]]\n",
      "Loop  1745 :    Loss_Train:  [[ 4847.44223182]]    Loss_Validation:  [[ 1409.29995172]]\n",
      "Loop  1746 :    Loss_Train:  [[ 4847.39729151]]    Loss_Validation:  [[ 1409.30794732]]\n",
      "Loop  1747 :    Loss_Train:  [[ 4847.35243717]]    Loss_Validation:  [[ 1409.31594009]]\n",
      "Loop  1748 :    Loss_Train:  [[ 4847.30766863]]    Loss_Validation:  [[ 1409.32393]]\n",
      "Loop  1749 :    Loss_Train:  [[ 4847.26298571]]    Loss_Validation:  [[ 1409.33191706]]\n",
      "Loop  1750 :    Loss_Train:  [[ 4847.21838823]]    Loss_Validation:  [[ 1409.33990123]]\n",
      "Loop  1751 :    Loss_Train:  [[ 4847.173876]]    Loss_Validation:  [[ 1409.34788251]]\n",
      "Loop  1752 :    Loss_Train:  [[ 4847.12944886]]    Loss_Validation:  [[ 1409.35586087]]\n",
      "Loop  1753 :    Loss_Train:  [[ 4847.08510661]]    Loss_Validation:  [[ 1409.36383632]]\n",
      "Loop  1754 :    Loss_Train:  [[ 4847.04084909]]    Loss_Validation:  [[ 1409.37180882]]\n",
      "Loop  1755 :    Loss_Train:  [[ 4846.99667612]]    Loss_Validation:  [[ 1409.37977837]]\n",
      "Loop  1756 :    Loss_Train:  [[ 4846.95258752]]    Loss_Validation:  [[ 1409.38774495]]\n",
      "Loop  1757 :    Loss_Train:  [[ 4846.90858311]]    Loss_Validation:  [[ 1409.39570854]]\n",
      "Loop  1758 :    Loss_Train:  [[ 4846.86466272]]    Loss_Validation:  [[ 1409.40366914]]\n",
      "Loop  1759 :    Loss_Train:  [[ 4846.82082617]]    Loss_Validation:  [[ 1409.41162672]]\n",
      "Loop  1760 :    Loss_Train:  [[ 4846.77707329]]    Loss_Validation:  [[ 1409.41958128]]\n",
      "Loop  1761 :    Loss_Train:  [[ 4846.7334039]]    Loss_Validation:  [[ 1409.4275328]]\n",
      "Loop  1762 :    Loss_Train:  [[ 4846.68981783]]    Loss_Validation:  [[ 1409.43548126]]\n",
      "Loop  1763 :    Loss_Train:  [[ 4846.6463149]]    Loss_Validation:  [[ 1409.44342666]]\n",
      "Loop  1764 :    Loss_Train:  [[ 4846.60289495]]    Loss_Validation:  [[ 1409.45136897]]\n",
      "Loop  1765 :    Loss_Train:  [[ 4846.55955779]]    Loss_Validation:  [[ 1409.45930819]]\n",
      "Loop  1766 :    Loss_Train:  [[ 4846.51630326]]    Loss_Validation:  [[ 1409.46724429]]\n",
      "Loop  1767 :    Loss_Train:  [[ 4846.47313119]]    Loss_Validation:  [[ 1409.47517728]]\n",
      "Loop  1768 :    Loss_Train:  [[ 4846.43004139]]    Loss_Validation:  [[ 1409.48310712]]\n",
      "Loop  1769 :    Loss_Train:  [[ 4846.3870337]]    Loss_Validation:  [[ 1409.49103382]]\n",
      "Loop  1770 :    Loss_Train:  [[ 4846.34410796]]    Loss_Validation:  [[ 1409.49895735]]\n",
      "Loop  1771 :    Loss_Train:  [[ 4846.30126398]]    Loss_Validation:  [[ 1409.5068777]]\n",
      "Loop  1772 :    Loss_Train:  [[ 4846.2585016]]    Loss_Validation:  [[ 1409.51479487]]\n",
      "Loop  1773 :    Loss_Train:  [[ 4846.21582065]]    Loss_Validation:  [[ 1409.52270883]]\n",
      "Loop  1774 :    Loss_Train:  [[ 4846.17322096]]    Loss_Validation:  [[ 1409.53061957]]\n",
      "Loop  1775 :    Loss_Train:  [[ 4846.13070235]]    Loss_Validation:  [[ 1409.53852709]]\n",
      "Loop  1776 :    Loss_Train:  [[ 4846.08826467]]    Loss_Validation:  [[ 1409.54643136]]\n",
      "Loop  1777 :    Loss_Train:  [[ 4846.04590775]]    Loss_Validation:  [[ 1409.55433238]]\n",
      "Loop  1778 :    Loss_Train:  [[ 4846.00363141]]    Loss_Validation:  [[ 1409.56223013]]\n",
      "Loop  1779 :    Loss_Train:  [[ 4845.96143548]]    Loss_Validation:  [[ 1409.57012461]]\n",
      "Loop  1780 :    Loss_Train:  [[ 4845.91931981]]    Loss_Validation:  [[ 1409.57801579]]\n",
      "Loop  1781 :    Loss_Train:  [[ 4845.87728422]]    Loss_Validation:  [[ 1409.58590366]]\n",
      "Loop  1782 :    Loss_Train:  [[ 4845.83532856]]    Loss_Validation:  [[ 1409.59378822]]\n",
      "Loop  1783 :    Loss_Train:  [[ 4845.79345264]]    Loss_Validation:  [[ 1409.60166945]]\n",
      "Loop  1784 :    Loss_Train:  [[ 4845.75165631]]    Loss_Validation:  [[ 1409.60954733]]\n",
      "Loop  1785 :    Loss_Train:  [[ 4845.70993941]]    Loss_Validation:  [[ 1409.61742187]]\n",
      "Loop  1786 :    Loss_Train:  [[ 4845.66830176]]    Loss_Validation:  [[ 1409.62529304]]\n",
      "Loop  1787 :    Loss_Train:  [[ 4845.6267432]]    Loss_Validation:  [[ 1409.63316083]]\n",
      "Loop  1788 :    Loss_Train:  [[ 4845.58526358]]    Loss_Validation:  [[ 1409.64102523]]\n",
      "Loop  1789 :    Loss_Train:  [[ 4845.54386272]]    Loss_Validation:  [[ 1409.64888623]]\n",
      "Loop  1790 :    Loss_Train:  [[ 4845.50254046]]    Loss_Validation:  [[ 1409.65674382]]\n",
      "Loop  1791 :    Loss_Train:  [[ 4845.46129664]]    Loss_Validation:  [[ 1409.66459798]]\n",
      "Loop  1792 :    Loss_Train:  [[ 4845.4201311]]    Loss_Validation:  [[ 1409.67244871]]\n",
      "Loop  1793 :    Loss_Train:  [[ 4845.37904368]]    Loss_Validation:  [[ 1409.68029599]]\n",
      "Loop  1794 :    Loss_Train:  [[ 4845.33803421]]    Loss_Validation:  [[ 1409.68813982]]\n",
      "Loop  1795 :    Loss_Train:  [[ 4845.29710253]]    Loss_Validation:  [[ 1409.69598017]]\n",
      "Loop  1796 :    Loss_Train:  [[ 4845.25624849]]    Loss_Validation:  [[ 1409.70381704]]\n",
      "Loop  1797 :    Loss_Train:  [[ 4845.21547192]]    Loss_Validation:  [[ 1409.71165042]]\n",
      "Loop  1798 :    Loss_Train:  [[ 4845.17477265]]    Loss_Validation:  [[ 1409.7194803]]\n",
      "Loop  1799 :    Loss_Train:  [[ 4845.13415055]]    Loss_Validation:  [[ 1409.72730666]]\n",
      "Loop  1800 :    Loss_Train:  [[ 4845.09360543]]    Loss_Validation:  [[ 1409.7351295]]\n",
      "Loop  1801 :    Loss_Train:  [[ 4845.05313715]]    Loss_Validation:  [[ 1409.7429488]]\n",
      "Loop  1802 :    Loss_Train:  [[ 4845.01274554]]    Loss_Validation:  [[ 1409.75076456]]\n",
      "Loop  1803 :    Loss_Train:  [[ 4844.97243045]]    Loss_Validation:  [[ 1409.75857676]]\n",
      "Loop  1804 :    Loss_Train:  [[ 4844.93219172]]    Loss_Validation:  [[ 1409.76638539]]\n",
      "Loop  1805 :    Loss_Train:  [[ 4844.89202919]]    Loss_Validation:  [[ 1409.77419044]]\n",
      "Loop  1806 :    Loss_Train:  [[ 4844.8519427]]    Loss_Validation:  [[ 1409.78199191]]\n",
      "Loop  1807 :    Loss_Train:  [[ 4844.8119321]]    Loss_Validation:  [[ 1409.78978977]]\n",
      "Loop  1808 :    Loss_Train:  [[ 4844.77199724]]    Loss_Validation:  [[ 1409.79758403]]\n",
      "Loop  1809 :    Loss_Train:  [[ 4844.73213795]]    Loss_Validation:  [[ 1409.80537467]]\n",
      "Loop  1810 :    Loss_Train:  [[ 4844.69235408]]    Loss_Validation:  [[ 1409.81316168]]\n",
      "Loop  1811 :    Loss_Train:  [[ 4844.65264547]]    Loss_Validation:  [[ 1409.82094504]]\n",
      "Loop  1812 :    Loss_Train:  [[ 4844.61301197]]    Loss_Validation:  [[ 1409.82872476]]\n",
      "Loop  1813 :    Loss_Train:  [[ 4844.57345343]]    Loss_Validation:  [[ 1409.83650082]]\n",
      "Loop  1814 :    Loss_Train:  [[ 4844.53396969]]    Loss_Validation:  [[ 1409.84427321]]\n",
      "Loop  1815 :    Loss_Train:  [[ 4844.49456059]]    Loss_Validation:  [[ 1409.85204192]]\n",
      "Loop  1816 :    Loss_Train:  [[ 4844.45522599]]    Loss_Validation:  [[ 1409.85980694]]\n",
      "Loop  1817 :    Loss_Train:  [[ 4844.41596573]]    Loss_Validation:  [[ 1409.86756826]]\n",
      "Loop  1818 :    Loss_Train:  [[ 4844.37677966]]    Loss_Validation:  [[ 1409.87532587]]\n",
      "Loop  1819 :    Loss_Train:  [[ 4844.33766762]]    Loss_Validation:  [[ 1409.88307977]]\n",
      "Loop  1820 :    Loss_Train:  [[ 4844.29862946]]    Loss_Validation:  [[ 1409.89082993]]\n",
      "Loop  1821 :    Loss_Train:  [[ 4844.25966504]]    Loss_Validation:  [[ 1409.89857636]]\n",
      "Loop  1822 :    Loss_Train:  [[ 4844.22077419]]    Loss_Validation:  [[ 1409.90631905]]\n",
      "Loop  1823 :    Loss_Train:  [[ 4844.18195678]]    Loss_Validation:  [[ 1409.91405798]]\n",
      "Loop  1824 :    Loss_Train:  [[ 4844.14321264]]    Loss_Validation:  [[ 1409.92179315]]\n",
      "Loop  1825 :    Loss_Train:  [[ 4844.10454163]]    Loss_Validation:  [[ 1409.92952454]]\n",
      "Loop  1826 :    Loss_Train:  [[ 4844.0659436]]    Loss_Validation:  [[ 1409.93725215]]\n",
      "Loop  1827 :    Loss_Train:  [[ 4844.0274184]]    Loss_Validation:  [[ 1409.94497597]]\n",
      "Loop  1828 :    Loss_Train:  [[ 4843.98896587]]    Loss_Validation:  [[ 1409.95269598]]\n",
      "Loop  1829 :    Loss_Train:  [[ 4843.95058588]]    Loss_Validation:  [[ 1409.96041219]]\n",
      "Loop  1830 :    Loss_Train:  [[ 4843.91227827]]    Loss_Validation:  [[ 1409.96812458]]\n",
      "Loop  1831 :    Loss_Train:  [[ 4843.87404289]]    Loss_Validation:  [[ 1409.97583315]]\n",
      "Loop  1832 :    Loss_Train:  [[ 4843.8358796]]    Loss_Validation:  [[ 1409.98353787]]\n",
      "Loop  1833 :    Loss_Train:  [[ 4843.79778824]]    Loss_Validation:  [[ 1409.99123876]]\n",
      "Loop  1834 :    Loss_Train:  [[ 4843.75976868]]    Loss_Validation:  [[ 1409.99893579]]\n",
      "Loop  1835 :    Loss_Train:  [[ 4843.72182076]]    Loss_Validation:  [[ 1410.00662896]]\n",
      "Loop  1836 :    Loss_Train:  [[ 4843.68394433]]    Loss_Validation:  [[ 1410.01431826]]\n",
      "Loop  1837 :    Loss_Train:  [[ 4843.64613926]]    Loss_Validation:  [[ 1410.02200369]]\n",
      "Loop  1838 :    Loss_Train:  [[ 4843.60840539]]    Loss_Validation:  [[ 1410.02968522]]\n",
      "Loop  1839 :    Loss_Train:  [[ 4843.57074259]]    Loss_Validation:  [[ 1410.03736287]]\n",
      "Loop  1840 :    Loss_Train:  [[ 4843.53315069]]    Loss_Validation:  [[ 1410.04503661]]\n",
      "Loop  1841 :    Loss_Train:  [[ 4843.49562957]]    Loss_Validation:  [[ 1410.05270644]]\n",
      "Loop  1842 :    Loss_Train:  [[ 4843.45817907]]    Loss_Validation:  [[ 1410.06037235]]\n",
      "Loop  1843 :    Loss_Train:  [[ 4843.42079905]]    Loss_Validation:  [[ 1410.06803434]]\n",
      "Loop  1844 :    Loss_Train:  [[ 4843.38348937]]    Loss_Validation:  [[ 1410.07569239]]\n",
      "Loop  1845 :    Loss_Train:  [[ 4843.34624989]]    Loss_Validation:  [[ 1410.0833465]]\n",
      "Loop  1846 :    Loss_Train:  [[ 4843.30908045]]    Loss_Validation:  [[ 1410.09099666]]\n",
      "Loop  1847 :    Loss_Train:  [[ 4843.27198092]]    Loss_Validation:  [[ 1410.09864286]]\n",
      "Loop  1848 :    Loss_Train:  [[ 4843.23495116]]    Loss_Validation:  [[ 1410.1062851]]\n",
      "Loop  1849 :    Loss_Train:  [[ 4843.19799102]]    Loss_Validation:  [[ 1410.11392336]]\n",
      "Loop  1850 :    Loss_Train:  [[ 4843.16110036]]    Loss_Validation:  [[ 1410.12155765]]\n",
      "Loop  1851 :    Loss_Train:  [[ 4843.12427903]]    Loss_Validation:  [[ 1410.12918794]]\n",
      "Loop  1852 :    Loss_Train:  [[ 4843.08752691]]    Loss_Validation:  [[ 1410.13681424]]\n",
      "Loop  1853 :    Loss_Train:  [[ 4843.05084385]]    Loss_Validation:  [[ 1410.14443654]]\n",
      "Loop  1854 :    Loss_Train:  [[ 4843.0142297]]    Loss_Validation:  [[ 1410.15205483]]\n",
      "Loop  1855 :    Loss_Train:  [[ 4842.97768432]]    Loss_Validation:  [[ 1410.1596691]]\n",
      "Loop  1856 :    Loss_Train:  [[ 4842.94120758]]    Loss_Validation:  [[ 1410.16727934]]\n",
      "Loop  1857 :    Loss_Train:  [[ 4842.90479934]]    Loss_Validation:  [[ 1410.17488556]]\n",
      "Loop  1858 :    Loss_Train:  [[ 4842.86845946]]    Loss_Validation:  [[ 1410.18248774]]\n",
      "Loop  1859 :    Loss_Train:  [[ 4842.8321878]]    Loss_Validation:  [[ 1410.19008587]]\n",
      "Loop  1860 :    Loss_Train:  [[ 4842.79598421]]    Loss_Validation:  [[ 1410.19767994]]\n",
      "Loop  1861 :    Loss_Train:  [[ 4842.75984857]]    Loss_Validation:  [[ 1410.20526996]]\n",
      "Loop  1862 :    Loss_Train:  [[ 4842.72378073]]    Loss_Validation:  [[ 1410.21285591]]\n",
      "Loop  1863 :    Loss_Train:  [[ 4842.68778055]]    Loss_Validation:  [[ 1410.22043779]]\n",
      "Loop  1864 :    Loss_Train:  [[ 4842.6518479]]    Loss_Validation:  [[ 1410.22801559]]\n",
      "Loop  1865 :    Loss_Train:  [[ 4842.61598265]]    Loss_Validation:  [[ 1410.2355893]]\n",
      "Loop  1866 :    Loss_Train:  [[ 4842.58018465]]    Loss_Validation:  [[ 1410.24315892]]\n",
      "Loop  1867 :    Loss_Train:  [[ 4842.54445376]]    Loss_Validation:  [[ 1410.25072444]]\n",
      "Loop  1868 :    Loss_Train:  [[ 4842.50878986]]    Loss_Validation:  [[ 1410.25828585]]\n",
      "Loop  1869 :    Loss_Train:  [[ 4842.4731928]]    Loss_Validation:  [[ 1410.26584315]]\n",
      "Loop  1870 :    Loss_Train:  [[ 4842.43766245]]    Loss_Validation:  [[ 1410.27339633]]\n",
      "Loop  1871 :    Loss_Train:  [[ 4842.40219868]]    Loss_Validation:  [[ 1410.28094539]]\n",
      "Loop  1872 :    Loss_Train:  [[ 4842.36680135]]    Loss_Validation:  [[ 1410.28849031]]\n",
      "Loop  1873 :    Loss_Train:  [[ 4842.33147032]]    Loss_Validation:  [[ 1410.2960311]]\n",
      "Loop  1874 :    Loss_Train:  [[ 4842.29620547]]    Loss_Validation:  [[ 1410.30356774]]\n",
      "Loop  1875 :    Loss_Train:  [[ 4842.26100665]]    Loss_Validation:  [[ 1410.31110023]]\n",
      "Loop  1876 :    Loss_Train:  [[ 4842.22587374]]    Loss_Validation:  [[ 1410.31862856]]\n",
      "Loop  1877 :    Loss_Train:  [[ 4842.19080659]]    Loss_Validation:  [[ 1410.32615273]]\n",
      "Loop  1878 :    Loss_Train:  [[ 4842.15580508]]    Loss_Validation:  [[ 1410.33367274]]\n",
      "Loop  1879 :    Loss_Train:  [[ 4842.12086908]]    Loss_Validation:  [[ 1410.34118856]]\n",
      "Loop  1880 :    Loss_Train:  [[ 4842.08599845]]    Loss_Validation:  [[ 1410.34870021]]\n",
      "Loop  1881 :    Loss_Train:  [[ 4842.05119305]]    Loss_Validation:  [[ 1410.35620767]]\n",
      "Loop  1882 :    Loss_Train:  [[ 4842.01645277]]    Loss_Validation:  [[ 1410.36371094]]\n",
      "Loop  1883 :    Loss_Train:  [[ 4841.98177746]]    Loss_Validation:  [[ 1410.37121001]]\n",
      "Loop  1884 :    Loss_Train:  [[ 4841.94716699]]    Loss_Validation:  [[ 1410.37870488]]\n",
      "Loop  1885 :    Loss_Train:  [[ 4841.91262124]]    Loss_Validation:  [[ 1410.38619554]]\n",
      "Loop  1886 :    Loss_Train:  [[ 4841.87814007]]    Loss_Validation:  [[ 1410.39368198]]\n",
      "Loop  1887 :    Loss_Train:  [[ 4841.84372335]]    Loss_Validation:  [[ 1410.4011642]]\n",
      "Loop  1888 :    Loss_Train:  [[ 4841.80937096]]    Loss_Validation:  [[ 1410.4086422]]\n",
      "Loop  1889 :    Loss_Train:  [[ 4841.77508276]]    Loss_Validation:  [[ 1410.41611597]]\n",
      "Loop  1890 :    Loss_Train:  [[ 4841.74085862]]    Loss_Validation:  [[ 1410.4235855]]\n",
      "Loop  1891 :    Loss_Train:  [[ 4841.70669841]]    Loss_Validation:  [[ 1410.43105078]]\n",
      "Loop  1892 :    Loss_Train:  [[ 4841.67260201]]    Loss_Validation:  [[ 1410.43851182]]\n",
      "Loop  1893 :    Loss_Train:  [[ 4841.63856929]]    Loss_Validation:  [[ 1410.44596861]]\n",
      "Loop  1894 :    Loss_Train:  [[ 4841.60460011]]    Loss_Validation:  [[ 1410.45342114]]\n",
      "Loop  1895 :    Loss_Train:  [[ 4841.57069435]]    Loss_Validation:  [[ 1410.4608694]]\n",
      "Loop  1896 :    Loss_Train:  [[ 4841.53685189]]    Loss_Validation:  [[ 1410.4683134]]\n",
      "Loop  1897 :    Loss_Train:  [[ 4841.50307259]]    Loss_Validation:  [[ 1410.47575313]]\n",
      "Loop  1898 :    Loss_Train:  [[ 4841.46935633]]    Loss_Validation:  [[ 1410.48318857]]\n",
      "Loop  1899 :    Loss_Train:  [[ 4841.43570297]]    Loss_Validation:  [[ 1410.49061974]]\n",
      "Loop  1900 :    Loss_Train:  [[ 4841.4021124]]    Loss_Validation:  [[ 1410.49804661]]\n",
      "Loop  1901 :    Loss_Train:  [[ 4841.36858449]]    Loss_Validation:  [[ 1410.50546919]]\n",
      "Loop  1902 :    Loss_Train:  [[ 4841.33511911]]    Loss_Validation:  [[ 1410.51288748]]\n",
      "Loop  1903 :    Loss_Train:  [[ 4841.30171613]]    Loss_Validation:  [[ 1410.52030146]]\n",
      "Loop  1904 :    Loss_Train:  [[ 4841.26837544]]    Loss_Validation:  [[ 1410.52771113]]\n",
      "Loop  1905 :    Loss_Train:  [[ 4841.2350969]]    Loss_Validation:  [[ 1410.5351165]]\n",
      "Loop  1906 :    Loss_Train:  [[ 4841.20188038]]    Loss_Validation:  [[ 1410.54251754]]\n",
      "Loop  1907 :    Loss_Train:  [[ 4841.16872578]]    Loss_Validation:  [[ 1410.54991427]]\n",
      "Loop  1908 :    Loss_Train:  [[ 4841.13563295]]    Loss_Validation:  [[ 1410.55730666]]\n",
      "Loop  1909 :    Loss_Train:  [[ 4841.10260178]]    Loss_Validation:  [[ 1410.56469473]]\n",
      "Loop  1910 :    Loss_Train:  [[ 4841.06963215]]    Loss_Validation:  [[ 1410.57207846]]\n",
      "Loop  1911 :    Loss_Train:  [[ 4841.03672392]]    Loss_Validation:  [[ 1410.57945786]]\n",
      "Loop  1912 :    Loss_Train:  [[ 4841.00387698]]    Loss_Validation:  [[ 1410.58683291]]\n",
      "Loop  1913 :    Loss_Train:  [[ 4840.9710912]]    Loss_Validation:  [[ 1410.59420361]]\n",
      "Loop  1914 :    Loss_Train:  [[ 4840.93836646]]    Loss_Validation:  [[ 1410.60156995]]\n",
      "Loop  1915 :    Loss_Train:  [[ 4840.90570264]]    Loss_Validation:  [[ 1410.60893195]]\n",
      "Loop  1916 :    Loss_Train:  [[ 4840.87309962]]    Loss_Validation:  [[ 1410.61628958]]\n",
      "Loop  1917 :    Loss_Train:  [[ 4840.84055727]]    Loss_Validation:  [[ 1410.62364284]]\n",
      "Loop  1918 :    Loss_Train:  [[ 4840.80807547]]    Loss_Validation:  [[ 1410.63099174]]\n",
      "Loop  1919 :    Loss_Train:  [[ 4840.7756541]]    Loss_Validation:  [[ 1410.63833626]]\n",
      "Loop  1920 :    Loss_Train:  [[ 4840.74329304]]    Loss_Validation:  [[ 1410.64567641]]\n",
      "Loop  1921 :    Loss_Train:  [[ 4840.71099217]]    Loss_Validation:  [[ 1410.65301217]]\n",
      "Loop  1922 :    Loss_Train:  [[ 4840.67875137]]    Loss_Validation:  [[ 1410.66034355]]\n",
      "Loop  1923 :    Loss_Train:  [[ 4840.64657052]]    Loss_Validation:  [[ 1410.66767054]]\n",
      "Loop  1924 :    Loss_Train:  [[ 4840.61444949]]    Loss_Validation:  [[ 1410.67499314]]\n",
      "Loop  1925 :    Loss_Train:  [[ 4840.58238818]]    Loss_Validation:  [[ 1410.68231133]]\n",
      "Loop  1926 :    Loss_Train:  [[ 4840.55038645]]    Loss_Validation:  [[ 1410.68962513]]\n",
      "Loop  1927 :    Loss_Train:  [[ 4840.51844419]]    Loss_Validation:  [[ 1410.69693453]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  1928 :    Loss_Train:  [[ 4840.48656129]]    Loss_Validation:  [[ 1410.70423951]]\n",
      "Loop  1929 :    Loss_Train:  [[ 4840.45473761]]    Loss_Validation:  [[ 1410.71154008]]\n",
      "Loop  1930 :    Loss_Train:  [[ 4840.42297305]]    Loss_Validation:  [[ 1410.71883624]]\n",
      "Loop  1931 :    Loss_Train:  [[ 4840.39126749]]    Loss_Validation:  [[ 1410.72612798]]\n",
      "Loop  1932 :    Loss_Train:  [[ 4840.3596208]]    Loss_Validation:  [[ 1410.73341529]]\n",
      "Loop  1933 :    Loss_Train:  [[ 4840.32803287]]    Loss_Validation:  [[ 1410.74069818]]\n",
      "Loop  1934 :    Loss_Train:  [[ 4840.29650359]]    Loss_Validation:  [[ 1410.74797663]]\n",
      "Loop  1935 :    Loss_Train:  [[ 4840.26503283]]    Loss_Validation:  [[ 1410.75525066]]\n",
      "Loop  1936 :    Loss_Train:  [[ 4840.23362048]]    Loss_Validation:  [[ 1410.76252025]]\n",
      "Loop  1937 :    Loss_Train:  [[ 4840.20226642]]    Loss_Validation:  [[ 1410.76978539]]\n",
      "Loop  1938 :    Loss_Train:  [[ 4840.17097054]]    Loss_Validation:  [[ 1410.7770461]]\n",
      "Loop  1939 :    Loss_Train:  [[ 4840.13973272]]    Loss_Validation:  [[ 1410.78430235]]\n",
      "Loop  1940 :    Loss_Train:  [[ 4840.10855284]]    Loss_Validation:  [[ 1410.79155416]]\n",
      "Loop  1941 :    Loss_Train:  [[ 4840.07743079]]    Loss_Validation:  [[ 1410.79880151]]\n",
      "Loop  1942 :    Loss_Train:  [[ 4840.04636645]]    Loss_Validation:  [[ 1410.80604441]]\n",
      "Loop  1943 :    Loss_Train:  [[ 4840.01535971]]    Loss_Validation:  [[ 1410.81328284]]\n",
      "Loop  1944 :    Loss_Train:  [[ 4839.98441046]]    Loss_Validation:  [[ 1410.82051681]]\n",
      "Loop  1945 :    Loss_Train:  [[ 4839.95351857]]    Loss_Validation:  [[ 1410.82774632]]\n",
      "Loop  1946 :    Loss_Train:  [[ 4839.92268394]]    Loss_Validation:  [[ 1410.83497136]]\n",
      "Loop  1947 :    Loss_Train:  [[ 4839.89190645]]    Loss_Validation:  [[ 1410.84219192]]\n",
      "Loop  1948 :    Loss_Train:  [[ 4839.86118599]]    Loss_Validation:  [[ 1410.84940801]]\n",
      "Loop  1949 :    Loss_Train:  [[ 4839.83052244]]    Loss_Validation:  [[ 1410.85661963]]\n",
      "Loop  1950 :    Loss_Train:  [[ 4839.79991569]]    Loss_Validation:  [[ 1410.86382676]]\n",
      "Loop  1951 :    Loss_Train:  [[ 4839.76936563]]    Loss_Validation:  [[ 1410.8710294]]\n",
      "Loop  1952 :    Loss_Train:  [[ 4839.73887214]]    Loss_Validation:  [[ 1410.87822757]]\n",
      "Loop  1953 :    Loss_Train:  [[ 4839.70843512]]    Loss_Validation:  [[ 1410.88542124]]\n",
      "Loop  1954 :    Loss_Train:  [[ 4839.67805444]]    Loss_Validation:  [[ 1410.89261042]]\n",
      "Loop  1955 :    Loss_Train:  [[ 4839.64773]]    Loss_Validation:  [[ 1410.8997951]]\n",
      "Loop  1956 :    Loss_Train:  [[ 4839.61746169]]    Loss_Validation:  [[ 1410.90697529]]\n",
      "Loop  1957 :    Loss_Train:  [[ 4839.58724939]]    Loss_Validation:  [[ 1410.91415097]]\n",
      "Loop  1958 :    Loss_Train:  [[ 4839.557093]]    Loss_Validation:  [[ 1410.92132215]]\n",
      "Loop  1959 :    Loss_Train:  [[ 4839.52699239]]    Loss_Validation:  [[ 1410.92848883]]\n",
      "Loop  1960 :    Loss_Train:  [[ 4839.49694747]]    Loss_Validation:  [[ 1410.935651]]\n",
      "Loop  1961 :    Loss_Train:  [[ 4839.46695812]]    Loss_Validation:  [[ 1410.94280866]]\n",
      "Loop  1962 :    Loss_Train:  [[ 4839.43702423]]    Loss_Validation:  [[ 1410.94996181]]\n",
      "Loop  1963 :    Loss_Train:  [[ 4839.40714569]]    Loss_Validation:  [[ 1410.95711044]]\n",
      "Loop  1964 :    Loss_Train:  [[ 4839.37732239]]    Loss_Validation:  [[ 1410.96425455]]\n",
      "Loop  1965 :    Loss_Train:  [[ 4839.34755422]]    Loss_Validation:  [[ 1410.97139414]]\n",
      "Loop  1966 :    Loss_Train:  [[ 4839.31784108]]    Loss_Validation:  [[ 1410.97852921]]\n",
      "Loop  1967 :    Loss_Train:  [[ 4839.28818284]]    Loss_Validation:  [[ 1410.98565975]]\n",
      "Loop  1968 :    Loss_Train:  [[ 4839.25857941]]    Loss_Validation:  [[ 1410.99278577]]\n",
      "Loop  1969 :    Loss_Train:  [[ 4839.22903068]]    Loss_Validation:  [[ 1410.99990725]]\n",
      "Loop  1970 :    Loss_Train:  [[ 4839.19953653]]    Loss_Validation:  [[ 1411.00702421]]\n",
      "Loop  1971 :    Loss_Train:  [[ 4839.17009686]]    Loss_Validation:  [[ 1411.01413663]]\n",
      "Loop  1972 :    Loss_Train:  [[ 4839.14071156]]    Loss_Validation:  [[ 1411.02124451]]\n",
      "Loop  1973 :    Loss_Train:  [[ 4839.11138053]]    Loss_Validation:  [[ 1411.02834786]]\n",
      "Loop  1974 :    Loss_Train:  [[ 4839.08210365]]    Loss_Validation:  [[ 1411.03544666]]\n",
      "Loop  1975 :    Loss_Train:  [[ 4839.05288082]]    Loss_Validation:  [[ 1411.04254092]]\n",
      "Loop  1976 :    Loss_Train:  [[ 4839.02371193]]    Loss_Validation:  [[ 1411.04963064]]\n",
      "Loop  1977 :    Loss_Train:  [[ 4838.99459687]]    Loss_Validation:  [[ 1411.05671581]]\n",
      "Loop  1978 :    Loss_Train:  [[ 4838.96553555]]    Loss_Validation:  [[ 1411.06379643]]\n",
      "Loop  1979 :    Loss_Train:  [[ 4838.93652785]]    Loss_Validation:  [[ 1411.0708725]]\n",
      "Loop  1980 :    Loss_Train:  [[ 4838.90757366]]    Loss_Validation:  [[ 1411.07794402]]\n",
      "Loop  1981 :    Loss_Train:  [[ 4838.87867288]]    Loss_Validation:  [[ 1411.08501099]]\n",
      "Loop  1982 :    Loss_Train:  [[ 4838.84982541]]    Loss_Validation:  [[ 1411.09207339]]\n",
      "Loop  1983 :    Loss_Train:  [[ 4838.82103114]]    Loss_Validation:  [[ 1411.09913124]]\n",
      "Loop  1984 :    Loss_Train:  [[ 4838.79228996]]    Loss_Validation:  [[ 1411.10618453]]\n",
      "Loop  1985 :    Loss_Train:  [[ 4838.76360177]]    Loss_Validation:  [[ 1411.11323326]]\n",
      "Loop  1986 :    Loss_Train:  [[ 4838.73496647]]    Loss_Validation:  [[ 1411.12027743]]\n",
      "Loop  1987 :    Loss_Train:  [[ 4838.70638395]]    Loss_Validation:  [[ 1411.12731703]]\n",
      "Loop  1988 :    Loss_Train:  [[ 4838.6778541]]    Loss_Validation:  [[ 1411.13435206]]\n",
      "Loop  1989 :    Loss_Train:  [[ 4838.64937683]]    Loss_Validation:  [[ 1411.14138252]]\n",
      "Loop  1990 :    Loss_Train:  [[ 4838.62095203]]    Loss_Validation:  [[ 1411.14840842]]\n",
      "Loop  1991 :    Loss_Train:  [[ 4838.59257959]]    Loss_Validation:  [[ 1411.15542974]]\n",
      "Loop  1992 :    Loss_Train:  [[ 4838.56425941]]    Loss_Validation:  [[ 1411.16244649]]\n",
      "Loop  1993 :    Loss_Train:  [[ 4838.53599139]]    Loss_Validation:  [[ 1411.16945866]]\n",
      "Loop  1994 :    Loss_Train:  [[ 4838.50777543]]    Loss_Validation:  [[ 1411.17646626]]\n",
      "Loop  1995 :    Loss_Train:  [[ 4838.47961143]]    Loss_Validation:  [[ 1411.18346928]]\n",
      "Loop  1996 :    Loss_Train:  [[ 4838.45149927]]    Loss_Validation:  [[ 1411.19046772]]\n",
      "Loop  1997 :    Loss_Train:  [[ 4838.42343886]]    Loss_Validation:  [[ 1411.19746158]]\n",
      "Loop  1998 :    Loss_Train:  [[ 4838.3954301]]    Loss_Validation:  [[ 1411.20445085]]\n",
      "Loop  1999 :    Loss_Train:  [[ 4838.36747289]]    Loss_Validation:  [[ 1411.21143555]]\n",
      "Loop  2000 :    Loss_Train:  [[ 4838.33956712]]    Loss_Validation:  [[ 1411.21841565]]\n",
      "Loop  2001 :    Loss_Train:  [[ 4838.31171269]]    Loss_Validation:  [[ 1411.22539118]]\n",
      "Loop  2002 :    Loss_Train:  [[ 4838.28390951]]    Loss_Validation:  [[ 1411.23236211]]\n",
      "Loop  2003 :    Loss_Train:  [[ 4838.25615746]]    Loss_Validation:  [[ 1411.23932846]]\n",
      "Loop  2004 :    Loss_Train:  [[ 4838.22845646]]    Loss_Validation:  [[ 1411.24629021]]\n",
      "Loop  2005 :    Loss_Train:  [[ 4838.20080639]]    Loss_Validation:  [[ 1411.25324738]]\n",
      "Loop  2006 :    Loss_Train:  [[ 4838.17320717]]    Loss_Validation:  [[ 1411.26019995]]\n",
      "Loop  2007 :    Loss_Train:  [[ 4838.14565868]]    Loss_Validation:  [[ 1411.26714793]]\n",
      "Loop  2008 :    Loss_Train:  [[ 4838.11816084]]    Loss_Validation:  [[ 1411.27409131]]\n",
      "Loop  2009 :    Loss_Train:  [[ 4838.09071354]]    Loss_Validation:  [[ 1411.2810301]]\n",
      "Loop  2010 :    Loss_Train:  [[ 4838.06331667]]    Loss_Validation:  [[ 1411.28796429]]\n",
      "Loop  2011 :    Loss_Train:  [[ 4838.03597015]]    Loss_Validation:  [[ 1411.29489389]]\n",
      "Loop  2012 :    Loss_Train:  [[ 4838.00867388]]    Loss_Validation:  [[ 1411.30181888]]\n",
      "Loop  2013 :    Loss_Train:  [[ 4837.98142775]]    Loss_Validation:  [[ 1411.30873927]]\n",
      "Loop  2014 :    Loss_Train:  [[ 4837.95423166]]    Loss_Validation:  [[ 1411.31565507]]\n",
      "Loop  2015 :    Loss_Train:  [[ 4837.92708552]]    Loss_Validation:  [[ 1411.32256626]]\n",
      "Loop  2016 :    Loss_Train:  [[ 4837.89998924]]    Loss_Validation:  [[ 1411.32947285]]\n",
      "Loop  2017 :    Loss_Train:  [[ 4837.8729427]]    Loss_Validation:  [[ 1411.33637483]]\n",
      "Loop  2018 :    Loss_Train:  [[ 4837.84594582]]    Loss_Validation:  [[ 1411.34327221]]\n",
      "Loop  2019 :    Loss_Train:  [[ 4837.8189985]]    Loss_Validation:  [[ 1411.35016499]]\n",
      "Loop  2020 :    Loss_Train:  [[ 4837.79210064]]    Loss_Validation:  [[ 1411.35705315]]\n",
      "Loop  2021 :    Loss_Train:  [[ 4837.76525214]]    Loss_Validation:  [[ 1411.36393672]]\n",
      "Loop  2022 :    Loss_Train:  [[ 4837.73845291]]    Loss_Validation:  [[ 1411.37081567]]\n",
      "Loop  2023 :    Loss_Train:  [[ 4837.71170284]]    Loss_Validation:  [[ 1411.37769001]]\n",
      "Loop  2024 :    Loss_Train:  [[ 4837.68500186]]    Loss_Validation:  [[ 1411.38455975]]\n",
      "Loop  2025 :    Loss_Train:  [[ 4837.65834985]]    Loss_Validation:  [[ 1411.39142487]]\n",
      "Loop  2026 :    Loss_Train:  [[ 4837.63174672]]    Loss_Validation:  [[ 1411.39828539]]\n",
      "Loop  2027 :    Loss_Train:  [[ 4837.60519237]]    Loss_Validation:  [[ 1411.40514129]]\n",
      "Loop  2028 :    Loss_Train:  [[ 4837.57868672]]    Loss_Validation:  [[ 1411.41199258]]\n",
      "Loop  2029 :    Loss_Train:  [[ 4837.55222966]]    Loss_Validation:  [[ 1411.41883926]]\n",
      "Loop  2030 :    Loss_Train:  [[ 4837.52582111]]    Loss_Validation:  [[ 1411.42568132]]\n",
      "Loop  2031 :    Loss_Train:  [[ 4837.49946095]]    Loss_Validation:  [[ 1411.43251877]]\n",
      "Loop  2032 :    Loss_Train:  [[ 4837.47314911]]    Loss_Validation:  [[ 1411.43935161]]\n",
      "Loop  2033 :    Loss_Train:  [[ 4837.44688549]]    Loss_Validation:  [[ 1411.44617983]]\n",
      "Loop  2034 :    Loss_Train:  [[ 4837.42066998]]    Loss_Validation:  [[ 1411.45300343]]\n",
      "Loop  2035 :    Loss_Train:  [[ 4837.39450251]]    Loss_Validation:  [[ 1411.45982242]]\n",
      "Loop  2036 :    Loss_Train:  [[ 4837.36838297]]    Loss_Validation:  [[ 1411.46663679]]\n",
      "Loop  2037 :    Loss_Train:  [[ 4837.34231126]]    Loss_Validation:  [[ 1411.47344655]]\n",
      "Loop  2038 :    Loss_Train:  [[ 4837.31628731]]    Loss_Validation:  [[ 1411.48025169]]\n",
      "Loop  2039 :    Loss_Train:  [[ 4837.29031101]]    Loss_Validation:  [[ 1411.48705221]]\n",
      "Loop  2040 :    Loss_Train:  [[ 4837.26438227]]    Loss_Validation:  [[ 1411.49384811]]\n",
      "Loop  2041 :    Loss_Train:  [[ 4837.23850099]]    Loss_Validation:  [[ 1411.5006394]]\n",
      "Loop  2042 :    Loss_Train:  [[ 4837.2126671]]    Loss_Validation:  [[ 1411.50742606]]\n",
      "Loop  2043 :    Loss_Train:  [[ 4837.18688048]]    Loss_Validation:  [[ 1411.51420811]]\n",
      "Loop  2044 :    Loss_Train:  [[ 4837.16114106]]    Loss_Validation:  [[ 1411.52098554]]\n",
      "Loop  2045 :    Loss_Train:  [[ 4837.13544873]]    Loss_Validation:  [[ 1411.52775834]]\n",
      "Loop  2046 :    Loss_Train:  [[ 4837.10980341]]    Loss_Validation:  [[ 1411.53452653]]\n",
      "Loop  2047 :    Loss_Train:  [[ 4837.084205]]    Loss_Validation:  [[ 1411.5412901]]\n",
      "Loop  2048 :    Loss_Train:  [[ 4837.05865342]]    Loss_Validation:  [[ 1411.54804905]]\n",
      "Loop  2049 :    Loss_Train:  [[ 4837.03314857]]    Loss_Validation:  [[ 1411.55480337]]\n",
      "Loop  2050 :    Loss_Train:  [[ 4837.00769036]]    Loss_Validation:  [[ 1411.56155308]]\n",
      "Loop  2051 :    Loss_Train:  [[ 4836.9822787]]    Loss_Validation:  [[ 1411.56829817]]\n",
      "Loop  2052 :    Loss_Train:  [[ 4836.9569135]]    Loss_Validation:  [[ 1411.57503863]]\n",
      "Loop  2053 :    Loss_Train:  [[ 4836.93159467]]    Loss_Validation:  [[ 1411.58177448]]\n",
      "Loop  2054 :    Loss_Train:  [[ 4836.90632211]]    Loss_Validation:  [[ 1411.5885057]]\n",
      "Loop  2055 :    Loss_Train:  [[ 4836.88109575]]    Loss_Validation:  [[ 1411.5952323]]\n",
      "Loop  2056 :    Loss_Train:  [[ 4836.85591548]]    Loss_Validation:  [[ 1411.60195429]]\n",
      "Loop  2057 :    Loss_Train:  [[ 4836.83078122]]    Loss_Validation:  [[ 1411.60867165]]\n",
      "Loop  2058 :    Loss_Train:  [[ 4836.80569289]]    Loss_Validation:  [[ 1411.61538439]]\n",
      "Loop  2059 :    Loss_Train:  [[ 4836.78065038]]    Loss_Validation:  [[ 1411.6220925]]\n",
      "Loop  2060 :    Loss_Train:  [[ 4836.75565361]]    Loss_Validation:  [[ 1411.628796]]\n",
      "Loop  2061 :    Loss_Train:  [[ 4836.73070249]]    Loss_Validation:  [[ 1411.63549488]]\n",
      "Loop  2062 :    Loss_Train:  [[ 4836.70579694]]    Loss_Validation:  [[ 1411.64218914]]\n",
      "Loop  2063 :    Loss_Train:  [[ 4836.68093686]]    Loss_Validation:  [[ 1411.64887877]]\n",
      "Loop  2064 :    Loss_Train:  [[ 4836.65612217]]    Loss_Validation:  [[ 1411.65556379]]\n",
      "Loop  2065 :    Loss_Train:  [[ 4836.63135278]]    Loss_Validation:  [[ 1411.66224418]]\n",
      "Loop  2066 :    Loss_Train:  [[ 4836.60662859]]    Loss_Validation:  [[ 1411.66891995]]\n",
      "Loop  2067 :    Loss_Train:  [[ 4836.58194953]]    Loss_Validation:  [[ 1411.67559111]]\n",
      "Loop  2068 :    Loss_Train:  [[ 4836.5573155]]    Loss_Validation:  [[ 1411.68225764]]\n",
      "Loop  2069 :    Loss_Train:  [[ 4836.53272642]]    Loss_Validation:  [[ 1411.68891956]]\n",
      "Loop  2070 :    Loss_Train:  [[ 4836.5081822]]    Loss_Validation:  [[ 1411.69557685]]\n",
      "Loop  2071 :    Loss_Train:  [[ 4836.48368275]]    Loss_Validation:  [[ 1411.70222953]]\n",
      "Loop  2072 :    Loss_Train:  [[ 4836.45922799]]    Loss_Validation:  [[ 1411.70887758]]\n",
      "Loop  2073 :    Loss_Train:  [[ 4836.43481782]]    Loss_Validation:  [[ 1411.71552102]]\n",
      "Loop  2074 :    Loss_Train:  [[ 4836.41045217]]    Loss_Validation:  [[ 1411.72215984]]\n",
      "Loop  2075 :    Loss_Train:  [[ 4836.38613095]]    Loss_Validation:  [[ 1411.72879404]]\n",
      "Loop  2076 :    Loss_Train:  [[ 4836.36185406]]    Loss_Validation:  [[ 1411.73542363]]\n",
      "Loop  2077 :    Loss_Train:  [[ 4836.33762143]]    Loss_Validation:  [[ 1411.7420486]]\n",
      "Loop  2078 :    Loss_Train:  [[ 4836.31343297]]    Loss_Validation:  [[ 1411.74866895]]\n",
      "Loop  2079 :    Loss_Train:  [[ 4836.28928859]]    Loss_Validation:  [[ 1411.75528468]]\n",
      "Loop  2080 :    Loss_Train:  [[ 4836.2651882]]    Loss_Validation:  [[ 1411.7618958]]\n",
      "Loop  2081 :    Loss_Train:  [[ 4836.24113173]]    Loss_Validation:  [[ 1411.7685023]]\n",
      "Loop  2082 :    Loss_Train:  [[ 4836.21711909]]    Loss_Validation:  [[ 1411.77510419]]\n",
      "Loop  2083 :    Loss_Train:  [[ 4836.19315019]]    Loss_Validation:  [[ 1411.78170146]]\n",
      "Loop  2084 :    Loss_Train:  [[ 4836.16922494]]    Loss_Validation:  [[ 1411.78829412]]\n",
      "Loop  2085 :    Loss_Train:  [[ 4836.14534327]]    Loss_Validation:  [[ 1411.79488216]]\n",
      "Loop  2086 :    Loss_Train:  [[ 4836.12150509]]    Loss_Validation:  [[ 1411.80146559]]\n",
      "Loop  2087 :    Loss_Train:  [[ 4836.09771031]]    Loss_Validation:  [[ 1411.80804441]]\n",
      "Loop  2088 :    Loss_Train:  [[ 4836.07395885]]    Loss_Validation:  [[ 1411.81461862]]\n",
      "Loop  2089 :    Loss_Train:  [[ 4836.05025063]]    Loss_Validation:  [[ 1411.82118822]]\n",
      "Loop  2090 :    Loss_Train:  [[ 4836.02658556]]    Loss_Validation:  [[ 1411.8277532]]\n",
      "Loop  2091 :    Loss_Train:  [[ 4836.00296356]]    Loss_Validation:  [[ 1411.83431357]]\n",
      "Loop  2092 :    Loss_Train:  [[ 4835.97938455]]    Loss_Validation:  [[ 1411.84086934]]\n",
      "Loop  2093 :    Loss_Train:  [[ 4835.95584843]]    Loss_Validation:  [[ 1411.84742049]]\n",
      "Loop  2094 :    Loss_Train:  [[ 4835.93235514]]    Loss_Validation:  [[ 1411.85396704]]\n",
      "Loop  2095 :    Loss_Train:  [[ 4835.90890459]]    Loss_Validation:  [[ 1411.86050898]]\n",
      "Loop  2096 :    Loss_Train:  [[ 4835.88549669]]    Loss_Validation:  [[ 1411.86704631]]\n",
      "Loop  2097 :    Loss_Train:  [[ 4835.86213137]]    Loss_Validation:  [[ 1411.87357904]]\n",
      "Loop  2098 :    Loss_Train:  [[ 4835.83880853]]    Loss_Validation:  [[ 1411.88010716]]\n",
      "Loop  2099 :    Loss_Train:  [[ 4835.81552811]]    Loss_Validation:  [[ 1411.88663067]]\n",
      "Loop  2100 :    Loss_Train:  [[ 4835.79229]]    Loss_Validation:  [[ 1411.89314959]]\n",
      "Loop  2101 :    Loss_Train:  [[ 4835.76909415]]    Loss_Validation:  [[ 1411.89966389]]\n",
      "Loop  2102 :    Loss_Train:  [[ 4835.74594045]]    Loss_Validation:  [[ 1411.9061736]]\n",
      "Loop  2103 :    Loss_Train:  [[ 4835.72282884]]    Loss_Validation:  [[ 1411.9126787]]\n",
      "Loop  2104 :    Loss_Train:  [[ 4835.69975923]]    Loss_Validation:  [[ 1411.91917921]]\n",
      "Loop  2105 :    Loss_Train:  [[ 4835.67673154]]    Loss_Validation:  [[ 1411.92567511]]\n",
      "Loop  2106 :    Loss_Train:  [[ 4835.65374569]]    Loss_Validation:  [[ 1411.93216641]]\n",
      "Loop  2107 :    Loss_Train:  [[ 4835.63080159]]    Loss_Validation:  [[ 1411.93865312]]\n",
      "Loop  2108 :    Loss_Train:  [[ 4835.60789918]]    Loss_Validation:  [[ 1411.94513522]]\n",
      "Loop  2109 :    Loss_Train:  [[ 4835.58503836]]    Loss_Validation:  [[ 1411.95161273]]\n",
      "Loop  2110 :    Loss_Train:  [[ 4835.56221905]]    Loss_Validation:  [[ 1411.95808565]]\n",
      "Loop  2111 :    Loss_Train:  [[ 4835.53944119]]    Loss_Validation:  [[ 1411.96455397]]\n",
      "Loop  2112 :    Loss_Train:  [[ 4835.51670468]]    Loss_Validation:  [[ 1411.9710177]]\n",
      "Loop  2113 :    Loss_Train:  [[ 4835.49400945]]    Loss_Validation:  [[ 1411.97747683]]\n",
      "Loop  2114 :    Loss_Train:  [[ 4835.47135541]]    Loss_Validation:  [[ 1411.98393137]]\n",
      "Loop  2115 :    Loss_Train:  [[ 4835.4487425]]    Loss_Validation:  [[ 1411.99038132]]\n",
      "Loop  2116 :    Loss_Train:  [[ 4835.42617062]]    Loss_Validation:  [[ 1411.99682668]]\n",
      "Loop  2117 :    Loss_Train:  [[ 4835.40363971]]    Loss_Validation:  [[ 1412.00326745]]\n",
      "Loop  2118 :    Loss_Train:  [[ 4835.38114967]]    Loss_Validation:  [[ 1412.00970363]]\n",
      "Loop  2119 :    Loss_Train:  [[ 4835.35870044]]    Loss_Validation:  [[ 1412.01613523]]\n",
      "Loop  2120 :    Loss_Train:  [[ 4835.33629194]]    Loss_Validation:  [[ 1412.02256224]]\n",
      "Loop  2121 :    Loss_Train:  [[ 4835.31392408]]    Loss_Validation:  [[ 1412.02898467]]\n",
      "Loop  2122 :    Loss_Train:  [[ 4835.29159679]]    Loss_Validation:  [[ 1412.03540251]]\n",
      "Loop  2123 :    Loss_Train:  [[ 4835.26930999]]    Loss_Validation:  [[ 1412.04181577]]\n",
      "Loop  2124 :    Loss_Train:  [[ 4835.2470636]]    Loss_Validation:  [[ 1412.04822444]]\n",
      "Loop  2125 :    Loss_Train:  [[ 4835.22485754]]    Loss_Validation:  [[ 1412.05462854]]\n",
      "Loop  2126 :    Loss_Train:  [[ 4835.20269174]]    Loss_Validation:  [[ 1412.06102806]]\n",
      "Loop  2127 :    Loss_Train:  [[ 4835.18056613]]    Loss_Validation:  [[ 1412.06742299]]\n",
      "Loop  2128 :    Loss_Train:  [[ 4835.15848061]]    Loss_Validation:  [[ 1412.07381336]]\n",
      "Loop  2129 :    Loss_Train:  [[ 4835.13643512]]    Loss_Validation:  [[ 1412.08019914]]\n",
      "Loop  2130 :    Loss_Train:  [[ 4835.11442958]]    Loss_Validation:  [[ 1412.08658035]]\n",
      "Loop  2131 :    Loss_Train:  [[ 4835.09246391]]    Loss_Validation:  [[ 1412.09295699]]\n",
      "Loop  2132 :    Loss_Train:  [[ 4835.07053804]]    Loss_Validation:  [[ 1412.09932906]]\n",
      "Loop  2133 :    Loss_Train:  [[ 4835.04865188]]    Loss_Validation:  [[ 1412.10569655]]\n",
      "Loop  2134 :    Loss_Train:  [[ 4835.02680537]]    Loss_Validation:  [[ 1412.11205947]]\n",
      "Loop  2135 :    Loss_Train:  [[ 4835.00499842]]    Loss_Validation:  [[ 1412.11841783]]\n",
      "Loop  2136 :    Loss_Train:  [[ 4834.98323097]]    Loss_Validation:  [[ 1412.12477162]]\n",
      "Loop  2137 :    Loss_Train:  [[ 4834.96150293]]    Loss_Validation:  [[ 1412.13112084]]\n",
      "Loop  2138 :    Loss_Train:  [[ 4834.93981423]]    Loss_Validation:  [[ 1412.1374655]]\n",
      "Loop  2139 :    Loss_Train:  [[ 4834.91816479]]    Loss_Validation:  [[ 1412.14380559]]\n",
      "Loop  2140 :    Loss_Train:  [[ 4834.89655455]]    Loss_Validation:  [[ 1412.15014112]]\n",
      "Loop  2141 :    Loss_Train:  [[ 4834.87498341]]    Loss_Validation:  [[ 1412.15647209]]\n",
      "Loop  2142 :    Loss_Train:  [[ 4834.85345132]]    Loss_Validation:  [[ 1412.1627985]]\n",
      "Loop  2143 :    Loss_Train:  [[ 4834.83195818]]    Loss_Validation:  [[ 1412.16912036]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  2144 :    Loss_Train:  [[ 4834.81050394]]    Loss_Validation:  [[ 1412.17543765]]\n",
      "Loop  2145 :    Loss_Train:  [[ 4834.78908852]]    Loss_Validation:  [[ 1412.18175039]]\n",
      "Loop  2146 :    Loss_Train:  [[ 4834.76771183]]    Loss_Validation:  [[ 1412.18805858]]\n",
      "Loop  2147 :    Loss_Train:  [[ 4834.74637381]]    Loss_Validation:  [[ 1412.19436221]]\n",
      "Loop  2148 :    Loss_Train:  [[ 4834.72507438]]    Loss_Validation:  [[ 1412.20066129]]\n",
      "Loop  2149 :    Loss_Train:  [[ 4834.70381347]]    Loss_Validation:  [[ 1412.20695582]]\n",
      "Loop  2150 :    Loss_Train:  [[ 4834.682591]]    Loss_Validation:  [[ 1412.21324581]]\n",
      "Loop  2151 :    Loss_Train:  [[ 4834.66140691]]    Loss_Validation:  [[ 1412.21953124]]\n",
      "Loop  2152 :    Loss_Train:  [[ 4834.64026111]]    Loss_Validation:  [[ 1412.22581214]]\n",
      "Loop  2153 :    Loss_Train:  [[ 4834.61915354]]    Loss_Validation:  [[ 1412.23208848]]\n",
      "Loop  2154 :    Loss_Train:  [[ 4834.59808412]]    Loss_Validation:  [[ 1412.23836029]]\n",
      "Loop  2155 :    Loss_Train:  [[ 4834.57705278]]    Loss_Validation:  [[ 1412.24462755]]\n",
      "Loop  2156 :    Loss_Train:  [[ 4834.55605944]]    Loss_Validation:  [[ 1412.25089027]]\n",
      "Loop  2157 :    Loss_Train:  [[ 4834.53510403]]    Loss_Validation:  [[ 1412.25714846]]\n",
      "Loop  2158 :    Loss_Train:  [[ 4834.51418649]]    Loss_Validation:  [[ 1412.2634021]]\n",
      "Loop  2159 :    Loss_Train:  [[ 4834.49330674]]    Loss_Validation:  [[ 1412.26965122]]\n",
      "Loop  2160 :    Loss_Train:  [[ 4834.4724647]]    Loss_Validation:  [[ 1412.2758958]]\n",
      "Loop  2161 :    Loss_Train:  [[ 4834.4516603]]    Loss_Validation:  [[ 1412.28213584]]\n",
      "Loop  2162 :    Loss_Train:  [[ 4834.43089348]]    Loss_Validation:  [[ 1412.28837136]]\n",
      "Loop  2163 :    Loss_Train:  [[ 4834.41016415]]    Loss_Validation:  [[ 1412.29460235]]\n",
      "Loop  2164 :    Loss_Train:  [[ 4834.38947226]]    Loss_Validation:  [[ 1412.30082881]]\n",
      "Loop  2165 :    Loss_Train:  [[ 4834.36881772]]    Loss_Validation:  [[ 1412.30705074]]\n",
      "Loop  2166 :    Loss_Train:  [[ 4834.34820047]]    Loss_Validation:  [[ 1412.31326816]]\n",
      "Loop  2167 :    Loss_Train:  [[ 4834.32762043]]    Loss_Validation:  [[ 1412.31948104]]\n",
      "Loop  2168 :    Loss_Train:  [[ 4834.30707753]]    Loss_Validation:  [[ 1412.32568941]]\n",
      "Loop  2169 :    Loss_Train:  [[ 4834.28657171]]    Loss_Validation:  [[ 1412.33189326]]\n",
      "Loop  2170 :    Loss_Train:  [[ 4834.26610289]]    Loss_Validation:  [[ 1412.33809259]]\n",
      "Loop  2171 :    Loss_Train:  [[ 4834.24567101]]    Loss_Validation:  [[ 1412.3442874]]\n",
      "Loop  2172 :    Loss_Train:  [[ 4834.22527598]]    Loss_Validation:  [[ 1412.3504777]]\n",
      "Loop  2173 :    Loss_Train:  [[ 4834.20491774]]    Loss_Validation:  [[ 1412.35666349]]\n",
      "Loop  2174 :    Loss_Train:  [[ 4834.18459623]]    Loss_Validation:  [[ 1412.36284477]]\n",
      "Loop  2175 :    Loss_Train:  [[ 4834.16431136]]    Loss_Validation:  [[ 1412.36902153]]\n",
      "Loop  2176 :    Loss_Train:  [[ 4834.14406308]]    Loss_Validation:  [[ 1412.37519379]]\n",
      "Loop  2177 :    Loss_Train:  [[ 4834.12385131]]    Loss_Validation:  [[ 1412.38136155]]\n",
      "Loop  2178 :    Loss_Train:  [[ 4834.10367598]]    Loss_Validation:  [[ 1412.38752479]]\n",
      "Loop  2179 :    Loss_Train:  [[ 4834.08353702]]    Loss_Validation:  [[ 1412.39368354]]\n",
      "Loop  2180 :    Loss_Train:  [[ 4834.06343437]]    Loss_Validation:  [[ 1412.39983779]]\n",
      "Loop  2181 :    Loss_Train:  [[ 4834.04336794]]    Loss_Validation:  [[ 1412.40598754]]\n",
      "Loop  2182 :    Loss_Train:  [[ 4834.02333769]]    Loss_Validation:  [[ 1412.41213279]]\n",
      "Loop  2183 :    Loss_Train:  [[ 4834.00334353]]    Loss_Validation:  [[ 1412.41827354]]\n",
      "Loop  2184 :    Loss_Train:  [[ 4833.98338539]]    Loss_Validation:  [[ 1412.4244098]]\n",
      "Loop  2185 :    Loss_Train:  [[ 4833.96346322]]    Loss_Validation:  [[ 1412.43054157]]\n",
      "Loop  2186 :    Loss_Train:  [[ 4833.94357694]]    Loss_Validation:  [[ 1412.43666885]]\n",
      "Loop  2187 :    Loss_Train:  [[ 4833.92372648]]    Loss_Validation:  [[ 1412.44279164]]\n",
      "Loop  2188 :    Loss_Train:  [[ 4833.90391177]]    Loss_Validation:  [[ 1412.44890995]]\n",
      "Loop  2189 :    Loss_Train:  [[ 4833.88413275]]    Loss_Validation:  [[ 1412.45502377]]\n",
      "Loop  2190 :    Loss_Train:  [[ 4833.86438934]]    Loss_Validation:  [[ 1412.46113311]]\n",
      "Loop  2191 :    Loss_Train:  [[ 4833.84468149]]    Loss_Validation:  [[ 1412.46723796]]\n",
      "Loop  2192 :    Loss_Train:  [[ 4833.82500912]]    Loss_Validation:  [[ 1412.47333834]]\n",
      "Loop  2193 :    Loss_Train:  [[ 4833.80537217]]    Loss_Validation:  [[ 1412.47943424]]\n",
      "Loop  2194 :    Loss_Train:  [[ 4833.78577056]]    Loss_Validation:  [[ 1412.48552567]]\n",
      "Loop  2195 :    Loss_Train:  [[ 4833.76620424]]    Loss_Validation:  [[ 1412.49161262]]\n",
      "Loop  2196 :    Loss_Train:  [[ 4833.74667312]]    Loss_Validation:  [[ 1412.4976951]]\n",
      "Loop  2197 :    Loss_Train:  [[ 4833.72717716]]    Loss_Validation:  [[ 1412.50377311]]\n",
      "Loop  2198 :    Loss_Train:  [[ 4833.70771628]]    Loss_Validation:  [[ 1412.50984665]]\n",
      "Loop  2199 :    Loss_Train:  [[ 4833.68829041]]    Loss_Validation:  [[ 1412.51591573]]\n",
      "Loop  2200 :    Loss_Train:  [[ 4833.66889949]]    Loss_Validation:  [[ 1412.52198034]]\n",
      "Loop  2201 :    Loss_Train:  [[ 4833.64954345]]    Loss_Validation:  [[ 1412.5280405]]\n",
      "Loop  2202 :    Loss_Train:  [[ 4833.63022222]]    Loss_Validation:  [[ 1412.53409619]]\n",
      "Loop  2203 :    Loss_Train:  [[ 4833.61093574]]    Loss_Validation:  [[ 1412.54014742]]\n",
      "Loop  2204 :    Loss_Train:  [[ 4833.59168395]]    Loss_Validation:  [[ 1412.5461942]]\n",
      "Loop  2205 :    Loss_Train:  [[ 4833.57246677]]    Loss_Validation:  [[ 1412.55223652]]\n",
      "Loop  2206 :    Loss_Train:  [[ 4833.55328415]]    Loss_Validation:  [[ 1412.55827439]]\n",
      "Loop  2207 :    Loss_Train:  [[ 4833.53413601]]    Loss_Validation:  [[ 1412.56430781]]\n",
      "Loop  2208 :    Loss_Train:  [[ 4833.51502229]]    Loss_Validation:  [[ 1412.57033679]]\n",
      "Loop  2209 :    Loss_Train:  [[ 4833.49594292]]    Loss_Validation:  [[ 1412.57636131]]\n",
      "Loop  2210 :    Loss_Train:  [[ 4833.47689785]]    Loss_Validation:  [[ 1412.5823814]]\n",
      "Loop  2211 :    Loss_Train:  [[ 4833.457887]]    Loss_Validation:  [[ 1412.58839704]]\n",
      "Loop  2212 :    Loss_Train:  [[ 4833.43891032]]    Loss_Validation:  [[ 1412.59440824]]\n",
      "Loop  2213 :    Loss_Train:  [[ 4833.41996772]]    Loss_Validation:  [[ 1412.600415]]\n",
      "Loop  2214 :    Loss_Train:  [[ 4833.40105916]]    Loss_Validation:  [[ 1412.60641733]]\n",
      "Loop  2215 :    Loss_Train:  [[ 4833.38218457]]    Loss_Validation:  [[ 1412.61241522]]\n",
      "Loop  2216 :    Loss_Train:  [[ 4833.36334388]]    Loss_Validation:  [[ 1412.61840868]]\n",
      "Loop  2217 :    Loss_Train:  [[ 4833.34453703]]    Loss_Validation:  [[ 1412.62439771]]\n",
      "Loop  2218 :    Loss_Train:  [[ 4833.32576395]]    Loss_Validation:  [[ 1412.63038231]]\n",
      "Loop  2219 :    Loss_Train:  [[ 4833.30702458]]    Loss_Validation:  [[ 1412.63636249]]\n",
      "Loop  2220 :    Loss_Train:  [[ 4833.28831886]]    Loss_Validation:  [[ 1412.64233824]]\n",
      "Loop  2221 :    Loss_Train:  [[ 4833.26964672]]    Loss_Validation:  [[ 1412.64830957]]\n",
      "Loop  2222 :    Loss_Train:  [[ 4833.2510081]]    Loss_Validation:  [[ 1412.65427648]]\n",
      "Loop  2223 :    Loss_Train:  [[ 4833.23240293]]    Loss_Validation:  [[ 1412.66023897]]\n",
      "Loop  2224 :    Loss_Train:  [[ 4833.21383116]]    Loss_Validation:  [[ 1412.66619705]]\n",
      "Loop  2225 :    Loss_Train:  [[ 4833.19529272]]    Loss_Validation:  [[ 1412.67215072]]\n",
      "Loop  2226 :    Loss_Train:  [[ 4833.17678755]]    Loss_Validation:  [[ 1412.67809997]]\n",
      "Loop  2227 :    Loss_Train:  [[ 4833.15831557]]    Loss_Validation:  [[ 1412.68404482]]\n",
      "Loop  2228 :    Loss_Train:  [[ 4833.13987674]]    Loss_Validation:  [[ 1412.68998525]]\n",
      "Loop  2229 :    Loss_Train:  [[ 4833.12147099]]    Loss_Validation:  [[ 1412.69592129]]\n",
      "Loop  2230 :    Loss_Train:  [[ 4833.10309826]]    Loss_Validation:  [[ 1412.70185292]]\n",
      "Loop  2231 :    Loss_Train:  [[ 4833.08475847]]    Loss_Validation:  [[ 1412.70778015]]\n",
      "Loop  2232 :    Loss_Train:  [[ 4833.06645158]]    Loss_Validation:  [[ 1412.71370298]]\n",
      "Loop  2233 :    Loss_Train:  [[ 4833.04817752]]    Loss_Validation:  [[ 1412.71962142]]\n",
      "Loop  2234 :    Loss_Train:  [[ 4833.02993622]]    Loss_Validation:  [[ 1412.72553546]]\n",
      "Loop  2235 :    Loss_Train:  [[ 4833.01172763]]    Loss_Validation:  [[ 1412.73144511]]\n",
      "Loop  2236 :    Loss_Train:  [[ 4832.99355168]]    Loss_Validation:  [[ 1412.73735037]]\n",
      "Loop  2237 :    Loss_Train:  [[ 4832.97540832]]    Loss_Validation:  [[ 1412.74325125]]\n",
      "Loop  2238 :    Loss_Train:  [[ 4832.95729747]]    Loss_Validation:  [[ 1412.74914774]]\n",
      "Loop  2239 :    Loss_Train:  [[ 4832.93921909]]    Loss_Validation:  [[ 1412.75503984]]\n",
      "Loop  2240 :    Loss_Train:  [[ 4832.9211731]]    Loss_Validation:  [[ 1412.76092757]]\n",
      "Loop  2241 :    Loss_Train:  [[ 4832.90315945]]    Loss_Validation:  [[ 1412.76681092]]\n",
      "Loop  2242 :    Loss_Train:  [[ 4832.88517807]]    Loss_Validation:  [[ 1412.77268989]]\n",
      "Loop  2243 :    Loss_Train:  [[ 4832.86722891]]    Loss_Validation:  [[ 1412.77856448]]\n",
      "Loop  2244 :    Loss_Train:  [[ 4832.84931191]]    Loss_Validation:  [[ 1412.78443471]]\n",
      "Loop  2245 :    Loss_Train:  [[ 4832.831427]]    Loss_Validation:  [[ 1412.79030056]]\n",
      "Loop  2246 :    Loss_Train:  [[ 4832.81357412]]    Loss_Validation:  [[ 1412.79616205]]\n",
      "Loop  2247 :    Loss_Train:  [[ 4832.79575321]]    Loss_Validation:  [[ 1412.80201917]]\n",
      "Loop  2248 :    Loss_Train:  [[ 4832.77796421]]    Loss_Validation:  [[ 1412.80787194]]\n",
      "Loop  2249 :    Loss_Train:  [[ 4832.76020707]]    Loss_Validation:  [[ 1412.81372034]]\n",
      "Loop  2250 :    Loss_Train:  [[ 4832.74248172]]    Loss_Validation:  [[ 1412.81956438]]\n",
      "Loop  2251 :    Loss_Train:  [[ 4832.72478811]]    Loss_Validation:  [[ 1412.82540406]]\n",
      "Loop  2252 :    Loss_Train:  [[ 4832.70712616]]    Loss_Validation:  [[ 1412.8312394]]\n",
      "Loop  2253 :    Loss_Train:  [[ 4832.68949583]]    Loss_Validation:  [[ 1412.83707038]]\n",
      "Loop  2254 :    Loss_Train:  [[ 4832.67189705]]    Loss_Validation:  [[ 1412.84289701]]\n",
      "Loop  2255 :    Loss_Train:  [[ 4832.65432977]]    Loss_Validation:  [[ 1412.84871929]]\n",
      "Loop  2256 :    Loss_Train:  [[ 4832.63679392]]    Loss_Validation:  [[ 1412.85453723]]\n",
      "Loop  2257 :    Loss_Train:  [[ 4832.61928945]]    Loss_Validation:  [[ 1412.86035083]]\n",
      "Loop  2258 :    Loss_Train:  [[ 4832.60181629]]    Loss_Validation:  [[ 1412.86616009]]\n",
      "Loop  2259 :    Loss_Train:  [[ 4832.58437439]]    Loss_Validation:  [[ 1412.87196501]]\n",
      "Loop  2260 :    Loss_Train:  [[ 4832.56696369]]    Loss_Validation:  [[ 1412.8777656]]\n",
      "Loop  2261 :    Loss_Train:  [[ 4832.54958413]]    Loss_Validation:  [[ 1412.88356185]]\n",
      "Loop  2262 :    Loss_Train:  [[ 4832.53223566]]    Loss_Validation:  [[ 1412.88935378]]\n",
      "Loop  2263 :    Loss_Train:  [[ 4832.5149182]]    Loss_Validation:  [[ 1412.89514137]]\n",
      "Loop  2264 :    Loss_Train:  [[ 4832.49763171]]    Loss_Validation:  [[ 1412.90092464]]\n",
      "Loop  2265 :    Loss_Train:  [[ 4832.48037613]]    Loss_Validation:  [[ 1412.90670359]]\n",
      "Loop  2266 :    Loss_Train:  [[ 4832.4631514]]    Loss_Validation:  [[ 1412.91247821]]\n",
      "Loop  2267 :    Loss_Train:  [[ 4832.44595746]]    Loss_Validation:  [[ 1412.91824852]]\n",
      "Loop  2268 :    Loss_Train:  [[ 4832.42879425]]    Loss_Validation:  [[ 1412.92401451]]\n",
      "Loop  2269 :    Loss_Train:  [[ 4832.41166171]]    Loss_Validation:  [[ 1412.92977619]]\n",
      "Loop  2270 :    Loss_Train:  [[ 4832.3945598]]    Loss_Validation:  [[ 1412.93553355]]\n",
      "Loop  2271 :    Loss_Train:  [[ 4832.37748844]]    Loss_Validation:  [[ 1412.94128661]]\n",
      "Loop  2272 :    Loss_Train:  [[ 4832.36044759]]    Loss_Validation:  [[ 1412.94703536]]\n",
      "Loop  2273 :    Loss_Train:  [[ 4832.34343718]]    Loss_Validation:  [[ 1412.9527798]]\n",
      "Loop  2274 :    Loss_Train:  [[ 4832.32645716]]    Loss_Validation:  [[ 1412.95851995]]\n",
      "Loop  2275 :    Loss_Train:  [[ 4832.30950747]]    Loss_Validation:  [[ 1412.96425579]]\n",
      "Loop  2276 :    Loss_Train:  [[ 4832.29258806]]    Loss_Validation:  [[ 1412.96998734]]\n",
      "Loop  2277 :    Loss_Train:  [[ 4832.27569886]]    Loss_Validation:  [[ 1412.97571459]]\n",
      "Loop  2278 :    Loss_Train:  [[ 4832.25883983]]    Loss_Validation:  [[ 1412.98143755]]\n",
      "Loop  2279 :    Loss_Train:  [[ 4832.2420109]]    Loss_Validation:  [[ 1412.98715622]]\n",
      "Loop  2280 :    Loss_Train:  [[ 4832.22521202]]    Loss_Validation:  [[ 1412.9928706]]\n",
      "Loop  2281 :    Loss_Train:  [[ 4832.20844313]]    Loss_Validation:  [[ 1412.9985807]]\n",
      "Loop  2282 :    Loss_Train:  [[ 4832.19170417]]    Loss_Validation:  [[ 1413.00428652]]\n",
      "Loop  2283 :    Loss_Train:  [[ 4832.1749951]]    Loss_Validation:  [[ 1413.00998805]]\n",
      "Loop  2284 :    Loss_Train:  [[ 4832.15831584]]    Loss_Validation:  [[ 1413.01568531]]\n",
      "Loop  2285 :    Loss_Train:  [[ 4832.14166636]]    Loss_Validation:  [[ 1413.02137829]]\n",
      "Loop  2286 :    Loss_Train:  [[ 4832.12504658]]    Loss_Validation:  [[ 1413.027067]]\n",
      "Loop  2287 :    Loss_Train:  [[ 4832.10845647]]    Loss_Validation:  [[ 1413.03275144]]\n",
      "Loop  2288 :    Loss_Train:  [[ 4832.09189595]]    Loss_Validation:  [[ 1413.03843161]]\n",
      "Loop  2289 :    Loss_Train:  [[ 4832.07536498]]    Loss_Validation:  [[ 1413.04410752]]\n",
      "Loop  2290 :    Loss_Train:  [[ 4832.05886349]]    Loss_Validation:  [[ 1413.04977917]]\n",
      "Loop  2291 :    Loss_Train:  [[ 4832.04239144]]    Loss_Validation:  [[ 1413.05544655]]\n",
      "Loop  2292 :    Loss_Train:  [[ 4832.02594878]]    Loss_Validation:  [[ 1413.06110968]]\n",
      "Loop  2293 :    Loss_Train:  [[ 4832.00953543]]    Loss_Validation:  [[ 1413.06676855]]\n",
      "Loop  2294 :    Loss_Train:  [[ 4831.99315136]]    Loss_Validation:  [[ 1413.07242317]]\n",
      "Loop  2295 :    Loss_Train:  [[ 4831.97679649]]    Loss_Validation:  [[ 1413.07807353]]\n",
      "Loop  2296 :    Loss_Train:  [[ 4831.96047079]]    Loss_Validation:  [[ 1413.08371965]]\n",
      "Loop  2297 :    Loss_Train:  [[ 4831.9441742]]    Loss_Validation:  [[ 1413.08936153]]\n",
      "Loop  2298 :    Loss_Train:  [[ 4831.92790665]]    Loss_Validation:  [[ 1413.09499916]]\n",
      "Loop  2299 :    Loss_Train:  [[ 4831.91166811]]    Loss_Validation:  [[ 1413.10063255]]\n",
      "Loop  2300 :    Loss_Train:  [[ 4831.8954585]]    Loss_Validation:  [[ 1413.10626171]]\n",
      "Loop  2301 :    Loss_Train:  [[ 4831.87927778]]    Loss_Validation:  [[ 1413.11188663]]\n",
      "Loop  2302 :    Loss_Train:  [[ 4831.8631259]]    Loss_Validation:  [[ 1413.11750731]]\n",
      "Loop  2303 :    Loss_Train:  [[ 4831.8470028]]    Loss_Validation:  [[ 1413.12312377]]\n",
      "Loop  2304 :    Loss_Train:  [[ 4831.83090842]]    Loss_Validation:  [[ 1413.128736]]\n",
      "Loop  2305 :    Loss_Train:  [[ 4831.81484272]]    Loss_Validation:  [[ 1413.134344]]\n",
      "Loop  2306 :    Loss_Train:  [[ 4831.79880564]]    Loss_Validation:  [[ 1413.13994778]]\n",
      "Loop  2307 :    Loss_Train:  [[ 4831.78279712]]    Loss_Validation:  [[ 1413.14554734]]\n",
      "Loop  2308 :    Loss_Train:  [[ 4831.76681712]]    Loss_Validation:  [[ 1413.15114269]]\n",
      "Loop  2309 :    Loss_Train:  [[ 4831.75086557]]    Loss_Validation:  [[ 1413.15673382]]\n",
      "Loop  2310 :    Loss_Train:  [[ 4831.73494243]]    Loss_Validation:  [[ 1413.16232073]]\n",
      "Loop  2311 :    Loss_Train:  [[ 4831.71904765]]    Loss_Validation:  [[ 1413.16790344]]\n",
      "Loop  2312 :    Loss_Train:  [[ 4831.70318116]]    Loss_Validation:  [[ 1413.17348194]]\n",
      "Loop  2313 :    Loss_Train:  [[ 4831.68734292]]    Loss_Validation:  [[ 1413.17905623]]\n",
      "Loop  2314 :    Loss_Train:  [[ 4831.67153288]]    Loss_Validation:  [[ 1413.18462633]]\n",
      "Loop  2315 :    Loss_Train:  [[ 4831.65575098]]    Loss_Validation:  [[ 1413.19019222]]\n",
      "Loop  2316 :    Loss_Train:  [[ 4831.63999716]]    Loss_Validation:  [[ 1413.19575392]]\n",
      "Loop  2317 :    Loss_Train:  [[ 4831.62427139]]    Loss_Validation:  [[ 1413.20131142]]\n",
      "Loop  2318 :    Loss_Train:  [[ 4831.6085736]]    Loss_Validation:  [[ 1413.20686473]]\n",
      "Loop  2319 :    Loss_Train:  [[ 4831.59290374]]    Loss_Validation:  [[ 1413.21241385]]\n",
      "Loop  2320 :    Loss_Train:  [[ 4831.57726176]]    Loss_Validation:  [[ 1413.21795879]]\n",
      "Loop  2321 :    Loss_Train:  [[ 4831.56164761]]    Loss_Validation:  [[ 1413.22349954]]\n",
      "Loop  2322 :    Loss_Train:  [[ 4831.54606124]]    Loss_Validation:  [[ 1413.22903611]]\n",
      "Loop  2323 :    Loss_Train:  [[ 4831.53050259]]    Loss_Validation:  [[ 1413.2345685]]\n",
      "Loop  2324 :    Loss_Train:  [[ 4831.51497162]]    Loss_Validation:  [[ 1413.24009671]]\n",
      "Loop  2325 :    Loss_Train:  [[ 4831.49946827]]    Loss_Validation:  [[ 1413.24562076]]\n",
      "Loop  2326 :    Loss_Train:  [[ 4831.48399249]]    Loss_Validation:  [[ 1413.25114063]]\n",
      "Loop  2327 :    Loss_Train:  [[ 4831.46854422]]    Loss_Validation:  [[ 1413.25665633]]\n",
      "Loop  2328 :    Loss_Train:  [[ 4831.45312343]]    Loss_Validation:  [[ 1413.26216786]]\n",
      "Loop  2329 :    Loss_Train:  [[ 4831.43773005]]    Loss_Validation:  [[ 1413.26767524]]\n",
      "Loop  2330 :    Loss_Train:  [[ 4831.42236403]]    Loss_Validation:  [[ 1413.27317845]]\n",
      "Loop  2331 :    Loss_Train:  [[ 4831.40702533]]    Loss_Validation:  [[ 1413.27867751]]\n",
      "Loop  2332 :    Loss_Train:  [[ 4831.39171389]]    Loss_Validation:  [[ 1413.28417241]]\n",
      "Loop  2333 :    Loss_Train:  [[ 4831.37642967]]    Loss_Validation:  [[ 1413.28966315]]\n",
      "Loop  2334 :    Loss_Train:  [[ 4831.36117261]]    Loss_Validation:  [[ 1413.29514975]]\n",
      "Loop  2335 :    Loss_Train:  [[ 4831.34594266]]    Loss_Validation:  [[ 1413.3006322]]\n",
      "Loop  2336 :    Loss_Train:  [[ 4831.33073977]]    Loss_Validation:  [[ 1413.30611051]]\n",
      "Loop  2337 :    Loss_Train:  [[ 4831.31556389]]    Loss_Validation:  [[ 1413.31158467]]\n",
      "Loop  2338 :    Loss_Train:  [[ 4831.30041497]]    Loss_Validation:  [[ 1413.31705469]]\n",
      "Loop  2339 :    Loss_Train:  [[ 4831.28529296]]    Loss_Validation:  [[ 1413.32252058]]\n",
      "Loop  2340 :    Loss_Train:  [[ 4831.27019782]]    Loss_Validation:  [[ 1413.32798234]]\n",
      "Loop  2341 :    Loss_Train:  [[ 4831.25512948]]    Loss_Validation:  [[ 1413.33343996]]\n",
      "Loop  2342 :    Loss_Train:  [[ 4831.2400879]]    Loss_Validation:  [[ 1413.33889345]]\n",
      "Loop  2343 :    Loss_Train:  [[ 4831.22507304]]    Loss_Validation:  [[ 1413.34434282]]\n",
      "Loop  2344 :    Loss_Train:  [[ 4831.21008483]]    Loss_Validation:  [[ 1413.34978806]]\n",
      "Loop  2345 :    Loss_Train:  [[ 4831.19512324]]    Loss_Validation:  [[ 1413.35522919]]\n",
      "Loop  2346 :    Loss_Train:  [[ 4831.18018821]]    Loss_Validation:  [[ 1413.36066619]]\n",
      "Loop  2347 :    Loss_Train:  [[ 4831.16527969]]    Loss_Validation:  [[ 1413.36609908]]\n",
      "Loop  2348 :    Loss_Train:  [[ 4831.15039763]]    Loss_Validation:  [[ 1413.37152786]]\n",
      "Loop  2349 :    Loss_Train:  [[ 4831.13554199]]    Loss_Validation:  [[ 1413.37695252]]\n",
      "Loop  2350 :    Loss_Train:  [[ 4831.12071272]]    Loss_Validation:  [[ 1413.38237308]]\n",
      "Loop  2351 :    Loss_Train:  [[ 4831.10590976]]    Loss_Validation:  [[ 1413.38778954]]\n",
      "Loop  2352 :    Loss_Train:  [[ 4831.09113307]]    Loss_Validation:  [[ 1413.39320189]]\n",
      "Loop  2353 :    Loss_Train:  [[ 4831.07638259]]    Loss_Validation:  [[ 1413.39861014]]\n",
      "Loop  2354 :    Loss_Train:  [[ 4831.06165829]]    Loss_Validation:  [[ 1413.4040143]]\n",
      "Loop  2355 :    Loss_Train:  [[ 4831.04696011]]    Loss_Validation:  [[ 1413.40941436]]\n",
      "Loop  2356 :    Loss_Train:  [[ 4831.032288]]    Loss_Validation:  [[ 1413.41481034]]\n",
      "Loop  2357 :    Loss_Train:  [[ 4831.01764191]]    Loss_Validation:  [[ 1413.42020222]]\n",
      "Loop  2358 :    Loss_Train:  [[ 4831.0030218]]    Loss_Validation:  [[ 1413.42559002]]\n",
      "Loop  2359 :    Loss_Train:  [[ 4830.98842762]]    Loss_Validation:  [[ 1413.43097373]]\n",
      "Loop  2360 :    Loss_Train:  [[ 4830.97385932]]    Loss_Validation:  [[ 1413.43635336]]\n",
      "Loop  2361 :    Loss_Train:  [[ 4830.95931685]]    Loss_Validation:  [[ 1413.44172892]]\n",
      "Loop  2362 :    Loss_Train:  [[ 4830.94480017]]    Loss_Validation:  [[ 1413.4471004]]\n",
      "Loop  2363 :    Loss_Train:  [[ 4830.93030922]]    Loss_Validation:  [[ 1413.45246781]]\n",
      "Loop  2364 :    Loss_Train:  [[ 4830.91584396]]    Loss_Validation:  [[ 1413.45783115]]\n",
      "Loop  2365 :    Loss_Train:  [[ 4830.90140434]]    Loss_Validation:  [[ 1413.46319042]]\n",
      "Loop  2366 :    Loss_Train:  [[ 4830.88699032]]    Loss_Validation:  [[ 1413.46854562]]\n",
      "Loop  2367 :    Loss_Train:  [[ 4830.87260184]]    Loss_Validation:  [[ 1413.47389677]]\n",
      "Loop  2368 :    Loss_Train:  [[ 4830.85823885]]    Loss_Validation:  [[ 1413.47924386]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  2369 :    Loss_Train:  [[ 4830.84390132]]    Loss_Validation:  [[ 1413.48458689]]\n",
      "Loop  2370 :    Loss_Train:  [[ 4830.8295892]]    Loss_Validation:  [[ 1413.48992587]]\n",
      "Loop  2371 :    Loss_Train:  [[ 4830.81530243]]    Loss_Validation:  [[ 1413.49526079]]\n",
      "Loop  2372 :    Loss_Train:  [[ 4830.80104097]]    Loss_Validation:  [[ 1413.50059167]]\n",
      "Loop  2373 :    Loss_Train:  [[ 4830.78680477]]    Loss_Validation:  [[ 1413.50591851]]\n",
      "Loop  2374 :    Loss_Train:  [[ 4830.7725938]]    Loss_Validation:  [[ 1413.5112413]]\n",
      "Loop  2375 :    Loss_Train:  [[ 4830.75840799]]    Loss_Validation:  [[ 1413.51656005]]\n",
      "Loop  2376 :    Loss_Train:  [[ 4830.7442473]]    Loss_Validation:  [[ 1413.52187476]]\n",
      "Loop  2377 :    Loss_Train:  [[ 4830.73011169]]    Loss_Validation:  [[ 1413.52718544]]\n",
      "Loop  2378 :    Loss_Train:  [[ 4830.71600111]]    Loss_Validation:  [[ 1413.53249209]]\n",
      "Loop  2379 :    Loss_Train:  [[ 4830.70191552]]    Loss_Validation:  [[ 1413.53779471]]\n",
      "Loop  2380 :    Loss_Train:  [[ 4830.68785486]]    Loss_Validation:  [[ 1413.54309331]]\n",
      "Loop  2381 :    Loss_Train:  [[ 4830.67381909]]    Loss_Validation:  [[ 1413.54838788]]\n",
      "Loop  2382 :    Loss_Train:  [[ 4830.65980817]]    Loss_Validation:  [[ 1413.55367843]]\n",
      "Loop  2383 :    Loss_Train:  [[ 4830.64582205]]    Loss_Validation:  [[ 1413.55896496]]\n",
      "Loop  2384 :    Loss_Train:  [[ 4830.63186069]]    Loss_Validation:  [[ 1413.56424748]]\n",
      "Loop  2385 :    Loss_Train:  [[ 4830.61792403]]    Loss_Validation:  [[ 1413.56952598]]\n",
      "Loop  2386 :    Loss_Train:  [[ 4830.60401203]]    Loss_Validation:  [[ 1413.57480048]]\n",
      "Loop  2387 :    Loss_Train:  [[ 4830.59012465]]    Loss_Validation:  [[ 1413.58007096]]\n",
      "Loop  2388 :    Loss_Train:  [[ 4830.57626184]]    Loss_Validation:  [[ 1413.58533745]]\n",
      "Loop  2389 :    Loss_Train:  [[ 4830.56242356]]    Loss_Validation:  [[ 1413.59059993]]\n",
      "Loop  2390 :    Loss_Train:  [[ 4830.54860976]]    Loss_Validation:  [[ 1413.59585841]]\n",
      "Loop  2391 :    Loss_Train:  [[ 4830.53482039]]    Loss_Validation:  [[ 1413.6011129]]\n",
      "Loop  2392 :    Loss_Train:  [[ 4830.52105541]]    Loss_Validation:  [[ 1413.6063634]]\n",
      "Loop  2393 :    Loss_Train:  [[ 4830.50731478]]    Loss_Validation:  [[ 1413.6116099]]\n",
      "Loop  2394 :    Loss_Train:  [[ 4830.49359845]]    Loss_Validation:  [[ 1413.61685242]]\n",
      "Loop  2395 :    Loss_Train:  [[ 4830.47990637]]    Loss_Validation:  [[ 1413.62209095]]\n",
      "Loop  2396 :    Loss_Train:  [[ 4830.4662385]]    Loss_Validation:  [[ 1413.6273255]]\n",
      "Loop  2397 :    Loss_Train:  [[ 4830.4525948]]    Loss_Validation:  [[ 1413.63255607]]\n",
      "Loop  2398 :    Loss_Train:  [[ 4830.43897522]]    Loss_Validation:  [[ 1413.63778267]]\n",
      "Loop  2399 :    Loss_Train:  [[ 4830.42537972]]    Loss_Validation:  [[ 1413.64300529]]\n",
      "Loop  2400 :    Loss_Train:  [[ 4830.41180825]]    Loss_Validation:  [[ 1413.64822394]]\n",
      "Loop  2401 :    Loss_Train:  [[ 4830.39826076]]    Loss_Validation:  [[ 1413.65343862]]\n",
      "Loop  2402 :    Loss_Train:  [[ 4830.38473722]]    Loss_Validation:  [[ 1413.65864934]]\n",
      "Loop  2403 :    Loss_Train:  [[ 4830.37123758]]    Loss_Validation:  [[ 1413.66385609]]\n",
      "Loop  2404 :    Loss_Train:  [[ 4830.3577618]]    Loss_Validation:  [[ 1413.66905888]]\n",
      "Loop  2405 :    Loss_Train:  [[ 4830.34430982]]    Loss_Validation:  [[ 1413.67425772]]\n",
      "Loop  2406 :    Loss_Train:  [[ 4830.33088161]]    Loss_Validation:  [[ 1413.6794526]]\n",
      "Loop  2407 :    Loss_Train:  [[ 4830.31747713]]    Loss_Validation:  [[ 1413.68464353]]\n",
      "Loop  2408 :    Loss_Train:  [[ 4830.30409633]]    Loss_Validation:  [[ 1413.68983051]]\n",
      "Loop  2409 :    Loss_Train:  [[ 4830.29073916]]    Loss_Validation:  [[ 1413.69501355]]\n",
      "Loop  2410 :    Loss_Train:  [[ 4830.27740558]]    Loss_Validation:  [[ 1413.70019264]]\n",
      "Loop  2411 :    Loss_Train:  [[ 4830.26409556]]    Loss_Validation:  [[ 1413.70536779]]\n",
      "Loop  2412 :    Loss_Train:  [[ 4830.25080904]]    Loss_Validation:  [[ 1413.71053901]]\n",
      "Loop  2413 :    Loss_Train:  [[ 4830.23754598]]    Loss_Validation:  [[ 1413.71570629]]\n",
      "Loop  2414 :    Loss_Train:  [[ 4830.22430634]]    Loss_Validation:  [[ 1413.72086963]]\n",
      "Loop  2415 :    Loss_Train:  [[ 4830.21109007]]    Loss_Validation:  [[ 1413.72602905]]\n",
      "Loop  2416 :    Loss_Train:  [[ 4830.19789714]]    Loss_Validation:  [[ 1413.73118454]]\n",
      "Loop  2417 :    Loss_Train:  [[ 4830.1847275]]    Loss_Validation:  [[ 1413.73633611]]\n",
      "Loop  2418 :    Loss_Train:  [[ 4830.17158111]]    Loss_Validation:  [[ 1413.74148376]]\n",
      "Loop  2419 :    Loss_Train:  [[ 4830.15845792]]    Loss_Validation:  [[ 1413.74662748]]\n",
      "Loop  2420 :    Loss_Train:  [[ 4830.14535789]]    Loss_Validation:  [[ 1413.7517673]]\n",
      "Loop  2421 :    Loss_Train:  [[ 4830.13228098]]    Loss_Validation:  [[ 1413.7569032]]\n",
      "Loop  2422 :    Loss_Train:  [[ 4830.11922715]]    Loss_Validation:  [[ 1413.76203519]]\n",
      "Loop  2423 :    Loss_Train:  [[ 4830.10619635]]    Loss_Validation:  [[ 1413.76716327]]\n",
      "Loop  2424 :    Loss_Train:  [[ 4830.09318854]]    Loss_Validation:  [[ 1413.77228745]]\n",
      "Loop  2425 :    Loss_Train:  [[ 4830.08020368]]    Loss_Validation:  [[ 1413.77740773]]\n",
      "Loop  2426 :    Loss_Train:  [[ 4830.06724173]]    Loss_Validation:  [[ 1413.78252411]]\n",
      "Loop  2427 :    Loss_Train:  [[ 4830.05430264]]    Loss_Validation:  [[ 1413.78763659]]\n",
      "Loop  2428 :    Loss_Train:  [[ 4830.04138637]]    Loss_Validation:  [[ 1413.79274518]]\n",
      "Loop  2429 :    Loss_Train:  [[ 4830.02849289]]    Loss_Validation:  [[ 1413.79784988]]\n",
      "Loop  2430 :    Loss_Train:  [[ 4830.01562214]]    Loss_Validation:  [[ 1413.80295069]]\n",
      "Loop  2431 :    Loss_Train:  [[ 4830.0027741]]    Loss_Validation:  [[ 1413.80804762]]\n",
      "Loop  2432 :    Loss_Train:  [[ 4829.9899487]]    Loss_Validation:  [[ 1413.81314066]]\n",
      "Loop  2433 :    Loss_Train:  [[ 4829.97714592]]    Loss_Validation:  [[ 1413.81822983]]\n",
      "Loop  2434 :    Loss_Train:  [[ 4829.96436571]]    Loss_Validation:  [[ 1413.82331512]]\n",
      "Loop  2435 :    Loss_Train:  [[ 4829.95160804]]    Loss_Validation:  [[ 1413.82839653]]\n",
      "Loop  2436 :    Loss_Train:  [[ 4829.93887285]]    Loss_Validation:  [[ 1413.83347408]]\n",
      "Loop  2437 :    Loss_Train:  [[ 4829.92616011]]    Loss_Validation:  [[ 1413.83854776]]\n",
      "Loop  2438 :    Loss_Train:  [[ 4829.91346977]]    Loss_Validation:  [[ 1413.84361757]]\n",
      "Loop  2439 :    Loss_Train:  [[ 4829.90080181]]    Loss_Validation:  [[ 1413.84868352]]\n",
      "Loop  2440 :    Loss_Train:  [[ 4829.88815616]]    Loss_Validation:  [[ 1413.85374561]]\n",
      "Loop  2441 :    Loss_Train:  [[ 4829.8755328]]    Loss_Validation:  [[ 1413.85880384]]\n",
      "Loop  2442 :    Loss_Train:  [[ 4829.86293168]]    Loss_Validation:  [[ 1413.86385822]]\n",
      "Loop  2443 :    Loss_Train:  [[ 4829.85035276]]    Loss_Validation:  [[ 1413.86890875]]\n",
      "Loop  2444 :    Loss_Train:  [[ 4829.83779601]]    Loss_Validation:  [[ 1413.87395543]]\n",
      "Loop  2445 :    Loss_Train:  [[ 4829.82526137]]    Loss_Validation:  [[ 1413.87899827]]\n",
      "Loop  2446 :    Loss_Train:  [[ 4829.81274882]]    Loss_Validation:  [[ 1413.88403726]]\n",
      "Loop  2447 :    Loss_Train:  [[ 4829.8002583]]    Loss_Validation:  [[ 1413.88907241]]\n",
      "Loop  2448 :    Loss_Train:  [[ 4829.78778978]]    Loss_Validation:  [[ 1413.89410373]]\n",
      "Loop  2449 :    Loss_Train:  [[ 4829.77534322]]    Loss_Validation:  [[ 1413.89913121]]\n",
      "Loop  2450 :    Loss_Train:  [[ 4829.76291857]]    Loss_Validation:  [[ 1413.90415486]]\n",
      "Loop  2451 :    Loss_Train:  [[ 4829.75051581]]    Loss_Validation:  [[ 1413.90917468]]\n",
      "Loop  2452 :    Loss_Train:  [[ 4829.73813488]]    Loss_Validation:  [[ 1413.91419068]]\n",
      "Loop  2453 :    Loss_Train:  [[ 4829.72577575]]    Loss_Validation:  [[ 1413.91920285]]\n",
      "Loop  2454 :    Loss_Train:  [[ 4829.71343838]]    Loss_Validation:  [[ 1413.9242112]]\n",
      "Loop  2455 :    Loss_Train:  [[ 4829.70112272]]    Loss_Validation:  [[ 1413.92921573]]\n",
      "Loop  2456 :    Loss_Train:  [[ 4829.68882874]]    Loss_Validation:  [[ 1413.93421645]]\n",
      "Loop  2457 :    Loss_Train:  [[ 4829.6765564]]    Loss_Validation:  [[ 1413.93921336]]\n",
      "Loop  2458 :    Loss_Train:  [[ 4829.66430566]]    Loss_Validation:  [[ 1413.94420646]]\n",
      "Loop  2459 :    Loss_Train:  [[ 4829.65207648]]    Loss_Validation:  [[ 1413.94919575]]\n",
      "Loop  2460 :    Loss_Train:  [[ 4829.63986881]]    Loss_Validation:  [[ 1413.95418124]]\n",
      "Loop  2461 :    Loss_Train:  [[ 4829.62768263]]    Loss_Validation:  [[ 1413.95916293]]\n",
      "Loop  2462 :    Loss_Train:  [[ 4829.61551789]]    Loss_Validation:  [[ 1413.96414082]]\n",
      "Loop  2463 :    Loss_Train:  [[ 4829.60337454]]    Loss_Validation:  [[ 1413.96911491]]\n",
      "Loop  2464 :    Loss_Train:  [[ 4829.59125256]]    Loss_Validation:  [[ 1413.97408522]]\n",
      "Loop  2465 :    Loss_Train:  [[ 4829.57915191]]    Loss_Validation:  [[ 1413.97905173]]\n",
      "Loop  2466 :    Loss_Train:  [[ 4829.56707253]]    Loss_Validation:  [[ 1413.98401446]]\n",
      "Loop  2467 :    Loss_Train:  [[ 4829.5550144]]    Loss_Validation:  [[ 1413.9889734]]\n",
      "Loop  2468 :    Loss_Train:  [[ 4829.54297748]]    Loss_Validation:  [[ 1413.99392857]]\n",
      "Loop  2469 :    Loss_Train:  [[ 4829.53096173]]    Loss_Validation:  [[ 1413.99887995]]\n",
      "Loop  2470 :    Loss_Train:  [[ 4829.5189671]]    Loss_Validation:  [[ 1414.00382756]]\n",
      "Loop  2471 :    Loss_Train:  [[ 4829.50699356]]    Loss_Validation:  [[ 1414.0087714]]\n",
      "Loop  2472 :    Loss_Train:  [[ 4829.49504107]]    Loss_Validation:  [[ 1414.01371146]]\n",
      "Loop  2473 :    Loss_Train:  [[ 4829.4831096]]    Loss_Validation:  [[ 1414.01864776]]\n",
      "Loop  2474 :    Loss_Train:  [[ 4829.4711991]]    Loss_Validation:  [[ 1414.0235803]]\n",
      "Loop  2475 :    Loss_Train:  [[ 4829.45930954]]    Loss_Validation:  [[ 1414.02850907]]\n",
      "Loop  2476 :    Loss_Train:  [[ 4829.44744087]]    Loss_Validation:  [[ 1414.03343409]]\n",
      "Loop  2477 :    Loss_Train:  [[ 4829.43559306]]    Loss_Validation:  [[ 1414.03835535]]\n",
      "Loop  2478 :    Loss_Train:  [[ 4829.42376608]]    Loss_Validation:  [[ 1414.04327286]]\n",
      "Loop  2479 :    Loss_Train:  [[ 4829.41195987]]    Loss_Validation:  [[ 1414.04818661]]\n",
      "Loop  2480 :    Loss_Train:  [[ 4829.40017441]]    Loss_Validation:  [[ 1414.05309662]]\n",
      "Loop  2481 :    Loss_Train:  [[ 4829.38840966]]    Loss_Validation:  [[ 1414.05800289]]\n",
      "Loop  2482 :    Loss_Train:  [[ 4829.37666558]]    Loss_Validation:  [[ 1414.06290541]]\n",
      "Loop  2483 :    Loss_Train:  [[ 4829.36494213]]    Loss_Validation:  [[ 1414.0678042]]\n",
      "Loop  2484 :    Loss_Train:  [[ 4829.35323927]]    Loss_Validation:  [[ 1414.07269925]]\n",
      "Loop  2485 :    Loss_Train:  [[ 4829.34155697]]    Loss_Validation:  [[ 1414.07759056]]\n",
      "Loop  2486 :    Loss_Train:  [[ 4829.32989519]]    Loss_Validation:  [[ 1414.08247815]]\n",
      "Loop  2487 :    Loss_Train:  [[ 4829.31825389]]    Loss_Validation:  [[ 1414.087362]]\n",
      "Loop  2488 :    Loss_Train:  [[ 4829.30663303]]    Loss_Validation:  [[ 1414.09224214]]\n",
      "Loop  2489 :    Loss_Train:  [[ 4829.29503258]]    Loss_Validation:  [[ 1414.09711855]]\n",
      "Loop  2490 :    Loss_Train:  [[ 4829.28345249]]    Loss_Validation:  [[ 1414.10199124]]\n",
      "Loop  2491 :    Loss_Train:  [[ 4829.27189274]]    Loss_Validation:  [[ 1414.10686021]]\n",
      "Loop  2492 :    Loss_Train:  [[ 4829.26035328]]    Loss_Validation:  [[ 1414.11172548]]\n",
      "Loop  2493 :    Loss_Train:  [[ 4829.24883409]]    Loss_Validation:  [[ 1414.11658703]]\n",
      "Loop  2494 :    Loss_Train:  [[ 4829.23733511]]    Loss_Validation:  [[ 1414.12144487]]\n",
      "Loop  2495 :    Loss_Train:  [[ 4829.22585631]]    Loss_Validation:  [[ 1414.12629901]]\n",
      "Loop  2496 :    Loss_Train:  [[ 4829.21439766]]    Loss_Validation:  [[ 1414.13114944]]\n",
      "Loop  2497 :    Loss_Train:  [[ 4829.20295913]]    Loss_Validation:  [[ 1414.13599618]]\n",
      "Loop  2498 :    Loss_Train:  [[ 4829.19154066]]    Loss_Validation:  [[ 1414.14083922]]\n",
      "Loop  2499 :    Loss_Train:  [[ 4829.18014224]]    Loss_Validation:  [[ 1414.14567856]]\n",
      "Loop  2500 :    Loss_Train:  [[ 4829.16876381]]    Loss_Validation:  [[ 1414.15051422]]\n",
      "Loop  2501 :    Loss_Train:  [[ 4829.15740534]]    Loss_Validation:  [[ 1414.15534618]]\n",
      "Loop  2502 :    Loss_Train:  [[ 4829.14606681]]    Loss_Validation:  [[ 1414.16017446]]\n",
      "Loop  2503 :    Loss_Train:  [[ 4829.13474816]]    Loss_Validation:  [[ 1414.16499906]]\n",
      "Loop  2504 :    Loss_Train:  [[ 4829.12344937]]    Loss_Validation:  [[ 1414.16981998]]\n",
      "Loop  2505 :    Loss_Train:  [[ 4829.1121704]]    Loss_Validation:  [[ 1414.17463722]]\n",
      "Loop  2506 :    Loss_Train:  [[ 4829.10091121]]    Loss_Validation:  [[ 1414.17945078]]\n",
      "Loop  2507 :    Loss_Train:  [[ 4829.08967176]]    Loss_Validation:  [[ 1414.18426068]]\n",
      "Loop  2508 :    Loss_Train:  [[ 4829.07845203]]    Loss_Validation:  [[ 1414.1890669]]\n",
      "Loop  2509 :    Loss_Train:  [[ 4829.06725197]]    Loss_Validation:  [[ 1414.19386946]]\n",
      "Loop  2510 :    Loss_Train:  [[ 4829.05607155]]    Loss_Validation:  [[ 1414.19866836]]\n",
      "Loop  2511 :    Loss_Train:  [[ 4829.04491073]]    Loss_Validation:  [[ 1414.2034636]]\n",
      "Loop  2512 :    Loss_Train:  [[ 4829.03376948]]    Loss_Validation:  [[ 1414.20825518]]\n",
      "Loop  2513 :    Loss_Train:  [[ 4829.02264776]]    Loss_Validation:  [[ 1414.2130431]]\n",
      "Loop  2514 :    Loss_Train:  [[ 4829.01154554]]    Loss_Validation:  [[ 1414.21782737]]\n",
      "Loop  2515 :    Loss_Train:  [[ 4829.00046277]]    Loss_Validation:  [[ 1414.22260799]]\n",
      "Loop  2516 :    Loss_Train:  [[ 4828.98939943]]    Loss_Validation:  [[ 1414.22738497]]\n",
      "Loop  2517 :    Loss_Train:  [[ 4828.97835548]]    Loss_Validation:  [[ 1414.2321583]]\n",
      "Loop  2518 :    Loss_Train:  [[ 4828.96733089]]    Loss_Validation:  [[ 1414.236928]]\n",
      "Loop  2519 :    Loss_Train:  [[ 4828.95632561]]    Loss_Validation:  [[ 1414.24169405]]\n",
      "Loop  2520 :    Loss_Train:  [[ 4828.94533962]]    Loss_Validation:  [[ 1414.24645647]]\n",
      "Loop  2521 :    Loss_Train:  [[ 4828.93437287]]    Loss_Validation:  [[ 1414.25121526]]\n",
      "Loop  2522 :    Loss_Train:  [[ 4828.92342534]]    Loss_Validation:  [[ 1414.25597041]]\n",
      "Loop  2523 :    Loss_Train:  [[ 4828.91249699]]    Loss_Validation:  [[ 1414.26072194]]\n",
      "Loop  2524 :    Loss_Train:  [[ 4828.90158778]]    Loss_Validation:  [[ 1414.26546985]]\n",
      "Loop  2525 :    Loss_Train:  [[ 4828.89069768]]    Loss_Validation:  [[ 1414.27021413]]\n",
      "Loop  2526 :    Loss_Train:  [[ 4828.87982665]]    Loss_Validation:  [[ 1414.2749548]]\n",
      "Loop  2527 :    Loss_Train:  [[ 4828.86897466]]    Loss_Validation:  [[ 1414.27969185]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  2528 :    Loss_Train:  [[ 4828.85814168]]    Loss_Validation:  [[ 1414.28442529]]\n",
      "Loop  2529 :    Loss_Train:  [[ 4828.84732767]]    Loss_Validation:  [[ 1414.28915512]]\n",
      "Loop  2530 :    Loss_Train:  [[ 4828.83653259]]    Loss_Validation:  [[ 1414.29388134]]\n",
      "Loop  2531 :    Loss_Train:  [[ 4828.82575642]]    Loss_Validation:  [[ 1414.29860395]]\n",
      "Loop  2532 :    Loss_Train:  [[ 4828.81499911]]    Loss_Validation:  [[ 1414.30332297]]\n",
      "Loop  2533 :    Loss_Train:  [[ 4828.80426063]]    Loss_Validation:  [[ 1414.30803839]]\n",
      "Loop  2534 :    Loss_Train:  [[ 4828.79354095]]    Loss_Validation:  [[ 1414.3127502]]\n",
      "Loop  2535 :    Loss_Train:  [[ 4828.78284004]]    Loss_Validation:  [[ 1414.31745843]]\n",
      "Loop  2536 :    Loss_Train:  [[ 4828.77215786]]    Loss_Validation:  [[ 1414.32216307]]\n",
      "Loop  2537 :    Loss_Train:  [[ 4828.76149437]]    Loss_Validation:  [[ 1414.32686411]]\n",
      "Loop  2538 :    Loss_Train:  [[ 4828.75084954]]    Loss_Validation:  [[ 1414.33156158]]\n",
      "Loop  2539 :    Loss_Train:  [[ 4828.74022334]]    Loss_Validation:  [[ 1414.33625546]]\n",
      "Loop  2540 :    Loss_Train:  [[ 4828.72961574]]    Loss_Validation:  [[ 1414.34094576]]\n",
      "Loop  2541 :    Loss_Train:  [[ 4828.7190267]]    Loss_Validation:  [[ 1414.34563248]]\n",
      "Loop  2542 :    Loss_Train:  [[ 4828.70845618]]    Loss_Validation:  [[ 1414.35031564]]\n",
      "Loop  2543 :    Loss_Train:  [[ 4828.69790416]]    Loss_Validation:  [[ 1414.35499521]]\n",
      "Loop  2544 :    Loss_Train:  [[ 4828.68737059]]    Loss_Validation:  [[ 1414.35967123]]\n",
      "Loop  2545 :    Loss_Train:  [[ 4828.67685546]]    Loss_Validation:  [[ 1414.36434367]]\n",
      "Loop  2546 :    Loss_Train:  [[ 4828.66635871]]    Loss_Validation:  [[ 1414.36901256]]\n",
      "Loop  2547 :    Loss_Train:  [[ 4828.65588032]]    Loss_Validation:  [[ 1414.37367788]]\n",
      "Loop  2548 :    Loss_Train:  [[ 4828.64542026]]    Loss_Validation:  [[ 1414.37833964]]\n",
      "Loop  2549 :    Loss_Train:  [[ 4828.6349785]]    Loss_Validation:  [[ 1414.38299786]]\n",
      "Loop  2550 :    Loss_Train:  [[ 4828.62455499]]    Loss_Validation:  [[ 1414.38765252]]\n",
      "Loop  2551 :    Loss_Train:  [[ 4828.6141497]]    Loss_Validation:  [[ 1414.39230363]]\n",
      "Loop  2552 :    Loss_Train:  [[ 4828.60376261]]    Loss_Validation:  [[ 1414.39695119]]\n",
      "Loop  2553 :    Loss_Train:  [[ 4828.59339369]]    Loss_Validation:  [[ 1414.40159521]]\n",
      "Loop  2554 :    Loss_Train:  [[ 4828.58304288]]    Loss_Validation:  [[ 1414.40623569]]\n",
      "Loop  2555 :    Loss_Train:  [[ 4828.57271018]]    Loss_Validation:  [[ 1414.41087264]]\n",
      "Loop  2556 :    Loss_Train:  [[ 4828.56239553]]    Loss_Validation:  [[ 1414.41550604]]\n",
      "Loop  2557 :    Loss_Train:  [[ 4828.55209891]]    Loss_Validation:  [[ 1414.42013592]]\n",
      "Loop  2558 :    Loss_Train:  [[ 4828.54182029]]    Loss_Validation:  [[ 1414.42476227]]\n",
      "Loop  2559 :    Loss_Train:  [[ 4828.53155963]]    Loss_Validation:  [[ 1414.42938509]]\n",
      "Loop  2560 :    Loss_Train:  [[ 4828.5213169]]    Loss_Validation:  [[ 1414.43400438]]\n",
      "Loop  2561 :    Loss_Train:  [[ 4828.51109207]]    Loss_Validation:  [[ 1414.43862015]]\n",
      "Loop  2562 :    Loss_Train:  [[ 4828.50088511]]    Loss_Validation:  [[ 1414.44323241]]\n",
      "Loop  2563 :    Loss_Train:  [[ 4828.49069598]]    Loss_Validation:  [[ 1414.44784115]]\n",
      "Loop  2564 :    Loss_Train:  [[ 4828.48052465]]    Loss_Validation:  [[ 1414.45244638]]\n",
      "Loop  2565 :    Loss_Train:  [[ 4828.47037109]]    Loss_Validation:  [[ 1414.45704809]]\n",
      "Loop  2566 :    Loss_Train:  [[ 4828.46023527]]    Loss_Validation:  [[ 1414.4616463]]\n",
      "Loop  2567 :    Loss_Train:  [[ 4828.45011715]]    Loss_Validation:  [[ 1414.46624101]]\n",
      "Loop  2568 :    Loss_Train:  [[ 4828.4400167]]    Loss_Validation:  [[ 1414.47083221]]\n",
      "Loop  2569 :    Loss_Train:  [[ 4828.4299339]]    Loss_Validation:  [[ 1414.47541991]]\n",
      "Loop  2570 :    Loss_Train:  [[ 4828.4198687]]    Loss_Validation:  [[ 1414.48000412]]\n",
      "Loop  2571 :    Loss_Train:  [[ 4828.40982108]]    Loss_Validation:  [[ 1414.48458484]]\n",
      "Loop  2572 :    Loss_Train:  [[ 4828.399791]]    Loss_Validation:  [[ 1414.48916206]]\n",
      "Loop  2573 :    Loss_Train:  [[ 4828.38977844]]    Loss_Validation:  [[ 1414.49373579]]\n",
      "Loop  2574 :    Loss_Train:  [[ 4828.37978336]]    Loss_Validation:  [[ 1414.49830604]]\n",
      "Loop  2575 :    Loss_Train:  [[ 4828.36980573]]    Loss_Validation:  [[ 1414.50287281]]\n",
      "Loop  2576 :    Loss_Train:  [[ 4828.35984551]]    Loss_Validation:  [[ 1414.50743609]]\n",
      "Loop  2577 :    Loss_Train:  [[ 4828.34990268]]    Loss_Validation:  [[ 1414.5119959]]\n",
      "Loop  2578 :    Loss_Train:  [[ 4828.33997721]]    Loss_Validation:  [[ 1414.51655224]]\n",
      "Loop  2579 :    Loss_Train:  [[ 4828.33006906]]    Loss_Validation:  [[ 1414.5211051]]\n",
      "Loop  2580 :    Loss_Train:  [[ 4828.32017821]]    Loss_Validation:  [[ 1414.5256545]]\n",
      "Loop  2581 :    Loss_Train:  [[ 4828.31030461]]    Loss_Validation:  [[ 1414.53020042]]\n",
      "Loop  2582 :    Loss_Train:  [[ 4828.30044824]]    Loss_Validation:  [[ 1414.53474289]]\n",
      "Loop  2583 :    Loss_Train:  [[ 4828.29060908]]    Loss_Validation:  [[ 1414.53928189]]\n",
      "Loop  2584 :    Loss_Train:  [[ 4828.28078708]]    Loss_Validation:  [[ 1414.54381744]]\n",
      "Loop  2585 :    Loss_Train:  [[ 4828.27098221]]    Loss_Validation:  [[ 1414.54834953]]\n",
      "Loop  2586 :    Loss_Train:  [[ 4828.26119445]]    Loss_Validation:  [[ 1414.55287817]]\n",
      "Loop  2587 :    Loss_Train:  [[ 4828.25142377]]    Loss_Validation:  [[ 1414.55740335]]\n",
      "Loop  2588 :    Loss_Train:  [[ 4828.24167013]]    Loss_Validation:  [[ 1414.5619251]]\n",
      "Loop  2589 :    Loss_Train:  [[ 4828.2319335]]    Loss_Validation:  [[ 1414.56644339]]\n",
      "Loop  2590 :    Loss_Train:  [[ 4828.22221386]]    Loss_Validation:  [[ 1414.57095825]]\n",
      "Loop  2591 :    Loss_Train:  [[ 4828.21251117]]    Loss_Validation:  [[ 1414.57546966]]\n",
      "Loop  2592 :    Loss_Train:  [[ 4828.20282539]]    Loss_Validation:  [[ 1414.57997765]]\n",
      "Loop  2593 :    Loss_Train:  [[ 4828.19315651]]    Loss_Validation:  [[ 1414.58448219]]\n",
      "Loop  2594 :    Loss_Train:  [[ 4828.18350449]]    Loss_Validation:  [[ 1414.58898331]]\n",
      "Loop  2595 :    Loss_Train:  [[ 4828.17386929]]    Loss_Validation:  [[ 1414.593481]]\n",
      "Loop  2596 :    Loss_Train:  [[ 4828.1642509]]    Loss_Validation:  [[ 1414.59797526]]\n",
      "Loop  2597 :    Loss_Train:  [[ 4828.15464927]]    Loss_Validation:  [[ 1414.6024661]]\n",
      "Loop  2598 :    Loss_Train:  [[ 4828.14506438]]    Loss_Validation:  [[ 1414.60695352]]\n",
      "Loop  2599 :    Loss_Train:  [[ 4828.1354962]]    Loss_Validation:  [[ 1414.61143753]]\n",
      "Loop  2600 :    Loss_Train:  [[ 4828.1259447]]    Loss_Validation:  [[ 1414.61591812]]\n",
      "Loop  2601 :    Loss_Train:  [[ 4828.11640984]]    Loss_Validation:  [[ 1414.62039529]]\n",
      "Loop  2602 :    Loss_Train:  [[ 4828.10689161]]    Loss_Validation:  [[ 1414.62486906]]\n",
      "Loop  2603 :    Loss_Train:  [[ 4828.09738996]]    Loss_Validation:  [[ 1414.62933943]]\n",
      "Loop  2604 :    Loss_Train:  [[ 4828.08790486]]    Loss_Validation:  [[ 1414.63380638]]\n",
      "Loop  2605 :    Loss_Train:  [[ 4828.0784363]]    Loss_Validation:  [[ 1414.63826994]]\n",
      "Loop  2606 :    Loss_Train:  [[ 4828.06898423]]    Loss_Validation:  [[ 1414.6427301]]\n",
      "Loop  2607 :    Loss_Train:  [[ 4828.05954863]]    Loss_Validation:  [[ 1414.64718687]]\n",
      "Loop  2608 :    Loss_Train:  [[ 4828.05012947]]    Loss_Validation:  [[ 1414.65164024]]\n",
      "Loop  2609 :    Loss_Train:  [[ 4828.04072672]]    Loss_Validation:  [[ 1414.65609022]]\n",
      "Loop  2610 :    Loss_Train:  [[ 4828.03134035]]    Loss_Validation:  [[ 1414.66053682]]\n",
      "Loop  2611 :    Loss_Train:  [[ 4828.02197032]]    Loss_Validation:  [[ 1414.66498003]]\n",
      "Loop  2612 :    Loss_Train:  [[ 4828.01261662]]    Loss_Validation:  [[ 1414.66941986]]\n",
      "Loop  2613 :    Loss_Train:  [[ 4828.00327921]]    Loss_Validation:  [[ 1414.67385631]]\n",
      "Loop  2614 :    Loss_Train:  [[ 4827.99395806]]    Loss_Validation:  [[ 1414.67828938]]\n",
      "Loop  2615 :    Loss_Train:  [[ 4827.98465314]]    Loss_Validation:  [[ 1414.68271908]]\n",
      "Loop  2616 :    Loss_Train:  [[ 4827.97536442]]    Loss_Validation:  [[ 1414.68714541]]\n",
      "Loop  2617 :    Loss_Train:  [[ 4827.96609188]]    Loss_Validation:  [[ 1414.69156837]]\n",
      "Loop  2618 :    Loss_Train:  [[ 4827.95683548]]    Loss_Validation:  [[ 1414.69598797]]\n",
      "Loop  2619 :    Loss_Train:  [[ 4827.94759519]]    Loss_Validation:  [[ 1414.7004042]]\n",
      "Loop  2620 :    Loss_Train:  [[ 4827.93837099]]    Loss_Validation:  [[ 1414.70481707]]\n",
      "Loop  2621 :    Loss_Train:  [[ 4827.92916285]]    Loss_Validation:  [[ 1414.70922659]]\n",
      "Loop  2622 :    Loss_Train:  [[ 4827.91997074]]    Loss_Validation:  [[ 1414.71363275]]\n",
      "Loop  2623 :    Loss_Train:  [[ 4827.91079463]]    Loss_Validation:  [[ 1414.71803556]]\n",
      "Loop  2624 :    Loss_Train:  [[ 4827.90163448]]    Loss_Validation:  [[ 1414.72243501]]\n",
      "Loop  2625 :    Loss_Train:  [[ 4827.89249028]]    Loss_Validation:  [[ 1414.72683113]]\n",
      "Loop  2626 :    Loss_Train:  [[ 4827.88336199]]    Loss_Validation:  [[ 1414.73122389]]\n",
      "Loop  2627 :    Loss_Train:  [[ 4827.87424959]]    Loss_Validation:  [[ 1414.73561332]]\n",
      "Loop  2628 :    Loss_Train:  [[ 4827.86515304]]    Loss_Validation:  [[ 1414.73999941]]\n",
      "Loop  2629 :    Loss_Train:  [[ 4827.85607232]]    Loss_Validation:  [[ 1414.74438216]]\n",
      "Loop  2630 :    Loss_Train:  [[ 4827.8470074]]    Loss_Validation:  [[ 1414.74876157]]\n",
      "Loop  2631 :    Loss_Train:  [[ 4827.83795824]]    Loss_Validation:  [[ 1414.75313766]]\n",
      "Loop  2632 :    Loss_Train:  [[ 4827.82892483]]    Loss_Validation:  [[ 1414.75751042]]\n",
      "Loop  2633 :    Loss_Train:  [[ 4827.81990714]]    Loss_Validation:  [[ 1414.76187985]]\n",
      "Loop  2634 :    Loss_Train:  [[ 4827.81090512]]    Loss_Validation:  [[ 1414.76624597]]\n",
      "Loop  2635 :    Loss_Train:  [[ 4827.80191877]]    Loss_Validation:  [[ 1414.77060876]]\n",
      "Loop  2636 :    Loss_Train:  [[ 4827.79294804]]    Loss_Validation:  [[ 1414.77496823]]\n",
      "Loop  2637 :    Loss_Train:  [[ 4827.78399292]]    Loss_Validation:  [[ 1414.77932439]]\n",
      "Loop  2638 :    Loss_Train:  [[ 4827.77505336]]    Loss_Validation:  [[ 1414.78367724]]\n",
      "Loop  2639 :    Loss_Train:  [[ 4827.76612935]]    Loss_Validation:  [[ 1414.78802677]]\n",
      "Loop  2640 :    Loss_Train:  [[ 4827.75722086]]    Loss_Validation:  [[ 1414.79237301]]\n",
      "Loop  2641 :    Loss_Train:  [[ 4827.74832786]]    Loss_Validation:  [[ 1414.79671593]]\n",
      "Loop  2642 :    Loss_Train:  [[ 4827.73945031]]    Loss_Validation:  [[ 1414.80105556]]\n",
      "Loop  2643 :    Loss_Train:  [[ 4827.7305882]]    Loss_Validation:  [[ 1414.80539189]]\n",
      "Loop  2644 :    Loss_Train:  [[ 4827.7217415]]    Loss_Validation:  [[ 1414.80972492]]\n",
      "Loop  2645 :    Loss_Train:  [[ 4827.71291017]]    Loss_Validation:  [[ 1414.81405466]]\n",
      "Loop  2646 :    Loss_Train:  [[ 4827.70409419]]    Loss_Validation:  [[ 1414.8183811]]\n",
      "Loop  2647 :    Loss_Train:  [[ 4827.69529354]]    Loss_Validation:  [[ 1414.82270426]]\n",
      "Loop  2648 :    Loss_Train:  [[ 4827.68650817]]    Loss_Validation:  [[ 1414.82702414]]\n",
      "Loop  2649 :    Loss_Train:  [[ 4827.67773808]]    Loss_Validation:  [[ 1414.83134073]]\n",
      "Loop  2650 :    Loss_Train:  [[ 4827.66898323]]    Loss_Validation:  [[ 1414.83565404]]\n",
      "Loop  2651 :    Loss_Train:  [[ 4827.66024358]]    Loss_Validation:  [[ 1414.83996407]]\n",
      "Loop  2652 :    Loss_Train:  [[ 4827.65151913]]    Loss_Validation:  [[ 1414.84427083]]\n",
      "Loop  2653 :    Loss_Train:  [[ 4827.64280983]]    Loss_Validation:  [[ 1414.84857432]]\n",
      "Loop  2654 :    Loss_Train:  [[ 4827.63411566]]    Loss_Validation:  [[ 1414.85287454]]\n",
      "Loop  2655 :    Loss_Train:  [[ 4827.62543659]]    Loss_Validation:  [[ 1414.85717149]]\n",
      "Loop  2656 :    Loss_Train:  [[ 4827.61677261]]    Loss_Validation:  [[ 1414.86146517]]\n",
      "Loop  2657 :    Loss_Train:  [[ 4827.60812366]]    Loss_Validation:  [[ 1414.8657556]]\n",
      "Loop  2658 :    Loss_Train:  [[ 4827.59948975]]    Loss_Validation:  [[ 1414.87004276]]\n",
      "Loop  2659 :    Loss_Train:  [[ 4827.59087082]]    Loss_Validation:  [[ 1414.87432667]]\n",
      "Loop  2660 :    Loss_Train:  [[ 4827.58226687]]    Loss_Validation:  [[ 1414.87860733]]\n",
      "Loop  2661 :    Loss_Train:  [[ 4827.57367785]]    Loss_Validation:  [[ 1414.88288473]]\n",
      "Loop  2662 :    Loss_Train:  [[ 4827.56510375]]    Loss_Validation:  [[ 1414.88715889]]\n",
      "Loop  2663 :    Loss_Train:  [[ 4827.55654454]]    Loss_Validation:  [[ 1414.8914298]]\n",
      "Loop  2664 :    Loss_Train:  [[ 4827.54800019]]    Loss_Validation:  [[ 1414.89569747]]\n",
      "Loop  2665 :    Loss_Train:  [[ 4827.53947067]]    Loss_Validation:  [[ 1414.89996189]]\n",
      "Loop  2666 :    Loss_Train:  [[ 4827.53095596]]    Loss_Validation:  [[ 1414.90422308]]\n",
      "Loop  2667 :    Loss_Train:  [[ 4827.52245604]]    Loss_Validation:  [[ 1414.90848104]]\n",
      "Loop  2668 :    Loss_Train:  [[ 4827.51397086]]    Loss_Validation:  [[ 1414.91273576]]\n",
      "Loop  2669 :    Loss_Train:  [[ 4827.50550042]]    Loss_Validation:  [[ 1414.91698725]]\n",
      "Loop  2670 :    Loss_Train:  [[ 4827.49704467]]    Loss_Validation:  [[ 1414.92123551]]\n",
      "Loop  2671 :    Loss_Train:  [[ 4827.4886036]]    Loss_Validation:  [[ 1414.92548055]]\n",
      "Loop  2672 :    Loss_Train:  [[ 4827.48017718]]    Loss_Validation:  [[ 1414.92972237]]\n",
      "Loop  2673 :    Loss_Train:  [[ 4827.47176538]]    Loss_Validation:  [[ 1414.93396097]]\n",
      "Loop  2674 :    Loss_Train:  [[ 4827.46336818]]    Loss_Validation:  [[ 1414.93819635]]\n",
      "Loop  2675 :    Loss_Train:  [[ 4827.45498555]]    Loss_Validation:  [[ 1414.94242851]]\n",
      "Loop  2676 :    Loss_Train:  [[ 4827.44661746]]    Loss_Validation:  [[ 1414.94665747]]\n",
      "Loop  2677 :    Loss_Train:  [[ 4827.43826389]]    Loss_Validation:  [[ 1414.95088321]]\n",
      "Loop  2678 :    Loss_Train:  [[ 4827.42992482]]    Loss_Validation:  [[ 1414.95510575]]\n",
      "Loop  2679 :    Loss_Train:  [[ 4827.42160021]]    Loss_Validation:  [[ 1414.95932509]]\n",
      "Loop  2680 :    Loss_Train:  [[ 4827.41329003]]    Loss_Validation:  [[ 1414.96354122]]\n",
      "Loop  2681 :    Loss_Train:  [[ 4827.40499428]]    Loss_Validation:  [[ 1414.96775416]]\n",
      "Loop  2682 :    Loss_Train:  [[ 4827.39671291]]    Loss_Validation:  [[ 1414.9719639]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  2683 :    Loss_Train:  [[ 4827.3884459]]    Loss_Validation:  [[ 1414.97617044]]\n",
      "Loop  2684 :    Loss_Train:  [[ 4827.38019323]]    Loss_Validation:  [[ 1414.9803738]]\n",
      "Loop  2685 :    Loss_Train:  [[ 4827.37195487]]    Loss_Validation:  [[ 1414.98457396]]\n",
      "Loop  2686 :    Loss_Train:  [[ 4827.3637308]]    Loss_Validation:  [[ 1414.98877094]]\n",
      "Loop  2687 :    Loss_Train:  [[ 4827.35552098]]    Loss_Validation:  [[ 1414.99296474]]\n",
      "Loop  2688 :    Loss_Train:  [[ 4827.3473254]]    Loss_Validation:  [[ 1414.99715536]]\n",
      "Loop  2689 :    Loss_Train:  [[ 4827.33914403]]    Loss_Validation:  [[ 1415.0013428]]\n",
      "Loop  2690 :    Loss_Train:  [[ 4827.33097685]]    Loss_Validation:  [[ 1415.00552706]]\n",
      "Loop  2691 :    Loss_Train:  [[ 4827.32282382]]    Loss_Validation:  [[ 1415.00970815]]\n",
      "Loop  2692 :    Loss_Train:  [[ 4827.31468492]]    Loss_Validation:  [[ 1415.01388607]]\n",
      "Loop  2693 :    Loss_Train:  [[ 4827.30656013]]    Loss_Validation:  [[ 1415.01806083]]\n",
      "Loop  2694 :    Loss_Train:  [[ 4827.29844942]]    Loss_Validation:  [[ 1415.02223241]]\n",
      "Loop  2695 :    Loss_Train:  [[ 4827.29035277]]    Loss_Validation:  [[ 1415.02640084]]\n",
      "Loop  2696 :    Loss_Train:  [[ 4827.28227015]]    Loss_Validation:  [[ 1415.03056611]]\n",
      "Loop  2697 :    Loss_Train:  [[ 4827.27420154]]    Loss_Validation:  [[ 1415.03472822]]\n",
      "Loop  2698 :    Loss_Train:  [[ 4827.2661469]]    Loss_Validation:  [[ 1415.03888717]]\n",
      "Loop  2699 :    Loss_Train:  [[ 4827.25810623]]    Loss_Validation:  [[ 1415.04304297]]\n",
      "Loop  2700 :    Loss_Train:  [[ 4827.25007948]]    Loss_Validation:  [[ 1415.04719562]]\n",
      "Loop  2701 :    Loss_Train:  [[ 4827.24206665]]    Loss_Validation:  [[ 1415.05134513]]\n",
      "Loop  2702 :    Loss_Train:  [[ 4827.23406769]]    Loss_Validation:  [[ 1415.05549149]]\n",
      "Loop  2703 :    Loss_Train:  [[ 4827.22608259]]    Loss_Validation:  [[ 1415.05963471]]\n",
      "Loop  2704 :    Loss_Train:  [[ 4827.21811132]]    Loss_Validation:  [[ 1415.06377479]]\n",
      "Loop  2705 :    Loss_Train:  [[ 4827.21015386]]    Loss_Validation:  [[ 1415.06791173]]\n",
      "Loop  2706 :    Loss_Train:  [[ 4827.20221019]]    Loss_Validation:  [[ 1415.07204554]]\n",
      "Loop  2707 :    Loss_Train:  [[ 4827.19428027]]    Loss_Validation:  [[ 1415.07617622]]\n",
      "Loop  2708 :    Loss_Train:  [[ 4827.18636408]]    Loss_Validation:  [[ 1415.08030377]]\n",
      "Loop  2709 :    Loss_Train:  [[ 4827.1784616]]    Loss_Validation:  [[ 1415.08442819]]\n",
      "Loop  2710 :    Loss_Train:  [[ 4827.17057281]]    Loss_Validation:  [[ 1415.08854949]]\n",
      "Loop  2711 :    Loss_Train:  [[ 4827.16269767]]    Loss_Validation:  [[ 1415.09266766]]\n",
      "Loop  2712 :    Loss_Train:  [[ 4827.15483617]]    Loss_Validation:  [[ 1415.09678272]]\n",
      "Loop  2713 :    Loss_Train:  [[ 4827.14698829]]    Loss_Validation:  [[ 1415.10089466]]\n",
      "Loop  2714 :    Loss_Train:  [[ 4827.13915398]]    Loss_Validation:  [[ 1415.10500349]]\n",
      "Loop  2715 :    Loss_Train:  [[ 4827.13133325]]    Loss_Validation:  [[ 1415.10910921]]\n",
      "Loop  2716 :    Loss_Train:  [[ 4827.12352604]]    Loss_Validation:  [[ 1415.11321181]]\n",
      "Loop  2717 :    Loss_Train:  [[ 4827.11573236]]    Loss_Validation:  [[ 1415.11731132]]\n",
      "Loop  2718 :    Loss_Train:  [[ 4827.10795216]]    Loss_Validation:  [[ 1415.12140771]]\n",
      "Loop  2719 :    Loss_Train:  [[ 4827.10018543]]    Loss_Validation:  [[ 1415.12550101]]\n",
      "Loop  2720 :    Loss_Train:  [[ 4827.09243214]]    Loss_Validation:  [[ 1415.12959121]]\n",
      "Loop  2721 :    Loss_Train:  [[ 4827.08469226]]    Loss_Validation:  [[ 1415.13367831]]\n",
      "Loop  2722 :    Loss_Train:  [[ 4827.07696578]]    Loss_Validation:  [[ 1415.13776232]]\n",
      "Loop  2723 :    Loss_Train:  [[ 4827.06925267]]    Loss_Validation:  [[ 1415.14184324]]\n",
      "Loop  2724 :    Loss_Train:  [[ 4827.06155291]]    Loss_Validation:  [[ 1415.14592107]]\n",
      "Loop  2725 :    Loss_Train:  [[ 4827.05386647]]    Loss_Validation:  [[ 1415.14999581]]\n",
      "Loop  2726 :    Loss_Train:  [[ 4827.04619332]]    Loss_Validation:  [[ 1415.15406747]]\n",
      "Loop  2727 :    Loss_Train:  [[ 4827.03853345]]    Loss_Validation:  [[ 1415.15813605]]\n",
      "Loop  2728 :    Loss_Train:  [[ 4827.03088683]]    Loss_Validation:  [[ 1415.16220155]]\n",
      "Loop  2729 :    Loss_Train:  [[ 4827.02325344]]    Loss_Validation:  [[ 1415.16626398]]\n",
      "Loop  2730 :    Loss_Train:  [[ 4827.01563325]]    Loss_Validation:  [[ 1415.17032333]]\n",
      "Loop  2731 :    Loss_Train:  [[ 4827.00802624]]    Loss_Validation:  [[ 1415.17437961]]\n",
      "Loop  2732 :    Loss_Train:  [[ 4827.00043239]]    Loss_Validation:  [[ 1415.17843283]]\n",
      "Loop  2733 :    Loss_Train:  [[ 4826.99285167]]    Loss_Validation:  [[ 1415.18248297]]\n",
      "Loop  2734 :    Loss_Train:  [[ 4826.98528406]]    Loss_Validation:  [[ 1415.18653006]]\n",
      "Loop  2735 :    Loss_Train:  [[ 4826.97772953]]    Loss_Validation:  [[ 1415.19057408]]\n",
      "Loop  2736 :    Loss_Train:  [[ 4826.97018807]]    Loss_Validation:  [[ 1415.19461505]]\n",
      "Loop  2737 :    Loss_Train:  [[ 4826.96265965]]    Loss_Validation:  [[ 1415.19865296]]\n",
      "Loop  2738 :    Loss_Train:  [[ 4826.95514424]]    Loss_Validation:  [[ 1415.20268782]]\n",
      "Loop  2739 :    Loss_Train:  [[ 4826.94764183]]    Loss_Validation:  [[ 1415.20671962]]\n",
      "Loop  2740 :    Loss_Train:  [[ 4826.94015238]]    Loss_Validation:  [[ 1415.21074838]]\n",
      "Loop  2741 :    Loss_Train:  [[ 4826.93267589]]    Loss_Validation:  [[ 1415.21477409]]\n",
      "Loop  2742 :    Loss_Train:  [[ 4826.92521231]]    Loss_Validation:  [[ 1415.21879676]]\n",
      "Loop  2743 :    Loss_Train:  [[ 4826.91776164]]    Loss_Validation:  [[ 1415.22281639]]\n",
      "Loop  2744 :    Loss_Train:  [[ 4826.91032384]]    Loss_Validation:  [[ 1415.22683298]]\n",
      "Loop  2745 :    Loss_Train:  [[ 4826.9028989]]    Loss_Validation:  [[ 1415.23084654]]\n",
      "Loop  2746 :    Loss_Train:  [[ 4826.89548679]]    Loss_Validation:  [[ 1415.23485706]]\n",
      "Loop  2747 :    Loss_Train:  [[ 4826.88808749]]    Loss_Validation:  [[ 1415.23886455]]\n",
      "Loop  2748 :    Loss_Train:  [[ 4826.88070097]]    Loss_Validation:  [[ 1415.24286901]]\n",
      "Loop  2749 :    Loss_Train:  [[ 4826.87332722]]    Loss_Validation:  [[ 1415.24687045]]\n",
      "Loop  2750 :    Loss_Train:  [[ 4826.8659662]]    Loss_Validation:  [[ 1415.25086886]]\n",
      "Loop  2751 :    Loss_Train:  [[ 4826.85861791]]    Loss_Validation:  [[ 1415.25486426]]\n",
      "Loop  2752 :    Loss_Train:  [[ 4826.85128231]]    Loss_Validation:  [[ 1415.25885663]]\n",
      "Loop  2753 :    Loss_Train:  [[ 4826.84395938]]    Loss_Validation:  [[ 1415.26284599]]\n",
      "Loop  2754 :    Loss_Train:  [[ 4826.8366491]]    Loss_Validation:  [[ 1415.26683234]]\n",
      "Loop  2755 :    Loss_Train:  [[ 4826.82935145]]    Loss_Validation:  [[ 1415.27081567]]\n",
      "Loop  2756 :    Loss_Train:  [[ 4826.8220664]]    Loss_Validation:  [[ 1415.274796]]\n",
      "Loop  2757 :    Loss_Train:  [[ 4826.81479394]]    Loss_Validation:  [[ 1415.27877332]]\n",
      "Loop  2758 :    Loss_Train:  [[ 4826.80753403]]    Loss_Validation:  [[ 1415.28274763]]\n",
      "Loop  2759 :    Loss_Train:  [[ 4826.80028666]]    Loss_Validation:  [[ 1415.28671895]]\n",
      "Loop  2760 :    Loss_Train:  [[ 4826.79305181]]    Loss_Validation:  [[ 1415.29068727]]\n",
      "Loop  2761 :    Loss_Train:  [[ 4826.78582945]]    Loss_Validation:  [[ 1415.29465259]]\n",
      "Loop  2762 :    Loss_Train:  [[ 4826.77861956]]    Loss_Validation:  [[ 1415.29861492]]\n",
      "Loop  2763 :    Loss_Train:  [[ 4826.77142212]]    Loss_Validation:  [[ 1415.30257425]]\n",
      "Loop  2764 :    Loss_Train:  [[ 4826.76423711]]    Loss_Validation:  [[ 1415.3065306]]\n",
      "Loop  2765 :    Loss_Train:  [[ 4826.7570645]]    Loss_Validation:  [[ 1415.31048396]]\n",
      "Loop  2766 :    Loss_Train:  [[ 4826.74990427]]    Loss_Validation:  [[ 1415.31443434]]\n",
      "Loop  2767 :    Loss_Train:  [[ 4826.7427564]]    Loss_Validation:  [[ 1415.31838174]]\n",
      "Loop  2768 :    Loss_Train:  [[ 4826.73562087]]    Loss_Validation:  [[ 1415.32232616]]\n",
      "Loop  2769 :    Loss_Train:  [[ 4826.72849765]]    Loss_Validation:  [[ 1415.3262676]]\n",
      "Loop  2770 :    Loss_Train:  [[ 4826.72138673]]    Loss_Validation:  [[ 1415.33020607]]\n",
      "Loop  2771 :    Loss_Train:  [[ 4826.71428808]]    Loss_Validation:  [[ 1415.33414156]]\n",
      "Loop  2772 :    Loss_Train:  [[ 4826.70720169]]    Loss_Validation:  [[ 1415.33807409]]\n",
      "Loop  2773 :    Loss_Train:  [[ 4826.70012752]]    Loss_Validation:  [[ 1415.34200365]]\n",
      "Loop  2774 :    Loss_Train:  [[ 4826.69306555]]    Loss_Validation:  [[ 1415.34593025]]\n",
      "Loop  2775 :    Loss_Train:  [[ 4826.68601578]]    Loss_Validation:  [[ 1415.34985388]]\n",
      "Loop  2776 :    Loss_Train:  [[ 4826.67897816]]    Loss_Validation:  [[ 1415.35377456]]\n",
      "Loop  2777 :    Loss_Train:  [[ 4826.67195269]]    Loss_Validation:  [[ 1415.35769227]]\n",
      "Loop  2778 :    Loss_Train:  [[ 4826.66493934]]    Loss_Validation:  [[ 1415.36160704]]\n",
      "Loop  2779 :    Loss_Train:  [[ 4826.65793808]]    Loss_Validation:  [[ 1415.36551885]]\n",
      "Loop  2780 :    Loss_Train:  [[ 4826.65094891]]    Loss_Validation:  [[ 1415.36942771]]\n",
      "Loop  2781 :    Loss_Train:  [[ 4826.64397179]]    Loss_Validation:  [[ 1415.37333363]]\n",
      "Loop  2782 :    Loss_Train:  [[ 4826.6370067]]    Loss_Validation:  [[ 1415.3772366]]\n",
      "Loop  2783 :    Loss_Train:  [[ 4826.63005363]]    Loss_Validation:  [[ 1415.38113662]]\n",
      "Loop  2784 :    Loss_Train:  [[ 4826.62311254]]    Loss_Validation:  [[ 1415.38503371]]\n",
      "Loop  2785 :    Loss_Train:  [[ 4826.61618343]]    Loss_Validation:  [[ 1415.38892786]]\n",
      "Loop  2786 :    Loss_Train:  [[ 4826.60926627]]    Loss_Validation:  [[ 1415.39281908]]\n",
      "Loop  2787 :    Loss_Train:  [[ 4826.60236103]]    Loss_Validation:  [[ 1415.39670736]]\n",
      "Loop  2788 :    Loss_Train:  [[ 4826.59546771]]    Loss_Validation:  [[ 1415.40059271]]\n",
      "Loop  2789 :    Loss_Train:  [[ 4826.58858626]]    Loss_Validation:  [[ 1415.40447514]]\n",
      "Loop  2790 :    Loss_Train:  [[ 4826.58171668]]    Loss_Validation:  [[ 1415.40835464]]\n",
      "Loop  2791 :    Loss_Train:  [[ 4826.57485895]]    Loss_Validation:  [[ 1415.41223121]]\n",
      "Loop  2792 :    Loss_Train:  [[ 4826.56801303]]    Loss_Validation:  [[ 1415.41610487]]\n",
      "Loop  2793 :    Loss_Train:  [[ 4826.56117892]]    Loss_Validation:  [[ 1415.41997561]]\n",
      "Loop  2794 :    Loss_Train:  [[ 4826.55435658]]    Loss_Validation:  [[ 1415.42384343]]\n",
      "Loop  2795 :    Loss_Train:  [[ 4826.54754601]]    Loss_Validation:  [[ 1415.42770834]]\n",
      "Loop  2796 :    Loss_Train:  [[ 4826.54074718]]    Loss_Validation:  [[ 1415.43157034]]\n",
      "Loop  2797 :    Loss_Train:  [[ 4826.53396006]]    Loss_Validation:  [[ 1415.43542942]]\n",
      "Loop  2798 :    Loss_Train:  [[ 4826.52718464]]    Loss_Validation:  [[ 1415.43928561]]\n",
      "Loop  2799 :    Loss_Train:  [[ 4826.52042089]]    Loss_Validation:  [[ 1415.44313889]]\n",
      "Loop  2800 :    Loss_Train:  [[ 4826.5136688]]    Loss_Validation:  [[ 1415.44698926]]\n",
      "Loop  2801 :    Loss_Train:  [[ 4826.50692834]]    Loss_Validation:  [[ 1415.45083674]]\n",
      "Loop  2802 :    Loss_Train:  [[ 4826.5001995]]    Loss_Validation:  [[ 1415.45468132]]\n",
      "Loop  2803 :    Loss_Train:  [[ 4826.49348225]]    Loss_Validation:  [[ 1415.45852301]]\n",
      "Loop  2804 :    Loss_Train:  [[ 4826.48677658]]    Loss_Validation:  [[ 1415.46236181]]\n",
      "Loop  2805 :    Loss_Train:  [[ 4826.48008245]]    Loss_Validation:  [[ 1415.46619771]]\n",
      "Loop  2806 :    Loss_Train:  [[ 4826.47339986]]    Loss_Validation:  [[ 1415.47003073]]\n",
      "Loop  2807 :    Loss_Train:  [[ 4826.46672878]]    Loss_Validation:  [[ 1415.47386086]]\n",
      "Loop  2808 :    Loss_Train:  [[ 4826.46006919]]    Loss_Validation:  [[ 1415.47768812]]\n",
      "Loop  2809 :    Loss_Train:  [[ 4826.45342107]]    Loss_Validation:  [[ 1415.48151249]]\n",
      "Loop  2810 :    Loss_Train:  [[ 4826.4467844]]    Loss_Validation:  [[ 1415.48533398]]\n",
      "Loop  2811 :    Loss_Train:  [[ 4826.44015915]]    Loss_Validation:  [[ 1415.4891526]]\n",
      "Loop  2812 :    Loss_Train:  [[ 4826.43354532]]    Loss_Validation:  [[ 1415.49296835]]\n",
      "Loop  2813 :    Loss_Train:  [[ 4826.42694288]]    Loss_Validation:  [[ 1415.49678122]]\n",
      "Loop  2814 :    Loss_Train:  [[ 4826.42035181]]    Loss_Validation:  [[ 1415.50059123]]\n",
      "Loop  2815 :    Loss_Train:  [[ 4826.41377208]]    Loss_Validation:  [[ 1415.50439837]]\n",
      "Loop  2816 :    Loss_Train:  [[ 4826.40720369]]    Loss_Validation:  [[ 1415.50820265]]\n",
      "Loop  2817 :    Loss_Train:  [[ 4826.4006466]]    Loss_Validation:  [[ 1415.51200407]]\n",
      "Loop  2818 :    Loss_Train:  [[ 4826.3941008]]    Loss_Validation:  [[ 1415.51580263]]\n",
      "Loop  2819 :    Loss_Train:  [[ 4826.38756627]]    Loss_Validation:  [[ 1415.51959833]]\n",
      "Loop  2820 :    Loss_Train:  [[ 4826.38104299]]    Loss_Validation:  [[ 1415.52339118]]\n",
      "Loop  2821 :    Loss_Train:  [[ 4826.37453094]]    Loss_Validation:  [[ 1415.52718117]]\n",
      "Loop  2822 :    Loss_Train:  [[ 4826.36803009]]    Loss_Validation:  [[ 1415.53096832]]\n",
      "Loop  2823 :    Loss_Train:  [[ 4826.36154044]]    Loss_Validation:  [[ 1415.53475262]]\n",
      "Loop  2824 :    Loss_Train:  [[ 4826.35506195]]    Loss_Validation:  [[ 1415.53853408]]\n",
      "Loop  2825 :    Loss_Train:  [[ 4826.34859461]]    Loss_Validation:  [[ 1415.54231269]]\n",
      "Loop  2826 :    Loss_Train:  [[ 4826.3421384]]    Loss_Validation:  [[ 1415.54608846]]\n",
      "Loop  2827 :    Loss_Train:  [[ 4826.33569331]]    Loss_Validation:  [[ 1415.5498614]]\n",
      "Loop  2828 :    Loss_Train:  [[ 4826.3292593]]    Loss_Validation:  [[ 1415.5536315]]\n",
      "Loop  2829 :    Loss_Train:  [[ 4826.32283636]]    Loss_Validation:  [[ 1415.55739877]]\n",
      "Loop  2830 :    Loss_Train:  [[ 4826.31642447]]    Loss_Validation:  [[ 1415.56116321]]\n",
      "Loop  2831 :    Loss_Train:  [[ 4826.31002362]]    Loss_Validation:  [[ 1415.56492482]]\n",
      "Loop  2832 :    Loss_Train:  [[ 4826.30363377]]    Loss_Validation:  [[ 1415.5686836]]\n",
      "Loop  2833 :    Loss_Train:  [[ 4826.29725492]]    Loss_Validation:  [[ 1415.57243956]]\n",
      "Loop  2834 :    Loss_Train:  [[ 4826.29088704]]    Loss_Validation:  [[ 1415.5761927]]\n",
      "Loop  2835 :    Loss_Train:  [[ 4826.28453012]]    Loss_Validation:  [[ 1415.57994302]]\n",
      "Loop  2836 :    Loss_Train:  [[ 4826.27818413]]    Loss_Validation:  [[ 1415.58369052]]\n",
      "Loop  2837 :    Loss_Train:  [[ 4826.27184905]]    Loss_Validation:  [[ 1415.58743521]]\n",
      "Loop  2838 :    Loss_Train:  [[ 4826.26552487]]    Loss_Validation:  [[ 1415.59117709]]\n",
      "Loop  2839 :    Loss_Train:  [[ 4826.25921156]]    Loss_Validation:  [[ 1415.59491615]]\n",
      "Loop  2840 :    Loss_Train:  [[ 4826.25290911]]    Loss_Validation:  [[ 1415.59865241]]\n",
      "Loop  2841 :    Loss_Train:  [[ 4826.2466175]]    Loss_Validation:  [[ 1415.60238587]]\n",
      "Loop  2842 :    Loss_Train:  [[ 4826.24033671]]    Loss_Validation:  [[ 1415.60611652]]\n",
      "Loop  2843 :    Loss_Train:  [[ 4826.23406671]]    Loss_Validation:  [[ 1415.60984437]]\n",
      "Loop  2844 :    Loss_Train:  [[ 4826.2278075]]    Loss_Validation:  [[ 1415.61356942]]\n",
      "Loop  2845 :    Loss_Train:  [[ 4826.22155904]]    Loss_Validation:  [[ 1415.61729168]]\n",
      "Loop  2846 :    Loss_Train:  [[ 4826.21532133]]    Loss_Validation:  [[ 1415.62101115]]\n",
      "Loop  2847 :    Loss_Train:  [[ 4826.20909434]]    Loss_Validation:  [[ 1415.62472782]]\n",
      "Loop  2848 :    Loss_Train:  [[ 4826.20287806]]    Loss_Validation:  [[ 1415.62844171]]\n",
      "Loop  2849 :    Loss_Train:  [[ 4826.19667246]]    Loss_Validation:  [[ 1415.6321528]]\n",
      "Loop  2850 :    Loss_Train:  [[ 4826.19047753]]    Loss_Validation:  [[ 1415.63586112]]\n",
      "Loop  2851 :    Loss_Train:  [[ 4826.18429324]]    Loss_Validation:  [[ 1415.63956665]]\n",
      "Loop  2852 :    Loss_Train:  [[ 4826.17811958]]    Loss_Validation:  [[ 1415.6432694]]\n",
      "Loop  2853 :    Loss_Train:  [[ 4826.17195654]]    Loss_Validation:  [[ 1415.64696938]]\n",
      "Loop  2854 :    Loss_Train:  [[ 4826.16580408]]    Loss_Validation:  [[ 1415.65066658]]\n",
      "Loop  2855 :    Loss_Train:  [[ 4826.15966219]]    Loss_Validation:  [[ 1415.654361]]\n",
      "Loop  2856 :    Loss_Train:  [[ 4826.15353086]]    Loss_Validation:  [[ 1415.65805266]]\n",
      "Loop  2857 :    Loss_Train:  [[ 4826.14741006]]    Loss_Validation:  [[ 1415.66174155]]\n",
      "Loop  2858 :    Loss_Train:  [[ 4826.14129978]]    Loss_Validation:  [[ 1415.66542767]]\n",
      "Loop  2859 :    Loss_Train:  [[ 4826.1352]]    Loss_Validation:  [[ 1415.66911103]]\n",
      "Loop  2860 :    Loss_Train:  [[ 4826.1291107]]    Loss_Validation:  [[ 1415.67279163]]\n",
      "Loop  2861 :    Loss_Train:  [[ 4826.12303185]]    Loss_Validation:  [[ 1415.67646946]]\n",
      "Loop  2862 :    Loss_Train:  [[ 4826.11696345]]    Loss_Validation:  [[ 1415.68014454]]\n",
      "Loop  2863 :    Loss_Train:  [[ 4826.11090547]]    Loss_Validation:  [[ 1415.68381687]]\n",
      "Loop  2864 :    Loss_Train:  [[ 4826.1048579]]    Loss_Validation:  [[ 1415.68748645]]\n",
      "Loop  2865 :    Loss_Train:  [[ 4826.09882072]]    Loss_Validation:  [[ 1415.69115327]]\n",
      "Loop  2866 :    Loss_Train:  [[ 4826.0927939]]    Loss_Validation:  [[ 1415.69481735]]\n",
      "Loop  2867 :    Loss_Train:  [[ 4826.08677743]]    Loss_Validation:  [[ 1415.69847868]]\n",
      "Loop  2868 :    Loss_Train:  [[ 4826.0807713]]    Loss_Validation:  [[ 1415.70213727]]\n",
      "Loop  2869 :    Loss_Train:  [[ 4826.07477547]]    Loss_Validation:  [[ 1415.70579311]]\n",
      "Loop  2870 :    Loss_Train:  [[ 4826.06878995]]    Loss_Validation:  [[ 1415.70944622]]\n",
      "Loop  2871 :    Loss_Train:  [[ 4826.0628147]]    Loss_Validation:  [[ 1415.71309659]]\n",
      "Loop  2872 :    Loss_Train:  [[ 4826.05684971]]    Loss_Validation:  [[ 1415.71674423]]\n",
      "Loop  2873 :    Loss_Train:  [[ 4826.05089496]]    Loss_Validation:  [[ 1415.72038914]]\n",
      "Loop  2874 :    Loss_Train:  [[ 4826.04495043]]    Loss_Validation:  [[ 1415.72403131]]\n",
      "Loop  2875 :    Loss_Train:  [[ 4826.03901611]]    Loss_Validation:  [[ 1415.72767076]]\n",
      "Loop  2876 :    Loss_Train:  [[ 4826.03309197]]    Loss_Validation:  [[ 1415.73130748]]\n",
      "Loop  2877 :    Loss_Train:  [[ 4826.02717801]]    Loss_Validation:  [[ 1415.73494149]]\n",
      "Loop  2878 :    Loss_Train:  [[ 4826.02127419]]    Loss_Validation:  [[ 1415.73857277]]\n",
      "Loop  2879 :    Loss_Train:  [[ 4826.01538051]]    Loss_Validation:  [[ 1415.74220133]]\n",
      "Loop  2880 :    Loss_Train:  [[ 4826.00949694]]    Loss_Validation:  [[ 1415.74582717]]\n",
      "Loop  2881 :    Loss_Train:  [[ 4826.00362347]]    Loss_Validation:  [[ 1415.7494503]]\n",
      "Loop  2882 :    Loss_Train:  [[ 4825.99776008]]    Loss_Validation:  [[ 1415.75307072]]\n",
      "Loop  2883 :    Loss_Train:  [[ 4825.99190675]]    Loss_Validation:  [[ 1415.75668843]]\n",
      "Loop  2884 :    Loss_Train:  [[ 4825.98606347]]    Loss_Validation:  [[ 1415.76030343]]\n",
      "Loop  2885 :    Loss_Train:  [[ 4825.98023021]]    Loss_Validation:  [[ 1415.76391573]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  2886 :    Loss_Train:  [[ 4825.97440696]]    Loss_Validation:  [[ 1415.76752533]]\n",
      "Loop  2887 :    Loss_Train:  [[ 4825.9685937]]    Loss_Validation:  [[ 1415.77113222]]\n",
      "Loop  2888 :    Loss_Train:  [[ 4825.96279041]]    Loss_Validation:  [[ 1415.77473642]]\n",
      "Loop  2889 :    Loss_Train:  [[ 4825.95699708]]    Loss_Validation:  [[ 1415.77833792]]\n",
      "Loop  2890 :    Loss_Train:  [[ 4825.95121368]]    Loss_Validation:  [[ 1415.78193672]]\n",
      "Loop  2891 :    Loss_Train:  [[ 4825.94544021]]    Loss_Validation:  [[ 1415.78553284]]\n",
      "Loop  2892 :    Loss_Train:  [[ 4825.93967664]]    Loss_Validation:  [[ 1415.78912626]]\n",
      "Loop  2893 :    Loss_Train:  [[ 4825.93392296]]    Loss_Validation:  [[ 1415.792717]]\n",
      "Loop  2894 :    Loss_Train:  [[ 4825.92817914]]    Loss_Validation:  [[ 1415.79630505]]\n",
      "Loop  2895 :    Loss_Train:  [[ 4825.92244517]]    Loss_Validation:  [[ 1415.79989042]]\n",
      "Loop  2896 :    Loss_Train:  [[ 4825.91672104]]    Loss_Validation:  [[ 1415.80347311]]\n",
      "Loop  2897 :    Loss_Train:  [[ 4825.91100673]]    Loss_Validation:  [[ 1415.80705312]]\n",
      "Loop  2898 :    Loss_Train:  [[ 4825.90530221]]    Loss_Validation:  [[ 1415.81063046]]\n",
      "Loop  2899 :    Loss_Train:  [[ 4825.89960747]]    Loss_Validation:  [[ 1415.81420512]]\n",
      "Loop  2900 :    Loss_Train:  [[ 4825.8939225]]    Loss_Validation:  [[ 1415.8177771]]\n",
      "Loop  2901 :    Loss_Train:  [[ 4825.88824727]]    Loss_Validation:  [[ 1415.82134642]]\n",
      "Loop  2902 :    Loss_Train:  [[ 4825.88258178]]    Loss_Validation:  [[ 1415.82491307]]\n",
      "Loop  2903 :    Loss_Train:  [[ 4825.87692599]]    Loss_Validation:  [[ 1415.82847706]]\n",
      "Loop  2904 :    Loss_Train:  [[ 4825.87127991]]    Loss_Validation:  [[ 1415.83203838]]\n",
      "Loop  2905 :    Loss_Train:  [[ 4825.8656435]]    Loss_Validation:  [[ 1415.83559705]]\n",
      "Loop  2906 :    Loss_Train:  [[ 4825.86001675]]    Loss_Validation:  [[ 1415.83915305]]\n",
      "Loop  2907 :    Loss_Train:  [[ 4825.85439965]]    Loss_Validation:  [[ 1415.8427064]]\n",
      "Loop  2908 :    Loss_Train:  [[ 4825.84879217]]    Loss_Validation:  [[ 1415.84625709]]\n",
      "Loop  2909 :    Loss_Train:  [[ 4825.84319431]]    Loss_Validation:  [[ 1415.84980513]]\n",
      "Loop  2910 :    Loss_Train:  [[ 4825.83760603]]    Loss_Validation:  [[ 1415.85335052]]\n",
      "Loop  2911 :    Loss_Train:  [[ 4825.83202734]]    Loss_Validation:  [[ 1415.85689327]]\n",
      "Loop  2912 :    Loss_Train:  [[ 4825.8264582]]    Loss_Validation:  [[ 1415.86043337]]\n",
      "Loop  2913 :    Loss_Train:  [[ 4825.82089861]]    Loss_Validation:  [[ 1415.86397082]]\n",
      "Loop  2914 :    Loss_Train:  [[ 4825.81534854]]    Loss_Validation:  [[ 1415.86750563]]\n",
      "Loop  2915 :    Loss_Train:  [[ 4825.80980799]]    Loss_Validation:  [[ 1415.87103781]]\n",
      "Loop  2916 :    Loss_Train:  [[ 4825.80427692]]    Loss_Validation:  [[ 1415.87456735]]\n",
      "Loop  2917 :    Loss_Train:  [[ 4825.79875533]]    Loss_Validation:  [[ 1415.87809425]]\n",
      "Loop  2918 :    Loss_Train:  [[ 4825.7932432]]    Loss_Validation:  [[ 1415.88161852]]\n",
      "Loop  2919 :    Loss_Train:  [[ 4825.78774052]]    Loss_Validation:  [[ 1415.88514016]]\n",
      "Loop  2920 :    Loss_Train:  [[ 4825.78224725]]    Loss_Validation:  [[ 1415.88865917]]\n",
      "Loop  2921 :    Loss_Train:  [[ 4825.7767634]]    Loss_Validation:  [[ 1415.89217556]]\n",
      "Loop  2922 :    Loss_Train:  [[ 4825.77128894]]    Loss_Validation:  [[ 1415.89568932]]\n",
      "Loop  2923 :    Loss_Train:  [[ 4825.76582386]]    Loss_Validation:  [[ 1415.89920046]]\n",
      "Loop  2924 :    Loss_Train:  [[ 4825.76036814]]    Loss_Validation:  [[ 1415.90270898]]\n",
      "Loop  2925 :    Loss_Train:  [[ 4825.75492176]]    Loss_Validation:  [[ 1415.90621489]]\n",
      "Loop  2926 :    Loss_Train:  [[ 4825.7494847]]    Loss_Validation:  [[ 1415.90971818]]\n",
      "Loop  2927 :    Loss_Train:  [[ 4825.74405696]]    Loss_Validation:  [[ 1415.91321885]]\n",
      "Loop  2928 :    Loss_Train:  [[ 4825.73863851]]    Loss_Validation:  [[ 1415.91671692]]\n",
      "Loop  2929 :    Loss_Train:  [[ 4825.73322934]]    Loss_Validation:  [[ 1415.92021237]]\n",
      "Loop  2930 :    Loss_Train:  [[ 4825.72782943]]    Loss_Validation:  [[ 1415.92370522]]\n",
      "Loop  2931 :    Loss_Train:  [[ 4825.72243877]]    Loss_Validation:  [[ 1415.92719547]]\n",
      "Loop  2932 :    Loss_Train:  [[ 4825.71705733]]    Loss_Validation:  [[ 1415.93068311]]\n",
      "Loop  2933 :    Loss_Train:  [[ 4825.71168511]]    Loss_Validation:  [[ 1415.93416815]]\n",
      "Loop  2934 :    Loss_Train:  [[ 4825.70632208]]    Loss_Validation:  [[ 1415.9376506]]\n",
      "Loop  2935 :    Loss_Train:  [[ 4825.70096824]]    Loss_Validation:  [[ 1415.94113045]]\n",
      "Loop  2936 :    Loss_Train:  [[ 4825.69562355]]    Loss_Validation:  [[ 1415.9446077]]\n",
      "Loop  2937 :    Loss_Train:  [[ 4825.69028802]]    Loss_Validation:  [[ 1415.94808237]]\n",
      "Loop  2938 :    Loss_Train:  [[ 4825.68496162]]    Loss_Validation:  [[ 1415.95155444]]\n",
      "Loop  2939 :    Loss_Train:  [[ 4825.67964433]]    Loss_Validation:  [[ 1415.95502393]]\n",
      "Loop  2940 :    Loss_Train:  [[ 4825.67433614]]    Loss_Validation:  [[ 1415.95849083]]\n",
      "Loop  2941 :    Loss_Train:  [[ 4825.66903704]]    Loss_Validation:  [[ 1415.96195515]]\n",
      "Loop  2942 :    Loss_Train:  [[ 4825.66374701]]    Loss_Validation:  [[ 1415.96541688]]\n",
      "Loop  2943 :    Loss_Train:  [[ 4825.65846602]]    Loss_Validation:  [[ 1415.96887604]]\n",
      "Loop  2944 :    Loss_Train:  [[ 4825.65319408]]    Loss_Validation:  [[ 1415.97233262]]\n",
      "Loop  2945 :    Loss_Train:  [[ 4825.64793115]]    Loss_Validation:  [[ 1415.97578663]]\n",
      "Loop  2946 :    Loss_Train:  [[ 4825.64267723]]    Loss_Validation:  [[ 1415.97923807]]\n",
      "Loop  2947 :    Loss_Train:  [[ 4825.63743229]]    Loss_Validation:  [[ 1415.98268693]]\n",
      "Loop  2948 :    Loss_Train:  [[ 4825.63219633]]    Loss_Validation:  [[ 1415.98613323]]\n",
      "Loop  2949 :    Loss_Train:  [[ 4825.62696933]]    Loss_Validation:  [[ 1415.98957696]]\n",
      "Loop  2950 :    Loss_Train:  [[ 4825.62175126]]    Loss_Validation:  [[ 1415.99301812]]\n",
      "Loop  2951 :    Loss_Train:  [[ 4825.61654213]]    Loss_Validation:  [[ 1415.99645673]]\n",
      "Loop  2952 :    Loss_Train:  [[ 4825.6113419]]    Loss_Validation:  [[ 1415.99989277]]\n",
      "Loop  2953 :    Loss_Train:  [[ 4825.60615057]]    Loss_Validation:  [[ 1416.00332626]]\n",
      "Loop  2954 :    Loss_Train:  [[ 4825.60096811]]    Loss_Validation:  [[ 1416.00675719]]\n",
      "Loop  2955 :    Loss_Train:  [[ 4825.59579452]]    Loss_Validation:  [[ 1416.01018556]]\n",
      "Loop  2956 :    Loss_Train:  [[ 4825.59062977]]    Loss_Validation:  [[ 1416.01361139]]\n",
      "Loop  2957 :    Loss_Train:  [[ 4825.58547386]]    Loss_Validation:  [[ 1416.01703467]]\n",
      "Loop  2958 :    Loss_Train:  [[ 4825.58032676]]    Loss_Validation:  [[ 1416.02045539]]\n",
      "Loop  2959 :    Loss_Train:  [[ 4825.57518847]]    Loss_Validation:  [[ 1416.02387358]]\n",
      "Loop  2960 :    Loss_Train:  [[ 4825.57005896]]    Loss_Validation:  [[ 1416.02728922]]\n",
      "Loop  2961 :    Loss_Train:  [[ 4825.56493822]]    Loss_Validation:  [[ 1416.03070232]]\n",
      "Loop  2962 :    Loss_Train:  [[ 4825.55982623]]    Loss_Validation:  [[ 1416.03411288]]\n",
      "Loop  2963 :    Loss_Train:  [[ 4825.55472298]]    Loss_Validation:  [[ 1416.0375209]]\n",
      "Loop  2964 :    Loss_Train:  [[ 4825.54962846]]    Loss_Validation:  [[ 1416.04092639]]\n",
      "Loop  2965 :    Loss_Train:  [[ 4825.54454265]]    Loss_Validation:  [[ 1416.04432935]]\n",
      "Loop  2966 :    Loss_Train:  [[ 4825.53946553]]    Loss_Validation:  [[ 1416.04772978]]\n",
      "Loop  2967 :    Loss_Train:  [[ 4825.53439708]]    Loss_Validation:  [[ 1416.05112767]]\n",
      "Loop  2968 :    Loss_Train:  [[ 4825.5293373]]    Loss_Validation:  [[ 1416.05452305]]\n",
      "Loop  2969 :    Loss_Train:  [[ 4825.52428617]]    Loss_Validation:  [[ 1416.05791589]]\n",
      "Loop  2970 :    Loss_Train:  [[ 4825.51924367]]    Loss_Validation:  [[ 1416.06130622]]\n",
      "Loop  2971 :    Loss_Train:  [[ 4825.51420979]]    Loss_Validation:  [[ 1416.06469402]]\n",
      "Loop  2972 :    Loss_Train:  [[ 4825.50918451]]    Loss_Validation:  [[ 1416.06807931]]\n",
      "Loop  2973 :    Loss_Train:  [[ 4825.50416782]]    Loss_Validation:  [[ 1416.07146208]]\n",
      "Loop  2974 :    Loss_Train:  [[ 4825.4991597]]    Loss_Validation:  [[ 1416.07484234]]\n",
      "Loop  2975 :    Loss_Train:  [[ 4825.49416013]]    Loss_Validation:  [[ 1416.07822008]]\n",
      "Loop  2976 :    Loss_Train:  [[ 4825.48916911]]    Loss_Validation:  [[ 1416.08159531]]\n",
      "Loop  2977 :    Loss_Train:  [[ 4825.48418662]]    Loss_Validation:  [[ 1416.08496804]]\n",
      "Loop  2978 :    Loss_Train:  [[ 4825.47921263]]    Loss_Validation:  [[ 1416.08833826]]\n",
      "Loop  2979 :    Loss_Train:  [[ 4825.47424715]]    Loss_Validation:  [[ 1416.09170598]]\n",
      "Loop  2980 :    Loss_Train:  [[ 4825.46929014]]    Loss_Validation:  [[ 1416.0950712]]\n",
      "Loop  2981 :    Loss_Train:  [[ 4825.46434161]]    Loss_Validation:  [[ 1416.09843391]]\n",
      "Loop  2982 :    Loss_Train:  [[ 4825.45940153]]    Loss_Validation:  [[ 1416.10179413]]\n",
      "Loop  2983 :    Loss_Train:  [[ 4825.45446988]]    Loss_Validation:  [[ 1416.10515185]]\n",
      "Loop  2984 :    Loss_Train:  [[ 4825.44954666]]    Loss_Validation:  [[ 1416.10850708]]\n",
      "Loop  2985 :    Loss_Train:  [[ 4825.44463184]]    Loss_Validation:  [[ 1416.11185982]]\n",
      "Loop  2986 :    Loss_Train:  [[ 4825.43972542]]    Loss_Validation:  [[ 1416.11521007]]\n",
      "Loop  2987 :    Loss_Train:  [[ 4825.43482738]]    Loss_Validation:  [[ 1416.11855783]]\n",
      "Loop  2988 :    Loss_Train:  [[ 4825.4299377]]    Loss_Validation:  [[ 1416.12190311]]\n",
      "Loop  2989 :    Loss_Train:  [[ 4825.42505637]]    Loss_Validation:  [[ 1416.1252459]]\n",
      "Loop  2990 :    Loss_Train:  [[ 4825.42018338]]    Loss_Validation:  [[ 1416.12858621]]\n",
      "Loop  2991 :    Loss_Train:  [[ 4825.41531871]]    Loss_Validation:  [[ 1416.13192405]]\n",
      "Loop  2992 :    Loss_Train:  [[ 4825.41046234]]    Loss_Validation:  [[ 1416.1352594]]\n",
      "Loop  2993 :    Loss_Train:  [[ 4825.40561426]]    Loss_Validation:  [[ 1416.13859228]]\n",
      "Loop  2994 :    Loss_Train:  [[ 4825.40077446]]    Loss_Validation:  [[ 1416.14192269]]\n",
      "Loop  2995 :    Loss_Train:  [[ 4825.39594292]]    Loss_Validation:  [[ 1416.14525063]]\n",
      "Loop  2996 :    Loss_Train:  [[ 4825.39111963]]    Loss_Validation:  [[ 1416.14857609]]\n",
      "Loop  2997 :    Loss_Train:  [[ 4825.38630457]]    Loss_Validation:  [[ 1416.15189909]]\n",
      "Loop  2998 :    Loss_Train:  [[ 4825.38149773]]    Loss_Validation:  [[ 1416.15521963]]\n",
      "Loop  2999 :    Loss_Train:  [[ 4825.3766991]]    Loss_Validation:  [[ 1416.1585377]]\n",
      "Loop  3000 :    Loss_Train:  [[ 4825.37190865]]    Loss_Validation:  [[ 1416.16185331]]\n",
      "Loop  3001 :    Loss_Train:  [[ 4825.36712639]]    Loss_Validation:  [[ 1416.16516647]]\n",
      "Loop  3002 :    Loss_Train:  [[ 4825.36235228]]    Loss_Validation:  [[ 1416.16847716]]\n",
      "Loop  3003 :    Loss_Train:  [[ 4825.35758632]]    Loss_Validation:  [[ 1416.1717854]]\n",
      "Loop  3004 :    Loss_Train:  [[ 4825.35282849]]    Loss_Validation:  [[ 1416.17509119]]\n",
      "Loop  3005 :    Loss_Train:  [[ 4825.34807878]]    Loss_Validation:  [[ 1416.17839453]]\n",
      "Loop  3006 :    Loss_Train:  [[ 4825.34333717]]    Loss_Validation:  [[ 1416.18169542]]\n",
      "Loop  3007 :    Loss_Train:  [[ 4825.33860366]]    Loss_Validation:  [[ 1416.18499386]]\n",
      "Loop  3008 :    Loss_Train:  [[ 4825.33387822]]    Loss_Validation:  [[ 1416.18828985]]\n",
      "Loop  3009 :    Loss_Train:  [[ 4825.32916084]]    Loss_Validation:  [[ 1416.19158341]]\n",
      "Loop  3010 :    Loss_Train:  [[ 4825.32445151]]    Loss_Validation:  [[ 1416.19487452]]\n",
      "Loop  3011 :    Loss_Train:  [[ 4825.31975022]]    Loss_Validation:  [[ 1416.19816319]]\n",
      "Loop  3012 :    Loss_Train:  [[ 4825.31505694]]    Loss_Validation:  [[ 1416.20144943]]\n",
      "Loop  3013 :    Loss_Train:  [[ 4825.31037167]]    Loss_Validation:  [[ 1416.20473323]]\n",
      "Loop  3014 :    Loss_Train:  [[ 4825.30569439]]    Loss_Validation:  [[ 1416.2080146]]\n",
      "Loop  3015 :    Loss_Train:  [[ 4825.30102509]]    Loss_Validation:  [[ 1416.21129354]]\n",
      "Loop  3016 :    Loss_Train:  [[ 4825.29636375]]    Loss_Validation:  [[ 1416.21457005]]\n",
      "Loop  3017 :    Loss_Train:  [[ 4825.29171036]]    Loss_Validation:  [[ 1416.21784413]]\n",
      "Loop  3018 :    Loss_Train:  [[ 4825.28706491]]    Loss_Validation:  [[ 1416.22111579]]\n",
      "Loop  3019 :    Loss_Train:  [[ 4825.28242738]]    Loss_Validation:  [[ 1416.22438502]]\n",
      "Loop  3020 :    Loss_Train:  [[ 4825.27779776]]    Loss_Validation:  [[ 1416.22765184]]\n",
      "Loop  3021 :    Loss_Train:  [[ 4825.27317603]]    Loss_Validation:  [[ 1416.23091623]]\n",
      "Loop  3022 :    Loss_Train:  [[ 4825.26856218]]    Loss_Validation:  [[ 1416.23417821]]\n",
      "Loop  3023 :    Loss_Train:  [[ 4825.2639562]]    Loss_Validation:  [[ 1416.23743777]]\n",
      "Loop  3024 :    Loss_Train:  [[ 4825.25935807]]    Loss_Validation:  [[ 1416.24069492]]\n",
      "Loop  3025 :    Loss_Train:  [[ 4825.25476778]]    Loss_Validation:  [[ 1416.24394966]]\n",
      "Loop  3026 :    Loss_Train:  [[ 4825.25018532]]    Loss_Validation:  [[ 1416.24720199]]\n",
      "Loop  3027 :    Loss_Train:  [[ 4825.24561067]]    Loss_Validation:  [[ 1416.25045191]]\n",
      "Loop  3028 :    Loss_Train:  [[ 4825.24104381]]    Loss_Validation:  [[ 1416.25369942]]\n",
      "Loop  3029 :    Loss_Train:  [[ 4825.23648474]]    Loss_Validation:  [[ 1416.25694454]]\n",
      "Loop  3030 :    Loss_Train:  [[ 4825.23193344]]    Loss_Validation:  [[ 1416.26018725]]\n",
      "Loop  3031 :    Loss_Train:  [[ 4825.2273899]]    Loss_Validation:  [[ 1416.26342756]]\n",
      "Loop  3032 :    Loss_Train:  [[ 4825.2228541]]    Loss_Validation:  [[ 1416.26666548]]\n",
      "Loop  3033 :    Loss_Train:  [[ 4825.21832604]]    Loss_Validation:  [[ 1416.269901]]\n",
      "Loop  3034 :    Loss_Train:  [[ 4825.21380569]]    Loss_Validation:  [[ 1416.27313412]]\n",
      "Loop  3035 :    Loss_Train:  [[ 4825.20929304]]    Loss_Validation:  [[ 1416.27636486]]\n",
      "Loop  3036 :    Loss_Train:  [[ 4825.20478808]]    Loss_Validation:  [[ 1416.27959321]]\n",
      "Loop  3037 :    Loss_Train:  [[ 4825.2002908]]    Loss_Validation:  [[ 1416.28281916]]\n",
      "Loop  3038 :    Loss_Train:  [[ 4825.19580118]]    Loss_Validation:  [[ 1416.28604274]]\n",
      "Loop  3039 :    Loss_Train:  [[ 4825.19131921]]    Loss_Validation:  [[ 1416.28926392]]\n",
      "Loop  3040 :    Loss_Train:  [[ 4825.18684488]]    Loss_Validation:  [[ 1416.29248273]]\n",
      "Loop  3041 :    Loss_Train:  [[ 4825.18237817]]    Loss_Validation:  [[ 1416.29569916]]\n",
      "Loop  3042 :    Loss_Train:  [[ 4825.17791907]]    Loss_Validation:  [[ 1416.29891321]]\n",
      "Loop  3043 :    Loss_Train:  [[ 4825.17346757]]    Loss_Validation:  [[ 1416.30212488]]\n",
      "Loop  3044 :    Loss_Train:  [[ 4825.16902365]]    Loss_Validation:  [[ 1416.30533418]]\n",
      "Loop  3045 :    Loss_Train:  [[ 4825.1645873]]    Loss_Validation:  [[ 1416.30854111]]\n",
      "Loop  3046 :    Loss_Train:  [[ 4825.1601585]]    Loss_Validation:  [[ 1416.31174567]]\n",
      "Loop  3047 :    Loss_Train:  [[ 4825.15573725]]    Loss_Validation:  [[ 1416.31494786]]\n",
      "Loop  3048 :    Loss_Train:  [[ 4825.15132353]]    Loss_Validation:  [[ 1416.31814768]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  3049 :    Loss_Train:  [[ 4825.14691732]]    Loss_Validation:  [[ 1416.32134514]]\n",
      "Loop  3050 :    Loss_Train:  [[ 4825.14251862]]    Loss_Validation:  [[ 1416.32454023]]\n",
      "Loop  3051 :    Loss_Train:  [[ 4825.13812741]]    Loss_Validation:  [[ 1416.32773297]]\n",
      "Loop  3052 :    Loss_Train:  [[ 4825.13374368]]    Loss_Validation:  [[ 1416.33092335]]\n",
      "Loop  3053 :    Loss_Train:  [[ 4825.12936742]]    Loss_Validation:  [[ 1416.33411137]]\n",
      "Loop  3054 :    Loss_Train:  [[ 4825.1249986]]    Loss_Validation:  [[ 1416.33729703]]\n",
      "Loop  3055 :    Loss_Train:  [[ 4825.12063722]]    Loss_Validation:  [[ 1416.34048035]]\n",
      "Loop  3056 :    Loss_Train:  [[ 4825.11628327]]    Loss_Validation:  [[ 1416.34366131]]\n",
      "Loop  3057 :    Loss_Train:  [[ 4825.11193673]]    Loss_Validation:  [[ 1416.34683992]]\n",
      "Loop  3058 :    Loss_Train:  [[ 4825.1075976]]    Loss_Validation:  [[ 1416.35001619]]\n",
      "Loop  3059 :    Loss_Train:  [[ 4825.10326584]]    Loss_Validation:  [[ 1416.35319011]]\n",
      "Loop  3060 :    Loss_Train:  [[ 4825.09894147]]    Loss_Validation:  [[ 1416.35636169]]\n",
      "Loop  3061 :    Loss_Train:  [[ 4825.09462445]]    Loss_Validation:  [[ 1416.35953093]]\n",
      "Loop  3062 :    Loss_Train:  [[ 4825.09031478]]    Loss_Validation:  [[ 1416.36269782]]\n",
      "Loop  3063 :    Loss_Train:  [[ 4825.08601245]]    Loss_Validation:  [[ 1416.36586238]]\n",
      "Loop  3064 :    Loss_Train:  [[ 4825.08171744]]    Loss_Validation:  [[ 1416.36902461]]\n",
      "Loop  3065 :    Loss_Train:  [[ 4825.07742974]]    Loss_Validation:  [[ 1416.3721845]]\n",
      "Loop  3066 :    Loss_Train:  [[ 4825.07314933]]    Loss_Validation:  [[ 1416.37534206]]\n",
      "Loop  3067 :    Loss_Train:  [[ 4825.06887621]]    Loss_Validation:  [[ 1416.37849729]]\n",
      "Loop  3068 :    Loss_Train:  [[ 4825.06461037]]    Loss_Validation:  [[ 1416.38165019]]\n",
      "Loop  3069 :    Loss_Train:  [[ 4825.06035178]]    Loss_Validation:  [[ 1416.38480076]]\n",
      "Loop  3070 :    Loss_Train:  [[ 4825.05610044]]    Loss_Validation:  [[ 1416.38794901]]\n",
      "Loop  3071 :    Loss_Train:  [[ 4825.05185633]]    Loss_Validation:  [[ 1416.39109494]]\n",
      "Loop  3072 :    Loss_Train:  [[ 4825.04761944]]    Loss_Validation:  [[ 1416.39423855]]\n",
      "Loop  3073 :    Loss_Train:  [[ 4825.04338976]]    Loss_Validation:  [[ 1416.39737984]]\n",
      "Loop  3074 :    Loss_Train:  [[ 4825.03916728]]    Loss_Validation:  [[ 1416.40051881]]\n",
      "Loop  3075 :    Loss_Train:  [[ 4825.03495198]]    Loss_Validation:  [[ 1416.40365547]]\n",
      "Loop  3076 :    Loss_Train:  [[ 4825.03074385]]    Loss_Validation:  [[ 1416.40678982]]\n",
      "Loop  3077 :    Loss_Train:  [[ 4825.02654288]]    Loss_Validation:  [[ 1416.40992185]]\n",
      "Loop  3078 :    Loss_Train:  [[ 4825.02234906]]    Loss_Validation:  [[ 1416.41305158]]\n",
      "Loop  3079 :    Loss_Train:  [[ 4825.01816237]]    Loss_Validation:  [[ 1416.41617899]]\n",
      "Loop  3080 :    Loss_Train:  [[ 4825.0139828]]    Loss_Validation:  [[ 1416.41930411]]\n",
      "Loop  3081 :    Loss_Train:  [[ 4825.00981034]]    Loss_Validation:  [[ 1416.42242692]]\n",
      "Loop  3082 :    Loss_Train:  [[ 4825.00564498]]    Loss_Validation:  [[ 1416.42554742]]\n",
      "Loop  3083 :    Loss_Train:  [[ 4825.0014867]]    Loss_Validation:  [[ 1416.42866563]]\n",
      "Loop  3084 :    Loss_Train:  [[ 4824.99733549]]    Loss_Validation:  [[ 1416.43178154]]\n",
      "Loop  3085 :    Loss_Train:  [[ 4824.99319134]]    Loss_Validation:  [[ 1416.43489516]]\n",
      "Loop  3086 :    Loss_Train:  [[ 4824.98905423]]    Loss_Validation:  [[ 1416.43800648]]\n",
      "Loop  3087 :    Loss_Train:  [[ 4824.98492417]]    Loss_Validation:  [[ 1416.4411155]]\n",
      "Loop  3088 :    Loss_Train:  [[ 4824.98080112]]    Loss_Validation:  [[ 1416.44422224]]\n",
      "Loop  3089 :    Loss_Train:  [[ 4824.97668509]]    Loss_Validation:  [[ 1416.44732669]]\n",
      "Loop  3090 :    Loss_Train:  [[ 4824.97257605]]    Loss_Validation:  [[ 1416.45042885]]\n",
      "Loop  3091 :    Loss_Train:  [[ 4824.968474]]    Loss_Validation:  [[ 1416.45352873]]\n",
      "Loop  3092 :    Loss_Train:  [[ 4824.96437892]]    Loss_Validation:  [[ 1416.45662632]]\n",
      "Loop  3093 :    Loss_Train:  [[ 4824.9602908]]    Loss_Validation:  [[ 1416.45972164]]\n",
      "Loop  3094 :    Loss_Train:  [[ 4824.95620964]]    Loss_Validation:  [[ 1416.46281467]]\n",
      "Loop  3095 :    Loss_Train:  [[ 4824.95213541]]    Loss_Validation:  [[ 1416.46590543]]\n",
      "Loop  3096 :    Loss_Train:  [[ 4824.9480681]]    Loss_Validation:  [[ 1416.46899391]]\n",
      "Loop  3097 :    Loss_Train:  [[ 4824.94400771]]    Loss_Validation:  [[ 1416.47208011]]\n",
      "Loop  3098 :    Loss_Train:  [[ 4824.93995422]]    Loss_Validation:  [[ 1416.47516405]]\n",
      "Loop  3099 :    Loss_Train:  [[ 4824.93590762]]    Loss_Validation:  [[ 1416.47824571]]\n",
      "Loop  3100 :    Loss_Train:  [[ 4824.93186789]]    Loss_Validation:  [[ 1416.48132511]]\n",
      "Loop  3101 :    Loss_Train:  [[ 4824.92783503]]    Loss_Validation:  [[ 1416.48440224]]\n",
      "Loop  3102 :    Loss_Train:  [[ 4824.92380903]]    Loss_Validation:  [[ 1416.48747711]]\n",
      "Loop  3103 :    Loss_Train:  [[ 4824.91978986]]    Loss_Validation:  [[ 1416.49054971]]\n",
      "Loop  3104 :    Loss_Train:  [[ 4824.91577753]]    Loss_Validation:  [[ 1416.49362005]]\n",
      "Loop  3105 :    Loss_Train:  [[ 4824.91177201]]    Loss_Validation:  [[ 1416.49668814]]\n",
      "Loop  3106 :    Loss_Train:  [[ 4824.9077733]]    Loss_Validation:  [[ 1416.49975396]]\n",
      "Loop  3107 :    Loss_Train:  [[ 4824.90378138]]    Loss_Validation:  [[ 1416.50281753]]\n",
      "Loop  3108 :    Loss_Train:  [[ 4824.89979624]]    Loss_Validation:  [[ 1416.50587885]]\n",
      "Loop  3109 :    Loss_Train:  [[ 4824.89581788]]    Loss_Validation:  [[ 1416.50893791]]\n",
      "Loop  3110 :    Loss_Train:  [[ 4824.89184627]]    Loss_Validation:  [[ 1416.51199473]]\n",
      "Loop  3111 :    Loss_Train:  [[ 4824.88788141]]    Loss_Validation:  [[ 1416.5150493]]\n",
      "Loop  3112 :    Loss_Train:  [[ 4824.88392328]]    Loss_Validation:  [[ 1416.51810162]]\n",
      "Loop  3113 :    Loss_Train:  [[ 4824.87997188]]    Loss_Validation:  [[ 1416.5211517]]\n",
      "Loop  3114 :    Loss_Train:  [[ 4824.87602719]]    Loss_Validation:  [[ 1416.52419953]]\n",
      "Loop  3115 :    Loss_Train:  [[ 4824.87208919]]    Loss_Validation:  [[ 1416.52724512]]\n",
      "Loop  3116 :    Loss_Train:  [[ 4824.86815789]]    Loss_Validation:  [[ 1416.53028848]]\n",
      "Loop  3117 :    Loss_Train:  [[ 4824.86423326]]    Loss_Validation:  [[ 1416.5333296]]\n",
      "Loop  3118 :    Loss_Train:  [[ 4824.8603153]]    Loss_Validation:  [[ 1416.53636848]]\n",
      "Loop  3119 :    Loss_Train:  [[ 4824.85640399]]    Loss_Validation:  [[ 1416.53940513]]\n",
      "Loop  3120 :    Loss_Train:  [[ 4824.85249932]]    Loss_Validation:  [[ 1416.54243954]]\n",
      "Loop  3121 :    Loss_Train:  [[ 4824.84860129]]    Loss_Validation:  [[ 1416.54547173]]\n",
      "Loop  3122 :    Loss_Train:  [[ 4824.84470987]]    Loss_Validation:  [[ 1416.54850169]]\n",
      "Loop  3123 :    Loss_Train:  [[ 4824.84082506]]    Loss_Validation:  [[ 1416.55152942]]\n",
      "Loop  3124 :    Loss_Train:  [[ 4824.83694684]]    Loss_Validation:  [[ 1416.55455493]]\n",
      "Loop  3125 :    Loss_Train:  [[ 4824.83307521]]    Loss_Validation:  [[ 1416.55757821]]\n",
      "Loop  3126 :    Loss_Train:  [[ 4824.82921015]]    Loss_Validation:  [[ 1416.56059928]]\n",
      "Loop  3127 :    Loss_Train:  [[ 4824.82535165]]    Loss_Validation:  [[ 1416.56361812]]\n",
      "Loop  3128 :    Loss_Train:  [[ 4824.82149971]]    Loss_Validation:  [[ 1416.56663475]]\n",
      "Loop  3129 :    Loss_Train:  [[ 4824.8176543]]    Loss_Validation:  [[ 1416.56964916]]\n",
      "Loop  3130 :    Loss_Train:  [[ 4824.81381542]]    Loss_Validation:  [[ 1416.57266136]]\n",
      "Loop  3131 :    Loss_Train:  [[ 4824.80998305]]    Loss_Validation:  [[ 1416.57567135]]\n",
      "Loop  3132 :    Loss_Train:  [[ 4824.80615719]]    Loss_Validation:  [[ 1416.57867912]]\n",
      "Loop  3133 :    Loss_Train:  [[ 4824.80233782]]    Loss_Validation:  [[ 1416.58168469]]\n",
      "Loop  3134 :    Loss_Train:  [[ 4824.79852493]]    Loss_Validation:  [[ 1416.58468805]]\n",
      "Loop  3135 :    Loss_Train:  [[ 4824.79471852]]    Loss_Validation:  [[ 1416.58768921]]\n",
      "Loop  3136 :    Loss_Train:  [[ 4824.79091856]]    Loss_Validation:  [[ 1416.59068816]]\n",
      "Loop  3137 :    Loss_Train:  [[ 4824.78712506]]    Loss_Validation:  [[ 1416.59368492]]\n",
      "Loop  3138 :    Loss_Train:  [[ 4824.78333799]]    Loss_Validation:  [[ 1416.59667947]]\n",
      "Loop  3139 :    Loss_Train:  [[ 4824.77955734]]    Loss_Validation:  [[ 1416.59967182]]\n",
      "Loop  3140 :    Loss_Train:  [[ 4824.77578311]]    Loss_Validation:  [[ 1416.60266198]]\n",
      "Loop  3141 :    Loss_Train:  [[ 4824.77201529]]    Loss_Validation:  [[ 1416.60564995]]\n",
      "Loop  3142 :    Loss_Train:  [[ 4824.76825385]]    Loss_Validation:  [[ 1416.60863572]]\n",
      "Loop  3143 :    Loss_Train:  [[ 4824.7644988]]    Loss_Validation:  [[ 1416.6116193]]\n",
      "Loop  3144 :    Loss_Train:  [[ 4824.76075012]]    Loss_Validation:  [[ 1416.61460069]]\n",
      "Loop  3145 :    Loss_Train:  [[ 4824.7570078]]    Loss_Validation:  [[ 1416.6175799]]\n",
      "Loop  3146 :    Loss_Train:  [[ 4824.75327182]]    Loss_Validation:  [[ 1416.62055692]]\n",
      "Loop  3147 :    Loss_Train:  [[ 4824.74954218]]    Loss_Validation:  [[ 1416.62353176]]\n",
      "Loop  3148 :    Loss_Train:  [[ 4824.74581887]]    Loss_Validation:  [[ 1416.62650441]]\n",
      "Loop  3149 :    Loss_Train:  [[ 4824.74210188]]    Loss_Validation:  [[ 1416.62947489]]\n",
      "Loop  3150 :    Loss_Train:  [[ 4824.73839118]]    Loss_Validation:  [[ 1416.63244319]]\n",
      "Loop  3151 :    Loss_Train:  [[ 4824.73468679]]    Loss_Validation:  [[ 1416.63540931]]\n",
      "Loop  3152 :    Loss_Train:  [[ 4824.73098867]]    Loss_Validation:  [[ 1416.63837325]]\n",
      "Loop  3153 :    Loss_Train:  [[ 4824.72729682]]    Loss_Validation:  [[ 1416.64133502]]\n",
      "Loop  3154 :    Loss_Train:  [[ 4824.72361124]]    Loss_Validation:  [[ 1416.64429463]]\n",
      "Loop  3155 :    Loss_Train:  [[ 4824.71993191]]    Loss_Validation:  [[ 1416.64725206]]\n",
      "Loop  3156 :    Loss_Train:  [[ 4824.71625881]]    Loss_Validation:  [[ 1416.65020732]]\n",
      "Loop  3157 :    Loss_Train:  [[ 4824.71259194]]    Loss_Validation:  [[ 1416.65316042]]\n",
      "Loop  3158 :    Loss_Train:  [[ 4824.70893129]]    Loss_Validation:  [[ 1416.65611135]]\n",
      "Loop  3159 :    Loss_Train:  [[ 4824.70527685]]    Loss_Validation:  [[ 1416.65906012]]\n",
      "Loop  3160 :    Loss_Train:  [[ 4824.7016286]]    Loss_Validation:  [[ 1416.66200674]]\n",
      "Loop  3161 :    Loss_Train:  [[ 4824.69798654]]    Loss_Validation:  [[ 1416.66495119]]\n",
      "Loop  3162 :    Loss_Train:  [[ 4824.69435065]]    Loss_Validation:  [[ 1416.66789348]]\n",
      "Loop  3163 :    Loss_Train:  [[ 4824.69072092]]    Loss_Validation:  [[ 1416.67083362]]\n",
      "Loop  3164 :    Loss_Train:  [[ 4824.68709735]]    Loss_Validation:  [[ 1416.6737716]]\n",
      "Loop  3165 :    Loss_Train:  [[ 4824.68347992]]    Loss_Validation:  [[ 1416.67670744]]\n",
      "Loop  3166 :    Loss_Train:  [[ 4824.67986862]]    Loss_Validation:  [[ 1416.67964112]]\n",
      "Loop  3167 :    Loss_Train:  [[ 4824.67626344]]    Loss_Validation:  [[ 1416.68257265]]\n",
      "Loop  3168 :    Loss_Train:  [[ 4824.67266437]]    Loss_Validation:  [[ 1416.68550204]]\n",
      "Loop  3169 :    Loss_Train:  [[ 4824.66907141]]    Loss_Validation:  [[ 1416.68842928]]\n",
      "Loop  3170 :    Loss_Train:  [[ 4824.66548453]]    Loss_Validation:  [[ 1416.69135438]]\n",
      "Loop  3171 :    Loss_Train:  [[ 4824.66190373]]    Loss_Validation:  [[ 1416.69427733]]\n",
      "Loop  3172 :    Loss_Train:  [[ 4824.65832899]]    Loss_Validation:  [[ 1416.69719815]]\n",
      "Loop  3173 :    Loss_Train:  [[ 4824.65476032]]    Loss_Validation:  [[ 1416.70011683]]\n",
      "Loop  3174 :    Loss_Train:  [[ 4824.65119769]]    Loss_Validation:  [[ 1416.70303337]]\n",
      "Loop  3175 :    Loss_Train:  [[ 4824.6476411]]    Loss_Validation:  [[ 1416.70594778]]\n",
      "Loop  3176 :    Loss_Train:  [[ 4824.64409053]]    Loss_Validation:  [[ 1416.70886005]]\n",
      "Loop  3177 :    Loss_Train:  [[ 4824.64054598]]    Loss_Validation:  [[ 1416.71177019]]\n",
      "Loop  3178 :    Loss_Train:  [[ 4824.63700744]]    Loss_Validation:  [[ 1416.7146782]]\n",
      "Loop  3179 :    Loss_Train:  [[ 4824.63347489]]    Loss_Validation:  [[ 1416.71758409]]\n",
      "Loop  3180 :    Loss_Train:  [[ 4824.62994832]]    Loss_Validation:  [[ 1416.72048785]]\n",
      "Loop  3181 :    Loss_Train:  [[ 4824.62642773]]    Loss_Validation:  [[ 1416.72338948]]\n",
      "Loop  3182 :    Loss_Train:  [[ 4824.6229131]]    Loss_Validation:  [[ 1416.72628899]]\n",
      "Loop  3183 :    Loss_Train:  [[ 4824.61940442]]    Loss_Validation:  [[ 1416.72918638]]\n",
      "Loop  3184 :    Loss_Train:  [[ 4824.61590169]]    Loss_Validation:  [[ 1416.73208165]]\n",
      "Loop  3185 :    Loss_Train:  [[ 4824.61240489]]    Loss_Validation:  [[ 1416.7349748]]\n",
      "Loop  3186 :    Loss_Train:  [[ 4824.60891402]]    Loss_Validation:  [[ 1416.73786584]]\n",
      "Loop  3187 :    Loss_Train:  [[ 4824.60542905]]    Loss_Validation:  [[ 1416.74075476]]\n",
      "Loop  3188 :    Loss_Train:  [[ 4824.60194999]]    Loss_Validation:  [[ 1416.74364157]]\n",
      "Loop  3189 :    Loss_Train:  [[ 4824.59847682]]    Loss_Validation:  [[ 1416.74652627]]\n",
      "Loop  3190 :    Loss_Train:  [[ 4824.59500953]]    Loss_Validation:  [[ 1416.74940886]]\n",
      "Loop  3191 :    Loss_Train:  [[ 4824.59154811]]    Loss_Validation:  [[ 1416.75228934]]\n",
      "Loop  3192 :    Loss_Train:  [[ 4824.58809255]]    Loss_Validation:  [[ 1416.75516771]]\n",
      "Loop  3193 :    Loss_Train:  [[ 4824.58464284]]    Loss_Validation:  [[ 1416.75804398]]\n",
      "Loop  3194 :    Loss_Train:  [[ 4824.58119898]]    Loss_Validation:  [[ 1416.76091815]]\n",
      "Loop  3195 :    Loss_Train:  [[ 4824.57776094]]    Loss_Validation:  [[ 1416.76379022]]\n",
      "Loop  3196 :    Loss_Train:  [[ 4824.57432873]]    Loss_Validation:  [[ 1416.76666019]]\n",
      "Loop  3197 :    Loss_Train:  [[ 4824.57090233]]    Loss_Validation:  [[ 1416.76952806]]\n",
      "Loop  3198 :    Loss_Train:  [[ 4824.56748172]]    Loss_Validation:  [[ 1416.77239383]]\n",
      "Loop  3199 :    Loss_Train:  [[ 4824.56406691]]    Loss_Validation:  [[ 1416.77525752]]\n",
      "Loop  3200 :    Loss_Train:  [[ 4824.56065788]]    Loss_Validation:  [[ 1416.7781191]]\n",
      "Loop  3201 :    Loss_Train:  [[ 4824.55725462]]    Loss_Validation:  [[ 1416.7809786]]\n",
      "Loop  3202 :    Loss_Train:  [[ 4824.55385712]]    Loss_Validation:  [[ 1416.78383601]]\n",
      "Loop  3203 :    Loss_Train:  [[ 4824.55046536]]    Loss_Validation:  [[ 1416.78669133]]\n",
      "Loop  3204 :    Loss_Train:  [[ 4824.54707935]]    Loss_Validation:  [[ 1416.78954457]]\n",
      "Loop  3205 :    Loss_Train:  [[ 4824.54369907]]    Loss_Validation:  [[ 1416.79239572]]\n",
      "Loop  3206 :    Loss_Train:  [[ 4824.54032452]]    Loss_Validation:  [[ 1416.79524479]]\n",
      "Loop  3207 :    Loss_Train:  [[ 4824.53695567]]    Loss_Validation:  [[ 1416.79809178]]\n",
      "Loop  3208 :    Loss_Train:  [[ 4824.53359252]]    Loss_Validation:  [[ 1416.80093669]]\n",
      "Loop  3209 :    Loss_Train:  [[ 4824.53023506]]    Loss_Validation:  [[ 1416.80377952]]\n",
      "Loop  3210 :    Loss_Train:  [[ 4824.52688329]]    Loss_Validation:  [[ 1416.80662028]]\n",
      "Loop  3211 :    Loss_Train:  [[ 4824.52353718]]    Loss_Validation:  [[ 1416.80945896]]\n",
      "Loop  3212 :    Loss_Train:  [[ 4824.52019674]]    Loss_Validation:  [[ 1416.81229557]]\n",
      "Loop  3213 :    Loss_Train:  [[ 4824.51686195]]    Loss_Validation:  [[ 1416.81513011]]\n",
      "Loop  3214 :    Loss_Train:  [[ 4824.5135328]]    Loss_Validation:  [[ 1416.81796258]]\n",
      "Loop  3215 :    Loss_Train:  [[ 4824.51020929]]    Loss_Validation:  [[ 1416.82079298]]\n",
      "Loop  3216 :    Loss_Train:  [[ 4824.50689139]]    Loss_Validation:  [[ 1416.82362132]]\n",
      "Loop  3217 :    Loss_Train:  [[ 4824.50357911]]    Loss_Validation:  [[ 1416.82644759]]\n",
      "Loop  3218 :    Loss_Train:  [[ 4824.50027243]]    Loss_Validation:  [[ 1416.8292718]]\n",
      "Loop  3219 :    Loss_Train:  [[ 4824.49697135]]    Loss_Validation:  [[ 1416.83209395]]\n",
      "Loop  3220 :    Loss_Train:  [[ 4824.49367585]]    Loss_Validation:  [[ 1416.83491404]]\n",
      "Loop  3221 :    Loss_Train:  [[ 4824.49038592]]    Loss_Validation:  [[ 1416.83773207]]\n",
      "Loop  3222 :    Loss_Train:  [[ 4824.48710156]]    Loss_Validation:  [[ 1416.84054805]]\n",
      "Loop  3223 :    Loss_Train:  [[ 4824.48382275]]    Loss_Validation:  [[ 1416.84336197]]\n",
      "Loop  3224 :    Loss_Train:  [[ 4824.48054949]]    Loss_Validation:  [[ 1416.84617384]]\n",
      "Loop  3225 :    Loss_Train:  [[ 4824.47728176]]    Loss_Validation:  [[ 1416.84898366]]\n",
      "Loop  3226 :    Loss_Train:  [[ 4824.47401956]]    Loss_Validation:  [[ 1416.85179143]]\n",
      "Loop  3227 :    Loss_Train:  [[ 4824.47076288]]    Loss_Validation:  [[ 1416.85459715]]\n",
      "Loop  3228 :    Loss_Train:  [[ 4824.4675117]]    Loss_Validation:  [[ 1416.85740083]]\n",
      "Loop  3229 :    Loss_Train:  [[ 4824.46426602]]    Loss_Validation:  [[ 1416.86020246]]\n",
      "Loop  3230 :    Loss_Train:  [[ 4824.46102583]]    Loss_Validation:  [[ 1416.86300205]]\n",
      "Loop  3231 :    Loss_Train:  [[ 4824.45779111]]    Loss_Validation:  [[ 1416.8657996]]\n",
      "Loop  3232 :    Loss_Train:  [[ 4824.45456187]]    Loss_Validation:  [[ 1416.8685951]]\n",
      "Loop  3233 :    Loss_Train:  [[ 4824.45133808]]    Loss_Validation:  [[ 1416.87138857]]\n",
      "Loop  3234 :    Loss_Train:  [[ 4824.44811975]]    Loss_Validation:  [[ 1416.87418001]]\n",
      "Loop  3235 :    Loss_Train:  [[ 4824.44490685]]    Loss_Validation:  [[ 1416.87696941]]\n",
      "Loop  3236 :    Loss_Train:  [[ 4824.44169939]]    Loss_Validation:  [[ 1416.87975677]]\n",
      "Loop  3237 :    Loss_Train:  [[ 4824.43849735]]    Loss_Validation:  [[ 1416.88254211]]\n",
      "Loop  3238 :    Loss_Train:  [[ 4824.43530072]]    Loss_Validation:  [[ 1416.88532541]]\n",
      "Loop  3239 :    Loss_Train:  [[ 4824.43210949]]    Loss_Validation:  [[ 1416.88810669]]\n",
      "Loop  3240 :    Loss_Train:  [[ 4824.42892366]]    Loss_Validation:  [[ 1416.89088594]]\n",
      "Loop  3241 :    Loss_Train:  [[ 4824.42574321]]    Loss_Validation:  [[ 1416.89366316]]\n",
      "Loop  3242 :    Loss_Train:  [[ 4824.42256814]]    Loss_Validation:  [[ 1416.89643837]]\n",
      "Loop  3243 :    Loss_Train:  [[ 4824.41939843]]    Loss_Validation:  [[ 1416.89921155]]\n",
      "Loop  3244 :    Loss_Train:  [[ 4824.41623408]]    Loss_Validation:  [[ 1416.90198271]]\n",
      "Loop  3245 :    Loss_Train:  [[ 4824.41307508]]    Loss_Validation:  [[ 1416.90475185]]\n",
      "Loop  3246 :    Loss_Train:  [[ 4824.40992141]]    Loss_Validation:  [[ 1416.90751897]]\n",
      "Loop  3247 :    Loss_Train:  [[ 4824.40677308]]    Loss_Validation:  [[ 1416.91028408]]\n",
      "Loop  3248 :    Loss_Train:  [[ 4824.40363006]]    Loss_Validation:  [[ 1416.91304718]]\n",
      "Loop  3249 :    Loss_Train:  [[ 4824.40049236]]    Loss_Validation:  [[ 1416.91580826]]\n",
      "Loop  3250 :    Loss_Train:  [[ 4824.39735995]]    Loss_Validation:  [[ 1416.91856733]]\n",
      "Loop  3251 :    Loss_Train:  [[ 4824.39423284]]    Loss_Validation:  [[ 1416.9213244]]\n",
      "Loop  3252 :    Loss_Train:  [[ 4824.39111101]]    Loss_Validation:  [[ 1416.92407945]]\n",
      "Loop  3253 :    Loss_Train:  [[ 4824.38799446]]    Loss_Validation:  [[ 1416.9268325]]\n",
      "Loop  3254 :    Loss_Train:  [[ 4824.38488317]]    Loss_Validation:  [[ 1416.92958355]]\n",
      "Loop  3255 :    Loss_Train:  [[ 4824.38177714]]    Loss_Validation:  [[ 1416.9323326]]\n",
      "Loop  3256 :    Loss_Train:  [[ 4824.37867635]]    Loss_Validation:  [[ 1416.93507964]]\n",
      "Loop  3257 :    Loss_Train:  [[ 4824.3755808]]    Loss_Validation:  [[ 1416.93782468]]\n",
      "Loop  3258 :    Loss_Train:  [[ 4824.37249048]]    Loss_Validation:  [[ 1416.94056773]]\n",
      "Loop  3259 :    Loss_Train:  [[ 4824.36940538]]    Loss_Validation:  [[ 1416.94330878]]\n",
      "Loop  3260 :    Loss_Train:  [[ 4824.36632549]]    Loss_Validation:  [[ 1416.94604784]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  3261 :    Loss_Train:  [[ 4824.3632508]]    Loss_Validation:  [[ 1416.9487849]]\n",
      "Loop  3262 :    Loss_Train:  [[ 4824.3601813]]    Loss_Validation:  [[ 1416.95151997]]\n",
      "Loop  3263 :    Loss_Train:  [[ 4824.35711699]]    Loss_Validation:  [[ 1416.95425305]]\n",
      "Loop  3264 :    Loss_Train:  [[ 4824.35405785]]    Loss_Validation:  [[ 1416.95698415]]\n",
      "Loop  3265 :    Loss_Train:  [[ 4824.35100388]]    Loss_Validation:  [[ 1416.95971326]]\n",
      "Loop  3266 :    Loss_Train:  [[ 4824.34795506]]    Loss_Validation:  [[ 1416.96244038]]\n",
      "Loop  3267 :    Loss_Train:  [[ 4824.34491139]]    Loss_Validation:  [[ 1416.96516552]]\n",
      "Loop  3268 :    Loss_Train:  [[ 4824.34187286]]    Loss_Validation:  [[ 1416.96788867]]\n",
      "Loop  3269 :    Loss_Train:  [[ 4824.33883947]]    Loss_Validation:  [[ 1416.97060985]]\n",
      "Loop  3270 :    Loss_Train:  [[ 4824.33581119]]    Loss_Validation:  [[ 1416.97332905]]\n",
      "Loop  3271 :    Loss_Train:  [[ 4824.33278802]]    Loss_Validation:  [[ 1416.97604627]]\n",
      "Loop  3272 :    Loss_Train:  [[ 4824.32976996]]    Loss_Validation:  [[ 1416.97876151]]\n",
      "Loop  3273 :    Loss_Train:  [[ 4824.326757]]    Loss_Validation:  [[ 1416.98147478]]\n",
      "Loop  3274 :    Loss_Train:  [[ 4824.32374912]]    Loss_Validation:  [[ 1416.98418608]]\n",
      "Loop  3275 :    Loss_Train:  [[ 4824.32074632]]    Loss_Validation:  [[ 1416.98689541]]\n",
      "Loop  3276 :    Loss_Train:  [[ 4824.31774858]]    Loss_Validation:  [[ 1416.98960277]]\n",
      "Loop  3277 :    Loss_Train:  [[ 4824.31475591]]    Loss_Validation:  [[ 1416.99230816]]\n",
      "Loop  3278 :    Loss_Train:  [[ 4824.31176829]]    Loss_Validation:  [[ 1416.99501158]]\n",
      "Loop  3279 :    Loss_Train:  [[ 4824.30878571]]    Loss_Validation:  [[ 1416.99771304]]\n",
      "Loop  3280 :    Loss_Train:  [[ 4824.30580816]]    Loss_Validation:  [[ 1417.00041254]]\n",
      "Loop  3281 :    Loss_Train:  [[ 4824.30283564]]    Loss_Validation:  [[ 1417.00311007]]\n",
      "Loop  3282 :    Loss_Train:  [[ 4824.29986813]]    Loss_Validation:  [[ 1417.00580565]]\n",
      "Loop  3283 :    Loss_Train:  [[ 4824.29690564]]    Loss_Validation:  [[ 1417.00849926]]\n",
      "Loop  3284 :    Loss_Train:  [[ 4824.29394814]]    Loss_Validation:  [[ 1417.01119092]]\n",
      "Loop  3285 :    Loss_Train:  [[ 4824.29099563]]    Loss_Validation:  [[ 1417.01388063]]\n",
      "Loop  3286 :    Loss_Train:  [[ 4824.28804811]]    Loss_Validation:  [[ 1417.01656838]]\n",
      "Loop  3287 :    Loss_Train:  [[ 4824.28510555]]    Loss_Validation:  [[ 1417.01925417]]\n",
      "Loop  3288 :    Loss_Train:  [[ 4824.28216797]]    Loss_Validation:  [[ 1417.02193802]]\n",
      "Loop  3289 :    Loss_Train:  [[ 4824.27923533]]    Loss_Validation:  [[ 1417.02461992]]\n",
      "Loop  3290 :    Loss_Train:  [[ 4824.27630765]]    Loss_Validation:  [[ 1417.02729987]]\n",
      "Loop  3291 :    Loss_Train:  [[ 4824.27338491]]    Loss_Validation:  [[ 1417.02997787]]\n",
      "Loop  3292 :    Loss_Train:  [[ 4824.27046709]]    Loss_Validation:  [[ 1417.03265393]]\n",
      "Loop  3293 :    Loss_Train:  [[ 4824.2675542]]    Loss_Validation:  [[ 1417.03532805]]\n",
      "Loop  3294 :    Loss_Train:  [[ 4824.26464622]]    Loss_Validation:  [[ 1417.03800023]]\n",
      "Loop  3295 :    Loss_Train:  [[ 4824.26174315]]    Loss_Validation:  [[ 1417.04067046]]\n",
      "Loop  3296 :    Loss_Train:  [[ 4824.25884497]]    Loss_Validation:  [[ 1417.04333876]]\n",
      "Loop  3297 :    Loss_Train:  [[ 4824.25595168]]    Loss_Validation:  [[ 1417.04600512]]\n",
      "Loop  3298 :    Loss_Train:  [[ 4824.25306328]]    Loss_Validation:  [[ 1417.04866955]]\n",
      "Loop  3299 :    Loss_Train:  [[ 4824.25017974]]    Loss_Validation:  [[ 1417.05133204]]\n",
      "Loop  3300 :    Loss_Train:  [[ 4824.24730107]]    Loss_Validation:  [[ 1417.0539926]]\n",
      "Loop  3301 :    Loss_Train:  [[ 4824.24442725]]    Loss_Validation:  [[ 1417.05665123]]\n",
      "Loop  3302 :    Loss_Train:  [[ 4824.24155827]]    Loss_Validation:  [[ 1417.05930792]]\n",
      "Loop  3303 :    Loss_Train:  [[ 4824.23869414]]    Loss_Validation:  [[ 1417.0619627]]\n",
      "Loop  3304 :    Loss_Train:  [[ 4824.23583483]]    Loss_Validation:  [[ 1417.06461554]]\n",
      "Loop  3305 :    Loss_Train:  [[ 4824.23298035]]    Loss_Validation:  [[ 1417.06726646]]\n",
      "Loop  3306 :    Loss_Train:  [[ 4824.23013068]]    Loss_Validation:  [[ 1417.06991546]]\n",
      "Loop  3307 :    Loss_Train:  [[ 4824.22728581]]    Loss_Validation:  [[ 1417.07256254]]\n",
      "Loop  3308 :    Loss_Train:  [[ 4824.22444575]]    Loss_Validation:  [[ 1417.07520769]]\n",
      "Loop  3309 :    Loss_Train:  [[ 4824.22161046]]    Loss_Validation:  [[ 1417.07785093]]\n",
      "Loop  3310 :    Loss_Train:  [[ 4824.21877996]]    Loss_Validation:  [[ 1417.08049225]]\n",
      "Loop  3311 :    Loss_Train:  [[ 4824.21595423]]    Loss_Validation:  [[ 1417.08313166]]\n",
      "Loop  3312 :    Loss_Train:  [[ 4824.21313327]]    Loss_Validation:  [[ 1417.08576915]]\n",
      "Loop  3313 :    Loss_Train:  [[ 4824.21031706]]    Loss_Validation:  [[ 1417.08840472]]\n",
      "Loop  3314 :    Loss_Train:  [[ 4824.20750559]]    Loss_Validation:  [[ 1417.09103839]]\n",
      "Loop  3315 :    Loss_Train:  [[ 4824.20469887]]    Loss_Validation:  [[ 1417.09367015]]\n",
      "Loop  3316 :    Loss_Train:  [[ 4824.20189688]]    Loss_Validation:  [[ 1417.0963]]\n",
      "Loop  3317 :    Loss_Train:  [[ 4824.19909961]]    Loss_Validation:  [[ 1417.09892794]]\n",
      "Loop  3318 :    Loss_Train:  [[ 4824.19630705]]    Loss_Validation:  [[ 1417.10155398]]\n",
      "Loop  3319 :    Loss_Train:  [[ 4824.1935192]]    Loss_Validation:  [[ 1417.10417812]]\n",
      "Loop  3320 :    Loss_Train:  [[ 4824.19073605]]    Loss_Validation:  [[ 1417.10680035]]\n",
      "Loop  3321 :    Loss_Train:  [[ 4824.18795759]]    Loss_Validation:  [[ 1417.10942068]]\n",
      "Loop  3322 :    Loss_Train:  [[ 4824.18518381]]    Loss_Validation:  [[ 1417.11203912]]\n",
      "Loop  3323 :    Loss_Train:  [[ 4824.1824147]]    Loss_Validation:  [[ 1417.11465565]]\n",
      "Loop  3324 :    Loss_Train:  [[ 4824.17965027]]    Loss_Validation:  [[ 1417.11727029]]\n",
      "Loop  3325 :    Loss_Train:  [[ 4824.17689048]]    Loss_Validation:  [[ 1417.11988304]]\n",
      "Loop  3326 :    Loss_Train:  [[ 4824.17413535]]    Loss_Validation:  [[ 1417.12249389]]\n",
      "Loop  3327 :    Loss_Train:  [[ 4824.17138487]]    Loss_Validation:  [[ 1417.12510285]]\n",
      "Loop  3328 :    Loss_Train:  [[ 4824.16863901]]    Loss_Validation:  [[ 1417.12770993]]\n",
      "Loop  3329 :    Loss_Train:  [[ 4824.16589778]]    Loss_Validation:  [[ 1417.13031511]]\n",
      "Loop  3330 :    Loss_Train:  [[ 4824.16316117]]    Loss_Validation:  [[ 1417.1329184]]\n",
      "Loop  3331 :    Loss_Train:  [[ 4824.16042917]]    Loss_Validation:  [[ 1417.13551982]]\n",
      "Loop  3332 :    Loss_Train:  [[ 4824.15770178]]    Loss_Validation:  [[ 1417.13811934]]\n",
      "Loop  3333 :    Loss_Train:  [[ 4824.15497897]]    Loss_Validation:  [[ 1417.14071699]]\n",
      "Loop  3334 :    Loss_Train:  [[ 4824.15226076]]    Loss_Validation:  [[ 1417.14331275]]\n",
      "Loop  3335 :    Loss_Train:  [[ 4824.14954712]]    Loss_Validation:  [[ 1417.14590663]]\n",
      "Loop  3336 :    Loss_Train:  [[ 4824.14683805]]    Loss_Validation:  [[ 1417.14849864]]\n",
      "Loop  3337 :    Loss_Train:  [[ 4824.14413354]]    Loss_Validation:  [[ 1417.15108876]]\n",
      "Loop  3338 :    Loss_Train:  [[ 4824.1414336]]    Loss_Validation:  [[ 1417.15367702]]\n",
      "Loop  3339 :    Loss_Train:  [[ 4824.13873819]]    Loss_Validation:  [[ 1417.1562634]]\n",
      "Loop  3340 :    Loss_Train:  [[ 4824.13604733]]    Loss_Validation:  [[ 1417.1588479]]\n",
      "Loop  3341 :    Loss_Train:  [[ 4824.133361]]    Loss_Validation:  [[ 1417.16143054]]\n",
      "Loop  3342 :    Loss_Train:  [[ 4824.13067919]]    Loss_Validation:  [[ 1417.16401131]]\n",
      "Loop  3343 :    Loss_Train:  [[ 4824.1280019]]    Loss_Validation:  [[ 1417.16659021]]\n",
      "Loop  3344 :    Loss_Train:  [[ 4824.12532911]]    Loss_Validation:  [[ 1417.16916724]]\n",
      "Loop  3345 :    Loss_Train:  [[ 4824.12266083]]    Loss_Validation:  [[ 1417.17174241]]\n",
      "Loop  3346 :    Loss_Train:  [[ 4824.11999704]]    Loss_Validation:  [[ 1417.17431571]]\n",
      "Loop  3347 :    Loss_Train:  [[ 4824.11733774]]    Loss_Validation:  [[ 1417.17688716]]\n",
      "Loop  3348 :    Loss_Train:  [[ 4824.11468291]]    Loss_Validation:  [[ 1417.17945674]]\n",
      "Loop  3349 :    Loss_Train:  [[ 4824.11203255]]    Loss_Validation:  [[ 1417.18202446]]\n",
      "Loop  3350 :    Loss_Train:  [[ 4824.10938665]]    Loss_Validation:  [[ 1417.18459033]]\n",
      "Loop  3351 :    Loss_Train:  [[ 4824.10674521]]    Loss_Validation:  [[ 1417.18715434]]\n",
      "Loop  3352 :    Loss_Train:  [[ 4824.10410821]]    Loss_Validation:  [[ 1417.18971649]]\n",
      "Loop  3353 :    Loss_Train:  [[ 4824.10147566]]    Loss_Validation:  [[ 1417.19227679]]\n",
      "Loop  3354 :    Loss_Train:  [[ 4824.09884753]]    Loss_Validation:  [[ 1417.19483524]]\n",
      "Loop  3355 :    Loss_Train:  [[ 4824.09622383]]    Loss_Validation:  [[ 1417.19739184]]\n",
      "Loop  3356 :    Loss_Train:  [[ 4824.09360455]]    Loss_Validation:  [[ 1417.19994659]]\n",
      "Loop  3357 :    Loss_Train:  [[ 4824.09098967]]    Loss_Validation:  [[ 1417.2024995]]\n",
      "Loop  3358 :    Loss_Train:  [[ 4824.08837919]]    Loss_Validation:  [[ 1417.20505056]]\n",
      "Loop  3359 :    Loss_Train:  [[ 4824.08577311]]    Loss_Validation:  [[ 1417.20759977]]\n",
      "Loop  3360 :    Loss_Train:  [[ 4824.08317141]]    Loss_Validation:  [[ 1417.21014714]]\n",
      "Loop  3361 :    Loss_Train:  [[ 4824.0805741]]    Loss_Validation:  [[ 1417.21269267]]\n",
      "Loop  3362 :    Loss_Train:  [[ 4824.07798115]]    Loss_Validation:  [[ 1417.21523636]]\n",
      "Loop  3363 :    Loss_Train:  [[ 4824.07539256]]    Loss_Validation:  [[ 1417.21777821]]\n",
      "Loop  3364 :    Loss_Train:  [[ 4824.07280834]]    Loss_Validation:  [[ 1417.22031822]]\n",
      "Loop  3365 :    Loss_Train:  [[ 4824.07022846]]    Loss_Validation:  [[ 1417.22285639]]\n",
      "Loop  3366 :    Loss_Train:  [[ 4824.06765292]]    Loss_Validation:  [[ 1417.22539274]]\n",
      "Loop  3367 :    Loss_Train:  [[ 4824.06508171]]    Loss_Validation:  [[ 1417.22792725]]\n",
      "Loop  3368 :    Loss_Train:  [[ 4824.06251483]]    Loss_Validation:  [[ 1417.23045992]]\n",
      "Loop  3369 :    Loss_Train:  [[ 4824.05995227]]    Loss_Validation:  [[ 1417.23299077]]\n",
      "Loop  3370 :    Loss_Train:  [[ 4824.05739402]]    Loss_Validation:  [[ 1417.23551979]]\n",
      "Loop  3371 :    Loss_Train:  [[ 4824.05484007]]    Loss_Validation:  [[ 1417.23804698]]\n",
      "Loop  3372 :    Loss_Train:  [[ 4824.05229042]]    Loss_Validation:  [[ 1417.24057235]]\n",
      "Loop  3373 :    Loss_Train:  [[ 4824.04974506]]    Loss_Validation:  [[ 1417.24309589]]\n",
      "Loop  3374 :    Loss_Train:  [[ 4824.04720398]]    Loss_Validation:  [[ 1417.24561761]]\n",
      "Loop  3375 :    Loss_Train:  [[ 4824.04466718]]    Loss_Validation:  [[ 1417.24813751]]\n",
      "Loop  3376 :    Loss_Train:  [[ 4824.04213464]]    Loss_Validation:  [[ 1417.25065558]]\n",
      "Loop  3377 :    Loss_Train:  [[ 4824.03960636]]    Loss_Validation:  [[ 1417.25317184]]\n",
      "Loop  3378 :    Loss_Train:  [[ 4824.03708234]]    Loss_Validation:  [[ 1417.25568628]]\n",
      "Loop  3379 :    Loss_Train:  [[ 4824.03456256]]    Loss_Validation:  [[ 1417.25819891]]\n",
      "Loop  3380 :    Loss_Train:  [[ 4824.03204701]]    Loss_Validation:  [[ 1417.26070972]]\n",
      "Loop  3381 :    Loss_Train:  [[ 4824.0295357]]    Loss_Validation:  [[ 1417.26321872]]\n",
      "Loop  3382 :    Loss_Train:  [[ 4824.02702861]]    Loss_Validation:  [[ 1417.26572591]]\n",
      "Loop  3383 :    Loss_Train:  [[ 4824.02452574]]    Loss_Validation:  [[ 1417.26823128]]\n",
      "Loop  3384 :    Loss_Train:  [[ 4824.02202707]]    Loss_Validation:  [[ 1417.27073485]]\n",
      "Loop  3385 :    Loss_Train:  [[ 4824.01953261]]    Loss_Validation:  [[ 1417.27323661]]\n",
      "Loop  3386 :    Loss_Train:  [[ 4824.01704234]]    Loss_Validation:  [[ 1417.27573657]]\n",
      "Loop  3387 :    Loss_Train:  [[ 4824.01455626]]    Loss_Validation:  [[ 1417.27823472]]\n",
      "Loop  3388 :    Loss_Train:  [[ 4824.01207435]]    Loss_Validation:  [[ 1417.28073106]]\n",
      "Loop  3389 :    Loss_Train:  [[ 4824.00959662]]    Loss_Validation:  [[ 1417.28322561]]\n",
      "Loop  3390 :    Loss_Train:  [[ 4824.00712306]]    Loss_Validation:  [[ 1417.28571836]]\n",
      "Loop  3391 :    Loss_Train:  [[ 4824.00465366]]    Loss_Validation:  [[ 1417.2882093]]\n",
      "Loop  3392 :    Loss_Train:  [[ 4824.0021884]]    Loss_Validation:  [[ 1417.29069845]]\n",
      "Loop  3393 :    Loss_Train:  [[ 4823.99972729]]    Loss_Validation:  [[ 1417.2931858]]\n",
      "Loop  3394 :    Loss_Train:  [[ 4823.99727032]]    Loss_Validation:  [[ 1417.29567136]]\n",
      "Loop  3395 :    Loss_Train:  [[ 4823.99481748]]    Loss_Validation:  [[ 1417.29815513]]\n",
      "Loop  3396 :    Loss_Train:  [[ 4823.99236876]]    Loss_Validation:  [[ 1417.3006371]]\n",
      "Loop  3397 :    Loss_Train:  [[ 4823.98992415]]    Loss_Validation:  [[ 1417.30311728]]\n",
      "Loop  3398 :    Loss_Train:  [[ 4823.98748366]]    Loss_Validation:  [[ 1417.30559568]]\n",
      "Loop  3399 :    Loss_Train:  [[ 4823.98504726]]    Loss_Validation:  [[ 1417.30807228]]\n",
      "Loop  3400 :    Loss_Train:  [[ 4823.98261496]]    Loss_Validation:  [[ 1417.3105471]]\n",
      "Loop  3401 :    Loss_Train:  [[ 4823.98018675]]    Loss_Validation:  [[ 1417.31302014]]\n",
      "Loop  3402 :    Loss_Train:  [[ 4823.97776262]]    Loss_Validation:  [[ 1417.31549139]]\n",
      "Loop  3403 :    Loss_Train:  [[ 4823.97534257]]    Loss_Validation:  [[ 1417.31796086]]\n",
      "Loop  3404 :    Loss_Train:  [[ 4823.97292658]]    Loss_Validation:  [[ 1417.32042855]]\n",
      "Loop  3405 :    Loss_Train:  [[ 4823.97051465]]    Loss_Validation:  [[ 1417.32289446]]\n",
      "Loop  3406 :    Loss_Train:  [[ 4823.96810677]]    Loss_Validation:  [[ 1417.32535859]]\n",
      "Loop  3407 :    Loss_Train:  [[ 4823.96570294]]    Loss_Validation:  [[ 1417.32782095]]\n",
      "Loop  3408 :    Loss_Train:  [[ 4823.96330314]]    Loss_Validation:  [[ 1417.33028153]]\n",
      "Loop  3409 :    Loss_Train:  [[ 4823.96090738]]    Loss_Validation:  [[ 1417.33274033]]\n",
      "Loop  3410 :    Loss_Train:  [[ 4823.95851565]]    Loss_Validation:  [[ 1417.33519737]]\n",
      "Loop  3411 :    Loss_Train:  [[ 4823.95612793]]    Loss_Validation:  [[ 1417.33765263]]\n",
      "Loop  3412 :    Loss_Train:  [[ 4823.95374422]]    Loss_Validation:  [[ 1417.34010612]]\n",
      "Loop  3413 :    Loss_Train:  [[ 4823.95136452]]    Loss_Validation:  [[ 1417.34255785]]\n",
      "Loop  3414 :    Loss_Train:  [[ 4823.94898882]]    Loss_Validation:  [[ 1417.34500781]]\n",
      "Loop  3415 :    Loss_Train:  [[ 4823.9466171]]    Loss_Validation:  [[ 1417.347456]]\n",
      "Loop  3416 :    Loss_Train:  [[ 4823.94424937]]    Loss_Validation:  [[ 1417.34990243]]\n",
      "Loop  3417 :    Loss_Train:  [[ 4823.94188562]]    Loss_Validation:  [[ 1417.35234709]]\n",
      "Loop  3418 :    Loss_Train:  [[ 4823.93952584]]    Loss_Validation:  [[ 1417.35479]]\n",
      "Loop  3419 :    Loss_Train:  [[ 4823.93717002]]    Loss_Validation:  [[ 1417.35723114]]\n",
      "Loop  3420 :    Loss_Train:  [[ 4823.93481815]]    Loss_Validation:  [[ 1417.35967053]]\n",
      "Loop  3421 :    Loss_Train:  [[ 4823.93247024]]    Loss_Validation:  [[ 1417.36210816]]\n",
      "Loop  3422 :    Loss_Train:  [[ 4823.93012627]]    Loss_Validation:  [[ 1417.36454403]]\n",
      "Loop  3423 :    Loss_Train:  [[ 4823.92778624]]    Loss_Validation:  [[ 1417.36697815]]\n",
      "Loop  3424 :    Loss_Train:  [[ 4823.92545014]]    Loss_Validation:  [[ 1417.36941052]]\n",
      "Loop  3425 :    Loss_Train:  [[ 4823.92311795]]    Loss_Validation:  [[ 1417.37184113]]\n",
      "Loop  3426 :    Loss_Train:  [[ 4823.92078969]]    Loss_Validation:  [[ 1417.37426999]]\n",
      "Loop  3427 :    Loss_Train:  [[ 4823.91846533]]    Loss_Validation:  [[ 1417.37669711]]\n",
      "Loop  3428 :    Loss_Train:  [[ 4823.91614488]]    Loss_Validation:  [[ 1417.37912247]]\n",
      "Loop  3429 :    Loss_Train:  [[ 4823.91382833]]    Loss_Validation:  [[ 1417.38154609]]\n",
      "Loop  3430 :    Loss_Train:  [[ 4823.91151566]]    Loss_Validation:  [[ 1417.38396797]]\n",
      "Loop  3431 :    Loss_Train:  [[ 4823.90920687]]    Loss_Validation:  [[ 1417.3863881]]\n",
      "Loop  3432 :    Loss_Train:  [[ 4823.90690197]]    Loss_Validation:  [[ 1417.38880649]]\n",
      "Loop  3433 :    Loss_Train:  [[ 4823.90460093]]    Loss_Validation:  [[ 1417.39122313]]\n",
      "Loop  3434 :    Loss_Train:  [[ 4823.90230375]]    Loss_Validation:  [[ 1417.39363804]]\n",
      "Loop  3435 :    Loss_Train:  [[ 4823.90001043]]    Loss_Validation:  [[ 1417.39605121]]\n",
      "Loop  3436 :    Loss_Train:  [[ 4823.89772096]]    Loss_Validation:  [[ 1417.39846265]]\n",
      "Loop  3437 :    Loss_Train:  [[ 4823.89543534]]    Loss_Validation:  [[ 1417.40087234]]\n",
      "Loop  3438 :    Loss_Train:  [[ 4823.89315354]]    Loss_Validation:  [[ 1417.40328031]]\n",
      "Loop  3439 :    Loss_Train:  [[ 4823.89087558]]    Loss_Validation:  [[ 1417.40568654]]\n",
      "Loop  3440 :    Loss_Train:  [[ 4823.88860145]]    Loss_Validation:  [[ 1417.40809104]]\n",
      "Loop  3441 :    Loss_Train:  [[ 4823.88633113]]    Loss_Validation:  [[ 1417.41049381]]\n",
      "Loop  3442 :    Loss_Train:  [[ 4823.88406462]]    Loss_Validation:  [[ 1417.41289485]]\n",
      "Loop  3443 :    Loss_Train:  [[ 4823.88180191]]    Loss_Validation:  [[ 1417.41529416]]\n",
      "Loop  3444 :    Loss_Train:  [[ 4823.879543]]    Loss_Validation:  [[ 1417.41769175]]\n",
      "Loop  3445 :    Loss_Train:  [[ 4823.87728788]]    Loss_Validation:  [[ 1417.42008761]]\n",
      "Loop  3446 :    Loss_Train:  [[ 4823.87503655]]    Loss_Validation:  [[ 1417.42248175]]\n",
      "Loop  3447 :    Loss_Train:  [[ 4823.87278899]]    Loss_Validation:  [[ 1417.42487416]]\n",
      "Loop  3448 :    Loss_Train:  [[ 4823.87054521]]    Loss_Validation:  [[ 1417.42726486]]\n",
      "Loop  3449 :    Loss_Train:  [[ 4823.86830519]]    Loss_Validation:  [[ 1417.42965384]]\n",
      "Loop  3450 :    Loss_Train:  [[ 4823.86606892]]    Loss_Validation:  [[ 1417.43204109]]\n",
      "Loop  3451 :    Loss_Train:  [[ 4823.86383641]]    Loss_Validation:  [[ 1417.43442663]]\n",
      "Loop  3452 :    Loss_Train:  [[ 4823.86160765]]    Loss_Validation:  [[ 1417.43681046]]\n",
      "Loop  3453 :    Loss_Train:  [[ 4823.85938262]]    Loss_Validation:  [[ 1417.43919257]]\n",
      "Loop  3454 :    Loss_Train:  [[ 4823.85716133]]    Loss_Validation:  [[ 1417.44157297]]\n",
      "Loop  3455 :    Loss_Train:  [[ 4823.85494377]]    Loss_Validation:  [[ 1417.44395166]]\n",
      "Loop  3456 :    Loss_Train:  [[ 4823.85272992]]    Loss_Validation:  [[ 1417.44632863]]\n",
      "Loop  3457 :    Loss_Train:  [[ 4823.85051979]]    Loss_Validation:  [[ 1417.4487039]]\n",
      "Loop  3458 :    Loss_Train:  [[ 4823.84831336]]    Loss_Validation:  [[ 1417.45107746]]\n",
      "Loop  3459 :    Loss_Train:  [[ 4823.84611064]]    Loss_Validation:  [[ 1417.45344932]]\n",
      "Loop  3460 :    Loss_Train:  [[ 4823.84391161]]    Loss_Validation:  [[ 1417.45581947]]\n",
      "Loop  3461 :    Loss_Train:  [[ 4823.84171627]]    Loss_Validation:  [[ 1417.45818791]]\n",
      "Loop  3462 :    Loss_Train:  [[ 4823.83952461]]    Loss_Validation:  [[ 1417.46055466]]\n",
      "Loop  3463 :    Loss_Train:  [[ 4823.83733662]]    Loss_Validation:  [[ 1417.4629197]]\n",
      "Loop  3464 :    Loss_Train:  [[ 4823.83515231]]    Loss_Validation:  [[ 1417.46528305]]\n",
      "Loop  3465 :    Loss_Train:  [[ 4823.83297166]]    Loss_Validation:  [[ 1417.46764469]]\n",
      "Loop  3466 :    Loss_Train:  [[ 4823.83079467]]    Loss_Validation:  [[ 1417.47000464]]\n",
      "Loop  3467 :    Loss_Train:  [[ 4823.82862132]]    Loss_Validation:  [[ 1417.47236289]]\n",
      "Loop  3468 :    Loss_Train:  [[ 4823.82645162]]    Loss_Validation:  [[ 1417.47471945]]\n",
      "Loop  3469 :    Loss_Train:  [[ 4823.82428556]]    Loss_Validation:  [[ 1417.47707431]]\n",
      "Loop  3470 :    Loss_Train:  [[ 4823.82212313]]    Loss_Validation:  [[ 1417.47942749]]\n",
      "Loop  3471 :    Loss_Train:  [[ 4823.81996433]]    Loss_Validation:  [[ 1417.48177897]]\n",
      "Loop  3472 :    Loss_Train:  [[ 4823.81780915]]    Loss_Validation:  [[ 1417.48412876]]\n",
      "Loop  3473 :    Loss_Train:  [[ 4823.81565758]]    Loss_Validation:  [[ 1417.48647687]]\n",
      "Loop  3474 :    Loss_Train:  [[ 4823.81350962]]    Loss_Validation:  [[ 1417.48882329]]\n",
      "Loop  3475 :    Loss_Train:  [[ 4823.81136525]]    Loss_Validation:  [[ 1417.49116802]]\n",
      "Loop  3476 :    Loss_Train:  [[ 4823.80922449]]    Loss_Validation:  [[ 1417.49351107]]\n",
      "Loop  3477 :    Loss_Train:  [[ 4823.80708731]]    Loss_Validation:  [[ 1417.49585244]]\n",
      "Loop  3478 :    Loss_Train:  [[ 4823.80495371]]    Loss_Validation:  [[ 1417.49819213]]\n",
      "Loop  3479 :    Loss_Train:  [[ 4823.80282369]]    Loss_Validation:  [[ 1417.50053014]]\n",
      "Loop  3480 :    Loss_Train:  [[ 4823.80069724]]    Loss_Validation:  [[ 1417.50286646]]\n",
      "Loop  3481 :    Loss_Train:  [[ 4823.79857436]]    Loss_Validation:  [[ 1417.50520111]]\n",
      "Loop  3482 :    Loss_Train:  [[ 4823.79645503]]    Loss_Validation:  [[ 1417.50753409]]\n",
      "Loop  3483 :    Loss_Train:  [[ 4823.79433926]]    Loss_Validation:  [[ 1417.50986539]]\n",
      "Loop  3484 :    Loss_Train:  [[ 4823.79222703]]    Loss_Validation:  [[ 1417.51219501]]\n",
      "Loop  3485 :    Loss_Train:  [[ 4823.79011834]]    Loss_Validation:  [[ 1417.51452297]]\n",
      "Loop  3486 :    Loss_Train:  [[ 4823.78801319]]    Loss_Validation:  [[ 1417.51684925]]\n",
      "Loop  3487 :    Loss_Train:  [[ 4823.78591156]]    Loss_Validation:  [[ 1417.51917386]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  3488 :    Loss_Train:  [[ 4823.78381346]]    Loss_Validation:  [[ 1417.52149681]]\n",
      "Loop  3489 :    Loss_Train:  [[ 4823.78171887]]    Loss_Validation:  [[ 1417.52381808]]\n",
      "Loop  3490 :    Loss_Train:  [[ 4823.77962779]]    Loss_Validation:  [[ 1417.5261377]]\n",
      "Loop  3491 :    Loss_Train:  [[ 4823.77754022]]    Loss_Validation:  [[ 1417.52845564]]\n",
      "Loop  3492 :    Loss_Train:  [[ 4823.77545614]]    Loss_Validation:  [[ 1417.53077193]]\n",
      "Loop  3493 :    Loss_Train:  [[ 4823.77337555]]    Loss_Validation:  [[ 1417.53308655]]\n",
      "Loop  3494 :    Loss_Train:  [[ 4823.77129845]]    Loss_Validation:  [[ 1417.53539951]]\n",
      "Loop  3495 :    Loss_Train:  [[ 4823.76922484]]    Loss_Validation:  [[ 1417.53771081]]\n",
      "Loop  3496 :    Loss_Train:  [[ 4823.76715469]]    Loss_Validation:  [[ 1417.54002046]]\n",
      "Loop  3497 :    Loss_Train:  [[ 4823.76508801]]    Loss_Validation:  [[ 1417.54232844]]\n",
      "Loop  3498 :    Loss_Train:  [[ 4823.7630248]]    Loss_Validation:  [[ 1417.54463477]]\n",
      "Loop  3499 :    Loss_Train:  [[ 4823.76096504]]    Loss_Validation:  [[ 1417.54693945]]\n",
      "Loop  3500 :    Loss_Train:  [[ 4823.75890873]]    Loss_Validation:  [[ 1417.54924247]]\n",
      "Loop  3501 :    Loss_Train:  [[ 4823.75685587]]    Loss_Validation:  [[ 1417.55154385]]\n",
      "Loop  3502 :    Loss_Train:  [[ 4823.75480644]]    Loss_Validation:  [[ 1417.55384357]]\n",
      "Loop  3503 :    Loss_Train:  [[ 4823.75276045]]    Loss_Validation:  [[ 1417.55614164]]\n",
      "Loop  3504 :    Loss_Train:  [[ 4823.75071789]]    Loss_Validation:  [[ 1417.55843807]]\n",
      "Loop  3505 :    Loss_Train:  [[ 4823.74867874]]    Loss_Validation:  [[ 1417.56073284]]\n",
      "Loop  3506 :    Loss_Train:  [[ 4823.74664301]]    Loss_Validation:  [[ 1417.56302598]]\n",
      "Loop  3507 :    Loss_Train:  [[ 4823.74461069]]    Loss_Validation:  [[ 1417.56531746]]\n",
      "Loop  3508 :    Loss_Train:  [[ 4823.74258178]]    Loss_Validation:  [[ 1417.56760731]]\n",
      "Loop  3509 :    Loss_Train:  [[ 4823.74055626]]    Loss_Validation:  [[ 1417.56989551]]\n",
      "Loop  3510 :    Loss_Train:  [[ 4823.73853413]]    Loss_Validation:  [[ 1417.57218208]]\n",
      "Loop  3511 :    Loss_Train:  [[ 4823.73651539]]    Loss_Validation:  [[ 1417.574467]]\n",
      "Loop  3512 :    Loss_Train:  [[ 4823.73450003]]    Loss_Validation:  [[ 1417.57675029]]\n",
      "Loop  3513 :    Loss_Train:  [[ 4823.73248805]]    Loss_Validation:  [[ 1417.57903194]]\n",
      "Loop  3514 :    Loss_Train:  [[ 4823.73047943]]    Loss_Validation:  [[ 1417.58131195]]\n",
      "Loop  3515 :    Loss_Train:  [[ 4823.72847418]]    Loss_Validation:  [[ 1417.58359033]]\n",
      "Loop  3516 :    Loss_Train:  [[ 4823.72647228]]    Loss_Validation:  [[ 1417.58586708]]\n",
      "Loop  3517 :    Loss_Train:  [[ 4823.72447374]]    Loss_Validation:  [[ 1417.58814219]]\n",
      "Loop  3518 :    Loss_Train:  [[ 4823.72247854]]    Loss_Validation:  [[ 1417.59041568]]\n",
      "Loop  3519 :    Loss_Train:  [[ 4823.72048668]]    Loss_Validation:  [[ 1417.59268754]]\n",
      "Loop  3520 :    Loss_Train:  [[ 4823.71849816]]    Loss_Validation:  [[ 1417.59495777]]\n",
      "Loop  3521 :    Loss_Train:  [[ 4823.71651296]]    Loss_Validation:  [[ 1417.59722637]]\n",
      "Loop  3522 :    Loss_Train:  [[ 4823.71453109]]    Loss_Validation:  [[ 1417.59949334]]\n",
      "Loop  3523 :    Loss_Train:  [[ 4823.71255253]]    Loss_Validation:  [[ 1417.6017587]]\n",
      "Loop  3524 :    Loss_Train:  [[ 4823.71057729]]    Loss_Validation:  [[ 1417.60402243]]\n",
      "Loop  3525 :    Loss_Train:  [[ 4823.70860536]]    Loss_Validation:  [[ 1417.60628454]]\n",
      "Loop  3526 :    Loss_Train:  [[ 4823.70663672]]    Loss_Validation:  [[ 1417.60854502]]\n",
      "Loop  3527 :    Loss_Train:  [[ 4823.70467138]]    Loss_Validation:  [[ 1417.61080389]]\n",
      "Loop  3528 :    Loss_Train:  [[ 4823.70270933]]    Loss_Validation:  [[ 1417.61306114]]\n",
      "Loop  3529 :    Loss_Train:  [[ 4823.70075056]]    Loss_Validation:  [[ 1417.61531678]]\n",
      "Loop  3530 :    Loss_Train:  [[ 4823.69879507]]    Loss_Validation:  [[ 1417.6175708]]\n",
      "Loop  3531 :    Loss_Train:  [[ 4823.69684286]]    Loss_Validation:  [[ 1417.6198232]]\n",
      "Loop  3532 :    Loss_Train:  [[ 4823.69489391]]    Loss_Validation:  [[ 1417.62207399]]\n",
      "Loop  3533 :    Loss_Train:  [[ 4823.69294822]]    Loss_Validation:  [[ 1417.62432318]]\n",
      "Loop  3534 :    Loss_Train:  [[ 4823.69100578]]    Loss_Validation:  [[ 1417.62657075]]\n",
      "Loop  3535 :    Loss_Train:  [[ 4823.6890666]]    Loss_Validation:  [[ 1417.62881671]]\n",
      "Loop  3536 :    Loss_Train:  [[ 4823.68713066]]    Loss_Validation:  [[ 1417.63106106]]\n",
      "Loop  3537 :    Loss_Train:  [[ 4823.68519796]]    Loss_Validation:  [[ 1417.63330381]]\n",
      "Loop  3538 :    Loss_Train:  [[ 4823.6832685]]    Loss_Validation:  [[ 1417.63554495]]\n",
      "Loop  3539 :    Loss_Train:  [[ 4823.68134226]]    Loss_Validation:  [[ 1417.63778448]]\n",
      "Loop  3540 :    Loss_Train:  [[ 4823.67941925]]    Loss_Validation:  [[ 1417.64002242]]\n",
      "Loop  3541 :    Loss_Train:  [[ 4823.67749945]]    Loss_Validation:  [[ 1417.64225875]]\n",
      "Loop  3542 :    Loss_Train:  [[ 4823.67558287]]    Loss_Validation:  [[ 1417.64449348]]\n",
      "Loop  3543 :    Loss_Train:  [[ 4823.67366949]]    Loss_Validation:  [[ 1417.64672661]]\n",
      "Loop  3544 :    Loss_Train:  [[ 4823.67175931]]    Loss_Validation:  [[ 1417.64895814]]\n",
      "Loop  3545 :    Loss_Train:  [[ 4823.66985233]]    Loss_Validation:  [[ 1417.65118808]]\n",
      "Loop  3546 :    Loss_Train:  [[ 4823.66794853]]    Loss_Validation:  [[ 1417.65341642]]\n",
      "Loop  3547 :    Loss_Train:  [[ 4823.66604792]]    Loss_Validation:  [[ 1417.65564317]]\n",
      "Loop  3548 :    Loss_Train:  [[ 4823.66415049]]    Loss_Validation:  [[ 1417.65786832]]\n",
      "Loop  3549 :    Loss_Train:  [[ 4823.66225624]]    Loss_Validation:  [[ 1417.66009188]]\n",
      "Loop  3550 :    Loss_Train:  [[ 4823.66036515]]    Loss_Validation:  [[ 1417.66231385]]\n",
      "Loop  3551 :    Loss_Train:  [[ 4823.65847722]]    Loss_Validation:  [[ 1417.66453423]]\n",
      "Loop  3552 :    Loss_Train:  [[ 4823.65659246]]    Loss_Validation:  [[ 1417.66675302]]\n",
      "Loop  3553 :    Loss_Train:  [[ 4823.65471084]]    Loss_Validation:  [[ 1417.66897023]]\n",
      "Loop  3554 :    Loss_Train:  [[ 4823.65283237]]    Loss_Validation:  [[ 1417.67118585]]\n",
      "Loop  3555 :    Loss_Train:  [[ 4823.65095704]]    Loss_Validation:  [[ 1417.67339988]]\n",
      "Loop  3556 :    Loss_Train:  [[ 4823.64908485]]    Loss_Validation:  [[ 1417.67561233]]\n",
      "Loop  3557 :    Loss_Train:  [[ 4823.64721579]]    Loss_Validation:  [[ 1417.6778232]]\n",
      "Loop  3558 :    Loss_Train:  [[ 4823.64534985]]    Loss_Validation:  [[ 1417.68003249]]\n",
      "Loop  3559 :    Loss_Train:  [[ 4823.64348704]]    Loss_Validation:  [[ 1417.6822402]]\n",
      "Loop  3560 :    Loss_Train:  [[ 4823.64162734]]    Loss_Validation:  [[ 1417.68444633]]\n",
      "Loop  3561 :    Loss_Train:  [[ 4823.63977074]]    Loss_Validation:  [[ 1417.68665088]]\n",
      "Loop  3562 :    Loss_Train:  [[ 4823.63791726]]    Loss_Validation:  [[ 1417.68885385]]\n",
      "Loop  3563 :    Loss_Train:  [[ 4823.63606687]]    Loss_Validation:  [[ 1417.69105525]]\n",
      "Loop  3564 :    Loss_Train:  [[ 4823.63421957]]    Loss_Validation:  [[ 1417.69325508]]\n",
      "Loop  3565 :    Loss_Train:  [[ 4823.63237536]]    Loss_Validation:  [[ 1417.69545333]]\n",
      "Loop  3566 :    Loss_Train:  [[ 4823.63053424]]    Loss_Validation:  [[ 1417.69765001]]\n",
      "Loop  3567 :    Loss_Train:  [[ 4823.62869619]]    Loss_Validation:  [[ 1417.69984512]]\n",
      "Loop  3568 :    Loss_Train:  [[ 4823.62686121]]    Loss_Validation:  [[ 1417.70203867]]\n",
      "Loop  3569 :    Loss_Train:  [[ 4823.62502931]]    Loss_Validation:  [[ 1417.70423064]]\n",
      "Loop  3570 :    Loss_Train:  [[ 4823.62320046]]    Loss_Validation:  [[ 1417.70642105]]\n",
      "Loop  3571 :    Loss_Train:  [[ 4823.62137467]]    Loss_Validation:  [[ 1417.70860989]]\n",
      "Loop  3572 :    Loss_Train:  [[ 4823.61955194]]    Loss_Validation:  [[ 1417.71079717]]\n",
      "Loop  3573 :    Loss_Train:  [[ 4823.61773224]]    Loss_Validation:  [[ 1417.71298288]]\n",
      "Loop  3574 :    Loss_Train:  [[ 4823.61591559]]    Loss_Validation:  [[ 1417.71516704]]\n",
      "Loop  3575 :    Loss_Train:  [[ 4823.61410198]]    Loss_Validation:  [[ 1417.71734963]]\n",
      "Loop  3576 :    Loss_Train:  [[ 4823.6122914]]    Loss_Validation:  [[ 1417.71953066]]\n",
      "Loop  3577 :    Loss_Train:  [[ 4823.61048384]]    Loss_Validation:  [[ 1417.72171013]]\n",
      "Loop  3578 :    Loss_Train:  [[ 4823.6086793]]    Loss_Validation:  [[ 1417.72388805]]\n",
      "Loop  3579 :    Loss_Train:  [[ 4823.60687778]]    Loss_Validation:  [[ 1417.72606441]]\n",
      "Loop  3580 :    Loss_Train:  [[ 4823.60507927]]    Loss_Validation:  [[ 1417.72823922]]\n",
      "Loop  3581 :    Loss_Train:  [[ 4823.60328377]]    Loss_Validation:  [[ 1417.73041247]]\n",
      "Loop  3582 :    Loss_Train:  [[ 4823.60149126]]    Loss_Validation:  [[ 1417.73258417]]\n",
      "Loop  3583 :    Loss_Train:  [[ 4823.59970175]]    Loss_Validation:  [[ 1417.73475432]]\n",
      "Loop  3584 :    Loss_Train:  [[ 4823.59791523]]    Loss_Validation:  [[ 1417.73692292]]\n",
      "Loop  3585 :    Loss_Train:  [[ 4823.59613169]]    Loss_Validation:  [[ 1417.73908997]]\n",
      "Loop  3586 :    Loss_Train:  [[ 4823.59435114]]    Loss_Validation:  [[ 1417.74125547]]\n",
      "Loop  3587 :    Loss_Train:  [[ 4823.59257356]]    Loss_Validation:  [[ 1417.74341943]]\n",
      "Loop  3588 :    Loss_Train:  [[ 4823.59079894]]    Loss_Validation:  [[ 1417.74558184]]\n",
      "Loop  3589 :    Loss_Train:  [[ 4823.5890273]]    Loss_Validation:  [[ 1417.7477427]]\n",
      "Loop  3590 :    Loss_Train:  [[ 4823.58725861]]    Loss_Validation:  [[ 1417.74990202]]\n",
      "Loop  3591 :    Loss_Train:  [[ 4823.58549287]]    Loss_Validation:  [[ 1417.75205981]]\n",
      "Loop  3592 :    Loss_Train:  [[ 4823.58373009]]    Loss_Validation:  [[ 1417.75421605]]\n",
      "Loop  3593 :    Loss_Train:  [[ 4823.58197025]]    Loss_Validation:  [[ 1417.75637075]]\n",
      "Loop  3594 :    Loss_Train:  [[ 4823.58021335]]    Loss_Validation:  [[ 1417.75852391]]\n",
      "Loop  3595 :    Loss_Train:  [[ 4823.57845938]]    Loss_Validation:  [[ 1417.76067554]]\n",
      "Loop  3596 :    Loss_Train:  [[ 4823.57670835]]    Loss_Validation:  [[ 1417.76282562]]\n",
      "Loop  3597 :    Loss_Train:  [[ 4823.57496023]]    Loss_Validation:  [[ 1417.76497418]]\n",
      "Loop  3598 :    Loss_Train:  [[ 4823.57321504]]    Loss_Validation:  [[ 1417.7671212]]\n",
      "Loop  3599 :    Loss_Train:  [[ 4823.57147276]]    Loss_Validation:  [[ 1417.76926669]]\n",
      "Loop  3600 :    Loss_Train:  [[ 4823.56973339]]    Loss_Validation:  [[ 1417.77141065]]\n",
      "Loop  3601 :    Loss_Train:  [[ 4823.56799693]]    Loss_Validation:  [[ 1417.77355307]]\n",
      "Loop  3602 :    Loss_Train:  [[ 4823.56626337]]    Loss_Validation:  [[ 1417.77569397]]\n",
      "Loop  3603 :    Loss_Train:  [[ 4823.5645327]]    Loss_Validation:  [[ 1417.77783334]]\n",
      "Loop  3604 :    Loss_Train:  [[ 4823.56280492]]    Loss_Validation:  [[ 1417.77997118]]\n",
      "Loop  3605 :    Loss_Train:  [[ 4823.56108002]]    Loss_Validation:  [[ 1417.7821075]]\n",
      "Loop  3606 :    Loss_Train:  [[ 4823.559358]]    Loss_Validation:  [[ 1417.7842423]]\n",
      "Loop  3607 :    Loss_Train:  [[ 4823.55763886]]    Loss_Validation:  [[ 1417.78637557]]\n",
      "Loop  3608 :    Loss_Train:  [[ 4823.55592259]]    Loss_Validation:  [[ 1417.78850731]]\n",
      "Loop  3609 :    Loss_Train:  [[ 4823.55420919]]    Loss_Validation:  [[ 1417.79063754]]\n",
      "Loop  3610 :    Loss_Train:  [[ 4823.55249865]]    Loss_Validation:  [[ 1417.79276625]]\n",
      "Loop  3611 :    Loss_Train:  [[ 4823.55079096]]    Loss_Validation:  [[ 1417.79489344]]\n",
      "Loop  3612 :    Loss_Train:  [[ 4823.54908612]]    Loss_Validation:  [[ 1417.79701911]]\n",
      "Loop  3613 :    Loss_Train:  [[ 4823.54738413]]    Loss_Validation:  [[ 1417.79914326]]\n",
      "Loop  3614 :    Loss_Train:  [[ 4823.54568498]]    Loss_Validation:  [[ 1417.8012659]]\n",
      "Loop  3615 :    Loss_Train:  [[ 4823.54398866]]    Loss_Validation:  [[ 1417.80338703]]\n",
      "Loop  3616 :    Loss_Train:  [[ 4823.54229518]]    Loss_Validation:  [[ 1417.80550664]]\n",
      "Loop  3617 :    Loss_Train:  [[ 4823.54060452]]    Loss_Validation:  [[ 1417.80762475]]\n",
      "Loop  3618 :    Loss_Train:  [[ 4823.53891669]]    Loss_Validation:  [[ 1417.80974134]]\n",
      "Loop  3619 :    Loss_Train:  [[ 4823.53723167]]    Loss_Validation:  [[ 1417.81185642]]\n",
      "Loop  3620 :    Loss_Train:  [[ 4823.53554946]]    Loss_Validation:  [[ 1417.81396999]]\n",
      "Loop  3621 :    Loss_Train:  [[ 4823.53387006]]    Loss_Validation:  [[ 1417.81608206]]\n",
      "Loop  3622 :    Loss_Train:  [[ 4823.53219347]]    Loss_Validation:  [[ 1417.81819262]]\n",
      "Loop  3623 :    Loss_Train:  [[ 4823.53051967]]    Loss_Validation:  [[ 1417.82030167]]\n",
      "Loop  3624 :    Loss_Train:  [[ 4823.52884867]]    Loss_Validation:  [[ 1417.82240923]]\n",
      "Loop  3625 :    Loss_Train:  [[ 4823.52718045]]    Loss_Validation:  [[ 1417.82451527]]\n",
      "Loop  3626 :    Loss_Train:  [[ 4823.52551502]]    Loss_Validation:  [[ 1417.82661982]]\n",
      "Loop  3627 :    Loss_Train:  [[ 4823.52385237]]    Loss_Validation:  [[ 1417.82872287]]\n",
      "Loop  3628 :    Loss_Train:  [[ 4823.52219249]]    Loss_Validation:  [[ 1417.83082442]]\n",
      "Loop  3629 :    Loss_Train:  [[ 4823.52053538]]    Loss_Validation:  [[ 1417.83292447]]\n",
      "Loop  3630 :    Loss_Train:  [[ 4823.51888103]]    Loss_Validation:  [[ 1417.83502302]]\n",
      "Loop  3631 :    Loss_Train:  [[ 4823.51722945]]    Loss_Validation:  [[ 1417.83712008]]\n",
      "Loop  3632 :    Loss_Train:  [[ 4823.51558062]]    Loss_Validation:  [[ 1417.83921564]]\n",
      "Loop  3633 :    Loss_Train:  [[ 4823.51393454]]    Loss_Validation:  [[ 1417.84130971]]\n",
      "Loop  3634 :    Loss_Train:  [[ 4823.51229121]]    Loss_Validation:  [[ 1417.84340229]]\n",
      "Loop  3635 :    Loss_Train:  [[ 4823.51065061]]    Loss_Validation:  [[ 1417.84549337]]\n",
      "Loop  3636 :    Loss_Train:  [[ 4823.50901276]]    Loss_Validation:  [[ 1417.84758297]]\n",
      "Loop  3637 :    Loss_Train:  [[ 4823.50737764]]    Loss_Validation:  [[ 1417.84967108]]\n",
      "Loop  3638 :    Loss_Train:  [[ 4823.50574524]]    Loss_Validation:  [[ 1417.8517577]]\n",
      "Loop  3639 :    Loss_Train:  [[ 4823.50411557]]    Loss_Validation:  [[ 1417.85384283]]\n",
      "Loop  3640 :    Loss_Train:  [[ 4823.50248862]]    Loss_Validation:  [[ 1417.85592647]]\n",
      "Loop  3641 :    Loss_Train:  [[ 4823.50086438]]    Loss_Validation:  [[ 1417.85800864]]\n",
      "Loop  3642 :    Loss_Train:  [[ 4823.49924285]]    Loss_Validation:  [[ 1417.86008932]]\n",
      "Loop  3643 :    Loss_Train:  [[ 4823.49762402]]    Loss_Validation:  [[ 1417.86216851]]\n",
      "Loop  3644 :    Loss_Train:  [[ 4823.49600789]]    Loss_Validation:  [[ 1417.86424623]]\n",
      "Loop  3645 :    Loss_Train:  [[ 4823.49439446]]    Loss_Validation:  [[ 1417.86632246]]\n",
      "Loop  3646 :    Loss_Train:  [[ 4823.49278372]]    Loss_Validation:  [[ 1417.86839722]]\n",
      "Loop  3647 :    Loss_Train:  [[ 4823.49117567]]    Loss_Validation:  [[ 1417.8704705]]\n",
      "Loop  3648 :    Loss_Train:  [[ 4823.48957029]]    Loss_Validation:  [[ 1417.8725423]]\n",
      "Loop  3649 :    Loss_Train:  [[ 4823.4879676]]    Loss_Validation:  [[ 1417.87461263]]\n",
      "Loop  3650 :    Loss_Train:  [[ 4823.48636757]]    Loss_Validation:  [[ 1417.87668148]]\n",
      "Loop  3651 :    Loss_Train:  [[ 4823.48477022]]    Loss_Validation:  [[ 1417.87874886]]\n",
      "Loop  3652 :    Loss_Train:  [[ 4823.48317552]]    Loss_Validation:  [[ 1417.88081476]]\n",
      "Loop  3653 :    Loss_Train:  [[ 4823.48158349]]    Loss_Validation:  [[ 1417.8828792]]\n",
      "Loop  3654 :    Loss_Train:  [[ 4823.47999411]]    Loss_Validation:  [[ 1417.88494217]]\n",
      "Loop  3655 :    Loss_Train:  [[ 4823.47840738]]    Loss_Validation:  [[ 1417.88700366]]\n",
      "Loop  3656 :    Loss_Train:  [[ 4823.4768233]]    Loss_Validation:  [[ 1417.88906369]]\n",
      "Loop  3657 :    Loss_Train:  [[ 4823.47524186]]    Loss_Validation:  [[ 1417.89112225]]\n",
      "Loop  3658 :    Loss_Train:  [[ 4823.47366305]]    Loss_Validation:  [[ 1417.89317935]]\n",
      "Loop  3659 :    Loss_Train:  [[ 4823.47208687]]    Loss_Validation:  [[ 1417.89523498]]\n",
      "Loop  3660 :    Loss_Train:  [[ 4823.47051333]]    Loss_Validation:  [[ 1417.89728915]]\n",
      "Loop  3661 :    Loss_Train:  [[ 4823.4689424]]    Loss_Validation:  [[ 1417.89934186]]\n",
      "Loop  3662 :    Loss_Train:  [[ 4823.4673741]]    Loss_Validation:  [[ 1417.9013931]]\n",
      "Loop  3663 :    Loss_Train:  [[ 4823.4658084]]    Loss_Validation:  [[ 1417.90344289]]\n",
      "Loop  3664 :    Loss_Train:  [[ 4823.46424532]]    Loss_Validation:  [[ 1417.90549122]]\n",
      "Loop  3665 :    Loss_Train:  [[ 4823.46268484]]    Loss_Validation:  [[ 1417.90753808]]\n",
      "Loop  3666 :    Loss_Train:  [[ 4823.46112697]]    Loss_Validation:  [[ 1417.9095835]]\n",
      "Loop  3667 :    Loss_Train:  [[ 4823.45957169]]    Loss_Validation:  [[ 1417.91162745]]\n",
      "Loop  3668 :    Loss_Train:  [[ 4823.458019]]    Loss_Validation:  [[ 1417.91366995]]\n",
      "Loop  3669 :    Loss_Train:  [[ 4823.4564689]]    Loss_Validation:  [[ 1417.915711]]\n",
      "Loop  3670 :    Loss_Train:  [[ 4823.45492138]]    Loss_Validation:  [[ 1417.9177506]]\n",
      "Loop  3671 :    Loss_Train:  [[ 4823.45337645]]    Loss_Validation:  [[ 1417.91978874]]\n",
      "Loop  3672 :    Loss_Train:  [[ 4823.45183408]]    Loss_Validation:  [[ 1417.92182544]]\n",
      "Loop  3673 :    Loss_Train:  [[ 4823.45029429]]    Loss_Validation:  [[ 1417.92386068]]\n",
      "Loop  3674 :    Loss_Train:  [[ 4823.44875706]]    Loss_Validation:  [[ 1417.92589448]]\n",
      "Loop  3675 :    Loss_Train:  [[ 4823.4472224]]    Loss_Validation:  [[ 1417.92792683]]\n",
      "Loop  3676 :    Loss_Train:  [[ 4823.44569029]]    Loss_Validation:  [[ 1417.92995774]]\n",
      "Loop  3677 :    Loss_Train:  [[ 4823.44416073]]    Loss_Validation:  [[ 1417.9319872]]\n",
      "Loop  3678 :    Loss_Train:  [[ 4823.44263372]]    Loss_Validation:  [[ 1417.93401521]]\n",
      "Loop  3679 :    Loss_Train:  [[ 4823.44110926]]    Loss_Validation:  [[ 1417.93604179]]\n",
      "Loop  3680 :    Loss_Train:  [[ 4823.43958734]]    Loss_Validation:  [[ 1417.93806692]]\n",
      "Loop  3681 :    Loss_Train:  [[ 4823.43806795]]    Loss_Validation:  [[ 1417.94009061]]\n",
      "Loop  3682 :    Loss_Train:  [[ 4823.43655109]]    Loss_Validation:  [[ 1417.94211287]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  3683 :    Loss_Train:  [[ 4823.43503676]]    Loss_Validation:  [[ 1417.94413368]]\n",
      "Loop  3684 :    Loss_Train:  [[ 4823.43352495]]    Loss_Validation:  [[ 1417.94615306]]\n",
      "Loop  3685 :    Loss_Train:  [[ 4823.43201566]]    Loss_Validation:  [[ 1417.948171]]\n",
      "Loop  3686 :    Loss_Train:  [[ 4823.43050889]]    Loss_Validation:  [[ 1417.95018751]]\n",
      "Loop  3687 :    Loss_Train:  [[ 4823.42900462]]    Loss_Validation:  [[ 1417.95220258]]\n",
      "Loop  3688 :    Loss_Train:  [[ 4823.42750286]]    Loss_Validation:  [[ 1417.95421622]]\n",
      "Loop  3689 :    Loss_Train:  [[ 4823.4260036]]    Loss_Validation:  [[ 1417.95622843]]\n",
      "Loop  3690 :    Loss_Train:  [[ 4823.42450684]]    Loss_Validation:  [[ 1417.9582392]]\n",
      "Loop  3691 :    Loss_Train:  [[ 4823.42301257]]    Loss_Validation:  [[ 1417.96024855]]\n",
      "Loop  3692 :    Loss_Train:  [[ 4823.42152079]]    Loss_Validation:  [[ 1417.96225647]]\n",
      "Loop  3693 :    Loss_Train:  [[ 4823.42003149]]    Loss_Validation:  [[ 1417.96426296]]\n",
      "Loop  3694 :    Loss_Train:  [[ 4823.41854468]]    Loss_Validation:  [[ 1417.96626803]]\n",
      "Loop  3695 :    Loss_Train:  [[ 4823.41706034]]    Loss_Validation:  [[ 1417.96827167]]\n",
      "Loop  3696 :    Loss_Train:  [[ 4823.41557847]]    Loss_Validation:  [[ 1417.97027388]]\n",
      "Loop  3697 :    Loss_Train:  [[ 4823.41409907]]    Loss_Validation:  [[ 1417.97227468]]\n",
      "Loop  3698 :    Loss_Train:  [[ 4823.41262213]]    Loss_Validation:  [[ 1417.97427405]]\n",
      "Loop  3699 :    Loss_Train:  [[ 4823.41114765]]    Loss_Validation:  [[ 1417.976272]]\n",
      "Loop  3700 :    Loss_Train:  [[ 4823.40967563]]    Loss_Validation:  [[ 1417.97826853]]\n",
      "Loop  3701 :    Loss_Train:  [[ 4823.40820606]]    Loss_Validation:  [[ 1417.98026364]]\n",
      "Loop  3702 :    Loss_Train:  [[ 4823.40673893]]    Loss_Validation:  [[ 1417.98225733]]\n",
      "Loop  3703 :    Loss_Train:  [[ 4823.40527425]]    Loss_Validation:  [[ 1417.98424961]]\n",
      "Loop  3704 :    Loss_Train:  [[ 4823.40381201]]    Loss_Validation:  [[ 1417.98624047]]\n",
      "Loop  3705 :    Loss_Train:  [[ 4823.4023522]]    Loss_Validation:  [[ 1417.98822991]]\n",
      "Loop  3706 :    Loss_Train:  [[ 4823.40089482]]    Loss_Validation:  [[ 1417.99021795]]\n",
      "Loop  3707 :    Loss_Train:  [[ 4823.39943987]]    Loss_Validation:  [[ 1417.99220457]]\n",
      "Loop  3708 :    Loss_Train:  [[ 4823.39798733]]    Loss_Validation:  [[ 1417.99418977]]\n",
      "Loop  3709 :    Loss_Train:  [[ 4823.39653722]]    Loss_Validation:  [[ 1417.99617357]]\n",
      "Loop  3710 :    Loss_Train:  [[ 4823.39508952]]    Loss_Validation:  [[ 1417.99815596]]\n",
      "Loop  3711 :    Loss_Train:  [[ 4823.39364423]]    Loss_Validation:  [[ 1418.00013694]]\n",
      "Loop  3712 :    Loss_Train:  [[ 4823.39220135]]    Loss_Validation:  [[ 1418.00211651]]\n",
      "Loop  3713 :    Loss_Train:  [[ 4823.39076086]]    Loss_Validation:  [[ 1418.00409468]]\n",
      "Loop  3714 :    Loss_Train:  [[ 4823.38932278]]    Loss_Validation:  [[ 1418.00607144]]\n",
      "Loop  3715 :    Loss_Train:  [[ 4823.38788709]]    Loss_Validation:  [[ 1418.0080468]]\n",
      "Loop  3716 :    Loss_Train:  [[ 4823.38645379]]    Loss_Validation:  [[ 1418.01002075]]\n",
      "Loop  3717 :    Loss_Train:  [[ 4823.38502287]]    Loss_Validation:  [[ 1418.01199331]]\n",
      "Loop  3718 :    Loss_Train:  [[ 4823.38359433]]    Loss_Validation:  [[ 1418.01396446]]\n",
      "Loop  3719 :    Loss_Train:  [[ 4823.38216818]]    Loss_Validation:  [[ 1418.01593421]]\n",
      "Loop  3720 :    Loss_Train:  [[ 4823.38074439]]    Loss_Validation:  [[ 1418.01790256]]\n",
      "Loop  3721 :    Loss_Train:  [[ 4823.37932297]]    Loss_Validation:  [[ 1418.01986952]]\n",
      "Loop  3722 :    Loss_Train:  [[ 4823.37790392]]    Loss_Validation:  [[ 1418.02183508]]\n",
      "Loop  3723 :    Loss_Train:  [[ 4823.37648724]]    Loss_Validation:  [[ 1418.02379924]]\n",
      "Loop  3724 :    Loss_Train:  [[ 4823.3750729]]    Loss_Validation:  [[ 1418.02576201]]\n",
      "Loop  3725 :    Loss_Train:  [[ 4823.37366092]]    Loss_Validation:  [[ 1418.02772338]]\n",
      "Loop  3726 :    Loss_Train:  [[ 4823.3722513]]    Loss_Validation:  [[ 1418.02968337]]\n",
      "Loop  3727 :    Loss_Train:  [[ 4823.37084401]]    Loss_Validation:  [[ 1418.03164196]]\n",
      "Loop  3728 :    Loss_Train:  [[ 4823.36943907]]    Loss_Validation:  [[ 1418.03359916]]\n",
      "Loop  3729 :    Loss_Train:  [[ 4823.36803646]]    Loss_Validation:  [[ 1418.03555497]]\n",
      "Loop  3730 :    Loss_Train:  [[ 4823.36663619]]    Loss_Validation:  [[ 1418.03750939]]\n",
      "Loop  3731 :    Loss_Train:  [[ 4823.36523825]]    Loss_Validation:  [[ 1418.03946242]]\n",
      "Loop  3732 :    Loss_Train:  [[ 4823.36384263]]    Loss_Validation:  [[ 1418.04141407]]\n",
      "Loop  3733 :    Loss_Train:  [[ 4823.36244934]]    Loss_Validation:  [[ 1418.04336434]]\n",
      "Loop  3734 :    Loss_Train:  [[ 4823.36105836]]    Loss_Validation:  [[ 1418.04531321]]\n",
      "Loop  3735 :    Loss_Train:  [[ 4823.35966969]]    Loss_Validation:  [[ 1418.04726071]]\n",
      "Loop  3736 :    Loss_Train:  [[ 4823.35828334]]    Loss_Validation:  [[ 1418.04920682]]\n",
      "Loop  3737 :    Loss_Train:  [[ 4823.35689929]]    Loss_Validation:  [[ 1418.05115156]]\n",
      "Loop  3738 :    Loss_Train:  [[ 4823.35551755]]    Loss_Validation:  [[ 1418.05309491]]\n",
      "Loop  3739 :    Loss_Train:  [[ 4823.3541381]]    Loss_Validation:  [[ 1418.05503688]]\n",
      "Loop  3740 :    Loss_Train:  [[ 4823.35276094]]    Loss_Validation:  [[ 1418.05697748]]\n",
      "Loop  3741 :    Loss_Train:  [[ 4823.35138608]]    Loss_Validation:  [[ 1418.0589167]]\n",
      "Loop  3742 :    Loss_Train:  [[ 4823.3500135]]    Loss_Validation:  [[ 1418.06085454]]\n",
      "Loop  3743 :    Loss_Train:  [[ 4823.34864321]]    Loss_Validation:  [[ 1418.06279101]]\n",
      "Loop  3744 :    Loss_Train:  [[ 4823.34727519]]    Loss_Validation:  [[ 1418.0647261]]\n",
      "Loop  3745 :    Loss_Train:  [[ 4823.34590945]]    Loss_Validation:  [[ 1418.06665982]]\n",
      "Loop  3746 :    Loss_Train:  [[ 4823.34454598]]    Loss_Validation:  [[ 1418.06859217]]\n",
      "Loop  3747 :    Loss_Train:  [[ 4823.34318478]]    Loss_Validation:  [[ 1418.07052314]]\n",
      "Loop  3748 :    Loss_Train:  [[ 4823.34182584]]    Loss_Validation:  [[ 1418.07245275]]\n",
      "Loop  3749 :    Loss_Train:  [[ 4823.34046916]]    Loss_Validation:  [[ 1418.07438099]]\n",
      "Loop  3750 :    Loss_Train:  [[ 4823.33911474]]    Loss_Validation:  [[ 1418.07630786]]\n",
      "Loop  3751 :    Loss_Train:  [[ 4823.33776257]]    Loss_Validation:  [[ 1418.07823337]]\n",
      "Loop  3752 :    Loss_Train:  [[ 4823.33641264]]    Loss_Validation:  [[ 1418.08015751]]\n",
      "Loop  3753 :    Loss_Train:  [[ 4823.33506496]]    Loss_Validation:  [[ 1418.08208028]]\n",
      "Loop  3754 :    Loss_Train:  [[ 4823.33371952]]    Loss_Validation:  [[ 1418.08400169]]\n",
      "Loop  3755 :    Loss_Train:  [[ 4823.33237632]]    Loss_Validation:  [[ 1418.08592174]]\n",
      "Loop  3756 :    Loss_Train:  [[ 4823.33103535]]    Loss_Validation:  [[ 1418.08784042]]\n",
      "Loop  3757 :    Loss_Train:  [[ 4823.32969661]]    Loss_Validation:  [[ 1418.08975775]]\n",
      "Loop  3758 :    Loss_Train:  [[ 4823.3283601]]    Loss_Validation:  [[ 1418.09167371]]\n",
      "Loop  3759 :    Loss_Train:  [[ 4823.32702581]]    Loss_Validation:  [[ 1418.09358832]]\n",
      "Loop  3760 :    Loss_Train:  [[ 4823.32569373]]    Loss_Validation:  [[ 1418.09550157]]\n",
      "Loop  3761 :    Loss_Train:  [[ 4823.32436387]]    Loss_Validation:  [[ 1418.09741346]]\n",
      "Loop  3762 :    Loss_Train:  [[ 4823.32303622]]    Loss_Validation:  [[ 1418.099324]]\n",
      "Loop  3763 :    Loss_Train:  [[ 4823.32171078]]    Loss_Validation:  [[ 1418.10123318]]\n",
      "Loop  3764 :    Loss_Train:  [[ 4823.32038753]]    Loss_Validation:  [[ 1418.10314101]]\n",
      "Loop  3765 :    Loss_Train:  [[ 4823.31906649]]    Loss_Validation:  [[ 1418.10504748]]\n",
      "Loop  3766 :    Loss_Train:  [[ 4823.31774765]]    Loss_Validation:  [[ 1418.10695261]]\n",
      "Loop  3767 :    Loss_Train:  [[ 4823.31643099]]    Loss_Validation:  [[ 1418.10885638]]\n",
      "Loop  3768 :    Loss_Train:  [[ 4823.31511653]]    Loss_Validation:  [[ 1418.11075881]]\n",
      "Loop  3769 :    Loss_Train:  [[ 4823.31380424]]    Loss_Validation:  [[ 1418.11265988]]\n",
      "Loop  3770 :    Loss_Train:  [[ 4823.31249414]]    Loss_Validation:  [[ 1418.11455961]]\n",
      "Loop  3771 :    Loss_Train:  [[ 4823.31118622]]    Loss_Validation:  [[ 1418.11645799]]\n",
      "Loop  3772 :    Loss_Train:  [[ 4823.30988047]]    Loss_Validation:  [[ 1418.11835503]]\n",
      "Loop  3773 :    Loss_Train:  [[ 4823.30857689]]    Loss_Validation:  [[ 1418.12025072]]\n",
      "Loop  3774 :    Loss_Train:  [[ 4823.30727547]]    Loss_Validation:  [[ 1418.12214507]]\n",
      "Loop  3775 :    Loss_Train:  [[ 4823.30597622]]    Loss_Validation:  [[ 1418.12403807]]\n",
      "Loop  3776 :    Loss_Train:  [[ 4823.30467913]]    Loss_Validation:  [[ 1418.12592974]]\n",
      "Loop  3777 :    Loss_Train:  [[ 4823.30338419]]    Loss_Validation:  [[ 1418.12782006]]\n",
      "Loop  3778 :    Loss_Train:  [[ 4823.3020914]]    Loss_Validation:  [[ 1418.12970904]]\n",
      "Loop  3779 :    Loss_Train:  [[ 4823.30080076]]    Loss_Validation:  [[ 1418.13159669]]\n",
      "Loop  3780 :    Loss_Train:  [[ 4823.29951226]]    Loss_Validation:  [[ 1418.13348299]]\n",
      "Loop  3781 :    Loss_Train:  [[ 4823.29822591]]    Loss_Validation:  [[ 1418.13536797]]\n",
      "Loop  3782 :    Loss_Train:  [[ 4823.29694169]]    Loss_Validation:  [[ 1418.1372516]]\n",
      "Loop  3783 :    Loss_Train:  [[ 4823.29565961]]    Loss_Validation:  [[ 1418.1391339]]\n",
      "Loop  3784 :    Loss_Train:  [[ 4823.29437965]]    Loss_Validation:  [[ 1418.14101487]]\n",
      "Loop  3785 :    Loss_Train:  [[ 4823.29310182]]    Loss_Validation:  [[ 1418.1428945]]\n",
      "Loop  3786 :    Loss_Train:  [[ 4823.29182611]]    Loss_Validation:  [[ 1418.14477281]]\n",
      "Loop  3787 :    Loss_Train:  [[ 4823.29055253]]    Loss_Validation:  [[ 1418.14664978]]\n",
      "Loop  3788 :    Loss_Train:  [[ 4823.28928105]]    Loss_Validation:  [[ 1418.14852542]]\n",
      "Loop  3789 :    Loss_Train:  [[ 4823.28801169]]    Loss_Validation:  [[ 1418.15039973]]\n",
      "Loop  3790 :    Loss_Train:  [[ 4823.28674444]]    Loss_Validation:  [[ 1418.15227272]]\n",
      "Loop  3791 :    Loss_Train:  [[ 4823.28547929]]    Loss_Validation:  [[ 1418.15414438]]\n",
      "Loop  3792 :    Loss_Train:  [[ 4823.28421625]]    Loss_Validation:  [[ 1418.15601471]]\n",
      "Loop  3793 :    Loss_Train:  [[ 4823.2829553]]    Loss_Validation:  [[ 1418.15788372]]\n",
      "Loop  3794 :    Loss_Train:  [[ 4823.28169644]]    Loss_Validation:  [[ 1418.15975141]]\n",
      "Loop  3795 :    Loss_Train:  [[ 4823.28043968]]    Loss_Validation:  [[ 1418.16161777]]\n",
      "Loop  3796 :    Loss_Train:  [[ 4823.279185]]    Loss_Validation:  [[ 1418.16348281]]\n",
      "Loop  3797 :    Loss_Train:  [[ 4823.27793241]]    Loss_Validation:  [[ 1418.16534653]]\n",
      "Loop  3798 :    Loss_Train:  [[ 4823.27668189]]    Loss_Validation:  [[ 1418.16720893]]\n",
      "Loop  3799 :    Loss_Train:  [[ 4823.27543346]]    Loss_Validation:  [[ 1418.16907001]]\n",
      "Loop  3800 :    Loss_Train:  [[ 4823.27418709]]    Loss_Validation:  [[ 1418.17092978]]\n",
      "Loop  3801 :    Loss_Train:  [[ 4823.2729428]]    Loss_Validation:  [[ 1418.17278822]]\n",
      "Loop  3802 :    Loss_Train:  [[ 4823.27170057]]    Loss_Validation:  [[ 1418.17464535]]\n",
      "Loop  3803 :    Loss_Train:  [[ 4823.2704604]]    Loss_Validation:  [[ 1418.17650117]]\n",
      "Loop  3804 :    Loss_Train:  [[ 4823.26922229]]    Loss_Validation:  [[ 1418.17835567]]\n",
      "Loop  3805 :    Loss_Train:  [[ 4823.26798624]]    Loss_Validation:  [[ 1418.18020886]]\n",
      "Loop  3806 :    Loss_Train:  [[ 4823.26675224]]    Loss_Validation:  [[ 1418.18206074]]\n",
      "Loop  3807 :    Loss_Train:  [[ 4823.26552029]]    Loss_Validation:  [[ 1418.1839113]]\n",
      "Loop  3808 :    Loss_Train:  [[ 4823.26429038]]    Loss_Validation:  [[ 1418.18576056]]\n",
      "Loop  3809 :    Loss_Train:  [[ 4823.26306251]]    Loss_Validation:  [[ 1418.18760851]]\n",
      "Loop  3810 :    Loss_Train:  [[ 4823.26183669]]    Loss_Validation:  [[ 1418.18945515]]\n",
      "Loop  3811 :    Loss_Train:  [[ 4823.26061289]]    Loss_Validation:  [[ 1418.19130048]]\n",
      "Loop  3812 :    Loss_Train:  [[ 4823.25939113]]    Loss_Validation:  [[ 1418.1931445]]\n",
      "Loop  3813 :    Loss_Train:  [[ 4823.2581714]]    Loss_Validation:  [[ 1418.19498722]]\n",
      "Loop  3814 :    Loss_Train:  [[ 4823.25695369]]    Loss_Validation:  [[ 1418.19682864]]\n",
      "Loop  3815 :    Loss_Train:  [[ 4823.255738]]    Loss_Validation:  [[ 1418.19866875]]\n",
      "Loop  3816 :    Loss_Train:  [[ 4823.25452433]]    Loss_Validation:  [[ 1418.20050756]]\n",
      "Loop  3817 :    Loss_Train:  [[ 4823.25331268]]    Loss_Validation:  [[ 1418.20234507]]\n",
      "Loop  3818 :    Loss_Train:  [[ 4823.25210303]]    Loss_Validation:  [[ 1418.20418128]]\n",
      "Loop  3819 :    Loss_Train:  [[ 4823.25089539]]    Loss_Validation:  [[ 1418.20601619]]\n",
      "Loop  3820 :    Loss_Train:  [[ 4823.24968976]]    Loss_Validation:  [[ 1418.2078498]]\n",
      "Loop  3821 :    Loss_Train:  [[ 4823.24848613]]    Loss_Validation:  [[ 1418.20968211]]\n",
      "Loop  3822 :    Loss_Train:  [[ 4823.24728449]]    Loss_Validation:  [[ 1418.21151313]]\n",
      "Loop  3823 :    Loss_Train:  [[ 4823.24608485]]    Loss_Validation:  [[ 1418.21334285]]\n",
      "Loop  3824 :    Loss_Train:  [[ 4823.2448872]]    Loss_Validation:  [[ 1418.21517128]]\n",
      "Loop  3825 :    Loss_Train:  [[ 4823.24369153]]    Loss_Validation:  [[ 1418.21699841]]\n",
      "Loop  3826 :    Loss_Train:  [[ 4823.24249785]]    Loss_Validation:  [[ 1418.21882425]]\n",
      "Loop  3827 :    Loss_Train:  [[ 4823.24130616]]    Loss_Validation:  [[ 1418.2206488]]\n",
      "Loop  3828 :    Loss_Train:  [[ 4823.24011643]]    Loss_Validation:  [[ 1418.22247206]]\n",
      "Loop  3829 :    Loss_Train:  [[ 4823.23892868]]    Loss_Validation:  [[ 1418.22429403]]\n",
      "Loop  3830 :    Loss_Train:  [[ 4823.23774291]]    Loss_Validation:  [[ 1418.2261147]]\n",
      "Loop  3831 :    Loss_Train:  [[ 4823.2365591]]    Loss_Validation:  [[ 1418.2279341]]\n",
      "Loop  3832 :    Loss_Train:  [[ 4823.23537725]]    Loss_Validation:  [[ 1418.2297522]]\n",
      "Loop  3833 :    Loss_Train:  [[ 4823.23419736]]    Loss_Validation:  [[ 1418.23156902]]\n",
      "Loop  3834 :    Loss_Train:  [[ 4823.23301943]]    Loss_Validation:  [[ 1418.23338455]]\n",
      "Loop  3835 :    Loss_Train:  [[ 4823.23184346]]    Loss_Validation:  [[ 1418.2351988]]\n",
      "Loop  3836 :    Loss_Train:  [[ 4823.23066943]]    Loss_Validation:  [[ 1418.23701177]]\n",
      "Loop  3837 :    Loss_Train:  [[ 4823.22949736]]    Loss_Validation:  [[ 1418.23882345]]\n",
      "Loop  3838 :    Loss_Train:  [[ 4823.22832723]]    Loss_Validation:  [[ 1418.24063385]]\n",
      "Loop  3839 :    Loss_Train:  [[ 4823.22715903]]    Loss_Validation:  [[ 1418.24244297]]\n",
      "Loop  3840 :    Loss_Train:  [[ 4823.22599278]]    Loss_Validation:  [[ 1418.24425082]]\n",
      "Loop  3841 :    Loss_Train:  [[ 4823.22482846]]    Loss_Validation:  [[ 1418.24605738]]\n",
      "Loop  3842 :    Loss_Train:  [[ 4823.22366607]]    Loss_Validation:  [[ 1418.24786267]]\n",
      "Loop  3843 :    Loss_Train:  [[ 4823.22250561]]    Loss_Validation:  [[ 1418.24966668]]\n",
      "Loop  3844 :    Loss_Train:  [[ 4823.22134707]]    Loss_Validation:  [[ 1418.25146941]]\n",
      "Loop  3845 :    Loss_Train:  [[ 4823.22019046]]    Loss_Validation:  [[ 1418.25327087]]\n",
      "Loop  3846 :    Loss_Train:  [[ 4823.21903576]]    Loss_Validation:  [[ 1418.25507106]]\n",
      "Loop  3847 :    Loss_Train:  [[ 4823.21788298]]    Loss_Validation:  [[ 1418.25686997]]\n",
      "Loop  3848 :    Loss_Train:  [[ 4823.21673211]]    Loss_Validation:  [[ 1418.25866761]]\n",
      "Loop  3849 :    Loss_Train:  [[ 4823.21558314]]    Loss_Validation:  [[ 1418.26046398]]\n",
      "Loop  3850 :    Loss_Train:  [[ 4823.21443609]]    Loss_Validation:  [[ 1418.26225908]]\n",
      "Loop  3851 :    Loss_Train:  [[ 4823.21329093]]    Loss_Validation:  [[ 1418.26405291]]\n",
      "Loop  3852 :    Loss_Train:  [[ 4823.21214767]]    Loss_Validation:  [[ 1418.26584548]]\n",
      "Loop  3853 :    Loss_Train:  [[ 4823.21100631]]    Loss_Validation:  [[ 1418.26763677]]\n",
      "Loop  3854 :    Loss_Train:  [[ 4823.20986684]]    Loss_Validation:  [[ 1418.2694268]]\n",
      "Loop  3855 :    Loss_Train:  [[ 4823.20872926]]    Loss_Validation:  [[ 1418.27121557]]\n",
      "Loop  3856 :    Loss_Train:  [[ 4823.20759357]]    Loss_Validation:  [[ 1418.27300307]]\n",
      "Loop  3857 :    Loss_Train:  [[ 4823.20645976]]    Loss_Validation:  [[ 1418.2747893]]\n",
      "Loop  3858 :    Loss_Train:  [[ 4823.20532783]]    Loss_Validation:  [[ 1418.27657428]]\n",
      "Loop  3859 :    Loss_Train:  [[ 4823.20419777]]    Loss_Validation:  [[ 1418.27835799]]\n",
      "Loop  3860 :    Loss_Train:  [[ 4823.20306959]]    Loss_Validation:  [[ 1418.28014044]]\n",
      "Loop  3861 :    Loss_Train:  [[ 4823.20194328]]    Loss_Validation:  [[ 1418.28192164]]\n",
      "Loop  3862 :    Loss_Train:  [[ 4823.20081884]]    Loss_Validation:  [[ 1418.28370157]]\n",
      "Loop  3863 :    Loss_Train:  [[ 4823.19969625]]    Loss_Validation:  [[ 1418.28548025]]\n",
      "Loop  3864 :    Loss_Train:  [[ 4823.19857554]]    Loss_Validation:  [[ 1418.28725767]]\n",
      "Loop  3865 :    Loss_Train:  [[ 4823.19745667]]    Loss_Validation:  [[ 1418.28903383]]\n",
      "Loop  3866 :    Loss_Train:  [[ 4823.19633967]]    Loss_Validation:  [[ 1418.29080874]]\n",
      "Loop  3867 :    Loss_Train:  [[ 4823.19522451]]    Loss_Validation:  [[ 1418.29258239]]\n",
      "Loop  3868 :    Loss_Train:  [[ 4823.1941112]]    Loss_Validation:  [[ 1418.29435479]]\n",
      "Loop  3869 :    Loss_Train:  [[ 4823.19299974]]    Loss_Validation:  [[ 1418.29612594]]\n",
      "Loop  3870 :    Loss_Train:  [[ 4823.19189012]]    Loss_Validation:  [[ 1418.29789584]]\n",
      "Loop  3871 :    Loss_Train:  [[ 4823.19078233]]    Loss_Validation:  [[ 1418.29966448]]\n",
      "Loop  3872 :    Loss_Train:  [[ 4823.18967639]]    Loss_Validation:  [[ 1418.30143188]]\n",
      "Loop  3873 :    Loss_Train:  [[ 4823.18857227]]    Loss_Validation:  [[ 1418.30319803]]\n",
      "Loop  3874 :    Loss_Train:  [[ 4823.18746999]]    Loss_Validation:  [[ 1418.30496293]]\n",
      "Loop  3875 :    Loss_Train:  [[ 4823.18636953]]    Loss_Validation:  [[ 1418.30672658]]\n",
      "Loop  3876 :    Loss_Train:  [[ 4823.1852709]]    Loss_Validation:  [[ 1418.30848899]]\n",
      "Loop  3877 :    Loss_Train:  [[ 4823.18417408]]    Loss_Validation:  [[ 1418.31025015]]\n",
      "Loop  3878 :    Loss_Train:  [[ 4823.18307909]]    Loss_Validation:  [[ 1418.31201007]]\n",
      "Loop  3879 :    Loss_Train:  [[ 4823.18198591]]    Loss_Validation:  [[ 1418.31376875]]\n",
      "Loop  3880 :    Loss_Train:  [[ 4823.18089454]]    Loss_Validation:  [[ 1418.31552618]]\n",
      "Loop  3881 :    Loss_Train:  [[ 4823.17980497]]    Loss_Validation:  [[ 1418.31728237]]\n",
      "Loop  3882 :    Loss_Train:  [[ 4823.17871722]]    Loss_Validation:  [[ 1418.31903733]]\n",
      "Loop  3883 :    Loss_Train:  [[ 4823.17763126]]    Loss_Validation:  [[ 1418.32079104]]\n",
      "Loop  3884 :    Loss_Train:  [[ 4823.1765471]]    Loss_Validation:  [[ 1418.32254351]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  3885 :    Loss_Train:  [[ 4823.17546474]]    Loss_Validation:  [[ 1418.32429475]]\n",
      "Loop  3886 :    Loss_Train:  [[ 4823.17438418]]    Loss_Validation:  [[ 1418.32604475]]\n",
      "Loop  3887 :    Loss_Train:  [[ 4823.1733054]]    Loss_Validation:  [[ 1418.32779351]]\n",
      "Loop  3888 :    Loss_Train:  [[ 4823.17222841]]    Loss_Validation:  [[ 1418.32954104]]\n",
      "Loop  3889 :    Loss_Train:  [[ 4823.1711532]]    Loss_Validation:  [[ 1418.33128734]]\n",
      "Loop  3890 :    Loss_Train:  [[ 4823.17007978]]    Loss_Validation:  [[ 1418.3330324]]\n",
      "Loop  3891 :    Loss_Train:  [[ 4823.16900813]]    Loss_Validation:  [[ 1418.33477623]]\n",
      "Loop  3892 :    Loss_Train:  [[ 4823.16793826]]    Loss_Validation:  [[ 1418.33651883]]\n",
      "Loop  3893 :    Loss_Train:  [[ 4823.16687016]]    Loss_Validation:  [[ 1418.33826019]]\n",
      "Loop  3894 :    Loss_Train:  [[ 4823.16580382]]    Loss_Validation:  [[ 1418.34000033]]\n",
      "Loop  3895 :    Loss_Train:  [[ 4823.16473926]]    Loss_Validation:  [[ 1418.34173924]]\n",
      "Loop  3896 :    Loss_Train:  [[ 4823.16367646]]    Loss_Validation:  [[ 1418.34347693]]\n",
      "Loop  3897 :    Loss_Train:  [[ 4823.16261541]]    Loss_Validation:  [[ 1418.34521338]]\n",
      "Loop  3898 :    Loss_Train:  [[ 4823.16155613]]    Loss_Validation:  [[ 1418.34694861]]\n",
      "Loop  3899 :    Loss_Train:  [[ 4823.1604986]]    Loss_Validation:  [[ 1418.34868262]]\n",
      "Loop  3900 :    Loss_Train:  [[ 4823.15944282]]    Loss_Validation:  [[ 1418.3504154]]\n",
      "Loop  3901 :    Loss_Train:  [[ 4823.15838879]]    Loss_Validation:  [[ 1418.35214695]]\n",
      "Loop  3902 :    Loss_Train:  [[ 4823.1573365]]    Loss_Validation:  [[ 1418.35387729]]\n",
      "Loop  3903 :    Loss_Train:  [[ 4823.15628596]]    Loss_Validation:  [[ 1418.3556064]]\n",
      "Loop  3904 :    Loss_Train:  [[ 4823.15523715]]    Loss_Validation:  [[ 1418.3573343]]\n",
      "Loop  3905 :    Loss_Train:  [[ 4823.15419009]]    Loss_Validation:  [[ 1418.35906097]]\n",
      "Loop  3906 :    Loss_Train:  [[ 4823.15314475]]    Loss_Validation:  [[ 1418.36078643]]\n",
      "Loop  3907 :    Loss_Train:  [[ 4823.15210115]]    Loss_Validation:  [[ 1418.36251066]]\n",
      "Loop  3908 :    Loss_Train:  [[ 4823.15105927]]    Loss_Validation:  [[ 1418.36423368]]\n",
      "Loop  3909 :    Loss_Train:  [[ 4823.15001912]]    Loss_Validation:  [[ 1418.36595549]]\n",
      "Loop  3910 :    Loss_Train:  [[ 4823.1489807]]    Loss_Validation:  [[ 1418.36767608]]\n",
      "Loop  3911 :    Loss_Train:  [[ 4823.14794399]]    Loss_Validation:  [[ 1418.36939545]]\n",
      "Loop  3912 :    Loss_Train:  [[ 4823.14690899]]    Loss_Validation:  [[ 1418.37111361]]\n",
      "Loop  3913 :    Loss_Train:  [[ 4823.14587571]]    Loss_Validation:  [[ 1418.37283056]]\n",
      "Loop  3914 :    Loss_Train:  [[ 4823.14484414]]    Loss_Validation:  [[ 1418.3745463]]\n",
      "Loop  3915 :    Loss_Train:  [[ 4823.14381428]]    Loss_Validation:  [[ 1418.37626083]]\n",
      "Loop  3916 :    Loss_Train:  [[ 4823.14278612]]    Loss_Validation:  [[ 1418.37797415]]\n",
      "Loop  3917 :    Loss_Train:  [[ 4823.14175967]]    Loss_Validation:  [[ 1418.37968626]]\n",
      "Loop  3918 :    Loss_Train:  [[ 4823.14073491]]    Loss_Validation:  [[ 1418.38139716]]\n",
      "Loop  3919 :    Loss_Train:  [[ 4823.13971185]]    Loss_Validation:  [[ 1418.38310685]]\n",
      "Loop  3920 :    Loss_Train:  [[ 4823.13869049]]    Loss_Validation:  [[ 1418.38481534]]\n",
      "Loop  3921 :    Loss_Train:  [[ 4823.13767081]]    Loss_Validation:  [[ 1418.38652262]]\n",
      "Loop  3922 :    Loss_Train:  [[ 4823.13665282]]    Loss_Validation:  [[ 1418.3882287]]\n",
      "Loop  3923 :    Loss_Train:  [[ 4823.13563652]]    Loss_Validation:  [[ 1418.38993357]]\n",
      "Loop  3924 :    Loss_Train:  [[ 4823.13462189]]    Loss_Validation:  [[ 1418.39163724]]\n",
      "Loop  3925 :    Loss_Train:  [[ 4823.13360895]]    Loss_Validation:  [[ 1418.39333971]]\n",
      "Loop  3926 :    Loss_Train:  [[ 4823.13259769]]    Loss_Validation:  [[ 1418.39504098]]\n",
      "Loop  3927 :    Loss_Train:  [[ 4823.13158809]]    Loss_Validation:  [[ 1418.39674105]]\n",
      "Loop  3928 :    Loss_Train:  [[ 4823.13058017]]    Loss_Validation:  [[ 1418.39843992]]\n",
      "Loop  3929 :    Loss_Train:  [[ 4823.12957391]]    Loss_Validation:  [[ 1418.40013759]]\n",
      "Loop  3930 :    Loss_Train:  [[ 4823.12856932]]    Loss_Validation:  [[ 1418.40183406]]\n",
      "Loop  3931 :    Loss_Train:  [[ 4823.1275664]]    Loss_Validation:  [[ 1418.40352934]]\n",
      "Loop  3932 :    Loss_Train:  [[ 4823.12656513]]    Loss_Validation:  [[ 1418.40522342]]\n",
      "Loop  3933 :    Loss_Train:  [[ 4823.12556552]]    Loss_Validation:  [[ 1418.40691631]]\n",
      "Loop  3934 :    Loss_Train:  [[ 4823.12456756]]    Loss_Validation:  [[ 1418.408608]]\n",
      "Loop  3935 :    Loss_Train:  [[ 4823.12357125]]    Loss_Validation:  [[ 1418.4102985]]\n",
      "Loop  3936 :    Loss_Train:  [[ 4823.12257659]]    Loss_Validation:  [[ 1418.4119878]]\n",
      "Loop  3937 :    Loss_Train:  [[ 4823.12158358]]    Loss_Validation:  [[ 1418.41367592]]\n",
      "Loop  3938 :    Loss_Train:  [[ 4823.12059221]]    Loss_Validation:  [[ 1418.41536285]]\n",
      "Loop  3939 :    Loss_Train:  [[ 4823.11960248]]    Loss_Validation:  [[ 1418.41704858]]\n",
      "Loop  3940 :    Loss_Train:  [[ 4823.11861439]]    Loss_Validation:  [[ 1418.41873313]]\n",
      "Loop  3941 :    Loss_Train:  [[ 4823.11762793]]    Loss_Validation:  [[ 1418.42041649]]\n",
      "Loop  3942 :    Loss_Train:  [[ 4823.1166431]]    Loss_Validation:  [[ 1418.42209866]]\n",
      "Loop  3943 :    Loss_Train:  [[ 4823.11565991]]    Loss_Validation:  [[ 1418.42377965]]\n",
      "Loop  3944 :    Loss_Train:  [[ 4823.11467834]]    Loss_Validation:  [[ 1418.42545945]]\n",
      "Loop  3945 :    Loss_Train:  [[ 4823.11369839]]    Loss_Validation:  [[ 1418.42713807]]\n",
      "Loop  3946 :    Loss_Train:  [[ 4823.11272006]]    Loss_Validation:  [[ 1418.4288155]]\n",
      "Loop  3947 :    Loss_Train:  [[ 4823.11174335]]    Loss_Validation:  [[ 1418.43049175]]\n",
      "Loop  3948 :    Loss_Train:  [[ 4823.11076826]]    Loss_Validation:  [[ 1418.43216682]]\n",
      "Loop  3949 :    Loss_Train:  [[ 4823.10979478]]    Loss_Validation:  [[ 1418.43384071]]\n",
      "Loop  3950 :    Loss_Train:  [[ 4823.10882291]]    Loss_Validation:  [[ 1418.43551342]]\n",
      "Loop  3951 :    Loss_Train:  [[ 4823.10785265]]    Loss_Validation:  [[ 1418.43718495]]\n",
      "Loop  3952 :    Loss_Train:  [[ 4823.10688399]]    Loss_Validation:  [[ 1418.4388553]]\n",
      "Loop  3953 :    Loss_Train:  [[ 4823.10591693]]    Loss_Validation:  [[ 1418.44052447]]\n",
      "Loop  3954 :    Loss_Train:  [[ 4823.10495147]]    Loss_Validation:  [[ 1418.44219247]]\n",
      "Loop  3955 :    Loss_Train:  [[ 4823.10398761]]    Loss_Validation:  [[ 1418.44385929]]\n",
      "Loop  3956 :    Loss_Train:  [[ 4823.10302535]]    Loss_Validation:  [[ 1418.44552493]]\n",
      "Loop  3957 :    Loss_Train:  [[ 4823.10206467]]    Loss_Validation:  [[ 1418.44718941]]\n",
      "Loop  3958 :    Loss_Train:  [[ 4823.10110558]]    Loss_Validation:  [[ 1418.4488527]]\n",
      "Loop  3959 :    Loss_Train:  [[ 4823.10014808]]    Loss_Validation:  [[ 1418.45051483]]\n",
      "Loop  3960 :    Loss_Train:  [[ 4823.09919216]]    Loss_Validation:  [[ 1418.45217579]]\n",
      "Loop  3961 :    Loss_Train:  [[ 4823.09823782]]    Loss_Validation:  [[ 1418.45383557]]\n",
      "Loop  3962 :    Loss_Train:  [[ 4823.09728506]]    Loss_Validation:  [[ 1418.45549419]]\n",
      "Loop  3963 :    Loss_Train:  [[ 4823.09633388]]    Loss_Validation:  [[ 1418.45715163]]\n",
      "Loop  3964 :    Loss_Train:  [[ 4823.09538426]]    Loss_Validation:  [[ 1418.45880791]]\n",
      "Loop  3965 :    Loss_Train:  [[ 4823.09443622]]    Loss_Validation:  [[ 1418.46046302]]\n",
      "Loop  3966 :    Loss_Train:  [[ 4823.09348975]]    Loss_Validation:  [[ 1418.46211697]]\n",
      "Loop  3967 :    Loss_Train:  [[ 4823.09254484]]    Loss_Validation:  [[ 1418.46376974]]\n",
      "Loop  3968 :    Loss_Train:  [[ 4823.09160149]]    Loss_Validation:  [[ 1418.46542136]]\n",
      "Loop  3969 :    Loss_Train:  [[ 4823.0906597]]    Loss_Validation:  [[ 1418.46707181]]\n",
      "Loop  3970 :    Loss_Train:  [[ 4823.08971946]]    Loss_Validation:  [[ 1418.4687211]]\n",
      "Loop  3971 :    Loss_Train:  [[ 4823.08878079]]    Loss_Validation:  [[ 1418.47036922]]\n",
      "Loop  3972 :    Loss_Train:  [[ 4823.08784366]]    Loss_Validation:  [[ 1418.47201619]]\n",
      "Loop  3973 :    Loss_Train:  [[ 4823.08690808]]    Loss_Validation:  [[ 1418.47366199]]\n",
      "Loop  3974 :    Loss_Train:  [[ 4823.08597405]]    Loss_Validation:  [[ 1418.47530664]]\n",
      "Loop  3975 :    Loss_Train:  [[ 4823.08504156]]    Loss_Validation:  [[ 1418.47695012]]\n",
      "Loop  3976 :    Loss_Train:  [[ 4823.08411061]]    Loss_Validation:  [[ 1418.47859245]]\n",
      "Loop  3977 :    Loss_Train:  [[ 4823.08318121]]    Loss_Validation:  [[ 1418.48023362]]\n",
      "Loop  3978 :    Loss_Train:  [[ 4823.08225333]]    Loss_Validation:  [[ 1418.48187364]]\n",
      "Loop  3979 :    Loss_Train:  [[ 4823.081327]]    Loss_Validation:  [[ 1418.4835125]]\n",
      "Loop  3980 :    Loss_Train:  [[ 4823.08040219]]    Loss_Validation:  [[ 1418.4851502]]\n",
      "Loop  3981 :    Loss_Train:  [[ 4823.07947891]]    Loss_Validation:  [[ 1418.48678675]]\n",
      "Loop  3982 :    Loss_Train:  [[ 4823.07855715]]    Loss_Validation:  [[ 1418.48842215]]\n",
      "Loop  3983 :    Loss_Train:  [[ 4823.07763692]]    Loss_Validation:  [[ 1418.4900564]]\n",
      "Loop  3984 :    Loss_Train:  [[ 4823.07671821]]    Loss_Validation:  [[ 1418.4916895]]\n",
      "Loop  3985 :    Loss_Train:  [[ 4823.07580102]]    Loss_Validation:  [[ 1418.49332144]]\n",
      "Loop  3986 :    Loss_Train:  [[ 4823.07488534]]    Loss_Validation:  [[ 1418.49495224]]\n",
      "Loop  3987 :    Loss_Train:  [[ 4823.07397118]]    Loss_Validation:  [[ 1418.49658189]]\n",
      "Loop  3988 :    Loss_Train:  [[ 4823.07305853]]    Loss_Validation:  [[ 1418.49821039]]\n",
      "Loop  3989 :    Loss_Train:  [[ 4823.07214738]]    Loss_Validation:  [[ 1418.49983774]]\n",
      "Loop  3990 :    Loss_Train:  [[ 4823.07123774]]    Loss_Validation:  [[ 1418.50146395]]\n",
      "Loop  3991 :    Loss_Train:  [[ 4823.0703296]]    Loss_Validation:  [[ 1418.50308901]]\n",
      "Loop  3992 :    Loss_Train:  [[ 4823.06942297]]    Loss_Validation:  [[ 1418.50471292]]\n",
      "Loop  3993 :    Loss_Train:  [[ 4823.06851783]]    Loss_Validation:  [[ 1418.5063357]]\n",
      "Loop  3994 :    Loss_Train:  [[ 4823.06761418]]    Loss_Validation:  [[ 1418.50795733]]\n",
      "Loop  3995 :    Loss_Train:  [[ 4823.06671203]]    Loss_Validation:  [[ 1418.50957782]]\n",
      "Loop  3996 :    Loss_Train:  [[ 4823.06581137]]    Loss_Validation:  [[ 1418.51119717]]\n",
      "Loop  3997 :    Loss_Train:  [[ 4823.0649122]]    Loss_Validation:  [[ 1418.51281537]]\n",
      "Loop  3998 :    Loss_Train:  [[ 4823.06401451]]    Loss_Validation:  [[ 1418.51443244]]\n",
      "Loop  3999 :    Loss_Train:  [[ 4823.06311831]]    Loss_Validation:  [[ 1418.51604837]]\n",
      "Loop  4000 :    Loss_Train:  [[ 4823.06222358]]    Loss_Validation:  [[ 1418.51766316]]\n",
      "Loop  4001 :    Loss_Train:  [[ 4823.06133034]]    Loss_Validation:  [[ 1418.51927682]]\n",
      "Loop  4002 :    Loss_Train:  [[ 4823.06043856]]    Loss_Validation:  [[ 1418.52088934]]\n",
      "Loop  4003 :    Loss_Train:  [[ 4823.05954827]]    Loss_Validation:  [[ 1418.52250072]]\n",
      "Loop  4004 :    Loss_Train:  [[ 4823.05865944]]    Loss_Validation:  [[ 1418.52411097]]\n",
      "Loop  4005 :    Loss_Train:  [[ 4823.05777208]]    Loss_Validation:  [[ 1418.52572009]]\n",
      "Loop  4006 :    Loss_Train:  [[ 4823.05688618]]    Loss_Validation:  [[ 1418.52732807]]\n",
      "Loop  4007 :    Loss_Train:  [[ 4823.05600175]]    Loss_Validation:  [[ 1418.52893492]]\n",
      "Loop  4008 :    Loss_Train:  [[ 4823.05511878]]    Loss_Validation:  [[ 1418.53054064]]\n",
      "Loop  4009 :    Loss_Train:  [[ 4823.05423727]]    Loss_Validation:  [[ 1418.53214523]]\n",
      "Loop  4010 :    Loss_Train:  [[ 4823.05335721]]    Loss_Validation:  [[ 1418.53374869]]\n",
      "Loop  4011 :    Loss_Train:  [[ 4823.0524786]]    Loss_Validation:  [[ 1418.53535102]]\n",
      "Loop  4012 :    Loss_Train:  [[ 4823.05160145]]    Loss_Validation:  [[ 1418.53695222]]\n",
      "Loop  4013 :    Loss_Train:  [[ 4823.05072575]]    Loss_Validation:  [[ 1418.5385523]]\n",
      "Loop  4014 :    Loss_Train:  [[ 4823.04985149]]    Loss_Validation:  [[ 1418.54015125]]\n",
      "Loop  4015 :    Loss_Train:  [[ 4823.04897867]]    Loss_Validation:  [[ 1418.54174907]]\n",
      "Loop  4016 :    Loss_Train:  [[ 4823.0481073]]    Loss_Validation:  [[ 1418.54334577]]\n",
      "Loop  4017 :    Loss_Train:  [[ 4823.04723736]]    Loss_Validation:  [[ 1418.54494135]]\n",
      "Loop  4018 :    Loss_Train:  [[ 4823.04636886]]    Loss_Validation:  [[ 1418.5465358]]\n",
      "Loop  4019 :    Loss_Train:  [[ 4823.0455018]]    Loss_Validation:  [[ 1418.54812913]]\n",
      "Loop  4020 :    Loss_Train:  [[ 4823.04463616]]    Loss_Validation:  [[ 1418.54972134]]\n",
      "Loop  4021 :    Loss_Train:  [[ 4823.04377196]]    Loss_Validation:  [[ 1418.55131243]]\n",
      "Loop  4022 :    Loss_Train:  [[ 4823.04290918]]    Loss_Validation:  [[ 1418.5529024]]\n",
      "Loop  4023 :    Loss_Train:  [[ 4823.04204782]]    Loss_Validation:  [[ 1418.55449125]]\n",
      "Loop  4024 :    Loss_Train:  [[ 4823.04118789]]    Loss_Validation:  [[ 1418.55607898]]\n",
      "Loop  4025 :    Loss_Train:  [[ 4823.04032938]]    Loss_Validation:  [[ 1418.5576656]]\n",
      "Loop  4026 :    Loss_Train:  [[ 4823.03947228]]    Loss_Validation:  [[ 1418.5592511]]\n",
      "Loop  4027 :    Loss_Train:  [[ 4823.0386166]]    Loss_Validation:  [[ 1418.56083548]]\n",
      "Loop  4028 :    Loss_Train:  [[ 4823.03776233]]    Loss_Validation:  [[ 1418.56241875]]\n",
      "Loop  4029 :    Loss_Train:  [[ 4823.03690948]]    Loss_Validation:  [[ 1418.5640009]]\n",
      "Loop  4030 :    Loss_Train:  [[ 4823.03605802]]    Loss_Validation:  [[ 1418.56558194]]\n",
      "Loop  4031 :    Loss_Train:  [[ 4823.03520798]]    Loss_Validation:  [[ 1418.56716187]]\n",
      "Loop  4032 :    Loss_Train:  [[ 4823.03435934]]    Loss_Validation:  [[ 1418.56874069]]\n",
      "Loop  4033 :    Loss_Train:  [[ 4823.03351209]]    Loss_Validation:  [[ 1418.57031839]]\n",
      "Loop  4034 :    Loss_Train:  [[ 4823.03266625]]    Loss_Validation:  [[ 1418.57189499]]\n",
      "Loop  4035 :    Loss_Train:  [[ 4823.0318218]]    Loss_Validation:  [[ 1418.57347048]]\n",
      "Loop  4036 :    Loss_Train:  [[ 4823.03097875]]    Loss_Validation:  [[ 1418.57504486]]\n",
      "Loop  4037 :    Loss_Train:  [[ 4823.03013709]]    Loss_Validation:  [[ 1418.57661813]]\n",
      "Loop  4038 :    Loss_Train:  [[ 4823.02929681]]    Loss_Validation:  [[ 1418.57819029]]\n",
      "Loop  4039 :    Loss_Train:  [[ 4823.02845792]]    Loss_Validation:  [[ 1418.57976135]]\n",
      "Loop  4040 :    Loss_Train:  [[ 4823.02762042]]    Loss_Validation:  [[ 1418.5813313]]\n",
      "Loop  4041 :    Loss_Train:  [[ 4823.0267843]]    Loss_Validation:  [[ 1418.58290015]]\n",
      "Loop  4042 :    Loss_Train:  [[ 4823.02594956]]    Loss_Validation:  [[ 1418.5844679]]\n",
      "Loop  4043 :    Loss_Train:  [[ 4823.02511619]]    Loss_Validation:  [[ 1418.58603454]]\n",
      "Loop  4044 :    Loss_Train:  [[ 4823.0242842]]    Loss_Validation:  [[ 1418.58760008]]\n",
      "Loop  4045 :    Loss_Train:  [[ 4823.02345359]]    Loss_Validation:  [[ 1418.58916452]]\n",
      "Loop  4046 :    Loss_Train:  [[ 4823.02262434]]    Loss_Validation:  [[ 1418.59072786]]\n",
      "Loop  4047 :    Loss_Train:  [[ 4823.02179646]]    Loss_Validation:  [[ 1418.5922901]]\n",
      "Loop  4048 :    Loss_Train:  [[ 4823.02096995]]    Loss_Validation:  [[ 1418.59385124]]\n",
      "Loop  4049 :    Loss_Train:  [[ 4823.0201448]]    Loss_Validation:  [[ 1418.59541128]]\n",
      "Loop  4050 :    Loss_Train:  [[ 4823.01932101]]    Loss_Validation:  [[ 1418.59697022]]\n",
      "Loop  4051 :    Loss_Train:  [[ 4823.01849859]]    Loss_Validation:  [[ 1418.59852807]]\n",
      "Loop  4052 :    Loss_Train:  [[ 4823.01767751]]    Loss_Validation:  [[ 1418.60008483]]\n",
      "Loop  4053 :    Loss_Train:  [[ 4823.0168578]]    Loss_Validation:  [[ 1418.60164048]]\n",
      "Loop  4054 :    Loss_Train:  [[ 4823.01603943]]    Loss_Validation:  [[ 1418.60319505]]\n",
      "Loop  4055 :    Loss_Train:  [[ 4823.01522242]]    Loss_Validation:  [[ 1418.60474852]]\n",
      "Loop  4056 :    Loss_Train:  [[ 4823.01440675]]    Loss_Validation:  [[ 1418.6063009]]\n",
      "Loop  4057 :    Loss_Train:  [[ 4823.01359243]]    Loss_Validation:  [[ 1418.60785219]]\n",
      "Loop  4058 :    Loss_Train:  [[ 4823.01277945]]    Loss_Validation:  [[ 1418.60940238]]\n",
      "Loop  4059 :    Loss_Train:  [[ 4823.01196781]]    Loss_Validation:  [[ 1418.61095149]]\n",
      "Loop  4060 :    Loss_Train:  [[ 4823.01115751]]    Loss_Validation:  [[ 1418.61249951]]\n",
      "Loop  4061 :    Loss_Train:  [[ 4823.01034854]]    Loss_Validation:  [[ 1418.61404643]]\n",
      "Loop  4062 :    Loss_Train:  [[ 4823.00954092]]    Loss_Validation:  [[ 1418.61559228]]\n",
      "Loop  4063 :    Loss_Train:  [[ 4823.00873462]]    Loss_Validation:  [[ 1418.61713703]]\n",
      "Loop  4064 :    Loss_Train:  [[ 4823.00792965]]    Loss_Validation:  [[ 1418.6186807]]\n",
      "Loop  4065 :    Loss_Train:  [[ 4823.00712601]]    Loss_Validation:  [[ 1418.62022328]]\n",
      "Loop  4066 :    Loss_Train:  [[ 4823.0063237]]    Loss_Validation:  [[ 1418.62176478]]\n",
      "Loop  4067 :    Loss_Train:  [[ 4823.0055227]]    Loss_Validation:  [[ 1418.62330519]]\n",
      "Loop  4068 :    Loss_Train:  [[ 4823.00472303]]    Loss_Validation:  [[ 1418.62484452]]\n",
      "Loop  4069 :    Loss_Train:  [[ 4823.00392468]]    Loss_Validation:  [[ 1418.62638277]]\n",
      "Loop  4070 :    Loss_Train:  [[ 4823.00312764]]    Loss_Validation:  [[ 1418.62791994]]\n",
      "Loop  4071 :    Loss_Train:  [[ 4823.00233192]]    Loss_Validation:  [[ 1418.62945603]]\n",
      "Loop  4072 :    Loss_Train:  [[ 4823.00153751]]    Loss_Validation:  [[ 1418.63099103]]\n",
      "Loop  4073 :    Loss_Train:  [[ 4823.00074441]]    Loss_Validation:  [[ 1418.63252496]]\n",
      "Loop  4074 :    Loss_Train:  [[ 4822.99995262]]    Loss_Validation:  [[ 1418.63405781]]\n",
      "Loop  4075 :    Loss_Train:  [[ 4822.99916213]]    Loss_Validation:  [[ 1418.63558959]]\n",
      "Loop  4076 :    Loss_Train:  [[ 4822.99837295]]    Loss_Validation:  [[ 1418.63712028]]\n",
      "Loop  4077 :    Loss_Train:  [[ 4822.99758507]]    Loss_Validation:  [[ 1418.6386499]]\n",
      "Loop  4078 :    Loss_Train:  [[ 4822.99679848]]    Loss_Validation:  [[ 1418.64017844]]\n",
      "Loop  4079 :    Loss_Train:  [[ 4822.9960132]]    Loss_Validation:  [[ 1418.64170592]]\n",
      "Loop  4080 :    Loss_Train:  [[ 4822.9952292]]    Loss_Validation:  [[ 1418.64323231]]\n",
      "Loop  4081 :    Loss_Train:  [[ 4822.9944465]]    Loss_Validation:  [[ 1418.64475764]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  4082 :    Loss_Train:  [[ 4822.9936651]]    Loss_Validation:  [[ 1418.64628189]]\n",
      "Loop  4083 :    Loss_Train:  [[ 4822.99288497]]    Loss_Validation:  [[ 1418.64780507]]\n",
      "Loop  4084 :    Loss_Train:  [[ 4822.99210614]]    Loss_Validation:  [[ 1418.64932718]]\n",
      "Loop  4085 :    Loss_Train:  [[ 4822.99132859]]    Loss_Validation:  [[ 1418.65084822]]\n",
      "Loop  4086 :    Loss_Train:  [[ 4822.99055232]]    Loss_Validation:  [[ 1418.65236819]]\n",
      "Loop  4087 :    Loss_Train:  [[ 4822.98977732]]    Loss_Validation:  [[ 1418.65388709]]\n",
      "Loop  4088 :    Loss_Train:  [[ 4822.98900361]]    Loss_Validation:  [[ 1418.65540493]]\n",
      "Loop  4089 :    Loss_Train:  [[ 4822.98823117]]    Loss_Validation:  [[ 1418.6569217]]\n",
      "Loop  4090 :    Loss_Train:  [[ 4822.98746001]]    Loss_Validation:  [[ 1418.6584374]]\n",
      "Loop  4091 :    Loss_Train:  [[ 4822.98669011]]    Loss_Validation:  [[ 1418.65995204]]\n",
      "Loop  4092 :    Loss_Train:  [[ 4822.98592149]]    Loss_Validation:  [[ 1418.66146561]]\n",
      "Loop  4093 :    Loss_Train:  [[ 4822.98515413]]    Loss_Validation:  [[ 1418.66297812]]\n",
      "Loop  4094 :    Loss_Train:  [[ 4822.98438803]]    Loss_Validation:  [[ 1418.66448957]]\n",
      "Loop  4095 :    Loss_Train:  [[ 4822.9836232]]    Loss_Validation:  [[ 1418.66599995]]\n",
      "Loop  4096 :    Loss_Train:  [[ 4822.98285963]]    Loss_Validation:  [[ 1418.66750927]]\n",
      "Loop  4097 :    Loss_Train:  [[ 4822.98209732]]    Loss_Validation:  [[ 1418.66901754]]\n",
      "Loop  4098 :    Loss_Train:  [[ 4822.98133626]]    Loss_Validation:  [[ 1418.67052474]]\n",
      "Loop  4099 :    Loss_Train:  [[ 4822.98057646]]    Loss_Validation:  [[ 1418.67203089]]\n",
      "Loop  4100 :    Loss_Train:  [[ 4822.9798179]]    Loss_Validation:  [[ 1418.67353597]]\n",
      "Loop  4101 :    Loss_Train:  [[ 4822.9790606]]    Loss_Validation:  [[ 1418.67504]]\n",
      "Loop  4102 :    Loss_Train:  [[ 4822.97830455]]    Loss_Validation:  [[ 1418.67654297]]\n",
      "Loop  4103 :    Loss_Train:  [[ 4822.97754974]]    Loss_Validation:  [[ 1418.67804489]]\n",
      "Loop  4104 :    Loss_Train:  [[ 4822.97679618]]    Loss_Validation:  [[ 1418.67954575]]\n",
      "Loop  4105 :    Loss_Train:  [[ 4822.97604385]]    Loss_Validation:  [[ 1418.68104556]]\n",
      "Loop  4106 :    Loss_Train:  [[ 4822.97529277]]    Loss_Validation:  [[ 1418.68254431]]\n",
      "Loop  4107 :    Loss_Train:  [[ 4822.97454293]]    Loss_Validation:  [[ 1418.68404201]]\n",
      "Loop  4108 :    Loss_Train:  [[ 4822.97379431]]    Loss_Validation:  [[ 1418.68553866]]\n",
      "Loop  4109 :    Loss_Train:  [[ 4822.97304694]]    Loss_Validation:  [[ 1418.68703426]]\n",
      "Loop  4110 :    Loss_Train:  [[ 4822.97230079]]    Loss_Validation:  [[ 1418.6885288]]\n",
      "Loop  4111 :    Loss_Train:  [[ 4822.97155587]]    Loss_Validation:  [[ 1418.6900223]]\n",
      "Loop  4112 :    Loss_Train:  [[ 4822.97081218]]    Loss_Validation:  [[ 1418.69151474]]\n",
      "Loop  4113 :    Loss_Train:  [[ 4822.97006972]]    Loss_Validation:  [[ 1418.69300614]]\n",
      "Loop  4114 :    Loss_Train:  [[ 4822.96932848]]    Loss_Validation:  [[ 1418.69449649]]\n",
      "Loop  4115 :    Loss_Train:  [[ 4822.96858845]]    Loss_Validation:  [[ 1418.6959858]]\n",
      "Loop  4116 :    Loss_Train:  [[ 4822.96784965]]    Loss_Validation:  [[ 1418.69747406]]\n",
      "Loop  4117 :    Loss_Train:  [[ 4822.96711207]]    Loss_Validation:  [[ 1418.69896127]]\n",
      "Loop  4118 :    Loss_Train:  [[ 4822.9663757]]    Loss_Validation:  [[ 1418.70044744]]\n",
      "Loop  4119 :    Loss_Train:  [[ 4822.96564054]]    Loss_Validation:  [[ 1418.70193256]]\n",
      "Loop  4120 :    Loss_Train:  [[ 4822.96490659]]    Loss_Validation:  [[ 1418.70341665]]\n",
      "Loop  4121 :    Loss_Train:  [[ 4822.96417385]]    Loss_Validation:  [[ 1418.70489968]]\n",
      "Loop  4122 :    Loss_Train:  [[ 4822.96344232]]    Loss_Validation:  [[ 1418.70638168]]\n",
      "Loop  4123 :    Loss_Train:  [[ 4822.96271199]]    Loss_Validation:  [[ 1418.70786264]]\n",
      "Loop  4124 :    Loss_Train:  [[ 4822.96198287]]    Loss_Validation:  [[ 1418.70934256]]\n",
      "Loop  4125 :    Loss_Train:  [[ 4822.96125494]]    Loss_Validation:  [[ 1418.71082143]]\n",
      "Loop  4126 :    Loss_Train:  [[ 4822.96052822]]    Loss_Validation:  [[ 1418.71229927]]\n",
      "Loop  4127 :    Loss_Train:  [[ 4822.95980269]]    Loss_Validation:  [[ 1418.71377607]]\n",
      "Loop  4128 :    Loss_Train:  [[ 4822.95907836]]    Loss_Validation:  [[ 1418.71525184]]\n",
      "Loop  4129 :    Loss_Train:  [[ 4822.95835522]]    Loss_Validation:  [[ 1418.71672657]]\n",
      "Loop  4130 :    Loss_Train:  [[ 4822.95763327]]    Loss_Validation:  [[ 1418.71820026]]\n",
      "Loop  4131 :    Loss_Train:  [[ 4822.9569125]]    Loss_Validation:  [[ 1418.71967292]]\n",
      "Loop  4132 :    Loss_Train:  [[ 4822.95619293]]    Loss_Validation:  [[ 1418.72114454]]\n",
      "Loop  4133 :    Loss_Train:  [[ 4822.95547454]]    Loss_Validation:  [[ 1418.72261513]]\n",
      "Loop  4134 :    Loss_Train:  [[ 4822.95475733]]    Loss_Validation:  [[ 1418.72408469]]\n",
      "Loop  4135 :    Loss_Train:  [[ 4822.9540413]]    Loss_Validation:  [[ 1418.72555321]]\n",
      "Loop  4136 :    Loss_Train:  [[ 4822.95332646]]    Loss_Validation:  [[ 1418.72702071]]\n",
      "Loop  4137 :    Loss_Train:  [[ 4822.95261279]]    Loss_Validation:  [[ 1418.72848717]]\n",
      "Loop  4138 :    Loss_Train:  [[ 4822.95190029]]    Loss_Validation:  [[ 1418.7299526]]\n",
      "Loop  4139 :    Loss_Train:  [[ 4822.95118897]]    Loss_Validation:  [[ 1418.73141701]]\n",
      "Loop  4140 :    Loss_Train:  [[ 4822.95047881]]    Loss_Validation:  [[ 1418.73288039]]\n",
      "Loop  4141 :    Loss_Train:  [[ 4822.94976983]]    Loss_Validation:  [[ 1418.73434274]]\n",
      "Loop  4142 :    Loss_Train:  [[ 4822.94906201]]    Loss_Validation:  [[ 1418.73580406]]\n",
      "Loop  4143 :    Loss_Train:  [[ 4822.94835536]]    Loss_Validation:  [[ 1418.73726436]]\n",
      "Loop  4144 :    Loss_Train:  [[ 4822.94764987]]    Loss_Validation:  [[ 1418.73872363]]\n",
      "Loop  4145 :    Loss_Train:  [[ 4822.94694555]]    Loss_Validation:  [[ 1418.74018188]]\n",
      "Loop  4146 :    Loss_Train:  [[ 4822.94624238]]    Loss_Validation:  [[ 1418.7416391]]\n",
      "Loop  4147 :    Loss_Train:  [[ 4822.94554037]]    Loss_Validation:  [[ 1418.7430953]]\n",
      "Loop  4148 :    Loss_Train:  [[ 4822.94483951]]    Loss_Validation:  [[ 1418.74455048]]\n",
      "Loop  4149 :    Loss_Train:  [[ 4822.94413981]]    Loss_Validation:  [[ 1418.74600464]]\n",
      "Loop  4150 :    Loss_Train:  [[ 4822.94344126]]    Loss_Validation:  [[ 1418.74745778]]\n",
      "Loop  4151 :    Loss_Train:  [[ 4822.94274386]]    Loss_Validation:  [[ 1418.74890989]]\n",
      "Loop  4152 :    Loss_Train:  [[ 4822.94204761]]    Loss_Validation:  [[ 1418.75036099]]\n",
      "Loop  4153 :    Loss_Train:  [[ 4822.9413525]]    Loss_Validation:  [[ 1418.75181107]]\n",
      "Loop  4154 :    Loss_Train:  [[ 4822.94065854]]    Loss_Validation:  [[ 1418.75326013]]\n",
      "Loop  4155 :    Loss_Train:  [[ 4822.93996572]]    Loss_Validation:  [[ 1418.75470818]]\n",
      "Loop  4156 :    Loss_Train:  [[ 4822.93927404]]    Loss_Validation:  [[ 1418.7561552]]\n",
      "Loop  4157 :    Loss_Train:  [[ 4822.9385835]]    Loss_Validation:  [[ 1418.75760121]]\n",
      "Loop  4158 :    Loss_Train:  [[ 4822.93789409]]    Loss_Validation:  [[ 1418.75904621]]\n",
      "Loop  4159 :    Loss_Train:  [[ 4822.93720582]]    Loss_Validation:  [[ 1418.76049019]]\n",
      "Loop  4160 :    Loss_Train:  [[ 4822.93651868]]    Loss_Validation:  [[ 1418.76193316]]\n",
      "Loop  4161 :    Loss_Train:  [[ 4822.93583267]]    Loss_Validation:  [[ 1418.76337512]]\n",
      "Loop  4162 :    Loss_Train:  [[ 4822.93514779]]    Loss_Validation:  [[ 1418.76481607]]\n",
      "Loop  4163 :    Loss_Train:  [[ 4822.93446403]]    Loss_Validation:  [[ 1418.766256]]\n",
      "Loop  4164 :    Loss_Train:  [[ 4822.9337814]]    Loss_Validation:  [[ 1418.76769492]]\n",
      "Loop  4165 :    Loss_Train:  [[ 4822.9330999]]    Loss_Validation:  [[ 1418.76913283]]\n",
      "Loop  4166 :    Loss_Train:  [[ 4822.93241951]]    Loss_Validation:  [[ 1418.77056974]]\n",
      "Loop  4167 :    Loss_Train:  [[ 4822.93174025]]    Loss_Validation:  [[ 1418.77200563]]\n",
      "Loop  4168 :    Loss_Train:  [[ 4822.9310621]]    Loss_Validation:  [[ 1418.77344052]]\n",
      "Loop  4169 :    Loss_Train:  [[ 4822.93038507]]    Loss_Validation:  [[ 1418.7748744]]\n",
      "Loop  4170 :    Loss_Train:  [[ 4822.92970915]]    Loss_Validation:  [[ 1418.77630728]]\n",
      "Loop  4171 :    Loss_Train:  [[ 4822.92903434]]    Loss_Validation:  [[ 1418.77773915]]\n",
      "Loop  4172 :    Loss_Train:  [[ 4822.92836065]]    Loss_Validation:  [[ 1418.77917001]]\n",
      "Loop  4173 :    Loss_Train:  [[ 4822.92768806]]    Loss_Validation:  [[ 1418.78059987]]\n",
      "Loop  4174 :    Loss_Train:  [[ 4822.92701658]]    Loss_Validation:  [[ 1418.78202873]]\n",
      "Loop  4175 :    Loss_Train:  [[ 4822.9263462]]    Loss_Validation:  [[ 1418.78345658]]\n",
      "Loop  4176 :    Loss_Train:  [[ 4822.92567692]]    Loss_Validation:  [[ 1418.78488344]]\n",
      "Loop  4177 :    Loss_Train:  [[ 4822.92500875]]    Loss_Validation:  [[ 1418.78630929]]\n",
      "Loop  4178 :    Loss_Train:  [[ 4822.92434168]]    Loss_Validation:  [[ 1418.78773414]]\n",
      "Loop  4179 :    Loss_Train:  [[ 4822.9236757]]    Loss_Validation:  [[ 1418.78915799]]\n",
      "Loop  4180 :    Loss_Train:  [[ 4822.92301081]]    Loss_Validation:  [[ 1418.79058084]]\n",
      "Loop  4181 :    Loss_Train:  [[ 4822.92234702]]    Loss_Validation:  [[ 1418.7920027]]\n",
      "Loop  4182 :    Loss_Train:  [[ 4822.92168433]]    Loss_Validation:  [[ 1418.79342355]]\n",
      "Loop  4183 :    Loss_Train:  [[ 4822.92102272]]    Loss_Validation:  [[ 1418.79484341]]\n",
      "Loop  4184 :    Loss_Train:  [[ 4822.9203622]]    Loss_Validation:  [[ 1418.79626228]]\n",
      "Loop  4185 :    Loss_Train:  [[ 4822.91970276]]    Loss_Validation:  [[ 1418.79768014]]\n",
      "Loop  4186 :    Loss_Train:  [[ 4822.91904441]]    Loss_Validation:  [[ 1418.79909702]]\n",
      "Loop  4187 :    Loss_Train:  [[ 4822.91838715]]    Loss_Validation:  [[ 1418.8005129]]\n",
      "Loop  4188 :    Loss_Train:  [[ 4822.91773096]]    Loss_Validation:  [[ 1418.80192778]]\n",
      "Loop  4189 :    Loss_Train:  [[ 4822.91707585]]    Loss_Validation:  [[ 1418.80334168]]\n",
      "Loop  4190 :    Loss_Train:  [[ 4822.91642182]]    Loss_Validation:  [[ 1418.80475458]]\n",
      "Loop  4191 :    Loss_Train:  [[ 4822.91576887]]    Loss_Validation:  [[ 1418.80616649]]\n",
      "Loop  4192 :    Loss_Train:  [[ 4822.91511699]]    Loss_Validation:  [[ 1418.80757741]]\n",
      "Loop  4193 :    Loss_Train:  [[ 4822.91446618]]    Loss_Validation:  [[ 1418.80898734]]\n",
      "Loop  4194 :    Loss_Train:  [[ 4822.91381644]]    Loss_Validation:  [[ 1418.81039628]]\n",
      "Loop  4195 :    Loss_Train:  [[ 4822.91316777]]    Loss_Validation:  [[ 1418.81180423]]\n",
      "Loop  4196 :    Loss_Train:  [[ 4822.91252016]]    Loss_Validation:  [[ 1418.8132112]]\n",
      "Loop  4197 :    Loss_Train:  [[ 4822.91187362]]    Loss_Validation:  [[ 1418.81461718]]\n",
      "Loop  4198 :    Loss_Train:  [[ 4822.91122815]]    Loss_Validation:  [[ 1418.81602217]]\n",
      "Loop  4199 :    Loss_Train:  [[ 4822.91058373]]    Loss_Validation:  [[ 1418.81742618]]\n",
      "Loop  4200 :    Loss_Train:  [[ 4822.90994037]]    Loss_Validation:  [[ 1418.8188292]]\n",
      "Loop  4201 :    Loss_Train:  [[ 4822.90929807]]    Loss_Validation:  [[ 1418.82023124]]\n",
      "Loop  4202 :    Loss_Train:  [[ 4822.90865683]]    Loss_Validation:  [[ 1418.82163229]]\n",
      "Loop  4203 :    Loss_Train:  [[ 4822.90801664]]    Loss_Validation:  [[ 1418.82303236]]\n",
      "Loop  4204 :    Loss_Train:  [[ 4822.9073775]]    Loss_Validation:  [[ 1418.82443145]]\n",
      "Loop  4205 :    Loss_Train:  [[ 4822.90673942]]    Loss_Validation:  [[ 1418.82582956]]\n",
      "Loop  4206 :    Loss_Train:  [[ 4822.90610238]]    Loss_Validation:  [[ 1418.82722669]]\n",
      "Loop  4207 :    Loss_Train:  [[ 4822.90546639]]    Loss_Validation:  [[ 1418.82862284]]\n",
      "Loop  4208 :    Loss_Train:  [[ 4822.90483144]]    Loss_Validation:  [[ 1418.83001801]]\n",
      "Loop  4209 :    Loss_Train:  [[ 4822.90419754]]    Loss_Validation:  [[ 1418.8314122]]\n",
      "Loop  4210 :    Loss_Train:  [[ 4822.90356468]]    Loss_Validation:  [[ 1418.83280541]]\n",
      "Loop  4211 :    Loss_Train:  [[ 4822.90293286]]    Loss_Validation:  [[ 1418.83419765]]\n",
      "Loop  4212 :    Loss_Train:  [[ 4822.90230208]]    Loss_Validation:  [[ 1418.83558891]]\n",
      "Loop  4213 :    Loss_Train:  [[ 4822.90167233]]    Loss_Validation:  [[ 1418.83697919]]\n",
      "Loop  4214 :    Loss_Train:  [[ 4822.90104362]]    Loss_Validation:  [[ 1418.8383685]]\n",
      "Loop  4215 :    Loss_Train:  [[ 4822.90041594]]    Loss_Validation:  [[ 1418.83975684]]\n",
      "Loop  4216 :    Loss_Train:  [[ 4822.8997893]]    Loss_Validation:  [[ 1418.8411442]]\n",
      "Loop  4217 :    Loss_Train:  [[ 4822.89916368]]    Loss_Validation:  [[ 1418.84253059]]\n",
      "Loop  4218 :    Loss_Train:  [[ 4822.89853909]]    Loss_Validation:  [[ 1418.84391601]]\n",
      "Loop  4219 :    Loss_Train:  [[ 4822.89791553]]    Loss_Validation:  [[ 1418.84530045]]\n",
      "Loop  4220 :    Loss_Train:  [[ 4822.897293]]    Loss_Validation:  [[ 1418.84668392]]\n",
      "Loop  4221 :    Loss_Train:  [[ 4822.89667148]]    Loss_Validation:  [[ 1418.84806643]]\n",
      "Loop  4222 :    Loss_Train:  [[ 4822.89605099]]    Loss_Validation:  [[ 1418.84944796]]\n",
      "Loop  4223 :    Loss_Train:  [[ 4822.89543151]]    Loss_Validation:  [[ 1418.85082853]]\n",
      "Loop  4224 :    Loss_Train:  [[ 4822.89481306]]    Loss_Validation:  [[ 1418.85220813]]\n",
      "Loop  4225 :    Loss_Train:  [[ 4822.89419562]]    Loss_Validation:  [[ 1418.85358676]]\n",
      "Loop  4226 :    Loss_Train:  [[ 4822.89357919]]    Loss_Validation:  [[ 1418.85496442]]\n",
      "Loop  4227 :    Loss_Train:  [[ 4822.89296378]]    Loss_Validation:  [[ 1418.85634112]]\n",
      "Loop  4228 :    Loss_Train:  [[ 4822.89234938]]    Loss_Validation:  [[ 1418.85771685]]\n",
      "Loop  4229 :    Loss_Train:  [[ 4822.89173599]]    Loss_Validation:  [[ 1418.85909162]]\n",
      "Loop  4230 :    Loss_Train:  [[ 4822.8911236]]    Loss_Validation:  [[ 1418.86046543]]\n",
      "Loop  4231 :    Loss_Train:  [[ 4822.89051222]]    Loss_Validation:  [[ 1418.86183827]]\n",
      "Loop  4232 :    Loss_Train:  [[ 4822.88990185]]    Loss_Validation:  [[ 1418.86321015]]\n",
      "Loop  4233 :    Loss_Train:  [[ 4822.88929248]]    Loss_Validation:  [[ 1418.86458107]]\n",
      "Loop  4234 :    Loss_Train:  [[ 4822.8886841]]    Loss_Validation:  [[ 1418.86595102]]\n",
      "Loop  4235 :    Loss_Train:  [[ 4822.88807673]]    Loss_Validation:  [[ 1418.86732002]]\n",
      "Loop  4236 :    Loss_Train:  [[ 4822.88747036]]    Loss_Validation:  [[ 1418.86868805]]\n",
      "Loop  4237 :    Loss_Train:  [[ 4822.88686498]]    Loss_Validation:  [[ 1418.87005513]]\n",
      "Loop  4238 :    Loss_Train:  [[ 4822.8862606]]    Loss_Validation:  [[ 1418.87142125]]\n",
      "Loop  4239 :    Loss_Train:  [[ 4822.88565721]]    Loss_Validation:  [[ 1418.87278641]]\n",
      "Loop  4240 :    Loss_Train:  [[ 4822.8850548]]    Loss_Validation:  [[ 1418.87415061]]\n",
      "Loop  4241 :    Loss_Train:  [[ 4822.88445339]]    Loss_Validation:  [[ 1418.87551386]]\n",
      "Loop  4242 :    Loss_Train:  [[ 4822.88385297]]    Loss_Validation:  [[ 1418.87687615]]\n",
      "Loop  4243 :    Loss_Train:  [[ 4822.88325353]]    Loss_Validation:  [[ 1418.87823749]]\n",
      "Loop  4244 :    Loss_Train:  [[ 4822.88265508]]    Loss_Validation:  [[ 1418.87959787]]\n",
      "Loop  4245 :    Loss_Train:  [[ 4822.88205761]]    Loss_Validation:  [[ 1418.8809573]]\n",
      "Loop  4246 :    Loss_Train:  [[ 4822.88146112]]    Loss_Validation:  [[ 1418.88231578]]\n",
      "Loop  4247 :    Loss_Train:  [[ 4822.88086561]]    Loss_Validation:  [[ 1418.88367331]]\n",
      "Loop  4248 :    Loss_Train:  [[ 4822.88027108]]    Loss_Validation:  [[ 1418.88502988]]\n",
      "Loop  4249 :    Loss_Train:  [[ 4822.87967753]]    Loss_Validation:  [[ 1418.8863855]]\n",
      "Loop  4250 :    Loss_Train:  [[ 4822.87908494]]    Loss_Validation:  [[ 1418.88774017]]\n",
      "Loop  4251 :    Loss_Train:  [[ 4822.87849334]]    Loss_Validation:  [[ 1418.88909389]]\n",
      "Loop  4252 :    Loss_Train:  [[ 4822.8779027]]    Loss_Validation:  [[ 1418.89044667]]\n",
      "Loop  4253 :    Loss_Train:  [[ 4822.87731303]]    Loss_Validation:  [[ 1418.89179849]]\n",
      "Loop  4254 :    Loss_Train:  [[ 4822.87672434]]    Loss_Validation:  [[ 1418.89314937]]\n",
      "Loop  4255 :    Loss_Train:  [[ 4822.8761366]]    Loss_Validation:  [[ 1418.8944993]]\n",
      "Loop  4256 :    Loss_Train:  [[ 4822.87554984]]    Loss_Validation:  [[ 1418.89584829]]\n",
      "Loop  4257 :    Loss_Train:  [[ 4822.87496403]]    Loss_Validation:  [[ 1418.89719633]]\n",
      "Loop  4258 :    Loss_Train:  [[ 4822.87437919]]    Loss_Validation:  [[ 1418.89854342]]\n",
      "Loop  4259 :    Loss_Train:  [[ 4822.87379531]]    Loss_Validation:  [[ 1418.89988957]]\n",
      "Loop  4260 :    Loss_Train:  [[ 4822.87321239]]    Loss_Validation:  [[ 1418.90123478]]\n",
      "Loop  4261 :    Loss_Train:  [[ 4822.87263042]]    Loss_Validation:  [[ 1418.90257905]]\n",
      "Loop  4262 :    Loss_Train:  [[ 4822.87204941]]    Loss_Validation:  [[ 1418.90392237]]\n",
      "Loop  4263 :    Loss_Train:  [[ 4822.87146935]]    Loss_Validation:  [[ 1418.90526475]]\n",
      "Loop  4264 :    Loss_Train:  [[ 4822.87089024]]    Loss_Validation:  [[ 1418.90660619]]\n",
      "Loop  4265 :    Loss_Train:  [[ 4822.87031209]]    Loss_Validation:  [[ 1418.90794669]]\n",
      "Loop  4266 :    Loss_Train:  [[ 4822.86973488]]    Loss_Validation:  [[ 1418.90928625]]\n",
      "Loop  4267 :    Loss_Train:  [[ 4822.86915863]]    Loss_Validation:  [[ 1418.91062488]]\n",
      "Loop  4268 :    Loss_Train:  [[ 4822.86858331]]    Loss_Validation:  [[ 1418.91196256]]\n",
      "Loop  4269 :    Loss_Train:  [[ 4822.86800895]]    Loss_Validation:  [[ 1418.91329931]]\n",
      "Loop  4270 :    Loss_Train:  [[ 4822.86743552]]    Loss_Validation:  [[ 1418.91463512]]\n",
      "Loop  4271 :    Loss_Train:  [[ 4822.86686304]]    Loss_Validation:  [[ 1418.91596999]]\n",
      "Loop  4272 :    Loss_Train:  [[ 4822.86629149]]    Loss_Validation:  [[ 1418.91730393]]\n",
      "Loop  4273 :    Loss_Train:  [[ 4822.86572088]]    Loss_Validation:  [[ 1418.91863694]]\n",
      "Loop  4274 :    Loss_Train:  [[ 4822.86515121]]    Loss_Validation:  [[ 1418.91996901]]\n",
      "Loop  4275 :    Loss_Train:  [[ 4822.86458248]]    Loss_Validation:  [[ 1418.92130015]]\n",
      "Loop  4276 :    Loss_Train:  [[ 4822.86401467]]    Loss_Validation:  [[ 1418.92263035]]\n",
      "Loop  4277 :    Loss_Train:  [[ 4822.8634478]]    Loss_Validation:  [[ 1418.92395962]]\n",
      "Loop  4278 :    Loss_Train:  [[ 4822.86288186]]    Loss_Validation:  [[ 1418.92528796]]\n",
      "Loop  4279 :    Loss_Train:  [[ 4822.86231685]]    Loss_Validation:  [[ 1418.92661537]]\n",
      "Loop  4280 :    Loss_Train:  [[ 4822.86175277]]    Loss_Validation:  [[ 1418.92794185]]\n",
      "Loop  4281 :    Loss_Train:  [[ 4822.86118961]]    Loss_Validation:  [[ 1418.92926741]]\n",
      "Loop  4282 :    Loss_Train:  [[ 4822.86062737]]    Loss_Validation:  [[ 1418.93059203]]\n",
      "Loop  4283 :    Loss_Train:  [[ 4822.86006606]]    Loss_Validation:  [[ 1418.93191572]]\n",
      "Loop  4284 :    Loss_Train:  [[ 4822.85950567]]    Loss_Validation:  [[ 1418.93323849]]\n",
      "Loop  4285 :    Loss_Train:  [[ 4822.8589462]]    Loss_Validation:  [[ 1418.93456033]]\n",
      "Loop  4286 :    Loss_Train:  [[ 4822.85838764]]    Loss_Validation:  [[ 1418.93588124]]\n",
      "Loop  4287 :    Loss_Train:  [[ 4822.85783001]]    Loss_Validation:  [[ 1418.93720123]]\n",
      "Loop  4288 :    Loss_Train:  [[ 4822.85727328]]    Loss_Validation:  [[ 1418.9385203]]\n",
      "Loop  4289 :    Loss_Train:  [[ 4822.85671747]]    Loss_Validation:  [[ 1418.93983844]]\n",
      "Loop  4290 :    Loss_Train:  [[ 4822.85616258]]    Loss_Validation:  [[ 1418.94115565]]\n",
      "Loop  4291 :    Loss_Train:  [[ 4822.85560859]]    Loss_Validation:  [[ 1418.94247195]]\n",
      "Loop  4292 :    Loss_Train:  [[ 4822.85505551]]    Loss_Validation:  [[ 1418.94378732]]\n",
      "Loop  4293 :    Loss_Train:  [[ 4822.85450334]]    Loss_Validation:  [[ 1418.94510177]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  4294 :    Loss_Train:  [[ 4822.85395207]]    Loss_Validation:  [[ 1418.9464153]]\n",
      "Loop  4295 :    Loss_Train:  [[ 4822.85340171]]    Loss_Validation:  [[ 1418.94772791]]\n",
      "Loop  4296 :    Loss_Train:  [[ 4822.85285225]]    Loss_Validation:  [[ 1418.9490396]]\n",
      "Loop  4297 :    Loss_Train:  [[ 4822.8523037]]    Loss_Validation:  [[ 1418.95035037]]\n",
      "Loop  4298 :    Loss_Train:  [[ 4822.85175604]]    Loss_Validation:  [[ 1418.95166022]]\n",
      "Loop  4299 :    Loss_Train:  [[ 4822.85120928]]    Loss_Validation:  [[ 1418.95296916]]\n",
      "Loop  4300 :    Loss_Train:  [[ 4822.85066342]]    Loss_Validation:  [[ 1418.95427718]]\n",
      "Loop  4301 :    Loss_Train:  [[ 4822.85011845]]    Loss_Validation:  [[ 1418.95558428]]\n",
      "Loop  4302 :    Loss_Train:  [[ 4822.84957438]]    Loss_Validation:  [[ 1418.95689046]]\n",
      "Loop  4303 :    Loss_Train:  [[ 4822.84903119]]    Loss_Validation:  [[ 1418.95819574]]\n",
      "Loop  4304 :    Loss_Train:  [[ 4822.8484889]]    Loss_Validation:  [[ 1418.95950009]]\n",
      "Loop  4305 :    Loss_Train:  [[ 4822.8479475]]    Loss_Validation:  [[ 1418.96080354]]\n",
      "Loop  4306 :    Loss_Train:  [[ 4822.84740699]]    Loss_Validation:  [[ 1418.96210607]]\n",
      "Loop  4307 :    Loss_Train:  [[ 4822.84686736]]    Loss_Validation:  [[ 1418.96340769]]\n",
      "Loop  4308 :    Loss_Train:  [[ 4822.84632862]]    Loss_Validation:  [[ 1418.9647084]]\n",
      "Loop  4309 :    Loss_Train:  [[ 4822.84579076]]    Loss_Validation:  [[ 1418.96600819]]\n",
      "Loop  4310 :    Loss_Train:  [[ 4822.84525379]]    Loss_Validation:  [[ 1418.96730708]]\n",
      "Loop  4311 :    Loss_Train:  [[ 4822.84471769]]    Loss_Validation:  [[ 1418.96860505]]\n",
      "Loop  4312 :    Loss_Train:  [[ 4822.84418247]]    Loss_Validation:  [[ 1418.96990212]]\n",
      "Loop  4313 :    Loss_Train:  [[ 4822.84364813]]    Loss_Validation:  [[ 1418.97119828]]\n",
      "Loop  4314 :    Loss_Train:  [[ 4822.84311467]]    Loss_Validation:  [[ 1418.97249353]]\n",
      "Loop  4315 :    Loss_Train:  [[ 4822.84258208]]    Loss_Validation:  [[ 1418.97378787]]\n",
      "Loop  4316 :    Loss_Train:  [[ 4822.84205037]]    Loss_Validation:  [[ 1418.97508131]]\n",
      "Loop  4317 :    Loss_Train:  [[ 4822.84151952]]    Loss_Validation:  [[ 1418.97637384]]\n",
      "Loop  4318 :    Loss_Train:  [[ 4822.84098955]]    Loss_Validation:  [[ 1418.97766547]]\n",
      "Loop  4319 :    Loss_Train:  [[ 4822.84046045]]    Loss_Validation:  [[ 1418.97895619]]\n",
      "Loop  4320 :    Loss_Train:  [[ 4822.83993221]]    Loss_Validation:  [[ 1418.98024601]]\n",
      "Loop  4321 :    Loss_Train:  [[ 4822.83940484]]    Loss_Validation:  [[ 1418.98153492]]\n",
      "Loop  4322 :    Loss_Train:  [[ 4822.83887833]]    Loss_Validation:  [[ 1418.98282293]]\n",
      "Loop  4323 :    Loss_Train:  [[ 4822.83835269]]    Loss_Validation:  [[ 1418.98411004]]\n",
      "Loop  4324 :    Loss_Train:  [[ 4822.83782791]]    Loss_Validation:  [[ 1418.98539625]]\n",
      "Loop  4325 :    Loss_Train:  [[ 4822.83730399]]    Loss_Validation:  [[ 1418.98668156]]\n",
      "Loop  4326 :    Loss_Train:  [[ 4822.83678093]]    Loss_Validation:  [[ 1418.98796597]]\n",
      "Loop  4327 :    Loss_Train:  [[ 4822.83625872]]    Loss_Validation:  [[ 1418.98924948]]\n",
      "Loop  4328 :    Loss_Train:  [[ 4822.83573737]]    Loss_Validation:  [[ 1418.99053209]]\n",
      "Loop  4329 :    Loss_Train:  [[ 4822.83521688]]    Loss_Validation:  [[ 1418.9918138]]\n",
      "Loop  4330 :    Loss_Train:  [[ 4822.83469724]]    Loss_Validation:  [[ 1418.99309461]]\n",
      "Loop  4331 :    Loss_Train:  [[ 4822.83417845]]    Loss_Validation:  [[ 1418.99437453]]\n",
      "Loop  4332 :    Loss_Train:  [[ 4822.83366051]]    Loss_Validation:  [[ 1418.99565355]]\n",
      "Loop  4333 :    Loss_Train:  [[ 4822.83314342]]    Loss_Validation:  [[ 1418.99693168]]\n",
      "Loop  4334 :    Loss_Train:  [[ 4822.83262717]]    Loss_Validation:  [[ 1418.99820891]]\n",
      "Loop  4335 :    Loss_Train:  [[ 4822.83211178]]    Loss_Validation:  [[ 1418.99948524]]\n",
      "Loop  4336 :    Loss_Train:  [[ 4822.83159722]]    Loss_Validation:  [[ 1419.00076068]]\n",
      "Loop  4337 :    Loss_Train:  [[ 4822.83108352]]    Loss_Validation:  [[ 1419.00203523]]\n",
      "Loop  4338 :    Loss_Train:  [[ 4822.83057065]]    Loss_Validation:  [[ 1419.00330889]]\n",
      "Loop  4339 :    Loss_Train:  [[ 4822.83005862]]    Loss_Validation:  [[ 1419.00458166]]\n",
      "Loop  4340 :    Loss_Train:  [[ 4822.82954743]]    Loss_Validation:  [[ 1419.00585353]]\n",
      "Loop  4341 :    Loss_Train:  [[ 4822.82903708]]    Loss_Validation:  [[ 1419.00712451]]\n",
      "Loop  4342 :    Loss_Train:  [[ 4822.82852757]]    Loss_Validation:  [[ 1419.00839461]]\n",
      "Loop  4343 :    Loss_Train:  [[ 4822.82801889]]    Loss_Validation:  [[ 1419.00966381]]\n",
      "Loop  4344 :    Loss_Train:  [[ 4822.82751105]]    Loss_Validation:  [[ 1419.01093213]]\n",
      "Loop  4345 :    Loss_Train:  [[ 4822.82700403]]    Loss_Validation:  [[ 1419.01219956]]\n",
      "Loop  4346 :    Loss_Train:  [[ 4822.82649785]]    Loss_Validation:  [[ 1419.0134661]]\n",
      "Loop  4347 :    Loss_Train:  [[ 4822.8259925]]    Loss_Validation:  [[ 1419.01473175]]\n",
      "Loop  4348 :    Loss_Train:  [[ 4822.82548797]]    Loss_Validation:  [[ 1419.01599652]]\n",
      "Loop  4349 :    Loss_Train:  [[ 4822.82498428]]    Loss_Validation:  [[ 1419.0172604]]\n",
      "Loop  4350 :    Loss_Train:  [[ 4822.8244814]]    Loss_Validation:  [[ 1419.0185234]]\n",
      "Loop  4351 :    Loss_Train:  [[ 4822.82397935]]    Loss_Validation:  [[ 1419.01978551]]\n",
      "Loop  4352 :    Loss_Train:  [[ 4822.82347813]]    Loss_Validation:  [[ 1419.02104674]]\n",
      "Loop  4353 :    Loss_Train:  [[ 4822.82297772]]    Loss_Validation:  [[ 1419.02230709]]\n",
      "Loop  4354 :    Loss_Train:  [[ 4822.82247813]]    Loss_Validation:  [[ 1419.02356655]]\n",
      "Loop  4355 :    Loss_Train:  [[ 4822.82197937]]    Loss_Validation:  [[ 1419.02482514]]\n",
      "Loop  4356 :    Loss_Train:  [[ 4822.82148142]]    Loss_Validation:  [[ 1419.02608284]]\n",
      "Loop  4357 :    Loss_Train:  [[ 4822.82098428]]    Loss_Validation:  [[ 1419.02733966]]\n",
      "Loop  4358 :    Loss_Train:  [[ 4822.82048796]]    Loss_Validation:  [[ 1419.0285956]]\n",
      "Loop  4359 :    Loss_Train:  [[ 4822.81999245]]    Loss_Validation:  [[ 1419.02985066]]\n",
      "Loop  4360 :    Loss_Train:  [[ 4822.81949776]]    Loss_Validation:  [[ 1419.03110485]]\n",
      "Loop  4361 :    Loss_Train:  [[ 4822.81900387]]    Loss_Validation:  [[ 1419.03235815]]\n",
      "Loop  4362 :    Loss_Train:  [[ 4822.8185108]]    Loss_Validation:  [[ 1419.03361058]]\n",
      "Loop  4363 :    Loss_Train:  [[ 4822.81801853]]    Loss_Validation:  [[ 1419.03486213]]\n",
      "Loop  4364 :    Loss_Train:  [[ 4822.81752707]]    Loss_Validation:  [[ 1419.03611281]]\n",
      "Loop  4365 :    Loss_Train:  [[ 4822.81703641]]    Loss_Validation:  [[ 1419.03736261]]\n",
      "Loop  4366 :    Loss_Train:  [[ 4822.81654655]]    Loss_Validation:  [[ 1419.03861154]]\n",
      "Loop  4367 :    Loss_Train:  [[ 4822.8160575]]    Loss_Validation:  [[ 1419.03985959]]\n",
      "Loop  4368 :    Loss_Train:  [[ 4822.81556925]]    Loss_Validation:  [[ 1419.04110676]]\n",
      "Loop  4369 :    Loss_Train:  [[ 4822.8150818]]    Loss_Validation:  [[ 1419.04235307]]\n",
      "Loop  4370 :    Loss_Train:  [[ 4822.81459515]]    Loss_Validation:  [[ 1419.0435985]]\n",
      "Loop  4371 :    Loss_Train:  [[ 4822.81410929]]    Loss_Validation:  [[ 1419.04484306]]\n",
      "Loop  4372 :    Loss_Train:  [[ 4822.81362423]]    Loss_Validation:  [[ 1419.04608675]]\n",
      "Loop  4373 :    Loss_Train:  [[ 4822.81313997]]    Loss_Validation:  [[ 1419.04732957]]\n",
      "Loop  4374 :    Loss_Train:  [[ 4822.81265649]]    Loss_Validation:  [[ 1419.04857152]]\n",
      "Loop  4375 :    Loss_Train:  [[ 4822.81217381]]    Loss_Validation:  [[ 1419.0498126]]\n",
      "Loop  4376 :    Loss_Train:  [[ 4822.81169192]]    Loss_Validation:  [[ 1419.05105281]]\n",
      "Loop  4377 :    Loss_Train:  [[ 4822.81121082]]    Loss_Validation:  [[ 1419.05229216]]\n",
      "Loop  4378 :    Loss_Train:  [[ 4822.81073051]]    Loss_Validation:  [[ 1419.05353063]]\n",
      "Loop  4379 :    Loss_Train:  [[ 4822.81025098]]    Loss_Validation:  [[ 1419.05476824]]\n",
      "Loop  4380 :    Loss_Train:  [[ 4822.80977223]]    Loss_Validation:  [[ 1419.05600498]]\n",
      "Loop  4381 :    Loss_Train:  [[ 4822.80929428]]    Loss_Validation:  [[ 1419.05724086]]\n",
      "Loop  4382 :    Loss_Train:  [[ 4822.8088171]]    Loss_Validation:  [[ 1419.05847587]]\n",
      "Loop  4383 :    Loss_Train:  [[ 4822.80834071]]    Loss_Validation:  [[ 1419.05971002]]\n",
      "Loop  4384 :    Loss_Train:  [[ 4822.80786509]]    Loss_Validation:  [[ 1419.06094331]]\n",
      "Loop  4385 :    Loss_Train:  [[ 4822.80739025]]    Loss_Validation:  [[ 1419.06217573]]\n",
      "Loop  4386 :    Loss_Train:  [[ 4822.80691619]]    Loss_Validation:  [[ 1419.06340729]]\n",
      "Loop  4387 :    Loss_Train:  [[ 4822.80644291]]    Loss_Validation:  [[ 1419.06463798]]\n",
      "Loop  4388 :    Loss_Train:  [[ 4822.8059704]]    Loss_Validation:  [[ 1419.06586782]]\n",
      "Loop  4389 :    Loss_Train:  [[ 4822.80549867]]    Loss_Validation:  [[ 1419.06709679]]\n",
      "Loop  4390 :    Loss_Train:  [[ 4822.80502771]]    Loss_Validation:  [[ 1419.06832491]]\n",
      "Loop  4391 :    Loss_Train:  [[ 4822.80455751]]    Loss_Validation:  [[ 1419.06955216]]\n",
      "Loop  4392 :    Loss_Train:  [[ 4822.80408809]]    Loss_Validation:  [[ 1419.07077856]]\n",
      "Loop  4393 :    Loss_Train:  [[ 4822.80361944]]    Loss_Validation:  [[ 1419.0720041]]\n",
      "Loop  4394 :    Loss_Train:  [[ 4822.80315155]]    Loss_Validation:  [[ 1419.07322878]]\n",
      "Loop  4395 :    Loss_Train:  [[ 4822.80268443]]    Loss_Validation:  [[ 1419.0744526]]\n",
      "Loop  4396 :    Loss_Train:  [[ 4822.80221808]]    Loss_Validation:  [[ 1419.07567557]]\n",
      "Loop  4397 :    Loss_Train:  [[ 4822.80175248]]    Loss_Validation:  [[ 1419.07689768]]\n",
      "Loop  4398 :    Loss_Train:  [[ 4822.80128765]]    Loss_Validation:  [[ 1419.07811894]]\n",
      "Loop  4399 :    Loss_Train:  [[ 4822.80082358]]    Loss_Validation:  [[ 1419.07933934]]\n",
      "Loop  4400 :    Loss_Train:  [[ 4822.80036027]]    Loss_Validation:  [[ 1419.08055889]]\n",
      "Loop  4401 :    Loss_Train:  [[ 4822.79989772]]    Loss_Validation:  [[ 1419.08177758]]\n",
      "Loop  4402 :    Loss_Train:  [[ 4822.79943593]]    Loss_Validation:  [[ 1419.08299543]]\n",
      "Loop  4403 :    Loss_Train:  [[ 4822.79897489]]    Loss_Validation:  [[ 1419.08421241]]\n",
      "Loop  4404 :    Loss_Train:  [[ 4822.7985146]]    Loss_Validation:  [[ 1419.08542855]]\n",
      "Loop  4405 :    Loss_Train:  [[ 4822.79805507]]    Loss_Validation:  [[ 1419.08664384]]\n",
      "Loop  4406 :    Loss_Train:  [[ 4822.79759629]]    Loss_Validation:  [[ 1419.08785828]]\n",
      "Loop  4407 :    Loss_Train:  [[ 4822.79713826]]    Loss_Validation:  [[ 1419.08907186]]\n",
      "Loop  4408 :    Loss_Train:  [[ 4822.79668098]]    Loss_Validation:  [[ 1419.0902846]]\n",
      "Loop  4409 :    Loss_Train:  [[ 4822.79622445]]    Loss_Validation:  [[ 1419.09149649]]\n",
      "Loop  4410 :    Loss_Train:  [[ 4822.79576867]]    Loss_Validation:  [[ 1419.09270753]]\n",
      "Loop  4411 :    Loss_Train:  [[ 4822.79531363]]    Loss_Validation:  [[ 1419.09391772]]\n",
      "Loop  4412 :    Loss_Train:  [[ 4822.79485933]]    Loss_Validation:  [[ 1419.09512707]]\n",
      "Loop  4413 :    Loss_Train:  [[ 4822.79440578]]    Loss_Validation:  [[ 1419.09633557]]\n",
      "Loop  4414 :    Loss_Train:  [[ 4822.79395297]]    Loss_Validation:  [[ 1419.09754323]]\n",
      "Loop  4415 :    Loss_Train:  [[ 4822.79350091]]    Loss_Validation:  [[ 1419.09875004]]\n",
      "Loop  4416 :    Loss_Train:  [[ 4822.79304958]]    Loss_Validation:  [[ 1419.099956]]\n",
      "Loop  4417 :    Loss_Train:  [[ 4822.79259899]]    Loss_Validation:  [[ 1419.10116113]]\n",
      "Loop  4418 :    Loss_Train:  [[ 4822.79214913]]    Loss_Validation:  [[ 1419.10236541]]\n",
      "Loop  4419 :    Loss_Train:  [[ 4822.79170002]]    Loss_Validation:  [[ 1419.10356884]]\n",
      "Loop  4420 :    Loss_Train:  [[ 4822.79125164]]    Loss_Validation:  [[ 1419.10477144]]\n",
      "Loop  4421 :    Loss_Train:  [[ 4822.79080399]]    Loss_Validation:  [[ 1419.10597319]]\n",
      "Loop  4422 :    Loss_Train:  [[ 4822.79035707]]    Loss_Validation:  [[ 1419.1071741]]\n",
      "Loop  4423 :    Loss_Train:  [[ 4822.78991089]]    Loss_Validation:  [[ 1419.10837418]]\n",
      "Loop  4424 :    Loss_Train:  [[ 4822.78946543]]    Loss_Validation:  [[ 1419.10957341]]\n",
      "Loop  4425 :    Loss_Train:  [[ 4822.7890207]]    Loss_Validation:  [[ 1419.1107718]]\n",
      "Loop  4426 :    Loss_Train:  [[ 4822.78857671]]    Loss_Validation:  [[ 1419.11196936]]\n",
      "Loop  4427 :    Loss_Train:  [[ 4822.78813343]]    Loss_Validation:  [[ 1419.11316607]]\n",
      "Loop  4428 :    Loss_Train:  [[ 4822.78769088]]    Loss_Validation:  [[ 1419.11436195]]\n",
      "Loop  4429 :    Loss_Train:  [[ 4822.78724906]]    Loss_Validation:  [[ 1419.115557]]\n",
      "Loop  4430 :    Loss_Train:  [[ 4822.78680796]]    Loss_Validation:  [[ 1419.11675121]]\n",
      "Loop  4431 :    Loss_Train:  [[ 4822.78636758]]    Loss_Validation:  [[ 1419.11794458]]\n",
      "Loop  4432 :    Loss_Train:  [[ 4822.78592792]]    Loss_Validation:  [[ 1419.11913712]]\n",
      "Loop  4433 :    Loss_Train:  [[ 4822.78548898]]    Loss_Validation:  [[ 1419.12032882]]\n",
      "Loop  4434 :    Loss_Train:  [[ 4822.78505076]]    Loss_Validation:  [[ 1419.12151969]]\n",
      "Loop  4435 :    Loss_Train:  [[ 4822.78461325]]    Loss_Validation:  [[ 1419.12270972]]\n",
      "Loop  4436 :    Loss_Train:  [[ 4822.78417646]]    Loss_Validation:  [[ 1419.12389893]]\n",
      "Loop  4437 :    Loss_Train:  [[ 4822.78374038]]    Loss_Validation:  [[ 1419.1250873]]\n",
      "Loop  4438 :    Loss_Train:  [[ 4822.78330502]]    Loss_Validation:  [[ 1419.12627484]]\n",
      "Loop  4439 :    Loss_Train:  [[ 4822.78287037]]    Loss_Validation:  [[ 1419.12746155]]\n",
      "Loop  4440 :    Loss_Train:  [[ 4822.78243643]]    Loss_Validation:  [[ 1419.12864743]]\n",
      "Loop  4441 :    Loss_Train:  [[ 4822.7820032]]    Loss_Validation:  [[ 1419.12983248]]\n",
      "Loop  4442 :    Loss_Train:  [[ 4822.78157067]]    Loss_Validation:  [[ 1419.1310167]]\n",
      "Loop  4443 :    Loss_Train:  [[ 4822.78113886]]    Loss_Validation:  [[ 1419.13220009]]\n",
      "Loop  4444 :    Loss_Train:  [[ 4822.78070775]]    Loss_Validation:  [[ 1419.13338266]]\n",
      "Loop  4445 :    Loss_Train:  [[ 4822.78027734]]    Loss_Validation:  [[ 1419.1345644]]\n",
      "Loop  4446 :    Loss_Train:  [[ 4822.77984764]]    Loss_Validation:  [[ 1419.13574531]]\n",
      "Loop  4447 :    Loss_Train:  [[ 4822.77941865]]    Loss_Validation:  [[ 1419.13692539]]\n",
      "Loop  4448 :    Loss_Train:  [[ 4822.77899035]]    Loss_Validation:  [[ 1419.13810465]]\n",
      "Loop  4449 :    Loss_Train:  [[ 4822.77856275]]    Loss_Validation:  [[ 1419.13928309]]\n",
      "Loop  4450 :    Loss_Train:  [[ 4822.77813586]]    Loss_Validation:  [[ 1419.1404607]]\n",
      "Loop  4451 :    Loss_Train:  [[ 4822.77770966]]    Loss_Validation:  [[ 1419.14163748]]\n",
      "Loop  4452 :    Loss_Train:  [[ 4822.77728415]]    Loss_Validation:  [[ 1419.14281345]]\n",
      "Loop  4453 :    Loss_Train:  [[ 4822.77685935]]    Loss_Validation:  [[ 1419.14398859]]\n",
      "Loop  4454 :    Loss_Train:  [[ 4822.77643523]]    Loss_Validation:  [[ 1419.14516291]]\n",
      "Loop  4455 :    Loss_Train:  [[ 4822.77601181]]    Loss_Validation:  [[ 1419.14633641]]\n",
      "Loop  4456 :    Loss_Train:  [[ 4822.77558909]]    Loss_Validation:  [[ 1419.14750908]]\n",
      "Loop  4457 :    Loss_Train:  [[ 4822.77516705]]    Loss_Validation:  [[ 1419.14868094]]\n",
      "Loop  4458 :    Loss_Train:  [[ 4822.7747457]]    Loss_Validation:  [[ 1419.14985198]]\n",
      "Loop  4459 :    Loss_Train:  [[ 4822.77432505]]    Loss_Validation:  [[ 1419.1510222]]\n",
      "Loop  4460 :    Loss_Train:  [[ 4822.77390508]]    Loss_Validation:  [[ 1419.1521916]]\n",
      "Loop  4461 :    Loss_Train:  [[ 4822.77348579]]    Loss_Validation:  [[ 1419.15336018]]\n",
      "Loop  4462 :    Loss_Train:  [[ 4822.77306719]]    Loss_Validation:  [[ 1419.15452794]]\n",
      "Loop  4463 :    Loss_Train:  [[ 4822.77264928]]    Loss_Validation:  [[ 1419.15569489]]\n",
      "Loop  4464 :    Loss_Train:  [[ 4822.77223205]]    Loss_Validation:  [[ 1419.15686102]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  4465 :    Loss_Train:  [[ 4822.7718155]]    Loss_Validation:  [[ 1419.15802634]]\n",
      "Loop  4466 :    Loss_Train:  [[ 4822.77139963]]    Loss_Validation:  [[ 1419.15919084]]\n",
      "Loop  4467 :    Loss_Train:  [[ 4822.77098444]]    Loss_Validation:  [[ 1419.16035452]]\n",
      "Loop  4468 :    Loss_Train:  [[ 4822.77056993]]    Loss_Validation:  [[ 1419.1615174]]\n",
      "Loop  4469 :    Loss_Train:  [[ 4822.7701561]]    Loss_Validation:  [[ 1419.16267946]]\n",
      "Loop  4470 :    Loss_Train:  [[ 4822.76974294]]    Loss_Validation:  [[ 1419.1638407]]\n",
      "Loop  4471 :    Loss_Train:  [[ 4822.76933046]]    Loss_Validation:  [[ 1419.16500114]]\n",
      "Loop  4472 :    Loss_Train:  [[ 4822.76891866]]    Loss_Validation:  [[ 1419.16616076]]\n",
      "Loop  4473 :    Loss_Train:  [[ 4822.76850752]]    Loss_Validation:  [[ 1419.16731957]]\n",
      "Loop  4474 :    Loss_Train:  [[ 4822.76809706]]    Loss_Validation:  [[ 1419.16847757]]\n",
      "Loop  4475 :    Loss_Train:  [[ 4822.76768727]]    Loss_Validation:  [[ 1419.16963476]]\n",
      "Loop  4476 :    Loss_Train:  [[ 4822.76727814]]    Loss_Validation:  [[ 1419.17079115]]\n",
      "Loop  4477 :    Loss_Train:  [[ 4822.76686969]]    Loss_Validation:  [[ 1419.17194672]]\n",
      "Loop  4478 :    Loss_Train:  [[ 4822.7664619]]    Loss_Validation:  [[ 1419.17310149]]\n",
      "Loop  4479 :    Loss_Train:  [[ 4822.76605478]]    Loss_Validation:  [[ 1419.17425544]]\n",
      "Loop  4480 :    Loss_Train:  [[ 4822.76564833]]    Loss_Validation:  [[ 1419.17540859]]\n",
      "Loop  4481 :    Loss_Train:  [[ 4822.76524254]]    Loss_Validation:  [[ 1419.17656094]]\n",
      "Loop  4482 :    Loss_Train:  [[ 4822.76483741]]    Loss_Validation:  [[ 1419.17771248]]\n",
      "Loop  4483 :    Loss_Train:  [[ 4822.76443295]]    Loss_Validation:  [[ 1419.17886321]]\n",
      "Loop  4484 :    Loss_Train:  [[ 4822.76402914]]    Loss_Validation:  [[ 1419.18001314]]\n",
      "Loop  4485 :    Loss_Train:  [[ 4822.763626]]    Loss_Validation:  [[ 1419.18116226]]\n",
      "Loop  4486 :    Loss_Train:  [[ 4822.76322351]]    Loss_Validation:  [[ 1419.18231058]]\n",
      "Loop  4487 :    Loss_Train:  [[ 4822.76282168]]    Loss_Validation:  [[ 1419.1834581]]\n",
      "Loop  4488 :    Loss_Train:  [[ 4822.76242051]]    Loss_Validation:  [[ 1419.18460482]]\n",
      "Loop  4489 :    Loss_Train:  [[ 4822.76201999]]    Loss_Validation:  [[ 1419.18575073]]\n",
      "Loop  4490 :    Loss_Train:  [[ 4822.76162013]]    Loss_Validation:  [[ 1419.18689584]]\n",
      "Loop  4491 :    Loss_Train:  [[ 4822.76122092]]    Loss_Validation:  [[ 1419.18804015]]\n",
      "Loop  4492 :    Loss_Train:  [[ 4822.76082236]]    Loss_Validation:  [[ 1419.18918366]]\n",
      "Loop  4493 :    Loss_Train:  [[ 4822.76042445]]    Loss_Validation:  [[ 1419.19032638]]\n",
      "Loop  4494 :    Loss_Train:  [[ 4822.76002719]]    Loss_Validation:  [[ 1419.19146829]]\n",
      "Loop  4495 :    Loss_Train:  [[ 4822.75963059]]    Loss_Validation:  [[ 1419.1926094]]\n",
      "Loop  4496 :    Loss_Train:  [[ 4822.75923463]]    Loss_Validation:  [[ 1419.19374972]]\n",
      "Loop  4497 :    Loss_Train:  [[ 4822.75883931]]    Loss_Validation:  [[ 1419.19488924]]\n",
      "Loop  4498 :    Loss_Train:  [[ 4822.75844464]]    Loss_Validation:  [[ 1419.19602796]]\n",
      "Loop  4499 :    Loss_Train:  [[ 4822.75805062]]    Loss_Validation:  [[ 1419.19716588]]\n",
      "Loop  4500 :    Loss_Train:  [[ 4822.75765724]]    Loss_Validation:  [[ 1419.19830301]]\n",
      "Loop  4501 :    Loss_Train:  [[ 4822.7572645]]    Loss_Validation:  [[ 1419.19943935]]\n",
      "Loop  4502 :    Loss_Train:  [[ 4822.75687241]]    Loss_Validation:  [[ 1419.20057489]]\n",
      "Loop  4503 :    Loss_Train:  [[ 4822.75648095]]    Loss_Validation:  [[ 1419.20170963]]\n",
      "Loop  4504 :    Loss_Train:  [[ 4822.75609014]]    Loss_Validation:  [[ 1419.20284359]]\n",
      "Loop  4505 :    Loss_Train:  [[ 4822.75569996]]    Loss_Validation:  [[ 1419.20397675]]\n",
      "Loop  4506 :    Loss_Train:  [[ 4822.75531042]]    Loss_Validation:  [[ 1419.20510911]]\n",
      "Loop  4507 :    Loss_Train:  [[ 4822.75492151]]    Loss_Validation:  [[ 1419.20624069]]\n",
      "Loop  4508 :    Loss_Train:  [[ 4822.75453324]]    Loss_Validation:  [[ 1419.20737147]]\n",
      "Loop  4509 :    Loss_Train:  [[ 4822.75414561]]    Loss_Validation:  [[ 1419.20850147]]\n",
      "Loop  4510 :    Loss_Train:  [[ 4822.7537586]]    Loss_Validation:  [[ 1419.20963067]]\n",
      "Loop  4511 :    Loss_Train:  [[ 4822.75337223]]    Loss_Validation:  [[ 1419.21075909]]\n",
      "Loop  4512 :    Loss_Train:  [[ 4822.75298649]]    Loss_Validation:  [[ 1419.21188671]]\n",
      "Loop  4513 :    Loss_Train:  [[ 4822.75260138]]    Loss_Validation:  [[ 1419.21301355]]\n",
      "Loop  4514 :    Loss_Train:  [[ 4822.7522169]]    Loss_Validation:  [[ 1419.2141396]]\n",
      "Loop  4515 :    Loss_Train:  [[ 4822.75183305]]    Loss_Validation:  [[ 1419.21526486]]\n",
      "Loop  4516 :    Loss_Train:  [[ 4822.75144982]]    Loss_Validation:  [[ 1419.21638933]]\n",
      "Loop  4517 :    Loss_Train:  [[ 4822.75106722]]    Loss_Validation:  [[ 1419.21751302]]\n",
      "Loop  4518 :    Loss_Train:  [[ 4822.75068524]]    Loss_Validation:  [[ 1419.21863592]]\n",
      "Loop  4519 :    Loss_Train:  [[ 4822.75030389]]    Loss_Validation:  [[ 1419.21975804]]\n",
      "Loop  4520 :    Loss_Train:  [[ 4822.74992316]]    Loss_Validation:  [[ 1419.22087938]]\n",
      "Loop  4521 :    Loss_Train:  [[ 4822.74954305]]    Loss_Validation:  [[ 1419.22199992]]\n",
      "Loop  4522 :    Loss_Train:  [[ 4822.74916356]]    Loss_Validation:  [[ 1419.22311969]]\n",
      "Loop  4523 :    Loss_Train:  [[ 4822.74878469]]    Loss_Validation:  [[ 1419.22423867]]\n",
      "Loop  4524 :    Loss_Train:  [[ 4822.74840644]]    Loss_Validation:  [[ 1419.22535687]]\n",
      "Loop  4525 :    Loss_Train:  [[ 4822.74802881]]    Loss_Validation:  [[ 1419.22647429]]\n",
      "Loop  4526 :    Loss_Train:  [[ 4822.74765179]]    Loss_Validation:  [[ 1419.22759093]]\n",
      "Loop  4527 :    Loss_Train:  [[ 4822.74727539]]    Loss_Validation:  [[ 1419.22870679]]\n",
      "Loop  4528 :    Loss_Train:  [[ 4822.74689961]]    Loss_Validation:  [[ 1419.22982186]]\n",
      "Loop  4529 :    Loss_Train:  [[ 4822.74652443]]    Loss_Validation:  [[ 1419.23093616]]\n",
      "Loop  4530 :    Loss_Train:  [[ 4822.74614987]]    Loss_Validation:  [[ 1419.23204968]]\n",
      "Loop  4531 :    Loss_Train:  [[ 4822.74577592]]    Loss_Validation:  [[ 1419.23316242]]\n",
      "Loop  4532 :    Loss_Train:  [[ 4822.74540258]]    Loss_Validation:  [[ 1419.23427438]]\n",
      "Loop  4533 :    Loss_Train:  [[ 4822.74502985]]    Loss_Validation:  [[ 1419.23538556]]\n",
      "Loop  4534 :    Loss_Train:  [[ 4822.74465773]]    Loss_Validation:  [[ 1419.23649597]]\n",
      "Loop  4535 :    Loss_Train:  [[ 4822.74428622]]    Loss_Validation:  [[ 1419.2376056]]\n",
      "Loop  4536 :    Loss_Train:  [[ 4822.74391531]]    Loss_Validation:  [[ 1419.23871446]]\n",
      "Loop  4537 :    Loss_Train:  [[ 4822.743545]]    Loss_Validation:  [[ 1419.23982254]]\n",
      "Loop  4538 :    Loss_Train:  [[ 4822.74317531]]    Loss_Validation:  [[ 1419.24092984]]\n",
      "Loop  4539 :    Loss_Train:  [[ 4822.74280621]]    Loss_Validation:  [[ 1419.24203638]]\n",
      "Loop  4540 :    Loss_Train:  [[ 4822.74243772]]    Loss_Validation:  [[ 1419.24314213]]\n",
      "Loop  4541 :    Loss_Train:  [[ 4822.74206983]]    Loss_Validation:  [[ 1419.24424712]]\n",
      "Loop  4542 :    Loss_Train:  [[ 4822.74170254]]    Loss_Validation:  [[ 1419.24535133]]\n",
      "Loop  4543 :    Loss_Train:  [[ 4822.74133584]]    Loss_Validation:  [[ 1419.24645477]]\n",
      "Loop  4544 :    Loss_Train:  [[ 4822.74096975]]    Loss_Validation:  [[ 1419.24755744]]\n",
      "Loop  4545 :    Loss_Train:  [[ 4822.74060425]]    Loss_Validation:  [[ 1419.24865934]]\n",
      "Loop  4546 :    Loss_Train:  [[ 4822.74023935]]    Loss_Validation:  [[ 1419.24976047]]\n",
      "Loop  4547 :    Loss_Train:  [[ 4822.73987505]]    Loss_Validation:  [[ 1419.25086082]]\n",
      "Loop  4548 :    Loss_Train:  [[ 4822.73951134]]    Loss_Validation:  [[ 1419.25196041]]\n",
      "Loop  4549 :    Loss_Train:  [[ 4822.73914822]]    Loss_Validation:  [[ 1419.25305923]]\n",
      "Loop  4550 :    Loss_Train:  [[ 4822.7387857]]    Loss_Validation:  [[ 1419.25415729]]\n",
      "Loop  4551 :    Loss_Train:  [[ 4822.73842377]]    Loss_Validation:  [[ 1419.25525457]]\n",
      "Loop  4552 :    Loss_Train:  [[ 4822.73806242]]    Loss_Validation:  [[ 1419.25635109]]\n",
      "Loop  4553 :    Loss_Train:  [[ 4822.73770167]]    Loss_Validation:  [[ 1419.25744684]]\n",
      "Loop  4554 :    Loss_Train:  [[ 4822.73734151]]    Loss_Validation:  [[ 1419.25854182]]\n",
      "Loop  4555 :    Loss_Train:  [[ 4822.73698193]]    Loss_Validation:  [[ 1419.25963604]]\n",
      "Loop  4556 :    Loss_Train:  [[ 4822.73662294]]    Loss_Validation:  [[ 1419.2607295]]\n",
      "Loop  4557 :    Loss_Train:  [[ 4822.73626454]]    Loss_Validation:  [[ 1419.26182219]]\n",
      "Loop  4558 :    Loss_Train:  [[ 4822.73590672]]    Loss_Validation:  [[ 1419.26291411]]\n",
      "Loop  4559 :    Loss_Train:  [[ 4822.73554948]]    Loss_Validation:  [[ 1419.26400528]]\n",
      "Loop  4560 :    Loss_Train:  [[ 4822.73519283]]    Loss_Validation:  [[ 1419.26509568]]\n",
      "Loop  4561 :    Loss_Train:  [[ 4822.73483676]]    Loss_Validation:  [[ 1419.26618531]]\n",
      "Loop  4562 :    Loss_Train:  [[ 4822.73448127]]    Loss_Validation:  [[ 1419.26727419]]\n",
      "Loop  4563 :    Loss_Train:  [[ 4822.73412636]]    Loss_Validation:  [[ 1419.26836231]]\n",
      "Loop  4564 :    Loss_Train:  [[ 4822.73377202]]    Loss_Validation:  [[ 1419.26944966]]\n",
      "Loop  4565 :    Loss_Train:  [[ 4822.73341827]]    Loss_Validation:  [[ 1419.27053626]]\n",
      "Loop  4566 :    Loss_Train:  [[ 4822.73306509]]    Loss_Validation:  [[ 1419.27162209]]\n",
      "Loop  4567 :    Loss_Train:  [[ 4822.73271249]]    Loss_Validation:  [[ 1419.27270717]]\n",
      "Loop  4568 :    Loss_Train:  [[ 4822.73236047]]    Loss_Validation:  [[ 1419.27379148]]\n",
      "Loop  4569 :    Loss_Train:  [[ 4822.73200901]]    Loss_Validation:  [[ 1419.27487504]]\n",
      "Loop  4570 :    Loss_Train:  [[ 4822.73165814]]    Loss_Validation:  [[ 1419.27595785]]\n",
      "Loop  4571 :    Loss_Train:  [[ 4822.73130783]]    Loss_Validation:  [[ 1419.27703989]]\n",
      "Loop  4572 :    Loss_Train:  [[ 4822.73095809]]    Loss_Validation:  [[ 1419.27812118]]\n",
      "Loop  4573 :    Loss_Train:  [[ 4822.73060893]]    Loss_Validation:  [[ 1419.27920171]]\n",
      "Loop  4574 :    Loss_Train:  [[ 4822.73026034]]    Loss_Validation:  [[ 1419.28028149]]\n",
      "Loop  4575 :    Loss_Train:  [[ 4822.72991231]]    Loss_Validation:  [[ 1419.28136052]]\n",
      "Loop  4576 :    Loss_Train:  [[ 4822.72956485]]    Loss_Validation:  [[ 1419.28243878]]\n",
      "Loop  4577 :    Loss_Train:  [[ 4822.72921796]]    Loss_Validation:  [[ 1419.2835163]]\n",
      "Loop  4578 :    Loss_Train:  [[ 4822.72887163]]    Loss_Validation:  [[ 1419.28459306]]\n",
      "Loop  4579 :    Loss_Train:  [[ 4822.72852587]]    Loss_Validation:  [[ 1419.28566907]]\n",
      "Loop  4580 :    Loss_Train:  [[ 4822.72818067]]    Loss_Validation:  [[ 1419.28674433]]\n",
      "Loop  4581 :    Loss_Train:  [[ 4822.72783603]]    Loss_Validation:  [[ 1419.28781883]]\n",
      "Loop  4582 :    Loss_Train:  [[ 4822.72749196]]    Loss_Validation:  [[ 1419.28889259]]\n",
      "Loop  4583 :    Loss_Train:  [[ 4822.72714845]]    Loss_Validation:  [[ 1419.28996559]]\n",
      "Loop  4584 :    Loss_Train:  [[ 4822.72680549]]    Loss_Validation:  [[ 1419.29103785]]\n",
      "Loop  4585 :    Loss_Train:  [[ 4822.7264631]]    Loss_Validation:  [[ 1419.29210935]]\n",
      "Loop  4586 :    Loss_Train:  [[ 4822.72612127]]    Loss_Validation:  [[ 1419.29318011]]\n",
      "Loop  4587 :    Loss_Train:  [[ 4822.72577999]]    Loss_Validation:  [[ 1419.29425012]]\n",
      "Loop  4588 :    Loss_Train:  [[ 4822.72543927]]    Loss_Validation:  [[ 1419.29531938]]\n",
      "Loop  4589 :    Loss_Train:  [[ 4822.7250991]]    Loss_Validation:  [[ 1419.29638789]]\n",
      "Loop  4590 :    Loss_Train:  [[ 4822.72475949]]    Loss_Validation:  [[ 1419.29745565]]\n",
      "Loop  4591 :    Loss_Train:  [[ 4822.72442043]]    Loss_Validation:  [[ 1419.29852267]]\n",
      "Loop  4592 :    Loss_Train:  [[ 4822.72408193]]    Loss_Validation:  [[ 1419.29958895]]\n",
      "Loop  4593 :    Loss_Train:  [[ 4822.72374397]]    Loss_Validation:  [[ 1419.30065447]]\n",
      "Loop  4594 :    Loss_Train:  [[ 4822.72340657]]    Loss_Validation:  [[ 1419.30171926]]\n",
      "Loop  4595 :    Loss_Train:  [[ 4822.72306972]]    Loss_Validation:  [[ 1419.3027833]]\n",
      "Loop  4596 :    Loss_Train:  [[ 4822.72273341]]    Loss_Validation:  [[ 1419.30384659]]\n",
      "Loop  4597 :    Loss_Train:  [[ 4822.72239766]]    Loss_Validation:  [[ 1419.30490914]]\n",
      "Loop  4598 :    Loss_Train:  [[ 4822.72206245]]    Loss_Validation:  [[ 1419.30597095]]\n",
      "Loop  4599 :    Loss_Train:  [[ 4822.72172779]]    Loss_Validation:  [[ 1419.30703202]]\n",
      "Loop  4600 :    Loss_Train:  [[ 4822.72139367]]    Loss_Validation:  [[ 1419.30809235]]\n",
      "Loop  4601 :    Loss_Train:  [[ 4822.7210601]]    Loss_Validation:  [[ 1419.30915193]]\n",
      "Loop  4602 :    Loss_Train:  [[ 4822.72072707]]    Loss_Validation:  [[ 1419.31021078]]\n",
      "Loop  4603 :    Loss_Train:  [[ 4822.72039459]]    Loss_Validation:  [[ 1419.31126888]]\n",
      "Loop  4604 :    Loss_Train:  [[ 4822.72006265]]    Loss_Validation:  [[ 1419.31232625]]\n",
      "Loop  4605 :    Loss_Train:  [[ 4822.71973124]]    Loss_Validation:  [[ 1419.31338287]]\n",
      "Loop  4606 :    Loss_Train:  [[ 4822.71940038]]    Loss_Validation:  [[ 1419.31443876]]\n",
      "Loop  4607 :    Loss_Train:  [[ 4822.71907006]]    Loss_Validation:  [[ 1419.31549391]]\n",
      "Loop  4608 :    Loss_Train:  [[ 4822.71874027]]    Loss_Validation:  [[ 1419.31654832]]\n",
      "Loop  4609 :    Loss_Train:  [[ 4822.71841103]]    Loss_Validation:  [[ 1419.317602]]\n",
      "Loop  4610 :    Loss_Train:  [[ 4822.71808232]]    Loss_Validation:  [[ 1419.31865494]]\n",
      "Loop  4611 :    Loss_Train:  [[ 4822.71775414]]    Loss_Validation:  [[ 1419.31970714]]\n",
      "Loop  4612 :    Loss_Train:  [[ 4822.7174265]]    Loss_Validation:  [[ 1419.32075861]]\n",
      "Loop  4613 :    Loss_Train:  [[ 4822.7170994]]    Loss_Validation:  [[ 1419.32180934]]\n",
      "Loop  4614 :    Loss_Train:  [[ 4822.71677282]]    Loss_Validation:  [[ 1419.32285934]]\n",
      "Loop  4615 :    Loss_Train:  [[ 4822.71644678]]    Loss_Validation:  [[ 1419.3239086]]\n",
      "Loop  4616 :    Loss_Train:  [[ 4822.71612127]]    Loss_Validation:  [[ 1419.32495713]]\n",
      "Loop  4617 :    Loss_Train:  [[ 4822.71579629]]    Loss_Validation:  [[ 1419.32600493]]\n",
      "Loop  4618 :    Loss_Train:  [[ 4822.71547184]]    Loss_Validation:  [[ 1419.327052]]\n",
      "Loop  4619 :    Loss_Train:  [[ 4822.71514792]]    Loss_Validation:  [[ 1419.32809833]]\n",
      "Loop  4620 :    Loss_Train:  [[ 4822.71482453]]    Loss_Validation:  [[ 1419.32914393]]\n",
      "Loop  4621 :    Loss_Train:  [[ 4822.71450166]]    Loss_Validation:  [[ 1419.33018881]]\n",
      "Loop  4622 :    Loss_Train:  [[ 4822.71417932]]    Loss_Validation:  [[ 1419.33123295]]\n",
      "Loop  4623 :    Loss_Train:  [[ 4822.71385751]]    Loss_Validation:  [[ 1419.33227636]]\n",
      "Loop  4624 :    Loss_Train:  [[ 4822.71353621]]    Loss_Validation:  [[ 1419.33331904]]\n",
      "Loop  4625 :    Loss_Train:  [[ 4822.71321545]]    Loss_Validation:  [[ 1419.334361]]\n",
      "Loop  4626 :    Loss_Train:  [[ 4822.7128952]]    Loss_Validation:  [[ 1419.33540222]]\n",
      "Loop  4627 :    Loss_Train:  [[ 4822.71257548]]    Loss_Validation:  [[ 1419.33644272]]\n",
      "Loop  4628 :    Loss_Train:  [[ 4822.71225628]]    Loss_Validation:  [[ 1419.33748249]]\n",
      "Loop  4629 :    Loss_Train:  [[ 4822.71193759]]    Loss_Validation:  [[ 1419.33852154]]\n",
      "Loop  4630 :    Loss_Train:  [[ 4822.71161943]]    Loss_Validation:  [[ 1419.33955986]]\n",
      "Loop  4631 :    Loss_Train:  [[ 4822.71130178]]    Loss_Validation:  [[ 1419.34059745]]\n",
      "Loop  4632 :    Loss_Train:  [[ 4822.71098466]]    Loss_Validation:  [[ 1419.34163432]]\n",
      "Loop  4633 :    Loss_Train:  [[ 4822.71066805]]    Loss_Validation:  [[ 1419.34267046]]\n",
      "Loop  4634 :    Loss_Train:  [[ 4822.71035195]]    Loss_Validation:  [[ 1419.34370588]]\n",
      "Loop  4635 :    Loss_Train:  [[ 4822.71003637]]    Loss_Validation:  [[ 1419.34474058]]\n",
      "Loop  4636 :    Loss_Train:  [[ 4822.7097213]]    Loss_Validation:  [[ 1419.34577455]]\n",
      "Loop  4637 :    Loss_Train:  [[ 4822.70940675]]    Loss_Validation:  [[ 1419.3468078]]\n",
      "Loop  4638 :    Loss_Train:  [[ 4822.70909271]]    Loss_Validation:  [[ 1419.34784033]]\n",
      "Loop  4639 :    Loss_Train:  [[ 4822.70877918]]    Loss_Validation:  [[ 1419.34887214]]\n",
      "Loop  4640 :    Loss_Train:  [[ 4822.70846616]]    Loss_Validation:  [[ 1419.34990322]]\n",
      "Loop  4641 :    Loss_Train:  [[ 4822.70815365]]    Loss_Validation:  [[ 1419.35093359]]\n",
      "Loop  4642 :    Loss_Train:  [[ 4822.70784165]]    Loss_Validation:  [[ 1419.35196323]]\n",
      "Loop  4643 :    Loss_Train:  [[ 4822.70753016]]    Loss_Validation:  [[ 1419.35299216]]\n",
      "Loop  4644 :    Loss_Train:  [[ 4822.70721917]]    Loss_Validation:  [[ 1419.35402036]]\n",
      "Loop  4645 :    Loss_Train:  [[ 4822.70690869]]    Loss_Validation:  [[ 1419.35504785]]\n",
      "Loop  4646 :    Loss_Train:  [[ 4822.70659872]]    Loss_Validation:  [[ 1419.35607462]]\n",
      "Loop  4647 :    Loss_Train:  [[ 4822.70628925]]    Loss_Validation:  [[ 1419.35710067]]\n",
      "Loop  4648 :    Loss_Train:  [[ 4822.70598029]]    Loss_Validation:  [[ 1419.35812601]]\n",
      "Loop  4649 :    Loss_Train:  [[ 4822.70567183]]    Loss_Validation:  [[ 1419.35915063]]\n",
      "Loop  4650 :    Loss_Train:  [[ 4822.70536387]]    Loss_Validation:  [[ 1419.36017453]]\n",
      "Loop  4651 :    Loss_Train:  [[ 4822.70505641]]    Loss_Validation:  [[ 1419.36119772]]\n",
      "Loop  4652 :    Loss_Train:  [[ 4822.70474945]]    Loss_Validation:  [[ 1419.36222019]]\n",
      "Loop  4653 :    Loss_Train:  [[ 4822.704443]]    Loss_Validation:  [[ 1419.36324195]]\n",
      "Loop  4654 :    Loss_Train:  [[ 4822.70413704]]    Loss_Validation:  [[ 1419.36426299]]\n",
      "Loop  4655 :    Loss_Train:  [[ 4822.70383158]]    Loss_Validation:  [[ 1419.36528332]]\n",
      "Loop  4656 :    Loss_Train:  [[ 4822.70352662]]    Loss_Validation:  [[ 1419.36630294]]\n",
      "Loop  4657 :    Loss_Train:  [[ 4822.70322215]]    Loss_Validation:  [[ 1419.36732184]]\n",
      "Loop  4658 :    Loss_Train:  [[ 4822.70291818]]    Loss_Validation:  [[ 1419.36834003]]\n",
      "Loop  4659 :    Loss_Train:  [[ 4822.70261471]]    Loss_Validation:  [[ 1419.36935752]]\n",
      "Loop  4660 :    Loss_Train:  [[ 4822.70231173]]    Loss_Validation:  [[ 1419.37037429]]\n",
      "Loop  4661 :    Loss_Train:  [[ 4822.70200924]]    Loss_Validation:  [[ 1419.37139035]]\n",
      "Loop  4662 :    Loss_Train:  [[ 4822.70170724]]    Loss_Validation:  [[ 1419.37240569]]\n",
      "Loop  4663 :    Loss_Train:  [[ 4822.70140574]]    Loss_Validation:  [[ 1419.37342034]]\n",
      "Loop  4664 :    Loss_Train:  [[ 4822.70110472]]    Loss_Validation:  [[ 1419.37443427]]\n",
      "Loop  4665 :    Loss_Train:  [[ 4822.7008042]]    Loss_Validation:  [[ 1419.37544749]]\n",
      "Loop  4666 :    Loss_Train:  [[ 4822.70050417]]    Loss_Validation:  [[ 1419.37646]]\n",
      "Loop  4667 :    Loss_Train:  [[ 4822.70020462]]    Loss_Validation:  [[ 1419.37747181]]\n",
      "Loop  4668 :    Loss_Train:  [[ 4822.69990556]]    Loss_Validation:  [[ 1419.37848291]]\n",
      "Loop  4669 :    Loss_Train:  [[ 4822.69960699]]    Loss_Validation:  [[ 1419.3794933]]\n",
      "Loop  4670 :    Loss_Train:  [[ 4822.69930891]]    Loss_Validation:  [[ 1419.38050299]]\n",
      "Loop  4671 :    Loss_Train:  [[ 4822.69901131]]    Loss_Validation:  [[ 1419.38151197]]\n",
      "Loop  4672 :    Loss_Train:  [[ 4822.69871419]]    Loss_Validation:  [[ 1419.38252025]]\n",
      "Loop  4673 :    Loss_Train:  [[ 4822.69841756]]    Loss_Validation:  [[ 1419.38352782]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  4674 :    Loss_Train:  [[ 4822.69812141]]    Loss_Validation:  [[ 1419.38453469]]\n",
      "Loop  4675 :    Loss_Train:  [[ 4822.69782574]]    Loss_Validation:  [[ 1419.38554086]]\n",
      "Loop  4676 :    Loss_Train:  [[ 4822.69753056]]    Loss_Validation:  [[ 1419.38654632]]\n",
      "Loop  4677 :    Loss_Train:  [[ 4822.69723585]]    Loss_Validation:  [[ 1419.38755108]]\n",
      "Loop  4678 :    Loss_Train:  [[ 4822.69694163]]    Loss_Validation:  [[ 1419.38855513]]\n",
      "Loop  4679 :    Loss_Train:  [[ 4822.69664788]]    Loss_Validation:  [[ 1419.38955849]]\n",
      "Loop  4680 :    Loss_Train:  [[ 4822.69635461]]    Loss_Validation:  [[ 1419.39056114]]\n",
      "Loop  4681 :    Loss_Train:  [[ 4822.69606182]]    Loss_Validation:  [[ 1419.3915631]]\n",
      "Loop  4682 :    Loss_Train:  [[ 4822.6957695]]    Loss_Validation:  [[ 1419.39256435]]\n",
      "Loop  4683 :    Loss_Train:  [[ 4822.69547766]]    Loss_Validation:  [[ 1419.39356491]]\n",
      "Loop  4684 :    Loss_Train:  [[ 4822.6951863]]    Loss_Validation:  [[ 1419.39456476]]\n",
      "Loop  4685 :    Loss_Train:  [[ 4822.69489541]]    Loss_Validation:  [[ 1419.39556392]]\n",
      "Loop  4686 :    Loss_Train:  [[ 4822.69460499]]    Loss_Validation:  [[ 1419.39656237]]\n",
      "Loop  4687 :    Loss_Train:  [[ 4822.69431505]]    Loss_Validation:  [[ 1419.39756014]]\n",
      "Loop  4688 :    Loss_Train:  [[ 4822.69402557]]    Loss_Validation:  [[ 1419.3985572]]\n",
      "Loop  4689 :    Loss_Train:  [[ 4822.69373657]]    Loss_Validation:  [[ 1419.39955357]]\n",
      "Loop  4690 :    Loss_Train:  [[ 4822.69344804]]    Loss_Validation:  [[ 1419.40054924]]\n",
      "Loop  4691 :    Loss_Train:  [[ 4822.69315998]]    Loss_Validation:  [[ 1419.40154421]]\n",
      "Loop  4692 :    Loss_Train:  [[ 4822.69287238]]    Loss_Validation:  [[ 1419.40253849]]\n",
      "Loop  4693 :    Loss_Train:  [[ 4822.69258526]]    Loss_Validation:  [[ 1419.40353207]]\n",
      "Loop  4694 :    Loss_Train:  [[ 4822.6922986]]    Loss_Validation:  [[ 1419.40452496]]\n",
      "Loop  4695 :    Loss_Train:  [[ 4822.69201241]]    Loss_Validation:  [[ 1419.40551716]]\n",
      "Loop  4696 :    Loss_Train:  [[ 4822.69172668]]    Loss_Validation:  [[ 1419.40650866]]\n",
      "Loop  4697 :    Loss_Train:  [[ 4822.69144142]]    Loss_Validation:  [[ 1419.40749948]]\n",
      "Loop  4698 :    Loss_Train:  [[ 4822.69115662]]    Loss_Validation:  [[ 1419.40848959]]\n",
      "Loop  4699 :    Loss_Train:  [[ 4822.69087229]]    Loss_Validation:  [[ 1419.40947902]]\n",
      "Loop  4700 :    Loss_Train:  [[ 4822.69058841]]    Loss_Validation:  [[ 1419.41046776]]\n",
      "Loop  4701 :    Loss_Train:  [[ 4822.690305]]    Loss_Validation:  [[ 1419.4114558]]\n",
      "Loop  4702 :    Loss_Train:  [[ 4822.69002206]]    Loss_Validation:  [[ 1419.41244315]]\n",
      "Loop  4703 :    Loss_Train:  [[ 4822.68973957]]    Loss_Validation:  [[ 1419.41342982]]\n",
      "Loop  4704 :    Loss_Train:  [[ 4822.68945754]]    Loss_Validation:  [[ 1419.41441579]]\n",
      "Loop  4705 :    Loss_Train:  [[ 4822.68917597]]    Loss_Validation:  [[ 1419.41540108]]\n",
      "Loop  4706 :    Loss_Train:  [[ 4822.68889485]]    Loss_Validation:  [[ 1419.41638567]]\n",
      "Loop  4707 :    Loss_Train:  [[ 4822.6886142]]    Loss_Validation:  [[ 1419.41736958]]\n",
      "Loop  4708 :    Loss_Train:  [[ 4822.688334]]    Loss_Validation:  [[ 1419.41835281]]\n",
      "Loop  4709 :    Loss_Train:  [[ 4822.68805426]]    Loss_Validation:  [[ 1419.41933534]]\n",
      "Loop  4710 :    Loss_Train:  [[ 4822.68777497]]    Loss_Validation:  [[ 1419.42031719]]\n",
      "Loop  4711 :    Loss_Train:  [[ 4822.68749614]]    Loss_Validation:  [[ 1419.42129835]]\n",
      "Loop  4712 :    Loss_Train:  [[ 4822.68721776]]    Loss_Validation:  [[ 1419.42227883]]\n",
      "Loop  4713 :    Loss_Train:  [[ 4822.68693983]]    Loss_Validation:  [[ 1419.42325862]]\n",
      "Loop  4714 :    Loss_Train:  [[ 4822.68666235]]    Loss_Validation:  [[ 1419.42423773]]\n",
      "Loop  4715 :    Loss_Train:  [[ 4822.68638533]]    Loss_Validation:  [[ 1419.42521615]]\n",
      "Loop  4716 :    Loss_Train:  [[ 4822.68610876]]    Loss_Validation:  [[ 1419.42619389]]\n",
      "Loop  4717 :    Loss_Train:  [[ 4822.68583263]]    Loss_Validation:  [[ 1419.42717094]]\n",
      "Loop  4718 :    Loss_Train:  [[ 4822.68555696]]    Loss_Validation:  [[ 1419.42814732]]\n",
      "Loop  4719 :    Loss_Train:  [[ 4822.68528173]]    Loss_Validation:  [[ 1419.42912301]]\n",
      "Loop  4720 :    Loss_Train:  [[ 4822.68500695]]    Loss_Validation:  [[ 1419.43009802]]\n",
      "Loop  4721 :    Loss_Train:  [[ 4822.68473262]]    Loss_Validation:  [[ 1419.43107235]]\n",
      "Loop  4722 :    Loss_Train:  [[ 4822.68445873]]    Loss_Validation:  [[ 1419.43204599]]\n",
      "Loop  4723 :    Loss_Train:  [[ 4822.68418529]]    Loss_Validation:  [[ 1419.43301896]]\n",
      "Loop  4724 :    Loss_Train:  [[ 4822.6839123]]    Loss_Validation:  [[ 1419.43399125]]\n",
      "Loop  4725 :    Loss_Train:  [[ 4822.68363974]]    Loss_Validation:  [[ 1419.43496286]]\n",
      "Loop  4726 :    Loss_Train:  [[ 4822.68336763]]    Loss_Validation:  [[ 1419.43593379]]\n",
      "Loop  4727 :    Loss_Train:  [[ 4822.68309597]]    Loss_Validation:  [[ 1419.43690404]]\n",
      "Loop  4728 :    Loss_Train:  [[ 4822.68282474]]    Loss_Validation:  [[ 1419.43787361]]\n",
      "Loop  4729 :    Loss_Train:  [[ 4822.68255396]]    Loss_Validation:  [[ 1419.4388425]]\n",
      "Loop  4730 :    Loss_Train:  [[ 4822.68228362]]    Loss_Validation:  [[ 1419.43981072]]\n",
      "Loop  4731 :    Loss_Train:  [[ 4822.68201371]]    Loss_Validation:  [[ 1419.44077827]]\n",
      "Loop  4732 :    Loss_Train:  [[ 4822.68174425]]    Loss_Validation:  [[ 1419.44174513]]\n",
      "Loop  4733 :    Loss_Train:  [[ 4822.68147522]]    Loss_Validation:  [[ 1419.44271132]]\n",
      "Loop  4734 :    Loss_Train:  [[ 4822.68120663]]    Loss_Validation:  [[ 1419.44367684]]\n",
      "Loop  4735 :    Loss_Train:  [[ 4822.68093848]]    Loss_Validation:  [[ 1419.44464168]]\n",
      "Loop  4736 :    Loss_Train:  [[ 4822.68067076]]    Loss_Validation:  [[ 1419.44560584]]\n",
      "Loop  4737 :    Loss_Train:  [[ 4822.68040348]]    Loss_Validation:  [[ 1419.44656934]]\n",
      "Loop  4738 :    Loss_Train:  [[ 4822.68013663]]    Loss_Validation:  [[ 1419.44753216]]\n",
      "Loop  4739 :    Loss_Train:  [[ 4822.67987022]]    Loss_Validation:  [[ 1419.4484943]]\n",
      "Loop  4740 :    Loss_Train:  [[ 4822.67960424]]    Loss_Validation:  [[ 1419.44945578]]\n",
      "Loop  4741 :    Loss_Train:  [[ 4822.67933869]]    Loss_Validation:  [[ 1419.45041658]]\n",
      "Loop  4742 :    Loss_Train:  [[ 4822.67907357]]    Loss_Validation:  [[ 1419.45137671]]\n",
      "Loop  4743 :    Loss_Train:  [[ 4822.67880888]]    Loss_Validation:  [[ 1419.45233617]]\n",
      "Loop  4744 :    Loss_Train:  [[ 4822.67854463]]    Loss_Validation:  [[ 1419.45329496]]\n",
      "Loop  4745 :    Loss_Train:  [[ 4822.6782808]]    Loss_Validation:  [[ 1419.45425309]]\n",
      "Loop  4746 :    Loss_Train:  [[ 4822.67801741]]    Loss_Validation:  [[ 1419.45521054]]\n",
      "Loop  4747 :    Loss_Train:  [[ 4822.67775444]]    Loss_Validation:  [[ 1419.45616732]]\n",
      "Loop  4748 :    Loss_Train:  [[ 4822.67749189]]    Loss_Validation:  [[ 1419.45712343]]\n",
      "Loop  4749 :    Loss_Train:  [[ 4822.67722978]]    Loss_Validation:  [[ 1419.45807888]]\n",
      "Loop  4750 :    Loss_Train:  [[ 4822.67696809]]    Loss_Validation:  [[ 1419.45903366]]\n",
      "Loop  4751 :    Loss_Train:  [[ 4822.67670683]]    Loss_Validation:  [[ 1419.45998777]]\n",
      "Loop  4752 :    Loss_Train:  [[ 4822.67644599]]    Loss_Validation:  [[ 1419.46094121]]\n",
      "Loop  4753 :    Loss_Train:  [[ 4822.67618557]]    Loss_Validation:  [[ 1419.46189399]]\n",
      "Loop  4754 :    Loss_Train:  [[ 4822.67592558]]    Loss_Validation:  [[ 1419.4628461]]\n",
      "Loop  4755 :    Loss_Train:  [[ 4822.67566601]]    Loss_Validation:  [[ 1419.46379755]]\n",
      "Loop  4756 :    Loss_Train:  [[ 4822.67540686]]    Loss_Validation:  [[ 1419.46474833]]\n",
      "Loop  4757 :    Loss_Train:  [[ 4822.67514814]]    Loss_Validation:  [[ 1419.46569845]]\n",
      "Loop  4758 :    Loss_Train:  [[ 4822.67488983]]    Loss_Validation:  [[ 1419.4666479]]\n",
      "Loop  4759 :    Loss_Train:  [[ 4822.67463195]]    Loss_Validation:  [[ 1419.4675967]]\n",
      "Loop  4760 :    Loss_Train:  [[ 4822.67437448]]    Loss_Validation:  [[ 1419.46854482]]\n",
      "Loop  4761 :    Loss_Train:  [[ 4822.67411743]]    Loss_Validation:  [[ 1419.46949229]]\n",
      "Loop  4762 :    Loss_Train:  [[ 4822.6738608]]    Loss_Validation:  [[ 1419.47043909]]\n",
      "Loop  4763 :    Loss_Train:  [[ 4822.67360458]]    Loss_Validation:  [[ 1419.47138524]]\n",
      "Loop  4764 :    Loss_Train:  [[ 4822.67334879]]    Loss_Validation:  [[ 1419.47233072]]\n",
      "Loop  4765 :    Loss_Train:  [[ 4822.6730934]]    Loss_Validation:  [[ 1419.47327554]]\n",
      "Loop  4766 :    Loss_Train:  [[ 4822.67283844]]    Loss_Validation:  [[ 1419.4742197]]\n",
      "Loop  4767 :    Loss_Train:  [[ 4822.67258388]]    Loss_Validation:  [[ 1419.4751632]]\n",
      "Loop  4768 :    Loss_Train:  [[ 4822.67232974]]    Loss_Validation:  [[ 1419.47610604]]\n",
      "Loop  4769 :    Loss_Train:  [[ 4822.67207602]]    Loss_Validation:  [[ 1419.47704822]]\n",
      "Loop  4770 :    Loss_Train:  [[ 4822.6718227]]    Loss_Validation:  [[ 1419.47798975]]\n",
      "Loop  4771 :    Loss_Train:  [[ 4822.6715698]]    Loss_Validation:  [[ 1419.47893061]]\n",
      "Loop  4772 :    Loss_Train:  [[ 4822.67131731]]    Loss_Validation:  [[ 1419.47987082]]\n",
      "Loop  4773 :    Loss_Train:  [[ 4822.67106523]]    Loss_Validation:  [[ 1419.48081038]]\n",
      "Loop  4774 :    Loss_Train:  [[ 4822.67081355]]    Loss_Validation:  [[ 1419.48174927]]\n",
      "Loop  4775 :    Loss_Train:  [[ 4822.67056229]]    Loss_Validation:  [[ 1419.48268751]]\n",
      "Loop  4776 :    Loss_Train:  [[ 4822.67031143]]    Loss_Validation:  [[ 1419.4836251]]\n",
      "Loop  4777 :    Loss_Train:  [[ 4822.67006099]]    Loss_Validation:  [[ 1419.48456203]]\n",
      "Loop  4778 :    Loss_Train:  [[ 4822.66981095]]    Loss_Validation:  [[ 1419.4854983]]\n",
      "Loop  4779 :    Loss_Train:  [[ 4822.66956131]]    Loss_Validation:  [[ 1419.48643392]]\n",
      "Loop  4780 :    Loss_Train:  [[ 4822.66931208]]    Loss_Validation:  [[ 1419.48736889]]\n",
      "Loop  4781 :    Loss_Train:  [[ 4822.66906326]]    Loss_Validation:  [[ 1419.4883032]]\n",
      "Loop  4782 :    Loss_Train:  [[ 4822.66881484]]    Loss_Validation:  [[ 1419.48923686]]\n",
      "Loop  4783 :    Loss_Train:  [[ 4822.66856682]]    Loss_Validation:  [[ 1419.49016987]]\n",
      "Loop  4784 :    Loss_Train:  [[ 4822.66831921]]    Loss_Validation:  [[ 1419.49110223]]\n",
      "Loop  4785 :    Loss_Train:  [[ 4822.66807199]]    Loss_Validation:  [[ 1419.49203394]]\n",
      "Loop  4786 :    Loss_Train:  [[ 4822.66782518]]    Loss_Validation:  [[ 1419.49296499]]\n",
      "Loop  4787 :    Loss_Train:  [[ 4822.66757877]]    Loss_Validation:  [[ 1419.49389539]]\n",
      "Loop  4788 :    Loss_Train:  [[ 4822.66733276]]    Loss_Validation:  [[ 1419.49482515]]\n",
      "Loop  4789 :    Loss_Train:  [[ 4822.66708715]]    Loss_Validation:  [[ 1419.49575425]]\n",
      "Loop  4790 :    Loss_Train:  [[ 4822.66684194]]    Loss_Validation:  [[ 1419.49668271]]\n",
      "Loop  4791 :    Loss_Train:  [[ 4822.66659713]]    Loss_Validation:  [[ 1419.49761051]]\n",
      "Loop  4792 :    Loss_Train:  [[ 4822.66635272]]    Loss_Validation:  [[ 1419.49853767]]\n",
      "Loop  4793 :    Loss_Train:  [[ 4822.6661087]]    Loss_Validation:  [[ 1419.49946418]]\n",
      "Loop  4794 :    Loss_Train:  [[ 4822.66586508]]    Loss_Validation:  [[ 1419.50039005]]\n",
      "Loop  4795 :    Loss_Train:  [[ 4822.66562185]]    Loss_Validation:  [[ 1419.50131526]]\n",
      "Loop  4796 :    Loss_Train:  [[ 4822.66537902]]    Loss_Validation:  [[ 1419.50223983]]\n",
      "Loop  4797 :    Loss_Train:  [[ 4822.66513658]]    Loss_Validation:  [[ 1419.50316376]]\n",
      "Loop  4798 :    Loss_Train:  [[ 4822.66489454]]    Loss_Validation:  [[ 1419.50408703]]\n",
      "Loop  4799 :    Loss_Train:  [[ 4822.66465289]]    Loss_Validation:  [[ 1419.50500967]]\n",
      "Loop  4800 :    Loss_Train:  [[ 4822.66441163]]    Loss_Validation:  [[ 1419.50593166]]\n",
      "Loop  4801 :    Loss_Train:  [[ 4822.66417076]]    Loss_Validation:  [[ 1419.506853]]\n",
      "Loop  4802 :    Loss_Train:  [[ 4822.66393029]]    Loss_Validation:  [[ 1419.5077737]]\n",
      "Loop  4803 :    Loss_Train:  [[ 4822.6636902]]    Loss_Validation:  [[ 1419.50869376]]\n",
      "Loop  4804 :    Loss_Train:  [[ 4822.66345051]]    Loss_Validation:  [[ 1419.50961317]]\n",
      "Loop  4805 :    Loss_Train:  [[ 4822.6632112]]    Loss_Validation:  [[ 1419.51053194]]\n",
      "Loop  4806 :    Loss_Train:  [[ 4822.66297229]]    Loss_Validation:  [[ 1419.51145008]]\n",
      "Loop  4807 :    Loss_Train:  [[ 4822.66273376]]    Loss_Validation:  [[ 1419.51236756]]\n",
      "Loop  4808 :    Loss_Train:  [[ 4822.66249561]]    Loss_Validation:  [[ 1419.51328441]]\n",
      "Loop  4809 :    Loss_Train:  [[ 4822.66225786]]    Loss_Validation:  [[ 1419.51420062]]\n",
      "Loop  4810 :    Loss_Train:  [[ 4822.66202049]]    Loss_Validation:  [[ 1419.51511619]]\n",
      "Loop  4811 :    Loss_Train:  [[ 4822.66178351]]    Loss_Validation:  [[ 1419.51603111]]\n",
      "Loop  4812 :    Loss_Train:  [[ 4822.66154691]]    Loss_Validation:  [[ 1419.5169454]]\n",
      "Loop  4813 :    Loss_Train:  [[ 4822.66131069]]    Loss_Validation:  [[ 1419.51785905]]\n",
      "Loop  4814 :    Loss_Train:  [[ 4822.66107486]]    Loss_Validation:  [[ 1419.51877206]]\n",
      "Loop  4815 :    Loss_Train:  [[ 4822.66083941]]    Loss_Validation:  [[ 1419.51968444]]\n",
      "Loop  4816 :    Loss_Train:  [[ 4822.66060434]]    Loss_Validation:  [[ 1419.52059617]]\n",
      "Loop  4817 :    Loss_Train:  [[ 4822.66036966]]    Loss_Validation:  [[ 1419.52150727]]\n",
      "Loop  4818 :    Loss_Train:  [[ 4822.66013535]]    Loss_Validation:  [[ 1419.52241773]]\n",
      "Loop  4819 :    Loss_Train:  [[ 4822.65990143]]    Loss_Validation:  [[ 1419.52332756]]\n",
      "Loop  4820 :    Loss_Train:  [[ 4822.65966789]]    Loss_Validation:  [[ 1419.52423675]]\n",
      "Loop  4821 :    Loss_Train:  [[ 4822.65943472]]    Loss_Validation:  [[ 1419.5251453]]\n",
      "Loop  4822 :    Loss_Train:  [[ 4822.65920193]]    Loss_Validation:  [[ 1419.52605322]]\n",
      "Loop  4823 :    Loss_Train:  [[ 4822.65896953]]    Loss_Validation:  [[ 1419.52696051]]\n",
      "Loop  4824 :    Loss_Train:  [[ 4822.65873749]]    Loss_Validation:  [[ 1419.52786716]]\n",
      "Loop  4825 :    Loss_Train:  [[ 4822.65850584]]    Loss_Validation:  [[ 1419.52877318]]\n",
      "Loop  4826 :    Loss_Train:  [[ 4822.65827456]]    Loss_Validation:  [[ 1419.52967857]]\n",
      "Loop  4827 :    Loss_Train:  [[ 4822.65804366]]    Loss_Validation:  [[ 1419.53058332]]\n",
      "Loop  4828 :    Loss_Train:  [[ 4822.65781313]]    Loss_Validation:  [[ 1419.53148744]]\n",
      "Loop  4829 :    Loss_Train:  [[ 4822.65758297]]    Loss_Validation:  [[ 1419.53239093]]\n",
      "Loop  4830 :    Loss_Train:  [[ 4822.65735319]]    Loss_Validation:  [[ 1419.53329379]]\n",
      "Loop  4831 :    Loss_Train:  [[ 4822.65712378]]    Loss_Validation:  [[ 1419.53419601]]\n",
      "Loop  4832 :    Loss_Train:  [[ 4822.65689475]]    Loss_Validation:  [[ 1419.53509761]]\n",
      "Loop  4833 :    Loss_Train:  [[ 4822.65666608]]    Loss_Validation:  [[ 1419.53599858]]\n",
      "Loop  4834 :    Loss_Train:  [[ 4822.65643779]]    Loss_Validation:  [[ 1419.53689892]]\n",
      "Loop  4835 :    Loss_Train:  [[ 4822.65620986]]    Loss_Validation:  [[ 1419.53779862]]\n",
      "Loop  4836 :    Loss_Train:  [[ 4822.65598231]]    Loss_Validation:  [[ 1419.5386977]]\n",
      "Loop  4837 :    Loss_Train:  [[ 4822.65575513]]    Loss_Validation:  [[ 1419.53959616]]\n",
      "Loop  4838 :    Loss_Train:  [[ 4822.65552831]]    Loss_Validation:  [[ 1419.54049398]]\n",
      "Loop  4839 :    Loss_Train:  [[ 4822.65530186]]    Loss_Validation:  [[ 1419.54139118]]\n",
      "Loop  4840 :    Loss_Train:  [[ 4822.65507578]]    Loss_Validation:  [[ 1419.54228775]]\n",
      "Loop  4841 :    Loss_Train:  [[ 4822.65485007]]    Loss_Validation:  [[ 1419.54318369]]\n",
      "Loop  4842 :    Loss_Train:  [[ 4822.65462472]]    Loss_Validation:  [[ 1419.54407901]]\n",
      "Loop  4843 :    Loss_Train:  [[ 4822.65439974]]    Loss_Validation:  [[ 1419.5449737]]\n",
      "Loop  4844 :    Loss_Train:  [[ 4822.65417513]]    Loss_Validation:  [[ 1419.54586776]]\n",
      "Loop  4845 :    Loss_Train:  [[ 4822.65395088]]    Loss_Validation:  [[ 1419.54676121]]\n",
      "Loop  4846 :    Loss_Train:  [[ 4822.65372699]]    Loss_Validation:  [[ 1419.54765402]]\n",
      "Loop  4847 :    Loss_Train:  [[ 4822.65350346]]    Loss_Validation:  [[ 1419.54854622]]\n",
      "Loop  4848 :    Loss_Train:  [[ 4822.6532803]]    Loss_Validation:  [[ 1419.54943779]]\n",
      "Loop  4849 :    Loss_Train:  [[ 4822.6530575]]    Loss_Validation:  [[ 1419.55032874]]\n",
      "Loop  4850 :    Loss_Train:  [[ 4822.65283506]]    Loss_Validation:  [[ 1419.55121906]]\n",
      "Loop  4851 :    Loss_Train:  [[ 4822.65261298]]    Loss_Validation:  [[ 1419.55210876]]\n",
      "Loop  4852 :    Loss_Train:  [[ 4822.65239127]]    Loss_Validation:  [[ 1419.55299785]]\n",
      "Loop  4853 :    Loss_Train:  [[ 4822.65216991]]    Loss_Validation:  [[ 1419.55388631]]\n",
      "Loop  4854 :    Loss_Train:  [[ 4822.65194891]]    Loss_Validation:  [[ 1419.55477415]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  4855 :    Loss_Train:  [[ 4822.65172827]]    Loss_Validation:  [[ 1419.55566136]]\n",
      "Loop  4856 :    Loss_Train:  [[ 4822.65150799]]    Loss_Validation:  [[ 1419.55654796]]\n",
      "Loop  4857 :    Loss_Train:  [[ 4822.65128806]]    Loss_Validation:  [[ 1419.55743394]]\n",
      "Loop  4858 :    Loss_Train:  [[ 4822.65106849]]    Loss_Validation:  [[ 1419.5583193]]\n",
      "Loop  4859 :    Loss_Train:  [[ 4822.65084928]]    Loss_Validation:  [[ 1419.55920405]]\n",
      "Loop  4860 :    Loss_Train:  [[ 4822.65063043]]    Loss_Validation:  [[ 1419.56008817]]\n",
      "Loop  4861 :    Loss_Train:  [[ 4822.65041192]]    Loss_Validation:  [[ 1419.56097168]]\n",
      "Loop  4862 :    Loss_Train:  [[ 4822.65019378]]    Loss_Validation:  [[ 1419.56185457]]\n",
      "Loop  4863 :    Loss_Train:  [[ 4822.64997598]]    Loss_Validation:  [[ 1419.56273684]]\n",
      "Loop  4864 :    Loss_Train:  [[ 4822.64975854]]    Loss_Validation:  [[ 1419.56361849]]\n",
      "Loop  4865 :    Loss_Train:  [[ 4822.64954146]]    Loss_Validation:  [[ 1419.56449953]]\n",
      "Loop  4866 :    Loss_Train:  [[ 4822.64932472]]    Loss_Validation:  [[ 1419.56537996]]\n",
      "Loop  4867 :    Loss_Train:  [[ 4822.64910834]]    Loss_Validation:  [[ 1419.56625977]]\n",
      "Loop  4868 :    Loss_Train:  [[ 4822.6488923]]    Loss_Validation:  [[ 1419.56713896]]\n",
      "Loop  4869 :    Loss_Train:  [[ 4822.64867662]]    Loss_Validation:  [[ 1419.56801754]]\n",
      "Loop  4870 :    Loss_Train:  [[ 4822.64846129]]    Loss_Validation:  [[ 1419.56889551]]\n",
      "Loop  4871 :    Loss_Train:  [[ 4822.6482463]]    Loss_Validation:  [[ 1419.56977286]]\n",
      "Loop  4872 :    Loss_Train:  [[ 4822.64803167]]    Loss_Validation:  [[ 1419.5706496]]\n",
      "Loop  4873 :    Loss_Train:  [[ 4822.64781738]]    Loss_Validation:  [[ 1419.57152572]]\n",
      "Loop  4874 :    Loss_Train:  [[ 4822.64760344]]    Loss_Validation:  [[ 1419.57240124]]\n",
      "Loop  4875 :    Loss_Train:  [[ 4822.64738985]]    Loss_Validation:  [[ 1419.57327614]]\n",
      "Loop  4876 :    Loss_Train:  [[ 4822.6471766]]    Loss_Validation:  [[ 1419.57415043]]\n",
      "Loop  4877 :    Loss_Train:  [[ 4822.6469637]]    Loss_Validation:  [[ 1419.57502412]]\n",
      "Loop  4878 :    Loss_Train:  [[ 4822.64675115]]    Loss_Validation:  [[ 1419.57589719]]\n",
      "Loop  4879 :    Loss_Train:  [[ 4822.64653894]]    Loss_Validation:  [[ 1419.57676965]]\n",
      "Loop  4880 :    Loss_Train:  [[ 4822.64632707]]    Loss_Validation:  [[ 1419.5776415]]\n",
      "Loop  4881 :    Loss_Train:  [[ 4822.64611555]]    Loss_Validation:  [[ 1419.57851274]]\n",
      "Loop  4882 :    Loss_Train:  [[ 4822.64590437]]    Loss_Validation:  [[ 1419.57938337]]\n",
      "Loop  4883 :    Loss_Train:  [[ 4822.64569353]]    Loss_Validation:  [[ 1419.5802534]]\n",
      "Loop  4884 :    Loss_Train:  [[ 4822.64548303]]    Loss_Validation:  [[ 1419.58112281]]\n",
      "Loop  4885 :    Loss_Train:  [[ 4822.64527288]]    Loss_Validation:  [[ 1419.58199162]]\n",
      "Loop  4886 :    Loss_Train:  [[ 4822.64506306]]    Loss_Validation:  [[ 1419.58285982]]\n",
      "Loop  4887 :    Loss_Train:  [[ 4822.64485359]]    Loss_Validation:  [[ 1419.58372742]]\n",
      "Loop  4888 :    Loss_Train:  [[ 4822.64464446]]    Loss_Validation:  [[ 1419.58459441]]\n",
      "Loop  4889 :    Loss_Train:  [[ 4822.64443566]]    Loss_Validation:  [[ 1419.58546079]]\n",
      "Loop  4890 :    Loss_Train:  [[ 4822.6442272]]    Loss_Validation:  [[ 1419.58632657]]\n",
      "Loop  4891 :    Loss_Train:  [[ 4822.64401909]]    Loss_Validation:  [[ 1419.58719174]]\n",
      "Loop  4892 :    Loss_Train:  [[ 4822.6438113]]    Loss_Validation:  [[ 1419.58805631]]\n",
      "Loop  4893 :    Loss_Train:  [[ 4822.64360386]]    Loss_Validation:  [[ 1419.58892028]]\n",
      "Loop  4894 :    Loss_Train:  [[ 4822.64339675]]    Loss_Validation:  [[ 1419.58978364]]\n",
      "Loop  4895 :    Loss_Train:  [[ 4822.64318998]]    Loss_Validation:  [[ 1419.5906464]]\n",
      "Loop  4896 :    Loss_Train:  [[ 4822.64298354]]    Loss_Validation:  [[ 1419.59150855]]\n",
      "Loop  4897 :    Loss_Train:  [[ 4822.64277744]]    Loss_Validation:  [[ 1419.5923701]]\n",
      "Loop  4898 :    Loss_Train:  [[ 4822.64257167]]    Loss_Validation:  [[ 1419.59323105]]\n",
      "Loop  4899 :    Loss_Train:  [[ 4822.64236623]]    Loss_Validation:  [[ 1419.5940914]]\n",
      "Loop  4900 :    Loss_Train:  [[ 4822.64216113]]    Loss_Validation:  [[ 1419.59495115]]\n",
      "Loop  4901 :    Loss_Train:  [[ 4822.64195636]]    Loss_Validation:  [[ 1419.5958103]]\n",
      "Loop  4902 :    Loss_Train:  [[ 4822.64175192]]    Loss_Validation:  [[ 1419.59666885]]\n",
      "Loop  4903 :    Loss_Train:  [[ 4822.64154782]]    Loss_Validation:  [[ 1419.59752679]]\n",
      "Loop  4904 :    Loss_Train:  [[ 4822.64134404]]    Loss_Validation:  [[ 1419.59838414]]\n",
      "Loop  4905 :    Loss_Train:  [[ 4822.6411406]]    Loss_Validation:  [[ 1419.59924089]]\n",
      "Loop  4906 :    Loss_Train:  [[ 4822.64093748]]    Loss_Validation:  [[ 1419.60009704]]\n",
      "Loop  4907 :    Loss_Train:  [[ 4822.64073469]]    Loss_Validation:  [[ 1419.60095259]]\n",
      "Loop  4908 :    Loss_Train:  [[ 4822.64053224]]    Loss_Validation:  [[ 1419.60180754]]\n",
      "Loop  4909 :    Loss_Train:  [[ 4822.64033011]]    Loss_Validation:  [[ 1419.6026619]]\n",
      "Loop  4910 :    Loss_Train:  [[ 4822.6401283]]    Loss_Validation:  [[ 1419.60351566]]\n",
      "Loop  4911 :    Loss_Train:  [[ 4822.63992683]]    Loss_Validation:  [[ 1419.60436882]]\n",
      "Loop  4912 :    Loss_Train:  [[ 4822.63972568]]    Loss_Validation:  [[ 1419.60522139]]\n",
      "Loop  4913 :    Loss_Train:  [[ 4822.63952486]]    Loss_Validation:  [[ 1419.60607336]]\n",
      "Loop  4914 :    Loss_Train:  [[ 4822.63932436]]    Loss_Validation:  [[ 1419.60692473]]\n",
      "Loop  4915 :    Loss_Train:  [[ 4822.63912419]]    Loss_Validation:  [[ 1419.60777551]]\n",
      "Loop  4916 :    Loss_Train:  [[ 4822.63892434]]    Loss_Validation:  [[ 1419.6086257]]\n",
      "Loop  4917 :    Loss_Train:  [[ 4822.63872481]]    Loss_Validation:  [[ 1419.60947529]]\n",
      "Loop  4918 :    Loss_Train:  [[ 4822.63852561]]    Loss_Validation:  [[ 1419.61032429]]\n",
      "Loop  4919 :    Loss_Train:  [[ 4822.63832673]]    Loss_Validation:  [[ 1419.6111727]]\n",
      "Loop  4920 :    Loss_Train:  [[ 4822.63812818]]    Loss_Validation:  [[ 1419.61202051]]\n",
      "Loop  4921 :    Loss_Train:  [[ 4822.63792994]]    Loss_Validation:  [[ 1419.61286773]]\n",
      "Loop  4922 :    Loss_Train:  [[ 4822.63773203]]    Loss_Validation:  [[ 1419.61371436]]\n",
      "Loop  4923 :    Loss_Train:  [[ 4822.63753444]]    Loss_Validation:  [[ 1419.61456039]]\n",
      "Loop  4924 :    Loss_Train:  [[ 4822.63733717]]    Loss_Validation:  [[ 1419.61540584]]\n",
      "Loop  4925 :    Loss_Train:  [[ 4822.63714021]]    Loss_Validation:  [[ 1419.61625069]]\n",
      "Loop  4926 :    Loss_Train:  [[ 4822.63694358]]    Loss_Validation:  [[ 1419.61709496]]\n",
      "Loop  4927 :    Loss_Train:  [[ 4822.63674726]]    Loss_Validation:  [[ 1419.61793863]]\n",
      "Loop  4928 :    Loss_Train:  [[ 4822.63655127]]    Loss_Validation:  [[ 1419.61878172]]\n",
      "Loop  4929 :    Loss_Train:  [[ 4822.63635559]]    Loss_Validation:  [[ 1419.61962421]]\n",
      "Loop  4930 :    Loss_Train:  [[ 4822.63616022]]    Loss_Validation:  [[ 1419.62046612]]\n",
      "Loop  4931 :    Loss_Train:  [[ 4822.63596518]]    Loss_Validation:  [[ 1419.62130744]]\n",
      "Loop  4932 :    Loss_Train:  [[ 4822.63577045]]    Loss_Validation:  [[ 1419.62214817]]\n",
      "Loop  4933 :    Loss_Train:  [[ 4822.63557603]]    Loss_Validation:  [[ 1419.62298831]]\n",
      "Loop  4934 :    Loss_Train:  [[ 4822.63538193]]    Loss_Validation:  [[ 1419.62382787]]\n",
      "Loop  4935 :    Loss_Train:  [[ 4822.63518815]]    Loss_Validation:  [[ 1419.62466684]]\n",
      "Loop  4936 :    Loss_Train:  [[ 4822.63499468]]    Loss_Validation:  [[ 1419.62550522]]\n",
      "Loop  4937 :    Loss_Train:  [[ 4822.63480152]]    Loss_Validation:  [[ 1419.62634302]]\n",
      "Loop  4938 :    Loss_Train:  [[ 4822.63460867]]    Loss_Validation:  [[ 1419.62718023]]\n",
      "Loop  4939 :    Loss_Train:  [[ 4822.63441614]]    Loss_Validation:  [[ 1419.62801685]]\n",
      "Loop  4940 :    Loss_Train:  [[ 4822.63422392]]    Loss_Validation:  [[ 1419.6288529]]\n",
      "Loop  4941 :    Loss_Train:  [[ 4822.63403201]]    Loss_Validation:  [[ 1419.62968835]]\n",
      "Loop  4942 :    Loss_Train:  [[ 4822.63384041]]    Loss_Validation:  [[ 1419.63052323]]\n",
      "Loop  4943 :    Loss_Train:  [[ 4822.63364912]]    Loss_Validation:  [[ 1419.63135752]]\n",
      "Loop  4944 :    Loss_Train:  [[ 4822.63345814]]    Loss_Validation:  [[ 1419.63219123]]\n",
      "Loop  4945 :    Loss_Train:  [[ 4822.63326747]]    Loss_Validation:  [[ 1419.63302435]]\n",
      "Loop  4946 :    Loss_Train:  [[ 4822.63307711]]    Loss_Validation:  [[ 1419.6338569]]\n",
      "Loop  4947 :    Loss_Train:  [[ 4822.63288706]]    Loss_Validation:  [[ 1419.63468886]]\n",
      "Loop  4948 :    Loss_Train:  [[ 4822.63269731]]    Loss_Validation:  [[ 1419.63552024]]\n",
      "Loop  4949 :    Loss_Train:  [[ 4822.63250788]]    Loss_Validation:  [[ 1419.63635104]]\n",
      "Loop  4950 :    Loss_Train:  [[ 4822.63231875]]    Loss_Validation:  [[ 1419.63718125]]\n",
      "Loop  4951 :    Loss_Train:  [[ 4822.63212992]]    Loss_Validation:  [[ 1419.63801089]]\n",
      "Loop  4952 :    Loss_Train:  [[ 4822.6319414]]    Loss_Validation:  [[ 1419.63883995]]\n",
      "Loop  4953 :    Loss_Train:  [[ 4822.63175319]]    Loss_Validation:  [[ 1419.63966843]]\n",
      "Loop  4954 :    Loss_Train:  [[ 4822.63156528]]    Loss_Validation:  [[ 1419.64049633]]\n",
      "Loop  4955 :    Loss_Train:  [[ 4822.63137768]]    Loss_Validation:  [[ 1419.64132365]]\n",
      "Loop  4956 :    Loss_Train:  [[ 4822.63119038]]    Loss_Validation:  [[ 1419.6421504]]\n",
      "Loop  4957 :    Loss_Train:  [[ 4822.63100338]]    Loss_Validation:  [[ 1419.64297656]]\n",
      "Loop  4958 :    Loss_Train:  [[ 4822.63081668]]    Loss_Validation:  [[ 1419.64380215]]\n",
      "Loop  4959 :    Loss_Train:  [[ 4822.63063029]]    Loss_Validation:  [[ 1419.64462716]]\n",
      "Loop  4960 :    Loss_Train:  [[ 4822.6304442]]    Loss_Validation:  [[ 1419.6454516]]\n",
      "Loop  4961 :    Loss_Train:  [[ 4822.63025841]]    Loss_Validation:  [[ 1419.64627546]]\n",
      "Loop  4962 :    Loss_Train:  [[ 4822.63007292]]    Loss_Validation:  [[ 1419.64709874]]\n",
      "Loop  4963 :    Loss_Train:  [[ 4822.62988774]]    Loss_Validation:  [[ 1419.64792145]]\n",
      "Loop  4964 :    Loss_Train:  [[ 4822.62970285]]    Loss_Validation:  [[ 1419.64874358]]\n",
      "Loop  4965 :    Loss_Train:  [[ 4822.62951826]]    Loss_Validation:  [[ 1419.64956514]]\n",
      "Loop  4966 :    Loss_Train:  [[ 4822.62933397]]    Loss_Validation:  [[ 1419.65038612]]\n",
      "Loop  4967 :    Loss_Train:  [[ 4822.62914998]]    Loss_Validation:  [[ 1419.65120653]]\n",
      "Loop  4968 :    Loss_Train:  [[ 4822.62896628]]    Loss_Validation:  [[ 1419.65202637]]\n",
      "Loop  4969 :    Loss_Train:  [[ 4822.62878289]]    Loss_Validation:  [[ 1419.65284563]]\n",
      "Loop  4970 :    Loss_Train:  [[ 4822.62859979]]    Loss_Validation:  [[ 1419.65366433]]\n",
      "Loop  4971 :    Loss_Train:  [[ 4822.62841699]]    Loss_Validation:  [[ 1419.65448245]]\n",
      "Loop  4972 :    Loss_Train:  [[ 4822.62823448]]    Loss_Validation:  [[ 1419.65529999]]\n",
      "Loop  4973 :    Loss_Train:  [[ 4822.62805227]]    Loss_Validation:  [[ 1419.65611697]]\n",
      "Loop  4974 :    Loss_Train:  [[ 4822.62787035]]    Loss_Validation:  [[ 1419.65693338]]\n",
      "Loop  4975 :    Loss_Train:  [[ 4822.62768873]]    Loss_Validation:  [[ 1419.65774921]]\n",
      "Loop  4976 :    Loss_Train:  [[ 4822.6275074]]    Loss_Validation:  [[ 1419.65856448]]\n",
      "Loop  4977 :    Loss_Train:  [[ 4822.62732636]]    Loss_Validation:  [[ 1419.65937917]]\n",
      "Loop  4978 :    Loss_Train:  [[ 4822.62714562]]    Loss_Validation:  [[ 1419.6601933]]\n",
      "Loop  4979 :    Loss_Train:  [[ 4822.62696517]]    Loss_Validation:  [[ 1419.66100686]]\n",
      "Loop  4980 :    Loss_Train:  [[ 4822.62678502]]    Loss_Validation:  [[ 1419.66181984]]\n",
      "Loop  4981 :    Loss_Train:  [[ 4822.62660515]]    Loss_Validation:  [[ 1419.66263226]]\n",
      "Loop  4982 :    Loss_Train:  [[ 4822.62642558]]    Loss_Validation:  [[ 1419.66344412]]\n",
      "Loop  4983 :    Loss_Train:  [[ 4822.62624629]]    Loss_Validation:  [[ 1419.6642554]]\n",
      "Loop  4984 :    Loss_Train:  [[ 4822.6260673]]    Loss_Validation:  [[ 1419.66506612]]\n",
      "Loop  4985 :    Loss_Train:  [[ 4822.62588859]]    Loss_Validation:  [[ 1419.66587627]]\n",
      "Loop  4986 :    Loss_Train:  [[ 4822.62571018]]    Loss_Validation:  [[ 1419.66668586]]\n",
      "Loop  4987 :    Loss_Train:  [[ 4822.62553205]]    Loss_Validation:  [[ 1419.66749488]]\n",
      "Loop  4988 :    Loss_Train:  [[ 4822.62535422]]    Loss_Validation:  [[ 1419.66830333]]\n",
      "Loop  4989 :    Loss_Train:  [[ 4822.62517667]]    Loss_Validation:  [[ 1419.66911122]]\n",
      "Loop  4990 :    Loss_Train:  [[ 4822.6249994]]    Loss_Validation:  [[ 1419.66991854]]\n",
      "Loop  4991 :    Loss_Train:  [[ 4822.62482243]]    Loss_Validation:  [[ 1419.67072531]]\n",
      "Loop  4992 :    Loss_Train:  [[ 4822.62464574]]    Loss_Validation:  [[ 1419.6715315]]\n",
      "Loop  4993 :    Loss_Train:  [[ 4822.62446933]]    Loss_Validation:  [[ 1419.67233714]]\n",
      "Loop  4994 :    Loss_Train:  [[ 4822.62429322]]    Loss_Validation:  [[ 1419.67314221]]\n",
      "Loop  4995 :    Loss_Train:  [[ 4822.62411738]]    Loss_Validation:  [[ 1419.67394671]]\n",
      "Loop  4996 :    Loss_Train:  [[ 4822.62394183]]    Loss_Validation:  [[ 1419.67475066]]\n",
      "Loop  4997 :    Loss_Train:  [[ 4822.62376657]]    Loss_Validation:  [[ 1419.67555404]]\n",
      "Loop  4998 :    Loss_Train:  [[ 4822.62359159]]    Loss_Validation:  [[ 1419.67635686]]\n",
      "Loop  4999 :    Loss_Train:  [[ 4822.62341689]]    Loss_Validation:  [[ 1419.67715912]]\n",
      "Loop  5000 :    Loss_Train:  [[ 4822.62324248]]    Loss_Validation:  [[ 1419.67796083]]\n",
      "Loop  5001 :    Loss_Train:  [[ 4822.62306834]]    Loss_Validation:  [[ 1419.67876197]]\n",
      "Loop  5002 :    Loss_Train:  [[ 4822.62289449]]    Loss_Validation:  [[ 1419.67956255]]\n",
      "Loop  5003 :    Loss_Train:  [[ 4822.62272092]]    Loss_Validation:  [[ 1419.68036257]]\n",
      "Loop  5004 :    Loss_Train:  [[ 4822.62254763]]    Loss_Validation:  [[ 1419.68116203]]\n",
      "Loop  5005 :    Loss_Train:  [[ 4822.62237463]]    Loss_Validation:  [[ 1419.68196093]]\n",
      "Loop  5006 :    Loss_Train:  [[ 4822.6222019]]    Loss_Validation:  [[ 1419.68275927]]\n",
      "Loop  5007 :    Loss_Train:  [[ 4822.62202945]]    Loss_Validation:  [[ 1419.68355706]]\n",
      "Loop  5008 :    Loss_Train:  [[ 4822.62185728]]    Loss_Validation:  [[ 1419.68435429]]\n",
      "Loop  5009 :    Loss_Train:  [[ 4822.62168538]]    Loss_Validation:  [[ 1419.68515096]]\n",
      "Loop  5010 :    Loss_Train:  [[ 4822.62151377]]    Loss_Validation:  [[ 1419.68594708]]\n",
      "Loop  5011 :    Loss_Train:  [[ 4822.62134243]]    Loss_Validation:  [[ 1419.68674263]]\n",
      "Loop  5012 :    Loss_Train:  [[ 4822.62117138]]    Loss_Validation:  [[ 1419.68753764]]\n",
      "Loop  5013 :    Loss_Train:  [[ 4822.62100059]]    Loss_Validation:  [[ 1419.68833208]]\n",
      "Loop  5014 :    Loss_Train:  [[ 4822.62083009]]    Loss_Validation:  [[ 1419.68912597]]\n",
      "Loop  5015 :    Loss_Train:  [[ 4822.62065986]]    Loss_Validation:  [[ 1419.68991931]]\n",
      "Loop  5016 :    Loss_Train:  [[ 4822.6204899]]    Loss_Validation:  [[ 1419.69071209]]\n",
      "Loop  5017 :    Loss_Train:  [[ 4822.62032022]]    Loss_Validation:  [[ 1419.69150432]]\n",
      "Loop  5018 :    Loss_Train:  [[ 4822.62015082]]    Loss_Validation:  [[ 1419.692296]]\n",
      "Loop  5019 :    Loss_Train:  [[ 4822.61998169]]    Loss_Validation:  [[ 1419.69308712]]\n",
      "Loop  5020 :    Loss_Train:  [[ 4822.61981283]]    Loss_Validation:  [[ 1419.69387769]]\n",
      "Loop  5021 :    Loss_Train:  [[ 4822.61964424]]    Loss_Validation:  [[ 1419.6946677]]\n",
      "Loop  5022 :    Loss_Train:  [[ 4822.61947593]]    Loss_Validation:  [[ 1419.69545716]]\n",
      "Loop  5023 :    Loss_Train:  [[ 4822.61930789]]    Loss_Validation:  [[ 1419.69624608]]\n",
      "Loop  5024 :    Loss_Train:  [[ 4822.61914012]]    Loss_Validation:  [[ 1419.69703444]]\n",
      "Loop  5025 :    Loss_Train:  [[ 4822.61897263]]    Loss_Validation:  [[ 1419.69782225]]\n",
      "Loop  5026 :    Loss_Train:  [[ 4822.6188054]]    Loss_Validation:  [[ 1419.6986095]]\n",
      "Loop  5027 :    Loss_Train:  [[ 4822.61863845]]    Loss_Validation:  [[ 1419.69939621]]\n",
      "Loop  5028 :    Loss_Train:  [[ 4822.61847176]]    Loss_Validation:  [[ 1419.70018237]]\n",
      "Loop  5029 :    Loss_Train:  [[ 4822.61830534]]    Loss_Validation:  [[ 1419.70096798]]\n",
      "Loop  5030 :    Loss_Train:  [[ 4822.6181392]]    Loss_Validation:  [[ 1419.70175304]]\n",
      "Loop  5031 :    Loss_Train:  [[ 4822.61797332]]    Loss_Validation:  [[ 1419.70253755]]\n",
      "Loop  5032 :    Loss_Train:  [[ 4822.61780771]]    Loss_Validation:  [[ 1419.70332151]]\n",
      "Loop  5033 :    Loss_Train:  [[ 4822.61764237]]    Loss_Validation:  [[ 1419.70410493]]\n",
      "Loop  5034 :    Loss_Train:  [[ 4822.61747729]]    Loss_Validation:  [[ 1419.7048878]]\n",
      "Loop  5035 :    Loss_Train:  [[ 4822.61731249]]    Loss_Validation:  [[ 1419.70567012]]\n",
      "Loop  5036 :    Loss_Train:  [[ 4822.61714794]]    Loss_Validation:  [[ 1419.70645189]]\n",
      "Loop  5037 :    Loss_Train:  [[ 4822.61698367]]    Loss_Validation:  [[ 1419.70723312]]\n",
      "Loop  5038 :    Loss_Train:  [[ 4822.61681966]]    Loss_Validation:  [[ 1419.7080138]]\n",
      "Loop  5039 :    Loss_Train:  [[ 4822.61665592]]    Loss_Validation:  [[ 1419.70879393]]\n",
      "Loop  5040 :    Loss_Train:  [[ 4822.61649244]]    Loss_Validation:  [[ 1419.70957352]]\n",
      "Loop  5041 :    Loss_Train:  [[ 4822.61632922]]    Loss_Validation:  [[ 1419.71035257]]\n",
      "Loop  5042 :    Loss_Train:  [[ 4822.61616627]]    Loss_Validation:  [[ 1419.71113107]]\n",
      "Loop  5043 :    Loss_Train:  [[ 4822.61600358]]    Loss_Validation:  [[ 1419.71190903]]\n",
      "Loop  5044 :    Loss_Train:  [[ 4822.61584116]]    Loss_Validation:  [[ 1419.71268644]]\n",
      "Loop  5045 :    Loss_Train:  [[ 4822.61567899]]    Loss_Validation:  [[ 1419.71346331]]\n",
      "Loop  5046 :    Loss_Train:  [[ 4822.61551709]]    Loss_Validation:  [[ 1419.71423963]]\n",
      "Loop  5047 :    Loss_Train:  [[ 4822.61535546]]    Loss_Validation:  [[ 1419.71501542]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  5048 :    Loss_Train:  [[ 4822.61519408]]    Loss_Validation:  [[ 1419.71579066]]\n",
      "Loop  5049 :    Loss_Train:  [[ 4822.61503296]]    Loss_Validation:  [[ 1419.71656536]]\n",
      "Loop  5050 :    Loss_Train:  [[ 4822.61487211]]    Loss_Validation:  [[ 1419.71733952]]\n",
      "Loop  5051 :    Loss_Train:  [[ 4822.61471151]]    Loss_Validation:  [[ 1419.71811313]]\n",
      "Loop  5052 :    Loss_Train:  [[ 4822.61455118]]    Loss_Validation:  [[ 1419.71888621]]\n",
      "Loop  5053 :    Loss_Train:  [[ 4822.6143911]]    Loss_Validation:  [[ 1419.71965874]]\n",
      "Loop  5054 :    Loss_Train:  [[ 4822.61423128]]    Loss_Validation:  [[ 1419.72043074]]\n",
      "Loop  5055 :    Loss_Train:  [[ 4822.61407172]]    Loss_Validation:  [[ 1419.7212022]]\n",
      "Loop  5056 :    Loss_Train:  [[ 4822.61391242]]    Loss_Validation:  [[ 1419.72197311]]\n",
      "Loop  5057 :    Loss_Train:  [[ 4822.61375338]]    Loss_Validation:  [[ 1419.72274349]]\n",
      "Loop  5058 :    Loss_Train:  [[ 4822.61359459]]    Loss_Validation:  [[ 1419.72351333]]\n",
      "Loop  5059 :    Loss_Train:  [[ 4822.61343606]]    Loss_Validation:  [[ 1419.72428263]]\n",
      "Loop  5060 :    Loss_Train:  [[ 4822.61327778]]    Loss_Validation:  [[ 1419.7250514]]\n",
      "Loop  5061 :    Loss_Train:  [[ 4822.61311977]]    Loss_Validation:  [[ 1419.72581962]]\n",
      "Loop  5062 :    Loss_Train:  [[ 4822.612962]]    Loss_Validation:  [[ 1419.72658731]]\n",
      "Loop  5063 :    Loss_Train:  [[ 4822.61280449]]    Loss_Validation:  [[ 1419.72735446]]\n",
      "Loop  5064 :    Loss_Train:  [[ 4822.61264724]]    Loss_Validation:  [[ 1419.72812108]]\n",
      "Loop  5065 :    Loss_Train:  [[ 4822.61249024]]    Loss_Validation:  [[ 1419.72888716]]\n",
      "Loop  5066 :    Loss_Train:  [[ 4822.6123335]]    Loss_Validation:  [[ 1419.72965271]]\n",
      "Loop  5067 :    Loss_Train:  [[ 4822.612177]]    Loss_Validation:  [[ 1419.73041772]]\n",
      "Loop  5068 :    Loss_Train:  [[ 4822.61202076]]    Loss_Validation:  [[ 1419.73118219]]\n",
      "Loop  5069 :    Loss_Train:  [[ 4822.61186478]]    Loss_Validation:  [[ 1419.73194613]]\n",
      "Loop  5070 :    Loss_Train:  [[ 4822.61170904]]    Loss_Validation:  [[ 1419.73270954]]\n",
      "Loop  5071 :    Loss_Train:  [[ 4822.61155356]]    Loss_Validation:  [[ 1419.73347241]]\n",
      "Loop  5072 :    Loss_Train:  [[ 4822.61139833]]    Loss_Validation:  [[ 1419.73423475]]\n",
      "Loop  5073 :    Loss_Train:  [[ 4822.61124335]]    Loss_Validation:  [[ 1419.73499656]]\n",
      "Loop  5074 :    Loss_Train:  [[ 4822.61108862]]    Loss_Validation:  [[ 1419.73575783]]\n",
      "Loop  5075 :    Loss_Train:  [[ 4822.61093414]]    Loss_Validation:  [[ 1419.73651857]]\n",
      "Loop  5076 :    Loss_Train:  [[ 4822.61077991]]    Loss_Validation:  [[ 1419.73727878]]\n",
      "Loop  5077 :    Loss_Train:  [[ 4822.61062592]]    Loss_Validation:  [[ 1419.73803846]]\n",
      "Loop  5078 :    Loss_Train:  [[ 4822.61047219]]    Loss_Validation:  [[ 1419.73879761]]\n",
      "Loop  5079 :    Loss_Train:  [[ 4822.61031871]]    Loss_Validation:  [[ 1419.73955623]]\n",
      "Loop  5080 :    Loss_Train:  [[ 4822.61016547]]    Loss_Validation:  [[ 1419.74031431]]\n",
      "Loop  5081 :    Loss_Train:  [[ 4822.61001248]]    Loss_Validation:  [[ 1419.74107187]]\n",
      "Loop  5082 :    Loss_Train:  [[ 4822.60985974]]    Loss_Validation:  [[ 1419.7418289]]\n",
      "Loop  5083 :    Loss_Train:  [[ 4822.60970725]]    Loss_Validation:  [[ 1419.7425854]]\n",
      "Loop  5084 :    Loss_Train:  [[ 4822.609555]]    Loss_Validation:  [[ 1419.74334137]]\n",
      "Loop  5085 :    Loss_Train:  [[ 4822.609403]]    Loss_Validation:  [[ 1419.74409681]]\n",
      "Loop  5086 :    Loss_Train:  [[ 4822.60925124]]    Loss_Validation:  [[ 1419.74485172]]\n",
      "Loop  5087 :    Loss_Train:  [[ 4822.60909973]]    Loss_Validation:  [[ 1419.7456061]]\n",
      "Loop  5088 :    Loss_Train:  [[ 4822.60894846]]    Loss_Validation:  [[ 1419.74635996]]\n",
      "Loop  5089 :    Loss_Train:  [[ 4822.60879744]]    Loss_Validation:  [[ 1419.74711329]]\n",
      "Loop  5090 :    Loss_Train:  [[ 4822.60864666]]    Loss_Validation:  [[ 1419.7478661]]\n",
      "Loop  5091 :    Loss_Train:  [[ 4822.60849612]]    Loss_Validation:  [[ 1419.74861837]]\n",
      "Loop  5092 :    Loss_Train:  [[ 4822.60834583]]    Loss_Validation:  [[ 1419.74937013]]\n",
      "Loop  5093 :    Loss_Train:  [[ 4822.60819578]]    Loss_Validation:  [[ 1419.75012135]]\n",
      "Loop  5094 :    Loss_Train:  [[ 4822.60804598]]    Loss_Validation:  [[ 1419.75087205]]\n",
      "Loop  5095 :    Loss_Train:  [[ 4822.60789641]]    Loss_Validation:  [[ 1419.75162223]]\n",
      "Loop  5096 :    Loss_Train:  [[ 4822.60774709]]    Loss_Validation:  [[ 1419.75237188]]\n",
      "Loop  5097 :    Loss_Train:  [[ 4822.60759801]]    Loss_Validation:  [[ 1419.75312101]]\n",
      "Loop  5098 :    Loss_Train:  [[ 4822.60744917]]    Loss_Validation:  [[ 1419.75386961]]\n",
      "Loop  5099 :    Loss_Train:  [[ 4822.60730057]]    Loss_Validation:  [[ 1419.75461769]]\n",
      "Loop  5100 :    Loss_Train:  [[ 4822.60715221]]    Loss_Validation:  [[ 1419.75536525]]\n",
      "Loop  5101 :    Loss_Train:  [[ 4822.60700409]]    Loss_Validation:  [[ 1419.75611229]]\n",
      "Loop  5102 :    Loss_Train:  [[ 4822.6068562]]    Loss_Validation:  [[ 1419.7568588]]\n",
      "Loop  5103 :    Loss_Train:  [[ 4822.60670856]]    Loss_Validation:  [[ 1419.75760479]]\n",
      "Loop  5104 :    Loss_Train:  [[ 4822.60656116]]    Loss_Validation:  [[ 1419.75835026]]\n",
      "Loop  5105 :    Loss_Train:  [[ 4822.60641399]]    Loss_Validation:  [[ 1419.75909521]]\n",
      "Loop  5106 :    Loss_Train:  [[ 4822.60626706]]    Loss_Validation:  [[ 1419.75983963]]\n",
      "Loop  5107 :    Loss_Train:  [[ 4822.60612037]]    Loss_Validation:  [[ 1419.76058354]]\n",
      "Loop  5108 :    Loss_Train:  [[ 4822.60597392]]    Loss_Validation:  [[ 1419.76132693]]\n",
      "Loop  5109 :    Loss_Train:  [[ 4822.6058277]]    Loss_Validation:  [[ 1419.76206979]]\n",
      "Loop  5110 :    Loss_Train:  [[ 4822.60568172]]    Loss_Validation:  [[ 1419.76281214]]\n",
      "Loop  5111 :    Loss_Train:  [[ 4822.60553597]]    Loss_Validation:  [[ 1419.76355397]]\n",
      "Loop  5112 :    Loss_Train:  [[ 4822.60539046]]    Loss_Validation:  [[ 1419.76429528]]\n",
      "Loop  5113 :    Loss_Train:  [[ 4822.60524519]]    Loss_Validation:  [[ 1419.76503607]]\n",
      "Loop  5114 :    Loss_Train:  [[ 4822.60510015]]    Loss_Validation:  [[ 1419.76577635]]\n",
      "Loop  5115 :    Loss_Train:  [[ 4822.60495534]]    Loss_Validation:  [[ 1419.7665161]]\n",
      "Loop  5116 :    Loss_Train:  [[ 4822.60481077]]    Loss_Validation:  [[ 1419.76725534]]\n",
      "Loop  5117 :    Loss_Train:  [[ 4822.60466643]]    Loss_Validation:  [[ 1419.76799406]]\n",
      "Loop  5118 :    Loss_Train:  [[ 4822.60452232]]    Loss_Validation:  [[ 1419.76873227]]\n",
      "Loop  5119 :    Loss_Train:  [[ 4822.60437845]]    Loss_Validation:  [[ 1419.76946996]]\n",
      "Loop  5120 :    Loss_Train:  [[ 4822.60423481]]    Loss_Validation:  [[ 1419.77020713]]\n",
      "Loop  5121 :    Loss_Train:  [[ 4822.6040914]]    Loss_Validation:  [[ 1419.77094379]]\n",
      "Loop  5122 :    Loss_Train:  [[ 4822.60394822]]    Loss_Validation:  [[ 1419.77167993]]\n",
      "Loop  5123 :    Loss_Train:  [[ 4822.60380528]]    Loss_Validation:  [[ 1419.77241556]]\n",
      "Loop  5124 :    Loss_Train:  [[ 4822.60366256]]    Loss_Validation:  [[ 1419.77315068]]\n",
      "Loop  5125 :    Loss_Train:  [[ 4822.60352007]]    Loss_Validation:  [[ 1419.77388528]]\n",
      "Loop  5126 :    Loss_Train:  [[ 4822.60337782]]    Loss_Validation:  [[ 1419.77461936]]\n",
      "Loop  5127 :    Loss_Train:  [[ 4822.60323579]]    Loss_Validation:  [[ 1419.77535294]]\n",
      "Loop  5128 :    Loss_Train:  [[ 4822.603094]]    Loss_Validation:  [[ 1419.776086]]\n",
      "Loop  5129 :    Loss_Train:  [[ 4822.60295243]]    Loss_Validation:  [[ 1419.77681855]]\n",
      "Loop  5130 :    Loss_Train:  [[ 4822.60281109]]    Loss_Validation:  [[ 1419.77755058]]\n",
      "Loop  5131 :    Loss_Train:  [[ 4822.60266998]]    Loss_Validation:  [[ 1419.7782821]]\n",
      "Loop  5132 :    Loss_Train:  [[ 4822.6025291]]    Loss_Validation:  [[ 1419.77901312]]\n",
      "Loop  5133 :    Loss_Train:  [[ 4822.60238844]]    Loss_Validation:  [[ 1419.77974362]]\n",
      "Loop  5134 :    Loss_Train:  [[ 4822.60224802]]    Loss_Validation:  [[ 1419.78047361]]\n",
      "Loop  5135 :    Loss_Train:  [[ 4822.60210781]]    Loss_Validation:  [[ 1419.78120309]]\n",
      "Loop  5136 :    Loss_Train:  [[ 4822.60196784]]    Loss_Validation:  [[ 1419.78193206]]\n",
      "Loop  5137 :    Loss_Train:  [[ 4822.60182809]]    Loss_Validation:  [[ 1419.78266052]]\n",
      "Loop  5138 :    Loss_Train:  [[ 4822.60168857]]    Loss_Validation:  [[ 1419.78338847]]\n",
      "Loop  5139 :    Loss_Train:  [[ 4822.60154927]]    Loss_Validation:  [[ 1419.78411591]]\n",
      "Loop  5140 :    Loss_Train:  [[ 4822.6014102]]    Loss_Validation:  [[ 1419.78484285]]\n",
      "Loop  5141 :    Loss_Train:  [[ 4822.60127135]]    Loss_Validation:  [[ 1419.78556927]]\n",
      "Loop  5142 :    Loss_Train:  [[ 4822.60113272]]    Loss_Validation:  [[ 1419.78629519]]\n",
      "Loop  5143 :    Loss_Train:  [[ 4822.60099432]]    Loss_Validation:  [[ 1419.7870206]]\n",
      "Loop  5144 :    Loss_Train:  [[ 4822.60085614]]    Loss_Validation:  [[ 1419.7877455]]\n",
      "Loop  5145 :    Loss_Train:  [[ 4822.60071819]]    Loss_Validation:  [[ 1419.7884699]]\n",
      "Loop  5146 :    Loss_Train:  [[ 4822.60058046]]    Loss_Validation:  [[ 1419.78919378]]\n",
      "Loop  5147 :    Loss_Train:  [[ 4822.60044295]]    Loss_Validation:  [[ 1419.78991717]]\n",
      "Loop  5148 :    Loss_Train:  [[ 4822.60030566]]    Loss_Validation:  [[ 1419.79064004]]\n",
      "Loop  5149 :    Loss_Train:  [[ 4822.60016859]]    Loss_Validation:  [[ 1419.79136242]]\n",
      "Loop  5150 :    Loss_Train:  [[ 4822.60003175]]    Loss_Validation:  [[ 1419.79208428]]\n",
      "Loop  5151 :    Loss_Train:  [[ 4822.59989512]]    Loss_Validation:  [[ 1419.79280564]]\n",
      "Loop  5152 :    Loss_Train:  [[ 4822.59975872]]    Loss_Validation:  [[ 1419.7935265]]\n",
      "Loop  5153 :    Loss_Train:  [[ 4822.59962254]]    Loss_Validation:  [[ 1419.79424685]]\n",
      "Loop  5154 :    Loss_Train:  [[ 4822.59948657]]    Loss_Validation:  [[ 1419.7949667]]\n",
      "Loop  5155 :    Loss_Train:  [[ 4822.59935083]]    Loss_Validation:  [[ 1419.79568605]]\n",
      "Loop  5156 :    Loss_Train:  [[ 4822.5992153]]    Loss_Validation:  [[ 1419.79640489]]\n",
      "Loop  5157 :    Loss_Train:  [[ 4822.59908]]    Loss_Validation:  [[ 1419.79712323]]\n",
      "Loop  5158 :    Loss_Train:  [[ 4822.59894491]]    Loss_Validation:  [[ 1419.79784107]]\n",
      "Loop  5159 :    Loss_Train:  [[ 4822.59881004]]    Loss_Validation:  [[ 1419.79855841]]\n",
      "Loop  5160 :    Loss_Train:  [[ 4822.59867539]]    Loss_Validation:  [[ 1419.79927524]]\n",
      "Loop  5161 :    Loss_Train:  [[ 4822.59854095]]    Loss_Validation:  [[ 1419.79999157]]\n",
      "Loop  5162 :    Loss_Train:  [[ 4822.59840673]]    Loss_Validation:  [[ 1419.80070741]]\n",
      "Loop  5163 :    Loss_Train:  [[ 4822.59827273]]    Loss_Validation:  [[ 1419.80142274]]\n",
      "Loop  5164 :    Loss_Train:  [[ 4822.59813895]]    Loss_Validation:  [[ 1419.80213757]]\n",
      "Loop  5165 :    Loss_Train:  [[ 4822.59800538]]    Loss_Validation:  [[ 1419.8028519]]\n",
      "Loop  5166 :    Loss_Train:  [[ 4822.59787202]]    Loss_Validation:  [[ 1419.80356573]]\n",
      "Loop  5167 :    Loss_Train:  [[ 4822.59773889]]    Loss_Validation:  [[ 1419.80427907]]\n",
      "Loop  5168 :    Loss_Train:  [[ 4822.59760596]]    Loss_Validation:  [[ 1419.8049919]]\n",
      "Loop  5169 :    Loss_Train:  [[ 4822.59747325]]    Loss_Validation:  [[ 1419.80570424]]\n",
      "Loop  5170 :    Loss_Train:  [[ 4822.59734076]]    Loss_Validation:  [[ 1419.80641607]]\n",
      "Loop  5171 :    Loss_Train:  [[ 4822.59720847]]    Loss_Validation:  [[ 1419.80712741]]\n",
      "Loop  5172 :    Loss_Train:  [[ 4822.59707641]]    Loss_Validation:  [[ 1419.80783826]]\n",
      "Loop  5173 :    Loss_Train:  [[ 4822.59694455]]    Loss_Validation:  [[ 1419.8085486]]\n",
      "Loop  5174 :    Loss_Train:  [[ 4822.59681291]]    Loss_Validation:  [[ 1419.80925845]]\n",
      "Loop  5175 :    Loss_Train:  [[ 4822.59668148]]    Loss_Validation:  [[ 1419.8099678]]\n",
      "Loop  5176 :    Loss_Train:  [[ 4822.59655026]]    Loss_Validation:  [[ 1419.81067666]]\n",
      "Loop  5177 :    Loss_Train:  [[ 4822.59641925]]    Loss_Validation:  [[ 1419.81138502]]\n",
      "Loop  5178 :    Loss_Train:  [[ 4822.59628846]]    Loss_Validation:  [[ 1419.81209288]]\n",
      "Loop  5179 :    Loss_Train:  [[ 4822.59615788]]    Loss_Validation:  [[ 1419.81280025]]\n",
      "Loop  5180 :    Loss_Train:  [[ 4822.5960275]]    Loss_Validation:  [[ 1419.81350713]]\n",
      "Loop  5181 :    Loss_Train:  [[ 4822.59589734]]    Loss_Validation:  [[ 1419.81421351]]\n",
      "Loop  5182 :    Loss_Train:  [[ 4822.59576739]]    Loss_Validation:  [[ 1419.81491939]]\n",
      "Loop  5183 :    Loss_Train:  [[ 4822.59563764]]    Loss_Validation:  [[ 1419.81562479]]\n",
      "Loop  5184 :    Loss_Train:  [[ 4822.59550811]]    Loss_Validation:  [[ 1419.81632968]]\n",
      "Loop  5185 :    Loss_Train:  [[ 4822.59537878]]    Loss_Validation:  [[ 1419.81703409]]\n",
      "Loop  5186 :    Loss_Train:  [[ 4822.59524967]]    Loss_Validation:  [[ 1419.81773801]]\n",
      "Loop  5187 :    Loss_Train:  [[ 4822.59512076]]    Loss_Validation:  [[ 1419.81844143]]\n",
      "Loop  5188 :    Loss_Train:  [[ 4822.59499206]]    Loss_Validation:  [[ 1419.81914436]]\n",
      "Loop  5189 :    Loss_Train:  [[ 4822.59486357]]    Loss_Validation:  [[ 1419.81984679]]\n",
      "Loop  5190 :    Loss_Train:  [[ 4822.59473528]]    Loss_Validation:  [[ 1419.82054874]]\n",
      "Loop  5191 :    Loss_Train:  [[ 4822.5946072]]    Loss_Validation:  [[ 1419.8212502]]\n",
      "Loop  5192 :    Loss_Train:  [[ 4822.59447933]]    Loss_Validation:  [[ 1419.82195116]]\n",
      "Loop  5193 :    Loss_Train:  [[ 4822.59435166]]    Loss_Validation:  [[ 1419.82265164]]\n",
      "Loop  5194 :    Loss_Train:  [[ 4822.5942242]]    Loss_Validation:  [[ 1419.82335162]]\n",
      "Loop  5195 :    Loss_Train:  [[ 4822.59409695]]    Loss_Validation:  [[ 1419.82405112]]\n",
      "Loop  5196 :    Loss_Train:  [[ 4822.5939699]]    Loss_Validation:  [[ 1419.82475013]]\n",
      "Loop  5197 :    Loss_Train:  [[ 4822.59384306]]    Loss_Validation:  [[ 1419.82544864]]\n",
      "Loop  5198 :    Loss_Train:  [[ 4822.59371642]]    Loss_Validation:  [[ 1419.82614667]]\n",
      "Loop  5199 :    Loss_Train:  [[ 4822.59358998]]    Loss_Validation:  [[ 1419.82684421]]\n",
      "Loop  5200 :    Loss_Train:  [[ 4822.59346375]]    Loss_Validation:  [[ 1419.82754127]]\n",
      "Loop  5201 :    Loss_Train:  [[ 4822.59333772]]    Loss_Validation:  [[ 1419.82823783]]\n",
      "Loop  5202 :    Loss_Train:  [[ 4822.5932119]]    Loss_Validation:  [[ 1419.82893391]]\n",
      "Loop  5203 :    Loss_Train:  [[ 4822.59308628]]    Loss_Validation:  [[ 1419.8296295]]\n",
      "Loop  5204 :    Loss_Train:  [[ 4822.59296086]]    Loss_Validation:  [[ 1419.8303246]]\n",
      "Loop  5205 :    Loss_Train:  [[ 4822.59283564]]    Loss_Validation:  [[ 1419.83101922]]\n",
      "Loop  5206 :    Loss_Train:  [[ 4822.59271063]]    Loss_Validation:  [[ 1419.83171336]]\n",
      "Loop  5207 :    Loss_Train:  [[ 4822.59258581]]    Loss_Validation:  [[ 1419.832407]]\n",
      "Loop  5208 :    Loss_Train:  [[ 4822.5924612]]    Loss_Validation:  [[ 1419.83310017]]\n",
      "Loop  5209 :    Loss_Train:  [[ 4822.59233679]]    Loss_Validation:  [[ 1419.83379284]]\n",
      "Loop  5210 :    Loss_Train:  [[ 4822.59221258]]    Loss_Validation:  [[ 1419.83448504]]\n",
      "Loop  5211 :    Loss_Train:  [[ 4822.59208857]]    Loss_Validation:  [[ 1419.83517674]]\n",
      "Loop  5212 :    Loss_Train:  [[ 4822.59196476]]    Loss_Validation:  [[ 1419.83586797]]\n",
      "Loop  5213 :    Loss_Train:  [[ 4822.59184115]]    Loss_Validation:  [[ 1419.83655871]]\n",
      "Loop  5214 :    Loss_Train:  [[ 4822.59171773]]    Loss_Validation:  [[ 1419.83724897]]\n",
      "Loop  5215 :    Loss_Train:  [[ 4822.59159452]]    Loss_Validation:  [[ 1419.83793874]]\n",
      "Loop  5216 :    Loss_Train:  [[ 4822.59147151]]    Loss_Validation:  [[ 1419.83862804]]\n",
      "Loop  5217 :    Loss_Train:  [[ 4822.59134869]]    Loss_Validation:  [[ 1419.83931685]]\n",
      "Loop  5218 :    Loss_Train:  [[ 4822.59122608]]    Loss_Validation:  [[ 1419.84000518]]\n",
      "Loop  5219 :    Loss_Train:  [[ 4822.59110366]]    Loss_Validation:  [[ 1419.84069302]]\n",
      "Loop  5220 :    Loss_Train:  [[ 4822.59098143]]    Loss_Validation:  [[ 1419.84138039]]\n",
      "Loop  5221 :    Loss_Train:  [[ 4822.59085941]]    Loss_Validation:  [[ 1419.84206728]]\n",
      "Loop  5222 :    Loss_Train:  [[ 4822.59073758]]    Loss_Validation:  [[ 1419.84275368]]\n",
      "Loop  5223 :    Loss_Train:  [[ 4822.59061595]]    Loss_Validation:  [[ 1419.84343961]]\n",
      "Loop  5224 :    Loss_Train:  [[ 4822.59049451]]    Loss_Validation:  [[ 1419.84412505]]\n",
      "Loop  5225 :    Loss_Train:  [[ 4822.59037327]]    Loss_Validation:  [[ 1419.84481002]]\n",
      "Loop  5226 :    Loss_Train:  [[ 4822.59025222]]    Loss_Validation:  [[ 1419.8454945]]\n",
      "Loop  5227 :    Loss_Train:  [[ 4822.59013137]]    Loss_Validation:  [[ 1419.84617851]]\n",
      "Loop  5228 :    Loss_Train:  [[ 4822.59001072]]    Loss_Validation:  [[ 1419.84686204]]\n",
      "Loop  5229 :    Loss_Train:  [[ 4822.58989026]]    Loss_Validation:  [[ 1419.84754509]]\n",
      "Loop  5230 :    Loss_Train:  [[ 4822.58976999]]    Loss_Validation:  [[ 1419.84822767]]\n",
      "Loop  5231 :    Loss_Train:  [[ 4822.58964992]]    Loss_Validation:  [[ 1419.84890976]]\n",
      "Loop  5232 :    Loss_Train:  [[ 4822.58953004]]    Loss_Validation:  [[ 1419.84959138]]\n",
      "Loop  5233 :    Loss_Train:  [[ 4822.58941036]]    Loss_Validation:  [[ 1419.85027252]]\n",
      "Loop  5234 :    Loss_Train:  [[ 4822.58929086]]    Loss_Validation:  [[ 1419.85095319]]\n",
      "Loop  5235 :    Loss_Train:  [[ 4822.58917156]]    Loss_Validation:  [[ 1419.85163338]]\n",
      "Loop  5236 :    Loss_Train:  [[ 4822.58905245]]    Loss_Validation:  [[ 1419.85231309]]\n",
      "Loop  5237 :    Loss_Train:  [[ 4822.58893354]]    Loss_Validation:  [[ 1419.85299233]]\n",
      "Loop  5238 :    Loss_Train:  [[ 4822.58881481]]    Loss_Validation:  [[ 1419.85367109]]\n",
      "Loop  5239 :    Loss_Train:  [[ 4822.58869628]]    Loss_Validation:  [[ 1419.85434938]]\n",
      "Loop  5240 :    Loss_Train:  [[ 4822.58857794]]    Loss_Validation:  [[ 1419.8550272]]\n",
      "Loop  5241 :    Loss_Train:  [[ 4822.58845979]]    Loss_Validation:  [[ 1419.85570453]]\n",
      "Loop  5242 :    Loss_Train:  [[ 4822.58834183]]    Loss_Validation:  [[ 1419.8563814]]\n",
      "Loop  5243 :    Loss_Train:  [[ 4822.58822406]]    Loss_Validation:  [[ 1419.85705779]]\n",
      "Loop  5244 :    Loss_Train:  [[ 4822.58810647]]    Loss_Validation:  [[ 1419.85773371]]\n",
      "Loop  5245 :    Loss_Train:  [[ 4822.58798908]]    Loss_Validation:  [[ 1419.85840916]]\n",
      "Loop  5246 :    Loss_Train:  [[ 4822.58787188]]    Loss_Validation:  [[ 1419.85908413]]\n",
      "Loop  5247 :    Loss_Train:  [[ 4822.58775487]]    Loss_Validation:  [[ 1419.85975863]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  5248 :    Loss_Train:  [[ 4822.58763804]]    Loss_Validation:  [[ 1419.86043266]]\n",
      "Loop  5249 :    Loss_Train:  [[ 4822.58752141]]    Loss_Validation:  [[ 1419.86110622]]\n",
      "Loop  5250 :    Loss_Train:  [[ 4822.58740496]]    Loss_Validation:  [[ 1419.86177931]]\n",
      "Loop  5251 :    Loss_Train:  [[ 4822.5872887]]    Loss_Validation:  [[ 1419.86245192]]\n",
      "Loop  5252 :    Loss_Train:  [[ 4822.58717262]]    Loss_Validation:  [[ 1419.86312407]]\n",
      "Loop  5253 :    Loss_Train:  [[ 4822.58705674]]    Loss_Validation:  [[ 1419.86379574]]\n",
      "Loop  5254 :    Loss_Train:  [[ 4822.58694104]]    Loss_Validation:  [[ 1419.86446695]]\n",
      "Loop  5255 :    Loss_Train:  [[ 4822.58682552]]    Loss_Validation:  [[ 1419.86513768]]\n",
      "Loop  5256 :    Loss_Train:  [[ 4822.58671019]]    Loss_Validation:  [[ 1419.86580795]]\n",
      "Loop  5257 :    Loss_Train:  [[ 4822.58659505]]    Loss_Validation:  [[ 1419.86647775]]\n",
      "Loop  5258 :    Loss_Train:  [[ 4822.5864801]]    Loss_Validation:  [[ 1419.86714708]]\n",
      "Loop  5259 :    Loss_Train:  [[ 4822.58636533]]    Loss_Validation:  [[ 1419.86781594]]\n",
      "Loop  5260 :    Loss_Train:  [[ 4822.58625074]]    Loss_Validation:  [[ 1419.86848433]]\n",
      "Loop  5261 :    Loss_Train:  [[ 4822.58613634]]    Loss_Validation:  [[ 1419.86915226]]\n",
      "Loop  5262 :    Loss_Train:  [[ 4822.58602212]]    Loss_Validation:  [[ 1419.86981971]]\n",
      "Loop  5263 :    Loss_Train:  [[ 4822.58590809]]    Loss_Validation:  [[ 1419.8704867]]\n",
      "Loop  5264 :    Loss_Train:  [[ 4822.58579424]]    Loss_Validation:  [[ 1419.87115323]]\n",
      "Loop  5265 :    Loss_Train:  [[ 4822.58568057]]    Loss_Validation:  [[ 1419.87181929]]\n",
      "Loop  5266 :    Loss_Train:  [[ 4822.58556709]]    Loss_Validation:  [[ 1419.87248488]]\n",
      "Loop  5267 :    Loss_Train:  [[ 4822.58545379]]    Loss_Validation:  [[ 1419.87315]]\n",
      "Loop  5268 :    Loss_Train:  [[ 4822.58534067]]    Loss_Validation:  [[ 1419.87381467]]\n",
      "Loop  5269 :    Loss_Train:  [[ 4822.58522774]]    Loss_Validation:  [[ 1419.87447886]]\n",
      "Loop  5270 :    Loss_Train:  [[ 4822.58511498]]    Loss_Validation:  [[ 1419.87514259]]\n",
      "Loop  5271 :    Loss_Train:  [[ 4822.58500241]]    Loss_Validation:  [[ 1419.87580586]]\n",
      "Loop  5272 :    Loss_Train:  [[ 4822.58489002]]    Loss_Validation:  [[ 1419.87646866]]\n",
      "Loop  5273 :    Loss_Train:  [[ 4822.58477781]]    Loss_Validation:  [[ 1419.877131]]\n",
      "Loop  5274 :    Loss_Train:  [[ 4822.58466578]]    Loss_Validation:  [[ 1419.87779288]]\n",
      "Loop  5275 :    Loss_Train:  [[ 4822.58455394]]    Loss_Validation:  [[ 1419.87845429]]\n",
      "Loop  5276 :    Loss_Train:  [[ 4822.58444227]]    Loss_Validation:  [[ 1419.87911524]]\n",
      "Loop  5277 :    Loss_Train:  [[ 4822.58433078]]    Loss_Validation:  [[ 1419.87977573]]\n",
      "Loop  5278 :    Loss_Train:  [[ 4822.58421947]]    Loss_Validation:  [[ 1419.88043575]]\n",
      "Loop  5279 :    Loss_Train:  [[ 4822.58410834]]    Loss_Validation:  [[ 1419.88109531]]\n",
      "Loop  5280 :    Loss_Train:  [[ 4822.58399739]]    Loss_Validation:  [[ 1419.88175442]]\n",
      "Loop  5281 :    Loss_Train:  [[ 4822.58388662]]    Loss_Validation:  [[ 1419.88241306]]\n",
      "Loop  5282 :    Loss_Train:  [[ 4822.58377603]]    Loss_Validation:  [[ 1419.88307124]]\n",
      "Loop  5283 :    Loss_Train:  [[ 4822.58366561]]    Loss_Validation:  [[ 1419.88372896]]\n",
      "Loop  5284 :    Loss_Train:  [[ 4822.58355538]]    Loss_Validation:  [[ 1419.88438621]]\n",
      "Loop  5285 :    Loss_Train:  [[ 4822.58344532]]    Loss_Validation:  [[ 1419.88504301]]\n",
      "Loop  5286 :    Loss_Train:  [[ 4822.58333543]]    Loss_Validation:  [[ 1419.88569935]]\n",
      "Loop  5287 :    Loss_Train:  [[ 4822.58322573]]    Loss_Validation:  [[ 1419.88635523]]\n",
      "Loop  5288 :    Loss_Train:  [[ 4822.5831162]]    Loss_Validation:  [[ 1419.88701065]]\n",
      "Loop  5289 :    Loss_Train:  [[ 4822.58300685]]    Loss_Validation:  [[ 1419.88766562]]\n",
      "Loop  5290 :    Loss_Train:  [[ 4822.58289767]]    Loss_Validation:  [[ 1419.88832012]]\n",
      "Loop  5291 :    Loss_Train:  [[ 4822.58278867]]    Loss_Validation:  [[ 1419.88897417]]\n",
      "Loop  5292 :    Loss_Train:  [[ 4822.58267985]]    Loss_Validation:  [[ 1419.88962776]]\n",
      "Loop  5293 :    Loss_Train:  [[ 4822.5825712]]    Loss_Validation:  [[ 1419.89028089]]\n",
      "Loop  5294 :    Loss_Train:  [[ 4822.58246272]]    Loss_Validation:  [[ 1419.89093356]]\n",
      "Loop  5295 :    Loss_Train:  [[ 4822.58235442]]    Loss_Validation:  [[ 1419.89158578]]\n",
      "Loop  5296 :    Loss_Train:  [[ 4822.5822463]]    Loss_Validation:  [[ 1419.89223754]]\n",
      "Loop  5297 :    Loss_Train:  [[ 4822.58213834]]    Loss_Validation:  [[ 1419.89288885]]\n",
      "Loop  5298 :    Loss_Train:  [[ 4822.58203057]]    Loss_Validation:  [[ 1419.8935397]]\n",
      "Loop  5299 :    Loss_Train:  [[ 4822.58192296]]    Loss_Validation:  [[ 1419.89419009]]\n",
      "Loop  5300 :    Loss_Train:  [[ 4822.58181553]]    Loss_Validation:  [[ 1419.89484003]]\n",
      "Loop  5301 :    Loss_Train:  [[ 4822.58170827]]    Loss_Validation:  [[ 1419.89548951]]\n",
      "Loop  5302 :    Loss_Train:  [[ 4822.58160119]]    Loss_Validation:  [[ 1419.89613854]]\n",
      "Loop  5303 :    Loss_Train:  [[ 4822.58149428]]    Loss_Validation:  [[ 1419.89678712]]\n",
      "Loop  5304 :    Loss_Train:  [[ 4822.58138754]]    Loss_Validation:  [[ 1419.89743524]]\n",
      "Loop  5305 :    Loss_Train:  [[ 4822.58128097]]    Loss_Validation:  [[ 1419.89808291]]\n",
      "Loop  5306 :    Loss_Train:  [[ 4822.58117457]]    Loss_Validation:  [[ 1419.89873012]]\n",
      "Loop  5307 :    Loss_Train:  [[ 4822.58106834]]    Loss_Validation:  [[ 1419.89937689]]\n",
      "Loop  5308 :    Loss_Train:  [[ 4822.58096229]]    Loss_Validation:  [[ 1419.9000232]]\n",
      "Loop  5309 :    Loss_Train:  [[ 4822.5808564]]    Loss_Validation:  [[ 1419.90066905]]\n",
      "Loop  5310 :    Loss_Train:  [[ 4822.58075069]]    Loss_Validation:  [[ 1419.90131446]]\n",
      "Loop  5311 :    Loss_Train:  [[ 4822.58064515]]    Loss_Validation:  [[ 1419.90195941]]\n",
      "Loop  5312 :    Loss_Train:  [[ 4822.58053977]]    Loss_Validation:  [[ 1419.90260391]]\n",
      "Loop  5313 :    Loss_Train:  [[ 4822.58043457]]    Loss_Validation:  [[ 1419.90324796]]\n",
      "Loop  5314 :    Loss_Train:  [[ 4822.58032953]]    Loss_Validation:  [[ 1419.90389156]]\n",
      "Loop  5315 :    Loss_Train:  [[ 4822.58022467]]    Loss_Validation:  [[ 1419.90453471]]\n",
      "Loop  5316 :    Loss_Train:  [[ 4822.58011997]]    Loss_Validation:  [[ 1419.90517741]]\n",
      "Loop  5317 :    Loss_Train:  [[ 4822.58001544]]    Loss_Validation:  [[ 1419.90581966]]\n",
      "Loop  5318 :    Loss_Train:  [[ 4822.57991108]]    Loss_Validation:  [[ 1419.90646147]]\n",
      "Loop  5319 :    Loss_Train:  [[ 4822.57980689]]    Loss_Validation:  [[ 1419.90710282]]\n",
      "Loop  5320 :    Loss_Train:  [[ 4822.57970287]]    Loss_Validation:  [[ 1419.90774372]]\n",
      "Loop  5321 :    Loss_Train:  [[ 4822.57959901]]    Loss_Validation:  [[ 1419.90838417]]\n",
      "Loop  5322 :    Loss_Train:  [[ 4822.57949532]]    Loss_Validation:  [[ 1419.90902418]]\n",
      "Loop  5323 :    Loss_Train:  [[ 4822.5793918]]    Loss_Validation:  [[ 1419.90966374]]\n",
      "Loop  5324 :    Loss_Train:  [[ 4822.57928844]]    Loss_Validation:  [[ 1419.91030285]]\n",
      "Loop  5325 :    Loss_Train:  [[ 4822.57918525]]    Loss_Validation:  [[ 1419.91094151]]\n",
      "Loop  5326 :    Loss_Train:  [[ 4822.57908223]]    Loss_Validation:  [[ 1419.91157973]]\n",
      "Loop  5327 :    Loss_Train:  [[ 4822.57897937]]    Loss_Validation:  [[ 1419.9122175]]\n",
      "Loop  5328 :    Loss_Train:  [[ 4822.57887668]]    Loss_Validation:  [[ 1419.91285482]]\n",
      "Loop  5329 :    Loss_Train:  [[ 4822.57877415]]    Loss_Validation:  [[ 1419.9134917]]\n",
      "Loop  5330 :    Loss_Train:  [[ 4822.57867179]]    Loss_Validation:  [[ 1419.91412813]]\n",
      "Loop  5331 :    Loss_Train:  [[ 4822.57856959]]    Loss_Validation:  [[ 1419.91476411]]\n",
      "Loop  5332 :    Loss_Train:  [[ 4822.57846756]]    Loss_Validation:  [[ 1419.91539965]]\n",
      "Loop  5333 :    Loss_Train:  [[ 4822.57836569]]    Loss_Validation:  [[ 1419.91603475]]\n",
      "Loop  5334 :    Loss_Train:  [[ 4822.57826399]]    Loss_Validation:  [[ 1419.9166694]]\n",
      "Loop  5335 :    Loss_Train:  [[ 4822.57816245]]    Loss_Validation:  [[ 1419.91730361]]\n",
      "Loop  5336 :    Loss_Train:  [[ 4822.57806107]]    Loss_Validation:  [[ 1419.91793737]]\n",
      "Loop  5337 :    Loss_Train:  [[ 4822.57795985]]    Loss_Validation:  [[ 1419.91857069]]\n",
      "Loop  5338 :    Loss_Train:  [[ 4822.5778588]]    Loss_Validation:  [[ 1419.91920357]]\n",
      "Loop  5339 :    Loss_Train:  [[ 4822.57775791]]    Loss_Validation:  [[ 1419.919836]]\n",
      "Loop  5340 :    Loss_Train:  [[ 4822.57765719]]    Loss_Validation:  [[ 1419.92046799]]\n",
      "Loop  5341 :    Loss_Train:  [[ 4822.57755662]]    Loss_Validation:  [[ 1419.92109954]]\n",
      "Loop  5342 :    Loss_Train:  [[ 4822.57745622]]    Loss_Validation:  [[ 1419.92173065]]\n",
      "Loop  5343 :    Loss_Train:  [[ 4822.57735598]]    Loss_Validation:  [[ 1419.92236131]]\n",
      "Loop  5344 :    Loss_Train:  [[ 4822.5772559]]    Loss_Validation:  [[ 1419.92299154]]\n",
      "Loop  5345 :    Loss_Train:  [[ 4822.57715598]]    Loss_Validation:  [[ 1419.92362132]]\n",
      "Loop  5346 :    Loss_Train:  [[ 4822.57705622]]    Loss_Validation:  [[ 1419.92425066]]\n",
      "Loop  5347 :    Loss_Train:  [[ 4822.57695662]]    Loss_Validation:  [[ 1419.92487956]]\n",
      "Loop  5348 :    Loss_Train:  [[ 4822.57685719]]    Loss_Validation:  [[ 1419.92550802]]\n",
      "Loop  5349 :    Loss_Train:  [[ 4822.57675791]]    Loss_Validation:  [[ 1419.92613604]]\n",
      "Loop  5350 :    Loss_Train:  [[ 4822.57665879]]    Loss_Validation:  [[ 1419.92676362]]\n",
      "Loop  5351 :    Loss_Train:  [[ 4822.57655983]]    Loss_Validation:  [[ 1419.92739077]]\n",
      "Loop  5352 :    Loss_Train:  [[ 4822.57646104]]    Loss_Validation:  [[ 1419.92801747]]\n",
      "Loop  5353 :    Loss_Train:  [[ 4822.5763624]]    Loss_Validation:  [[ 1419.92864373]]\n",
      "Loop  5354 :    Loss_Train:  [[ 4822.57626391]]    Loss_Validation:  [[ 1419.92926956]]\n",
      "Loop  5355 :    Loss_Train:  [[ 4822.57616559]]    Loss_Validation:  [[ 1419.92989495]]\n",
      "Loop  5356 :    Loss_Train:  [[ 4822.57606743]]    Loss_Validation:  [[ 1419.9305199]]\n",
      "Loop  5357 :    Loss_Train:  [[ 4822.57596942]]    Loss_Validation:  [[ 1419.93114441]]\n",
      "Loop  5358 :    Loss_Train:  [[ 4822.57587157]]    Loss_Validation:  [[ 1419.93176849]]\n",
      "Loop  5359 :    Loss_Train:  [[ 4822.57577388]]    Loss_Validation:  [[ 1419.93239212]]\n",
      "Loop  5360 :    Loss_Train:  [[ 4822.57567634]]    Loss_Validation:  [[ 1419.93301533]]\n",
      "Loop  5361 :    Loss_Train:  [[ 4822.57557897]]    Loss_Validation:  [[ 1419.93363809]]\n",
      "Loop  5362 :    Loss_Train:  [[ 4822.57548175]]    Loss_Validation:  [[ 1419.93426042]]\n",
      "Loop  5363 :    Loss_Train:  [[ 4822.57538468]]    Loss_Validation:  [[ 1419.93488232]]\n",
      "Loop  5364 :    Loss_Train:  [[ 4822.57528777]]    Loss_Validation:  [[ 1419.93550377]]\n",
      "Loop  5365 :    Loss_Train:  [[ 4822.57519102]]    Loss_Validation:  [[ 1419.9361248]]\n",
      "Loop  5366 :    Loss_Train:  [[ 4822.57509442]]    Loss_Validation:  [[ 1419.93674539]]\n",
      "Loop  5367 :    Loss_Train:  [[ 4822.57499798]]    Loss_Validation:  [[ 1419.93736554]]\n",
      "Loop  5368 :    Loss_Train:  [[ 4822.5749017]]    Loss_Validation:  [[ 1419.93798526]]\n",
      "Loop  5369 :    Loss_Train:  [[ 4822.57480556]]    Loss_Validation:  [[ 1419.93860455]]\n",
      "Loop  5370 :    Loss_Train:  [[ 4822.57470959]]    Loss_Validation:  [[ 1419.9392234]]\n",
      "Loop  5371 :    Loss_Train:  [[ 4822.57461377]]    Loss_Validation:  [[ 1419.93984182]]\n",
      "Loop  5372 :    Loss_Train:  [[ 4822.5745181]]    Loss_Validation:  [[ 1419.94045981]]\n",
      "Loop  5373 :    Loss_Train:  [[ 4822.57442258]]    Loss_Validation:  [[ 1419.94107737]]\n",
      "Loop  5374 :    Loss_Train:  [[ 4822.57432722]]    Loss_Validation:  [[ 1419.94169449]]\n",
      "Loop  5375 :    Loss_Train:  [[ 4822.57423201]]    Loss_Validation:  [[ 1419.94231118]]\n",
      "Loop  5376 :    Loss_Train:  [[ 4822.57413696]]    Loss_Validation:  [[ 1419.94292744]]\n",
      "Loop  5377 :    Loss_Train:  [[ 4822.57404206]]    Loss_Validation:  [[ 1419.94354326]]\n",
      "Loop  5378 :    Loss_Train:  [[ 4822.57394731]]    Loss_Validation:  [[ 1419.94415866]]\n",
      "Loop  5379 :    Loss_Train:  [[ 4822.57385271]]    Loss_Validation:  [[ 1419.94477362]]\n",
      "Loop  5380 :    Loss_Train:  [[ 4822.57375827]]    Loss_Validation:  [[ 1419.94538816]]\n",
      "Loop  5381 :    Loss_Train:  [[ 4822.57366398]]    Loss_Validation:  [[ 1419.94600226]]\n",
      "Loop  5382 :    Loss_Train:  [[ 4822.57356983]]    Loss_Validation:  [[ 1419.94661594]]\n",
      "Loop  5383 :    Loss_Train:  [[ 4822.57347585]]    Loss_Validation:  [[ 1419.94722918]]\n",
      "Loop  5384 :    Loss_Train:  [[ 4822.57338201]]    Loss_Validation:  [[ 1419.947842]]\n",
      "Loop  5385 :    Loss_Train:  [[ 4822.57328832]]    Loss_Validation:  [[ 1419.94845438]]\n",
      "Loop  5386 :    Loss_Train:  [[ 4822.57319478]]    Loss_Validation:  [[ 1419.94906634]]\n",
      "Loop  5387 :    Loss_Train:  [[ 4822.5731014]]    Loss_Validation:  [[ 1419.94967787]]\n",
      "Loop  5388 :    Loss_Train:  [[ 4822.57300816]]    Loss_Validation:  [[ 1419.95028897]]\n",
      "Loop  5389 :    Loss_Train:  [[ 4822.57291507]]    Loss_Validation:  [[ 1419.95089965]]\n",
      "Loop  5390 :    Loss_Train:  [[ 4822.57282214]]    Loss_Validation:  [[ 1419.95150989]]\n",
      "Loop  5391 :    Loss_Train:  [[ 4822.57272935]]    Loss_Validation:  [[ 1419.95211971]]\n",
      "Loop  5392 :    Loss_Train:  [[ 4822.57263671]]    Loss_Validation:  [[ 1419.9527291]]\n",
      "Loop  5393 :    Loss_Train:  [[ 4822.57254422]]    Loss_Validation:  [[ 1419.95333807]]\n",
      "Loop  5394 :    Loss_Train:  [[ 4822.57245188]]    Loss_Validation:  [[ 1419.9539466]]\n",
      "Loop  5395 :    Loss_Train:  [[ 4822.57235969]]    Loss_Validation:  [[ 1419.95455472]]\n",
      "Loop  5396 :    Loss_Train:  [[ 4822.57226765]]    Loss_Validation:  [[ 1419.9551624]]\n",
      "Loop  5397 :    Loss_Train:  [[ 4822.57217575]]    Loss_Validation:  [[ 1419.95576966]]\n",
      "Loop  5398 :    Loss_Train:  [[ 4822.572084]]    Loss_Validation:  [[ 1419.9563765]]\n",
      "Loop  5399 :    Loss_Train:  [[ 4822.5719924]]    Loss_Validation:  [[ 1419.95698291]]\n",
      "Loop  5400 :    Loss_Train:  [[ 4822.57190095]]    Loss_Validation:  [[ 1419.9575889]]\n",
      "Loop  5401 :    Loss_Train:  [[ 4822.57180964]]    Loss_Validation:  [[ 1419.95819446]]\n",
      "Loop  5402 :    Loss_Train:  [[ 4822.57171848]]    Loss_Validation:  [[ 1419.9587996]]\n",
      "Loop  5403 :    Loss_Train:  [[ 4822.57162747]]    Loss_Validation:  [[ 1419.95940431]]\n",
      "Loop  5404 :    Loss_Train:  [[ 4822.57153661]]    Loss_Validation:  [[ 1419.9600086]]\n",
      "Loop  5405 :    Loss_Train:  [[ 4822.57144588]]    Loss_Validation:  [[ 1419.96061247]]\n",
      "Loop  5406 :    Loss_Train:  [[ 4822.57135531]]    Loss_Validation:  [[ 1419.96121592]]\n",
      "Loop  5407 :    Loss_Train:  [[ 4822.57126488]]    Loss_Validation:  [[ 1419.96181894]]\n",
      "Loop  5408 :    Loss_Train:  [[ 4822.5711746]]    Loss_Validation:  [[ 1419.96242154]]\n",
      "Loop  5409 :    Loss_Train:  [[ 4822.57108446]]    Loss_Validation:  [[ 1419.96302372]]\n",
      "Loop  5410 :    Loss_Train:  [[ 4822.57099447]]    Loss_Validation:  [[ 1419.96362548]]\n",
      "Loop  5411 :    Loss_Train:  [[ 4822.57090462]]    Loss_Validation:  [[ 1419.96422681]]\n",
      "Loop  5412 :    Loss_Train:  [[ 4822.57081491]]    Loss_Validation:  [[ 1419.96482773]]\n",
      "Loop  5413 :    Loss_Train:  [[ 4822.57072535]]    Loss_Validation:  [[ 1419.96542822]]\n",
      "Loop  5414 :    Loss_Train:  [[ 4822.57063594]]    Loss_Validation:  [[ 1419.96602829]]\n",
      "Loop  5415 :    Loss_Train:  [[ 4822.57054666]]    Loss_Validation:  [[ 1419.96662794]]\n",
      "Loop  5416 :    Loss_Train:  [[ 4822.57045753]]    Loss_Validation:  [[ 1419.96722718]]\n",
      "Loop  5417 :    Loss_Train:  [[ 4822.57036855]]    Loss_Validation:  [[ 1419.96782599]]\n",
      "Loop  5418 :    Loss_Train:  [[ 4822.57027971]]    Loss_Validation:  [[ 1419.96842439]]\n",
      "Loop  5419 :    Loss_Train:  [[ 4822.57019101]]    Loss_Validation:  [[ 1419.96902236]]\n",
      "Loop  5420 :    Loss_Train:  [[ 4822.57010245]]    Loss_Validation:  [[ 1419.96961992]]\n",
      "Loop  5421 :    Loss_Train:  [[ 4822.57001403]]    Loss_Validation:  [[ 1419.97021705]]\n",
      "Loop  5422 :    Loss_Train:  [[ 4822.56992576]]    Loss_Validation:  [[ 1419.97081377]]\n",
      "Loop  5423 :    Loss_Train:  [[ 4822.56983763]]    Loss_Validation:  [[ 1419.97141008]]\n",
      "Loop  5424 :    Loss_Train:  [[ 4822.56974964]]    Loss_Validation:  [[ 1419.97200596]]\n",
      "Loop  5425 :    Loss_Train:  [[ 4822.56966179]]    Loss_Validation:  [[ 1419.97260143]]\n",
      "Loop  5426 :    Loss_Train:  [[ 4822.56957408]]    Loss_Validation:  [[ 1419.97319648]]\n",
      "Loop  5427 :    Loss_Train:  [[ 4822.56948652]]    Loss_Validation:  [[ 1419.97379111]]\n",
      "Loop  5428 :    Loss_Train:  [[ 4822.56939909]]    Loss_Validation:  [[ 1419.97438533]]\n",
      "Loop  5429 :    Loss_Train:  [[ 4822.56931181]]    Loss_Validation:  [[ 1419.97497913]]\n",
      "Loop  5430 :    Loss_Train:  [[ 4822.56922466]]    Loss_Validation:  [[ 1419.97557251]]\n",
      "Loop  5431 :    Loss_Train:  [[ 4822.56913766]]    Loss_Validation:  [[ 1419.97616548]]\n",
      "Loop  5432 :    Loss_Train:  [[ 4822.56905079]]    Loss_Validation:  [[ 1419.97675804]]\n",
      "Loop  5433 :    Loss_Train:  [[ 4822.56896407]]    Loss_Validation:  [[ 1419.97735018]]\n",
      "Loop  5434 :    Loss_Train:  [[ 4822.56887748]]    Loss_Validation:  [[ 1419.9779419]]\n",
      "Loop  5435 :    Loss_Train:  [[ 4822.56879104]]    Loss_Validation:  [[ 1419.97853321]]\n",
      "Loop  5436 :    Loss_Train:  [[ 4822.56870473]]    Loss_Validation:  [[ 1419.97912411]]\n",
      "Loop  5437 :    Loss_Train:  [[ 4822.56861856]]    Loss_Validation:  [[ 1419.97971459]]\n",
      "Loop  5438 :    Loss_Train:  [[ 4822.56853253]]    Loss_Validation:  [[ 1419.98030466]]\n",
      "Loop  5439 :    Loss_Train:  [[ 4822.56844664]]    Loss_Validation:  [[ 1419.98089431]]\n",
      "Loop  5440 :    Loss_Train:  [[ 4822.56836088]]    Loss_Validation:  [[ 1419.98148356]]\n",
      "Loop  5441 :    Loss_Train:  [[ 4822.56827527]]    Loss_Validation:  [[ 1419.98207239]]\n",
      "Loop  5442 :    Loss_Train:  [[ 4822.56818979]]    Loss_Validation:  [[ 1419.9826608]]\n",
      "Loop  5443 :    Loss_Train:  [[ 4822.56810445]]    Loss_Validation:  [[ 1419.98324881]]\n",
      "Loop  5444 :    Loss_Train:  [[ 4822.56801924]]    Loss_Validation:  [[ 1419.9838364]]\n",
      "Loop  5445 :    Loss_Train:  [[ 4822.56793418]]    Loss_Validation:  [[ 1419.98442358]]\n",
      "Loop  5446 :    Loss_Train:  [[ 4822.56784924]]    Loss_Validation:  [[ 1419.98501036]]\n",
      "Loop  5447 :    Loss_Train:  [[ 4822.56776445]]    Loss_Validation:  [[ 1419.98559672]]\n",
      "Loop  5448 :    Loss_Train:  [[ 4822.56767979]]    Loss_Validation:  [[ 1419.98618266]]\n",
      "Loop  5449 :    Loss_Train:  [[ 4822.56759527]]    Loss_Validation:  [[ 1419.9867682]]\n",
      "Loop  5450 :    Loss_Train:  [[ 4822.56751088]]    Loss_Validation:  [[ 1419.98735333]]\n",
      "Loop  5451 :    Loss_Train:  [[ 4822.56742663]]    Loss_Validation:  [[ 1419.98793805]]\n",
      "Loop  5452 :    Loss_Train:  [[ 4822.56734252]]    Loss_Validation:  [[ 1419.98852236]]\n",
      "Loop  5453 :    Loss_Train:  [[ 4822.56725854]]    Loss_Validation:  [[ 1419.98910626]]\n",
      "Loop  5454 :    Loss_Train:  [[ 4822.56717469]]    Loss_Validation:  [[ 1419.98968975]]\n",
      "Loop  5455 :    Loss_Train:  [[ 4822.56709098]]    Loss_Validation:  [[ 1419.99027283]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  5456 :    Loss_Train:  [[ 4822.5670074]]    Loss_Validation:  [[ 1419.99085551]]\n",
      "Loop  5457 :    Loss_Train:  [[ 4822.56692396]]    Loss_Validation:  [[ 1419.99143777]]\n",
      "Loop  5458 :    Loss_Train:  [[ 4822.56684065]]    Loss_Validation:  [[ 1419.99201963]]\n",
      "Loop  5459 :    Loss_Train:  [[ 4822.56675748]]    Loss_Validation:  [[ 1419.99260108]]\n",
      "Loop  5460 :    Loss_Train:  [[ 4822.56667444]]    Loss_Validation:  [[ 1419.99318213]]\n",
      "Loop  5461 :    Loss_Train:  [[ 4822.56659153]]    Loss_Validation:  [[ 1419.99376276]]\n",
      "Loop  5462 :    Loss_Train:  [[ 4822.56650876]]    Loss_Validation:  [[ 1419.99434299]]\n",
      "Loop  5463 :    Loss_Train:  [[ 4822.56642612]]    Loss_Validation:  [[ 1419.99492281]]\n",
      "Loop  5464 :    Loss_Train:  [[ 4822.56634361]]    Loss_Validation:  [[ 1419.99550223]]\n",
      "Loop  5465 :    Loss_Train:  [[ 4822.56626123]]    Loss_Validation:  [[ 1419.99608124]]\n",
      "Loop  5466 :    Loss_Train:  [[ 4822.56617899]]    Loss_Validation:  [[ 1419.99665985]]\n",
      "Loop  5467 :    Loss_Train:  [[ 4822.56609688]]    Loss_Validation:  [[ 1419.99723805]]\n",
      "Loop  5468 :    Loss_Train:  [[ 4822.5660149]]    Loss_Validation:  [[ 1419.99781584]]\n",
      "Loop  5469 :    Loss_Train:  [[ 4822.56593305]]    Loss_Validation:  [[ 1419.99839323]]\n",
      "Loop  5470 :    Loss_Train:  [[ 4822.56585133]]    Loss_Validation:  [[ 1419.99897022]]\n",
      "Loop  5471 :    Loss_Train:  [[ 4822.56576975]]    Loss_Validation:  [[ 1419.9995468]]\n",
      "Loop  5472 :    Loss_Train:  [[ 4822.56568829]]    Loss_Validation:  [[ 1420.00012298]]\n",
      "Loop  5473 :    Loss_Train:  [[ 4822.56560697]]    Loss_Validation:  [[ 1420.00069875]]\n",
      "Loop  5474 :    Loss_Train:  [[ 4822.56552578]]    Loss_Validation:  [[ 1420.00127413]]\n",
      "Loop  5475 :    Loss_Train:  [[ 4822.56544472]]    Loss_Validation:  [[ 1420.00184909]]\n",
      "Loop  5476 :    Loss_Train:  [[ 4822.56536378]]    Loss_Validation:  [[ 1420.00242366]]\n",
      "Loop  5477 :    Loss_Train:  [[ 4822.56528298]]    Loss_Validation:  [[ 1420.00299782]]\n",
      "Loop  5478 :    Loss_Train:  [[ 4822.56520231]]    Loss_Validation:  [[ 1420.00357158]]\n",
      "Loop  5479 :    Loss_Train:  [[ 4822.56512177]]    Loss_Validation:  [[ 1420.00414494]]\n",
      "Loop  5480 :    Loss_Train:  [[ 4822.56504135]]    Loss_Validation:  [[ 1420.0047179]]\n",
      "Loop  5481 :    Loss_Train:  [[ 4822.56496107]]    Loss_Validation:  [[ 1420.00529045]]\n",
      "Loop  5482 :    Loss_Train:  [[ 4822.56488091]]    Loss_Validation:  [[ 1420.00586261]]\n",
      "Loop  5483 :    Loss_Train:  [[ 4822.56480089]]    Loss_Validation:  [[ 1420.00643436]]\n",
      "Loop  5484 :    Loss_Train:  [[ 4822.56472099]]    Loss_Validation:  [[ 1420.00700572]]\n",
      "Loop  5485 :    Loss_Train:  [[ 4822.56464122]]    Loss_Validation:  [[ 1420.00757667]]\n",
      "Loop  5486 :    Loss_Train:  [[ 4822.56456158]]    Loss_Validation:  [[ 1420.00814722]]\n",
      "Loop  5487 :    Loss_Train:  [[ 4822.56448206]]    Loss_Validation:  [[ 1420.00871738]]\n",
      "Loop  5488 :    Loss_Train:  [[ 4822.56440268]]    Loss_Validation:  [[ 1420.00928713]]\n",
      "Loop  5489 :    Loss_Train:  [[ 4822.56432342]]    Loss_Validation:  [[ 1420.00985648]]\n",
      "Loop  5490 :    Loss_Train:  [[ 4822.56424428]]    Loss_Validation:  [[ 1420.01042544]]\n",
      "Loop  5491 :    Loss_Train:  [[ 4822.56416528]]    Loss_Validation:  [[ 1420.010994]]\n",
      "Loop  5492 :    Loss_Train:  [[ 4822.5640864]]    Loss_Validation:  [[ 1420.01156216]]\n",
      "Loop  5493 :    Loss_Train:  [[ 4822.56400765]]    Loss_Validation:  [[ 1420.01212992]]\n",
      "Loop  5494 :    Loss_Train:  [[ 4822.56392903]]    Loss_Validation:  [[ 1420.01269728]]\n",
      "Loop  5495 :    Loss_Train:  [[ 4822.56385053]]    Loss_Validation:  [[ 1420.01326425]]\n",
      "Loop  5496 :    Loss_Train:  [[ 4822.56377216]]    Loss_Validation:  [[ 1420.01383082]]\n",
      "Loop  5497 :    Loss_Train:  [[ 4822.56369391]]    Loss_Validation:  [[ 1420.01439699]]\n",
      "Loop  5498 :    Loss_Train:  [[ 4822.56361579]]    Loss_Validation:  [[ 1420.01496276]]\n",
      "Loop  5499 :    Loss_Train:  [[ 4822.56353779]]    Loss_Validation:  [[ 1420.01552814]]\n",
      "Loop  5500 :    Loss_Train:  [[ 4822.56345992]]    Loss_Validation:  [[ 1420.01609312]]\n",
      "Loop  5501 :    Loss_Train:  [[ 4822.56338218]]    Loss_Validation:  [[ 1420.01665771]]\n",
      "Loop  5502 :    Loss_Train:  [[ 4822.56330456]]    Loss_Validation:  [[ 1420.0172219]]\n",
      "Loop  5503 :    Loss_Train:  [[ 4822.56322706]]    Loss_Validation:  [[ 1420.0177857]]\n",
      "Loop  5504 :    Loss_Train:  [[ 4822.56314969]]    Loss_Validation:  [[ 1420.0183491]]\n",
      "Loop  5505 :    Loss_Train:  [[ 4822.56307244]]    Loss_Validation:  [[ 1420.0189121]]\n",
      "Loop  5506 :    Loss_Train:  [[ 4822.56299532]]    Loss_Validation:  [[ 1420.01947471]]\n",
      "Loop  5507 :    Loss_Train:  [[ 4822.56291832]]    Loss_Validation:  [[ 1420.02003693]]\n",
      "Loop  5508 :    Loss_Train:  [[ 4822.56284144]]    Loss_Validation:  [[ 1420.02059876]]\n",
      "Loop  5509 :    Loss_Train:  [[ 4822.56276469]]    Loss_Validation:  [[ 1420.02116019]]\n",
      "Loop  5510 :    Loss_Train:  [[ 4822.56268806]]    Loss_Validation:  [[ 1420.02172122]]\n",
      "Loop  5511 :    Loss_Train:  [[ 4822.56261156]]    Loss_Validation:  [[ 1420.02228186]]\n",
      "Loop  5512 :    Loss_Train:  [[ 4822.56253517]]    Loss_Validation:  [[ 1420.02284212]]\n",
      "Loop  5513 :    Loss_Train:  [[ 4822.56245891]]    Loss_Validation:  [[ 1420.02340197]]\n",
      "Loop  5514 :    Loss_Train:  [[ 4822.56238277]]    Loss_Validation:  [[ 1420.02396144]]\n",
      "Loop  5515 :    Loss_Train:  [[ 4822.56230676]]    Loss_Validation:  [[ 1420.02452051]]\n",
      "Loop  5516 :    Loss_Train:  [[ 4822.56223086]]    Loss_Validation:  [[ 1420.02507919]]\n",
      "Loop  5517 :    Loss_Train:  [[ 4822.56215509]]    Loss_Validation:  [[ 1420.02563749]]\n",
      "Loop  5518 :    Loss_Train:  [[ 4822.56207944]]    Loss_Validation:  [[ 1420.02619538]]\n",
      "Loop  5519 :    Loss_Train:  [[ 4822.56200391]]    Loss_Validation:  [[ 1420.02675289]]\n",
      "Loop  5520 :    Loss_Train:  [[ 4822.5619285]]    Loss_Validation:  [[ 1420.02731001]]\n",
      "Loop  5521 :    Loss_Train:  [[ 4822.56185321]]    Loss_Validation:  [[ 1420.02786674]]\n",
      "Loop  5522 :    Loss_Train:  [[ 4822.56177805]]    Loss_Validation:  [[ 1420.02842308]]\n",
      "Loop  5523 :    Loss_Train:  [[ 4822.561703]]    Loss_Validation:  [[ 1420.02897902]]\n",
      "Loop  5524 :    Loss_Train:  [[ 4822.56162808]]    Loss_Validation:  [[ 1420.02953458]]\n",
      "Loop  5525 :    Loss_Train:  [[ 4822.56155327]]    Loss_Validation:  [[ 1420.03008975]]\n",
      "Loop  5526 :    Loss_Train:  [[ 4822.56147859]]    Loss_Validation:  [[ 1420.03064453]]\n",
      "Loop  5527 :    Loss_Train:  [[ 4822.56140402]]    Loss_Validation:  [[ 1420.03119892]]\n",
      "Loop  5528 :    Loss_Train:  [[ 4822.56132957]]    Loss_Validation:  [[ 1420.03175292]]\n",
      "Loop  5529 :    Loss_Train:  [[ 4822.56125525]]    Loss_Validation:  [[ 1420.03230654]]\n",
      "Loop  5530 :    Loss_Train:  [[ 4822.56118104]]    Loss_Validation:  [[ 1420.03285976]]\n",
      "Loop  5531 :    Loss_Train:  [[ 4822.56110695]]    Loss_Validation:  [[ 1420.0334126]]\n",
      "Loop  5532 :    Loss_Train:  [[ 4822.56103299]]    Loss_Validation:  [[ 1420.03396505]]\n",
      "Loop  5533 :    Loss_Train:  [[ 4822.56095913]]    Loss_Validation:  [[ 1420.03451712]]\n",
      "Loop  5534 :    Loss_Train:  [[ 4822.5608854]]    Loss_Validation:  [[ 1420.03506879]]\n",
      "Loop  5535 :    Loss_Train:  [[ 4822.56081179]]    Loss_Validation:  [[ 1420.03562008]]\n",
      "Loop  5536 :    Loss_Train:  [[ 4822.56073829]]    Loss_Validation:  [[ 1420.03617099]]\n",
      "Loop  5537 :    Loss_Train:  [[ 4822.56066492]]    Loss_Validation:  [[ 1420.03672151]]\n",
      "Loop  5538 :    Loss_Train:  [[ 4822.56059166]]    Loss_Validation:  [[ 1420.03727164]]\n",
      "Loop  5539 :    Loss_Train:  [[ 4822.56051852]]    Loss_Validation:  [[ 1420.03782138]]\n",
      "Loop  5540 :    Loss_Train:  [[ 4822.56044549]]    Loss_Validation:  [[ 1420.03837075]]\n",
      "Loop  5541 :    Loss_Train:  [[ 4822.56037258]]    Loss_Validation:  [[ 1420.03891972]]\n",
      "Loop  5542 :    Loss_Train:  [[ 4822.56029979]]    Loss_Validation:  [[ 1420.03946831]]\n",
      "Loop  5543 :    Loss_Train:  [[ 4822.56022712]]    Loss_Validation:  [[ 1420.04001652]]\n",
      "Loop  5544 :    Loss_Train:  [[ 4822.56015456]]    Loss_Validation:  [[ 1420.04056435]]\n",
      "Loop  5545 :    Loss_Train:  [[ 4822.56008212]]    Loss_Validation:  [[ 1420.04111178]]\n",
      "Loop  5546 :    Loss_Train:  [[ 4822.5600098]]    Loss_Validation:  [[ 1420.04165884]]\n",
      "Loop  5547 :    Loss_Train:  [[ 4822.55993759]]    Loss_Validation:  [[ 1420.04220551]]\n",
      "Loop  5548 :    Loss_Train:  [[ 4822.5598655]]    Loss_Validation:  [[ 1420.0427518]]\n",
      "Loop  5549 :    Loss_Train:  [[ 4822.55979352]]    Loss_Validation:  [[ 1420.04329771]]\n",
      "Loop  5550 :    Loss_Train:  [[ 4822.55972166]]    Loss_Validation:  [[ 1420.04384323]]\n",
      "Loop  5551 :    Loss_Train:  [[ 4822.55964991]]    Loss_Validation:  [[ 1420.04438837]]\n",
      "Loop  5552 :    Loss_Train:  [[ 4822.55957828]]    Loss_Validation:  [[ 1420.04493313]]\n",
      "Loop  5553 :    Loss_Train:  [[ 4822.55950676]]    Loss_Validation:  [[ 1420.04547751]]\n",
      "Loop  5554 :    Loss_Train:  [[ 4822.55943536]]    Loss_Validation:  [[ 1420.0460215]]\n",
      "Loop  5555 :    Loss_Train:  [[ 4822.55936407]]    Loss_Validation:  [[ 1420.04656512]]\n",
      "Loop  5556 :    Loss_Train:  [[ 4822.5592929]]    Loss_Validation:  [[ 1420.04710835]]\n",
      "Loop  5557 :    Loss_Train:  [[ 4822.55922184]]    Loss_Validation:  [[ 1420.04765121]]\n",
      "Loop  5558 :    Loss_Train:  [[ 4822.5591509]]    Loss_Validation:  [[ 1420.04819368]]\n",
      "Loop  5559 :    Loss_Train:  [[ 4822.55908007]]    Loss_Validation:  [[ 1420.04873577]]\n",
      "Loop  5560 :    Loss_Train:  [[ 4822.55900935]]    Loss_Validation:  [[ 1420.04927748]]\n",
      "Loop  5561 :    Loss_Train:  [[ 4822.55893875]]    Loss_Validation:  [[ 1420.04981882]]\n",
      "Loop  5562 :    Loss_Train:  [[ 4822.55886826]]    Loss_Validation:  [[ 1420.05035977]]\n",
      "Loop  5563 :    Loss_Train:  [[ 4822.55879788]]    Loss_Validation:  [[ 1420.05090034]]\n",
      "Loop  5564 :    Loss_Train:  [[ 4822.55872761]]    Loss_Validation:  [[ 1420.05144054]]\n",
      "Loop  5565 :    Loss_Train:  [[ 4822.55865746]]    Loss_Validation:  [[ 1420.05198035]]\n",
      "Loop  5566 :    Loss_Train:  [[ 4822.55858742]]    Loss_Validation:  [[ 1420.05251979]]\n",
      "Loop  5567 :    Loss_Train:  [[ 4822.5585175]]    Loss_Validation:  [[ 1420.05305885]]\n",
      "Loop  5568 :    Loss_Train:  [[ 4822.55844768]]    Loss_Validation:  [[ 1420.05359753]]\n",
      "Loop  5569 :    Loss_Train:  [[ 4822.55837798]]    Loss_Validation:  [[ 1420.05413584]]\n",
      "Loop  5570 :    Loss_Train:  [[ 4822.55830839]]    Loss_Validation:  [[ 1420.05467377]]\n",
      "Loop  5571 :    Loss_Train:  [[ 4822.55823891]]    Loss_Validation:  [[ 1420.05521132]]\n",
      "Loop  5572 :    Loss_Train:  [[ 4822.55816954]]    Loss_Validation:  [[ 1420.05574849]]\n",
      "Loop  5573 :    Loss_Train:  [[ 4822.55810028]]    Loss_Validation:  [[ 1420.05628529]]\n",
      "Loop  5574 :    Loss_Train:  [[ 4822.55803114]]    Loss_Validation:  [[ 1420.05682171]]\n",
      "Loop  5575 :    Loss_Train:  [[ 4822.5579621]]    Loss_Validation:  [[ 1420.05735775]]\n",
      "Loop  5576 :    Loss_Train:  [[ 4822.55789318]]    Loss_Validation:  [[ 1420.05789342]]\n",
      "Loop  5577 :    Loss_Train:  [[ 4822.55782437]]    Loss_Validation:  [[ 1420.05842871]]\n",
      "Loop  5578 :    Loss_Train:  [[ 4822.55775566]]    Loss_Validation:  [[ 1420.05896363]]\n",
      "Loop  5579 :    Loss_Train:  [[ 4822.55768707]]    Loss_Validation:  [[ 1420.05949818]]\n",
      "Loop  5580 :    Loss_Train:  [[ 4822.55761859]]    Loss_Validation:  [[ 1420.06003234]]\n",
      "Loop  5581 :    Loss_Train:  [[ 4822.55755021]]    Loss_Validation:  [[ 1420.06056614]]\n",
      "Loop  5582 :    Loss_Train:  [[ 4822.55748195]]    Loss_Validation:  [[ 1420.06109956]]\n",
      "Loop  5583 :    Loss_Train:  [[ 4822.5574138]]    Loss_Validation:  [[ 1420.0616326]]\n",
      "Loop  5584 :    Loss_Train:  [[ 4822.55734575]]    Loss_Validation:  [[ 1420.06216528]]\n",
      "Loop  5585 :    Loss_Train:  [[ 4822.55727781]]    Loss_Validation:  [[ 1420.06269757]]\n",
      "Loop  5586 :    Loss_Train:  [[ 4822.55720999]]    Loss_Validation:  [[ 1420.0632295]]\n",
      "Loop  5587 :    Loss_Train:  [[ 4822.55714227]]    Loss_Validation:  [[ 1420.06376105]]\n",
      "Loop  5588 :    Loss_Train:  [[ 4822.55707466]]    Loss_Validation:  [[ 1420.06429223]]\n",
      "Loop  5589 :    Loss_Train:  [[ 4822.55700716]]    Loss_Validation:  [[ 1420.06482304]]\n",
      "Loop  5590 :    Loss_Train:  [[ 4822.55693977]]    Loss_Validation:  [[ 1420.06535348]]\n",
      "Loop  5591 :    Loss_Train:  [[ 4822.55687248]]    Loss_Validation:  [[ 1420.06588354]]\n",
      "Loop  5592 :    Loss_Train:  [[ 4822.5568053]]    Loss_Validation:  [[ 1420.06641323]]\n",
      "Loop  5593 :    Loss_Train:  [[ 4822.55673823]]    Loss_Validation:  [[ 1420.06694255]]\n",
      "Loop  5594 :    Loss_Train:  [[ 4822.55667127]]    Loss_Validation:  [[ 1420.0674715]]\n",
      "Loop  5595 :    Loss_Train:  [[ 4822.55660442]]    Loss_Validation:  [[ 1420.06800008]]\n",
      "Loop  5596 :    Loss_Train:  [[ 4822.55653767]]    Loss_Validation:  [[ 1420.06852829]]\n",
      "Loop  5597 :    Loss_Train:  [[ 4822.55647103]]    Loss_Validation:  [[ 1420.06905613]]\n",
      "Loop  5598 :    Loss_Train:  [[ 4822.5564045]]    Loss_Validation:  [[ 1420.0695836]]\n",
      "Loop  5599 :    Loss_Train:  [[ 4822.55633807]]    Loss_Validation:  [[ 1420.0701107]]\n",
      "Loop  5600 :    Loss_Train:  [[ 4822.55627175]]    Loss_Validation:  [[ 1420.07063742]]\n",
      "Loop  5601 :    Loss_Train:  [[ 4822.55620554]]    Loss_Validation:  [[ 1420.07116378]]\n",
      "Loop  5602 :    Loss_Train:  [[ 4822.55613943]]    Loss_Validation:  [[ 1420.07168977]]\n",
      "Loop  5603 :    Loss_Train:  [[ 4822.55607343]]    Loss_Validation:  [[ 1420.0722154]]\n",
      "Loop  5604 :    Loss_Train:  [[ 4822.55600753]]    Loss_Validation:  [[ 1420.07274065]]\n",
      "Loop  5605 :    Loss_Train:  [[ 4822.55594174]]    Loss_Validation:  [[ 1420.07326553]]\n",
      "Loop  5606 :    Loss_Train:  [[ 4822.55587606]]    Loss_Validation:  [[ 1420.07379005]]\n",
      "Loop  5607 :    Loss_Train:  [[ 4822.55581048]]    Loss_Validation:  [[ 1420.0743142]]\n",
      "Loop  5608 :    Loss_Train:  [[ 4822.555745]]    Loss_Validation:  [[ 1420.07483798]]\n",
      "Loop  5609 :    Loss_Train:  [[ 4822.55567963]]    Loss_Validation:  [[ 1420.0753614]]\n",
      "Loop  5610 :    Loss_Train:  [[ 4822.55561437]]    Loss_Validation:  [[ 1420.07588444]]\n",
      "Loop  5611 :    Loss_Train:  [[ 4822.55554921]]    Loss_Validation:  [[ 1420.07640712]]\n",
      "Loop  5612 :    Loss_Train:  [[ 4822.55548415]]    Loss_Validation:  [[ 1420.07692944]]\n",
      "Loop  5613 :    Loss_Train:  [[ 4822.5554192]]    Loss_Validation:  [[ 1420.07745139]]\n",
      "Loop  5614 :    Loss_Train:  [[ 4822.55535435]]    Loss_Validation:  [[ 1420.07797297]]\n",
      "Loop  5615 :    Loss_Train:  [[ 4822.55528961]]    Loss_Validation:  [[ 1420.07849418]]\n",
      "Loop  5616 :    Loss_Train:  [[ 4822.55522497]]    Loss_Validation:  [[ 1420.07901504]]\n",
      "Loop  5617 :    Loss_Train:  [[ 4822.55516043]]    Loss_Validation:  [[ 1420.07953552]]\n",
      "Loop  5618 :    Loss_Train:  [[ 4822.555096]]    Loss_Validation:  [[ 1420.08005564]]\n",
      "Loop  5619 :    Loss_Train:  [[ 4822.55503167]]    Loss_Validation:  [[ 1420.0805754]]\n",
      "Loop  5620 :    Loss_Train:  [[ 4822.55496745]]    Loss_Validation:  [[ 1420.08109479]]\n",
      "Loop  5621 :    Loss_Train:  [[ 4822.55490332]]    Loss_Validation:  [[ 1420.08161382]]\n",
      "Loop  5622 :    Loss_Train:  [[ 4822.5548393]]    Loss_Validation:  [[ 1420.08213248]]\n",
      "Loop  5623 :    Loss_Train:  [[ 4822.55477538]]    Loss_Validation:  [[ 1420.08265078]]\n",
      "Loop  5624 :    Loss_Train:  [[ 4822.55471157]]    Loss_Validation:  [[ 1420.08316872]]\n",
      "Loop  5625 :    Loss_Train:  [[ 4822.55464786]]    Loss_Validation:  [[ 1420.08368629]]\n",
      "Loop  5626 :    Loss_Train:  [[ 4822.55458424]]    Loss_Validation:  [[ 1420.0842035]]\n",
      "Loop  5627 :    Loss_Train:  [[ 4822.55452074]]    Loss_Validation:  [[ 1420.08472035]]\n",
      "Loop  5628 :    Loss_Train:  [[ 4822.55445733]]    Loss_Validation:  [[ 1420.08523683]]\n",
      "Loop  5629 :    Loss_Train:  [[ 4822.55439402]]    Loss_Validation:  [[ 1420.08575295]]\n",
      "Loop  5630 :    Loss_Train:  [[ 4822.55433082]]    Loss_Validation:  [[ 1420.08626872]]\n",
      "Loop  5631 :    Loss_Train:  [[ 4822.55426771]]    Loss_Validation:  [[ 1420.08678412]]\n",
      "Loop  5632 :    Loss_Train:  [[ 4822.55420471]]    Loss_Validation:  [[ 1420.08729915]]\n",
      "Loop  5633 :    Loss_Train:  [[ 4822.55414181]]    Loss_Validation:  [[ 1420.08781383]]\n",
      "Loop  5634 :    Loss_Train:  [[ 4822.55407901]]    Loss_Validation:  [[ 1420.08832815]]\n",
      "Loop  5635 :    Loss_Train:  [[ 4822.55401631]]    Loss_Validation:  [[ 1420.0888421]]\n",
      "Loop  5636 :    Loss_Train:  [[ 4822.55395371]]    Loss_Validation:  [[ 1420.0893557]]\n",
      "Loop  5637 :    Loss_Train:  [[ 4822.55389121]]    Loss_Validation:  [[ 1420.08986893]]\n",
      "Loop  5638 :    Loss_Train:  [[ 4822.55382881]]    Loss_Validation:  [[ 1420.09038181]]\n",
      "Loop  5639 :    Loss_Train:  [[ 4822.55376652]]    Loss_Validation:  [[ 1420.09089432]]\n",
      "Loop  5640 :    Loss_Train:  [[ 4822.55370432]]    Loss_Validation:  [[ 1420.09140648]]\n",
      "Loop  5641 :    Loss_Train:  [[ 4822.55364222]]    Loss_Validation:  [[ 1420.09191827]]\n",
      "Loop  5642 :    Loss_Train:  [[ 4822.55358022]]    Loss_Validation:  [[ 1420.09242971]]\n",
      "Loop  5643 :    Loss_Train:  [[ 4822.55351832]]    Loss_Validation:  [[ 1420.09294079]]\n",
      "Loop  5644 :    Loss_Train:  [[ 4822.55345652]]    Loss_Validation:  [[ 1420.09345151]]\n",
      "Loop  5645 :    Loss_Train:  [[ 4822.55339481]]    Loss_Validation:  [[ 1420.09396187]]\n",
      "Loop  5646 :    Loss_Train:  [[ 4822.55333321]]    Loss_Validation:  [[ 1420.09447188]]\n",
      "Loop  5647 :    Loss_Train:  [[ 4822.55327171]]    Loss_Validation:  [[ 1420.09498152]]\n",
      "Loop  5648 :    Loss_Train:  [[ 4822.5532103]]    Loss_Validation:  [[ 1420.09549081]]\n",
      "Loop  5649 :    Loss_Train:  [[ 4822.55314899]]    Loss_Validation:  [[ 1420.09599974]]\n",
      "Loop  5650 :    Loss_Train:  [[ 4822.55308778]]    Loss_Validation:  [[ 1420.09650832]]\n",
      "Loop  5651 :    Loss_Train:  [[ 4822.55302667]]    Loss_Validation:  [[ 1420.09701654]]\n",
      "Loop  5652 :    Loss_Train:  [[ 4822.55296566]]    Loss_Validation:  [[ 1420.0975244]]\n",
      "Loop  5653 :    Loss_Train:  [[ 4822.55290474]]    Loss_Validation:  [[ 1420.09803191]]\n",
      "Loop  5654 :    Loss_Train:  [[ 4822.55284392]]    Loss_Validation:  [[ 1420.09853905]]\n",
      "Loop  5655 :    Loss_Train:  [[ 4822.5527832]]    Loss_Validation:  [[ 1420.09904585]]\n",
      "Loop  5656 :    Loss_Train:  [[ 4822.55272258]]    Loss_Validation:  [[ 1420.09955229]]\n",
      "Loop  5657 :    Loss_Train:  [[ 4822.55266205]]    Loss_Validation:  [[ 1420.10005837]]\n",
      "Loop  5658 :    Loss_Train:  [[ 4822.55260162]]    Loss_Validation:  [[ 1420.1005641]]\n",
      "Loop  5659 :    Loss_Train:  [[ 4822.55254129]]    Loss_Validation:  [[ 1420.10106947]]\n",
      "Loop  5660 :    Loss_Train:  [[ 4822.55248105]]    Loss_Validation:  [[ 1420.10157449]]\n",
      "Loop  5661 :    Loss_Train:  [[ 4822.55242091]]    Loss_Validation:  [[ 1420.10207916]]\n",
      "Loop  5662 :    Loss_Train:  [[ 4822.55236087]]    Loss_Validation:  [[ 1420.10258347]]\n",
      "Loop  5663 :    Loss_Train:  [[ 4822.55230092]]    Loss_Validation:  [[ 1420.10308743]]\n",
      "Loop  5664 :    Loss_Train:  [[ 4822.55224107]]    Loss_Validation:  [[ 1420.10359103]]\n",
      "Loop  5665 :    Loss_Train:  [[ 4822.55218132]]    Loss_Validation:  [[ 1420.10409428]]\n",
      "Loop  5666 :    Loss_Train:  [[ 4822.55212166]]    Loss_Validation:  [[ 1420.10459718]]\n",
      "Loop  5667 :    Loss_Train:  [[ 4822.55206209]]    Loss_Validation:  [[ 1420.10509973]]\n",
      "Loop  5668 :    Loss_Train:  [[ 4822.55200262]]    Loss_Validation:  [[ 1420.10560192]]\n",
      "Loop  5669 :    Loss_Train:  [[ 4822.55194325]]    Loss_Validation:  [[ 1420.10610376]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  5670 :    Loss_Train:  [[ 4822.55188397]]    Loss_Validation:  [[ 1420.10660525]]\n",
      "Loop  5671 :    Loss_Train:  [[ 4822.55182479]]    Loss_Validation:  [[ 1420.10710638]]\n",
      "Loop  5672 :    Loss_Train:  [[ 4822.5517657]]    Loss_Validation:  [[ 1420.10760717]]\n",
      "Loop  5673 :    Loss_Train:  [[ 4822.55170671]]    Loss_Validation:  [[ 1420.1081076]]\n",
      "Loop  5674 :    Loss_Train:  [[ 4822.55164781]]    Loss_Validation:  [[ 1420.10860769]]\n",
      "Loop  5675 :    Loss_Train:  [[ 4822.551589]]    Loss_Validation:  [[ 1420.10910742]]\n",
      "Loop  5676 :    Loss_Train:  [[ 4822.55153029]]    Loss_Validation:  [[ 1420.1096068]]\n",
      "Loop  5677 :    Loss_Train:  [[ 4822.55147167]]    Loss_Validation:  [[ 1420.11010583]]\n",
      "Loop  5678 :    Loss_Train:  [[ 4822.55141315]]    Loss_Validation:  [[ 1420.11060451]]\n",
      "Loop  5679 :    Loss_Train:  [[ 4822.55135472]]    Loss_Validation:  [[ 1420.11110284]]\n",
      "Loop  5680 :    Loss_Train:  [[ 4822.55129639]]    Loss_Validation:  [[ 1420.11160082]]\n",
      "Loop  5681 :    Loss_Train:  [[ 4822.55123814]]    Loss_Validation:  [[ 1420.11209846]]\n",
      "Loop  5682 :    Loss_Train:  [[ 4822.55118]]    Loss_Validation:  [[ 1420.11259574]]\n",
      "Loop  5683 :    Loss_Train:  [[ 4822.55112194]]    Loss_Validation:  [[ 1420.11309267]]\n",
      "Loop  5684 :    Loss_Train:  [[ 4822.55106398]]    Loss_Validation:  [[ 1420.11358926]]\n",
      "Loop  5685 :    Loss_Train:  [[ 4822.55100611]]    Loss_Validation:  [[ 1420.1140855]]\n",
      "Loop  5686 :    Loss_Train:  [[ 4822.55094833]]    Loss_Validation:  [[ 1420.11458139]]\n",
      "Loop  5687 :    Loss_Train:  [[ 4822.55089064]]    Loss_Validation:  [[ 1420.11507693]]\n",
      "Loop  5688 :    Loss_Train:  [[ 4822.55083305]]    Loss_Validation:  [[ 1420.11557212]]\n",
      "Loop  5689 :    Loss_Train:  [[ 4822.55077555]]    Loss_Validation:  [[ 1420.11606697]]\n",
      "Loop  5690 :    Loss_Train:  [[ 4822.55071814]]    Loss_Validation:  [[ 1420.11656147]]\n",
      "Loop  5691 :    Loss_Train:  [[ 4822.55066083]]    Loss_Validation:  [[ 1420.11705562]]\n",
      "Loop  5692 :    Loss_Train:  [[ 4822.5506036]]    Loss_Validation:  [[ 1420.11754943]]\n",
      "Loop  5693 :    Loss_Train:  [[ 4822.55054647]]    Loss_Validation:  [[ 1420.11804289]]\n",
      "Loop  5694 :    Loss_Train:  [[ 4822.55048943]]    Loss_Validation:  [[ 1420.118536]]\n",
      "Loop  5695 :    Loss_Train:  [[ 4822.55043248]]    Loss_Validation:  [[ 1420.11902877]]\n",
      "Loop  5696 :    Loss_Train:  [[ 4822.55037562]]    Loss_Validation:  [[ 1420.11952119]]\n",
      "Loop  5697 :    Loss_Train:  [[ 4822.55031885]]    Loss_Validation:  [[ 1420.12001326]]\n",
      "Loop  5698 :    Loss_Train:  [[ 4822.55026217]]    Loss_Validation:  [[ 1420.12050499]]\n",
      "Loop  5699 :    Loss_Train:  [[ 4822.55020558]]    Loss_Validation:  [[ 1420.12099638]]\n",
      "Loop  5700 :    Loss_Train:  [[ 4822.55014909]]    Loss_Validation:  [[ 1420.12148742]]\n",
      "Loop  5701 :    Loss_Train:  [[ 4822.55009268]]    Loss_Validation:  [[ 1420.12197812]]\n",
      "Loop  5702 :    Loss_Train:  [[ 4822.55003637]]    Loss_Validation:  [[ 1420.12246847]]\n",
      "Loop  5703 :    Loss_Train:  [[ 4822.54998014]]    Loss_Validation:  [[ 1420.12295848]]\n",
      "Loop  5704 :    Loss_Train:  [[ 4822.54992401]]    Loss_Validation:  [[ 1420.12344814]]\n",
      "Loop  5705 :    Loss_Train:  [[ 4822.54986796]]    Loss_Validation:  [[ 1420.12393746]]\n",
      "Loop  5706 :    Loss_Train:  [[ 4822.54981201]]    Loss_Validation:  [[ 1420.12442644]]\n",
      "Loop  5707 :    Loss_Train:  [[ 4822.54975614]]    Loss_Validation:  [[ 1420.12491508]]\n",
      "Loop  5708 :    Loss_Train:  [[ 4822.54970037]]    Loss_Validation:  [[ 1420.12540337]]\n",
      "Loop  5709 :    Loss_Train:  [[ 4822.54964468]]    Loss_Validation:  [[ 1420.12589132]]\n",
      "Loop  5710 :    Loss_Train:  [[ 4822.54958908]]    Loss_Validation:  [[ 1420.12637892]]\n",
      "Loop  5711 :    Loss_Train:  [[ 4822.54953357]]    Loss_Validation:  [[ 1420.12686619]]\n",
      "Loop  5712 :    Loss_Train:  [[ 4822.54947815]]    Loss_Validation:  [[ 1420.12735311]]\n",
      "Loop  5713 :    Loss_Train:  [[ 4822.54942282]]    Loss_Validation:  [[ 1420.12783969]]\n",
      "Loop  5714 :    Loss_Train:  [[ 4822.54936758]]    Loss_Validation:  [[ 1420.12832593]]\n",
      "Loop  5715 :    Loss_Train:  [[ 4822.54931242]]    Loss_Validation:  [[ 1420.12881183]]\n",
      "Loop  5716 :    Loss_Train:  [[ 4822.54925736]]    Loss_Validation:  [[ 1420.12929739]]\n",
      "Loop  5717 :    Loss_Train:  [[ 4822.54920238]]    Loss_Validation:  [[ 1420.1297826]]\n",
      "Loop  5718 :    Loss_Train:  [[ 4822.54914749]]    Loss_Validation:  [[ 1420.13026748]]\n",
      "Loop  5719 :    Loss_Train:  [[ 4822.54909269]]    Loss_Validation:  [[ 1420.13075202]]\n",
      "Loop  5720 :    Loss_Train:  [[ 4822.54903797]]    Loss_Validation:  [[ 1420.13123621]]\n",
      "Loop  5721 :    Loss_Train:  [[ 4822.54898334]]    Loss_Validation:  [[ 1420.13172007]]\n",
      "Loop  5722 :    Loss_Train:  [[ 4822.54892881]]    Loss_Validation:  [[ 1420.13220359]]\n",
      "Loop  5723 :    Loss_Train:  [[ 4822.54887435]]    Loss_Validation:  [[ 1420.13268676]]\n",
      "Loop  5724 :    Loss_Train:  [[ 4822.54881999]]    Loss_Validation:  [[ 1420.1331696]]\n",
      "Loop  5725 :    Loss_Train:  [[ 4822.54876571]]    Loss_Validation:  [[ 1420.1336521]]\n",
      "Loop  5726 :    Loss_Train:  [[ 4822.54871152]]    Loss_Validation:  [[ 1420.13413426]]\n",
      "Loop  5727 :    Loss_Train:  [[ 4822.54865741]]    Loss_Validation:  [[ 1420.13461609]]\n",
      "Loop  5728 :    Loss_Train:  [[ 4822.5486034]]    Loss_Validation:  [[ 1420.13509757]]\n",
      "Loop  5729 :    Loss_Train:  [[ 4822.54854946]]    Loss_Validation:  [[ 1420.13557872]]\n",
      "Loop  5730 :    Loss_Train:  [[ 4822.54849562]]    Loss_Validation:  [[ 1420.13605953]]\n",
      "Loop  5731 :    Loss_Train:  [[ 4822.54844186]]    Loss_Validation:  [[ 1420.13654]]\n",
      "Loop  5732 :    Loss_Train:  [[ 4822.54838819]]    Loss_Validation:  [[ 1420.13702013]]\n",
      "Loop  5733 :    Loss_Train:  [[ 4822.5483346]]    Loss_Validation:  [[ 1420.13749993]]\n",
      "Loop  5734 :    Loss_Train:  [[ 4822.5482811]]    Loss_Validation:  [[ 1420.13797939]]\n",
      "Loop  5735 :    Loss_Train:  [[ 4822.54822768]]    Loss_Validation:  [[ 1420.13845852]]\n",
      "Loop  5736 :    Loss_Train:  [[ 4822.54817435]]    Loss_Validation:  [[ 1420.1389373]]\n",
      "Loop  5737 :    Loss_Train:  [[ 4822.54812111]]    Loss_Validation:  [[ 1420.13941576]]\n",
      "Loop  5738 :    Loss_Train:  [[ 4822.54806795]]    Loss_Validation:  [[ 1420.13989387]]\n",
      "Loop  5739 :    Loss_Train:  [[ 4822.54801487]]    Loss_Validation:  [[ 1420.14037165]]\n",
      "Loop  5740 :    Loss_Train:  [[ 4822.54796188]]    Loss_Validation:  [[ 1420.1408491]]\n",
      "Loop  5741 :    Loss_Train:  [[ 4822.54790898]]    Loss_Validation:  [[ 1420.14132621]]\n",
      "Loop  5742 :    Loss_Train:  [[ 4822.54785616]]    Loss_Validation:  [[ 1420.14180299]]\n",
      "Loop  5743 :    Loss_Train:  [[ 4822.54780342]]    Loss_Validation:  [[ 1420.14227943]]\n",
      "Loop  5744 :    Loss_Train:  [[ 4822.54775077]]    Loss_Validation:  [[ 1420.14275553]]\n",
      "Loop  5745 :    Loss_Train:  [[ 4822.54769821]]    Loss_Validation:  [[ 1420.14323131]]\n",
      "Loop  5746 :    Loss_Train:  [[ 4822.54764572]]    Loss_Validation:  [[ 1420.14370675]]\n",
      "Loop  5747 :    Loss_Train:  [[ 4822.54759332]]    Loss_Validation:  [[ 1420.14418185]]\n",
      "Loop  5748 :    Loss_Train:  [[ 4822.54754101]]    Loss_Validation:  [[ 1420.14465662]]\n",
      "Loop  5749 :    Loss_Train:  [[ 4822.54748878]]    Loss_Validation:  [[ 1420.14513106]]\n",
      "Loop  5750 :    Loss_Train:  [[ 4822.54743663]]    Loss_Validation:  [[ 1420.14560517]]\n",
      "Loop  5751 :    Loss_Train:  [[ 4822.54738456]]    Loss_Validation:  [[ 1420.14607894]]\n",
      "Loop  5752 :    Loss_Train:  [[ 4822.54733258]]    Loss_Validation:  [[ 1420.14655238]]\n",
      "Loop  5753 :    Loss_Train:  [[ 4822.54728068]]    Loss_Validation:  [[ 1420.14702549]]\n",
      "Loop  5754 :    Loss_Train:  [[ 4822.54722887]]    Loss_Validation:  [[ 1420.14749826]]\n",
      "Loop  5755 :    Loss_Train:  [[ 4822.54717714]]    Loss_Validation:  [[ 1420.14797071]]\n",
      "Loop  5756 :    Loss_Train:  [[ 4822.54712549]]    Loss_Validation:  [[ 1420.14844282]]\n",
      "Loop  5757 :    Loss_Train:  [[ 4822.54707392]]    Loss_Validation:  [[ 1420.1489146]]\n",
      "Loop  5758 :    Loss_Train:  [[ 4822.54702244]]    Loss_Validation:  [[ 1420.14938605]]\n",
      "Loop  5759 :    Loss_Train:  [[ 4822.54697103]]    Loss_Validation:  [[ 1420.14985717]]\n",
      "Loop  5760 :    Loss_Train:  [[ 4822.54691972]]    Loss_Validation:  [[ 1420.15032796]]\n",
      "Loop  5761 :    Loss_Train:  [[ 4822.54686848]]    Loss_Validation:  [[ 1420.15079841]]\n",
      "Loop  5762 :    Loss_Train:  [[ 4822.54681732]]    Loss_Validation:  [[ 1420.15126854]]\n",
      "Loop  5763 :    Loss_Train:  [[ 4822.54676625]]    Loss_Validation:  [[ 1420.15173834]]\n",
      "Loop  5764 :    Loss_Train:  [[ 4822.54671526]]    Loss_Validation:  [[ 1420.15220781]]\n",
      "Loop  5765 :    Loss_Train:  [[ 4822.54666435]]    Loss_Validation:  [[ 1420.15267695]]\n",
      "Loop  5766 :    Loss_Train:  [[ 4822.54661352]]    Loss_Validation:  [[ 1420.15314576]]\n",
      "Loop  5767 :    Loss_Train:  [[ 4822.54656277]]    Loss_Validation:  [[ 1420.15361424]]\n",
      "Loop  5768 :    Loss_Train:  [[ 4822.5465121]]    Loss_Validation:  [[ 1420.15408239]]\n",
      "Loop  5769 :    Loss_Train:  [[ 4822.54646152]]    Loss_Validation:  [[ 1420.15455021]]\n",
      "Loop  5770 :    Loss_Train:  [[ 4822.54641101]]    Loss_Validation:  [[ 1420.1550177]]\n",
      "Loop  5771 :    Loss_Train:  [[ 4822.54636059]]    Loss_Validation:  [[ 1420.15548487]]\n",
      "Loop  5772 :    Loss_Train:  [[ 4822.54631024]]    Loss_Validation:  [[ 1420.15595171]]\n",
      "Loop  5773 :    Loss_Train:  [[ 4822.54625998]]    Loss_Validation:  [[ 1420.15641822]]\n",
      "Loop  5774 :    Loss_Train:  [[ 4822.5462098]]    Loss_Validation:  [[ 1420.1568844]]\n",
      "Loop  5775 :    Loss_Train:  [[ 4822.5461597]]    Loss_Validation:  [[ 1420.15735026]]\n",
      "Loop  5776 :    Loss_Train:  [[ 4822.54610967]]    Loss_Validation:  [[ 1420.15781578]]\n",
      "Loop  5777 :    Loss_Train:  [[ 4822.54605973]]    Loss_Validation:  [[ 1420.15828099]]\n",
      "Loop  5778 :    Loss_Train:  [[ 4822.54600987]]    Loss_Validation:  [[ 1420.15874586]]\n",
      "Loop  5779 :    Loss_Train:  [[ 4822.54596009]]    Loss_Validation:  [[ 1420.15921041]]\n",
      "Loop  5780 :    Loss_Train:  [[ 4822.54591038]]    Loss_Validation:  [[ 1420.15967463]]\n",
      "Loop  5781 :    Loss_Train:  [[ 4822.54586076]]    Loss_Validation:  [[ 1420.16013853]]\n",
      "Loop  5782 :    Loss_Train:  [[ 4822.54581122]]    Loss_Validation:  [[ 1420.1606021]]\n",
      "Loop  5783 :    Loss_Train:  [[ 4822.54576175]]    Loss_Validation:  [[ 1420.16106535]]\n",
      "Loop  5784 :    Loss_Train:  [[ 4822.54571237]]    Loss_Validation:  [[ 1420.16152827]]\n",
      "Loop  5785 :    Loss_Train:  [[ 4822.54566306]]    Loss_Validation:  [[ 1420.16199086]]\n",
      "Loop  5786 :    Loss_Train:  [[ 4822.54561383]]    Loss_Validation:  [[ 1420.16245313]]\n",
      "Loop  5787 :    Loss_Train:  [[ 4822.54556468]]    Loss_Validation:  [[ 1420.16291508]]\n",
      "Loop  5788 :    Loss_Train:  [[ 4822.54551561]]    Loss_Validation:  [[ 1420.1633767]]\n",
      "Loop  5789 :    Loss_Train:  [[ 4822.54546662]]    Loss_Validation:  [[ 1420.163838]]\n",
      "Loop  5790 :    Loss_Train:  [[ 4822.54541771]]    Loss_Validation:  [[ 1420.16429898]]\n",
      "Loop  5791 :    Loss_Train:  [[ 4822.54536887]]    Loss_Validation:  [[ 1420.16475963]]\n",
      "Loop  5792 :    Loss_Train:  [[ 4822.54532011]]    Loss_Validation:  [[ 1420.16521995]]\n",
      "Loop  5793 :    Loss_Train:  [[ 4822.54527143]]    Loss_Validation:  [[ 1420.16567996]]\n",
      "Loop  5794 :    Loss_Train:  [[ 4822.54522283]]    Loss_Validation:  [[ 1420.16613964]]\n",
      "Loop  5795 :    Loss_Train:  [[ 4822.54517431]]    Loss_Validation:  [[ 1420.166599]]\n",
      "Loop  5796 :    Loss_Train:  [[ 4822.54512586]]    Loss_Validation:  [[ 1420.16705803]]\n",
      "Loop  5797 :    Loss_Train:  [[ 4822.54507749]]    Loss_Validation:  [[ 1420.16751674]]\n",
      "Loop  5798 :    Loss_Train:  [[ 4822.5450292]]    Loss_Validation:  [[ 1420.16797514]]\n",
      "Loop  5799 :    Loss_Train:  [[ 4822.54498099]]    Loss_Validation:  [[ 1420.16843321]]\n",
      "Loop  5800 :    Loss_Train:  [[ 4822.54493285]]    Loss_Validation:  [[ 1420.16889095]]\n",
      "Loop  5801 :    Loss_Train:  [[ 4822.54488479]]    Loss_Validation:  [[ 1420.16934838]]\n",
      "Loop  5802 :    Loss_Train:  [[ 4822.54483681]]    Loss_Validation:  [[ 1420.16980549]]\n",
      "Loop  5803 :    Loss_Train:  [[ 4822.5447889]]    Loss_Validation:  [[ 1420.17026227]]\n",
      "Loop  5804 :    Loss_Train:  [[ 4822.54474107]]    Loss_Validation:  [[ 1420.17071873]]\n",
      "Loop  5805 :    Loss_Train:  [[ 4822.54469332]]    Loss_Validation:  [[ 1420.17117488]]\n",
      "Loop  5806 :    Loss_Train:  [[ 4822.54464564]]    Loss_Validation:  [[ 1420.1716307]]\n",
      "Loop  5807 :    Loss_Train:  [[ 4822.54459804]]    Loss_Validation:  [[ 1420.1720862]]\n",
      "Loop  5808 :    Loss_Train:  [[ 4822.54455051]]    Loss_Validation:  [[ 1420.17254139]]\n",
      "Loop  5809 :    Loss_Train:  [[ 4822.54450306]]    Loss_Validation:  [[ 1420.17299625]]\n",
      "Loop  5810 :    Loss_Train:  [[ 4822.54445569]]    Loss_Validation:  [[ 1420.17345079]]\n",
      "Loop  5811 :    Loss_Train:  [[ 4822.54440839]]    Loss_Validation:  [[ 1420.17390502]]\n",
      "Loop  5812 :    Loss_Train:  [[ 4822.54436117]]    Loss_Validation:  [[ 1420.17435892]]\n",
      "Loop  5813 :    Loss_Train:  [[ 4822.54431403]]    Loss_Validation:  [[ 1420.17481251]]\n",
      "Loop  5814 :    Loss_Train:  [[ 4822.54426695]]    Loss_Validation:  [[ 1420.17526578]]\n",
      "Loop  5815 :    Loss_Train:  [[ 4822.54421996]]    Loss_Validation:  [[ 1420.17571873]]\n",
      "Loop  5816 :    Loss_Train:  [[ 4822.54417304]]    Loss_Validation:  [[ 1420.17617136]]\n",
      "Loop  5817 :    Loss_Train:  [[ 4822.54412619]]    Loss_Validation:  [[ 1420.17662368]]\n",
      "Loop  5818 :    Loss_Train:  [[ 4822.54407942]]    Loss_Validation:  [[ 1420.17707567]]\n",
      "Loop  5819 :    Loss_Train:  [[ 4822.54403273]]    Loss_Validation:  [[ 1420.17752735]]\n",
      "Loop  5820 :    Loss_Train:  [[ 4822.5439861]]    Loss_Validation:  [[ 1420.17797872]]\n",
      "Loop  5821 :    Loss_Train:  [[ 4822.54393956]]    Loss_Validation:  [[ 1420.17842976]]\n",
      "Loop  5822 :    Loss_Train:  [[ 4822.54389308]]    Loss_Validation:  [[ 1420.17888049]]\n",
      "Loop  5823 :    Loss_Train:  [[ 4822.54384669]]    Loss_Validation:  [[ 1420.1793309]]\n",
      "Loop  5824 :    Loss_Train:  [[ 4822.54380036]]    Loss_Validation:  [[ 1420.179781]]\n",
      "Loop  5825 :    Loss_Train:  [[ 4822.54375411]]    Loss_Validation:  [[ 1420.18023078]]\n",
      "Loop  5826 :    Loss_Train:  [[ 4822.54370794]]    Loss_Validation:  [[ 1420.18068024]]\n",
      "Loop  5827 :    Loss_Train:  [[ 4822.54366183]]    Loss_Validation:  [[ 1420.18112939]]\n",
      "Loop  5828 :    Loss_Train:  [[ 4822.54361581]]    Loss_Validation:  [[ 1420.18157822]]\n",
      "Loop  5829 :    Loss_Train:  [[ 4822.54356985]]    Loss_Validation:  [[ 1420.18202674]]\n",
      "Loop  5830 :    Loss_Train:  [[ 4822.54352397]]    Loss_Validation:  [[ 1420.18247494]]\n",
      "Loop  5831 :    Loss_Train:  [[ 4822.54347816]]    Loss_Validation:  [[ 1420.18292283]]\n",
      "Loop  5832 :    Loss_Train:  [[ 4822.54343243]]    Loss_Validation:  [[ 1420.1833704]]\n",
      "Loop  5833 :    Loss_Train:  [[ 4822.54338676]]    Loss_Validation:  [[ 1420.18381766]]\n",
      "Loop  5834 :    Loss_Train:  [[ 4822.54334118]]    Loss_Validation:  [[ 1420.18426461]]\n",
      "Loop  5835 :    Loss_Train:  [[ 4822.54329566]]    Loss_Validation:  [[ 1420.18471124]]\n",
      "Loop  5836 :    Loss_Train:  [[ 4822.54325022]]    Loss_Validation:  [[ 1420.18515756]]\n",
      "Loop  5837 :    Loss_Train:  [[ 4822.54320484]]    Loss_Validation:  [[ 1420.18560356]]\n",
      "Loop  5838 :    Loss_Train:  [[ 4822.54315955]]    Loss_Validation:  [[ 1420.18604925]]\n",
      "Loop  5839 :    Loss_Train:  [[ 4822.54311432]]    Loss_Validation:  [[ 1420.18649463]]\n",
      "Loop  5840 :    Loss_Train:  [[ 4822.54306917]]    Loss_Validation:  [[ 1420.18693969]]\n",
      "Loop  5841 :    Loss_Train:  [[ 4822.54302409]]    Loss_Validation:  [[ 1420.18738445]]\n",
      "Loop  5842 :    Loss_Train:  [[ 4822.54297908]]    Loss_Validation:  [[ 1420.18782889]]\n",
      "Loop  5843 :    Loss_Train:  [[ 4822.54293414]]    Loss_Validation:  [[ 1420.18827301]]\n",
      "Loop  5844 :    Loss_Train:  [[ 4822.54288927]]    Loss_Validation:  [[ 1420.18871683]]\n",
      "Loop  5845 :    Loss_Train:  [[ 4822.54284448]]    Loss_Validation:  [[ 1420.18916033]]\n",
      "Loop  5846 :    Loss_Train:  [[ 4822.54279976]]    Loss_Validation:  [[ 1420.18960353]]\n",
      "Loop  5847 :    Loss_Train:  [[ 4822.54275511]]    Loss_Validation:  [[ 1420.19004641]]\n",
      "Loop  5848 :    Loss_Train:  [[ 4822.54271053]]    Loss_Validation:  [[ 1420.19048898]]\n",
      "Loop  5849 :    Loss_Train:  [[ 4822.54266602]]    Loss_Validation:  [[ 1420.19093124]]\n",
      "Loop  5850 :    Loss_Train:  [[ 4822.54262158]]    Loss_Validation:  [[ 1420.19137319]]\n",
      "Loop  5851 :    Loss_Train:  [[ 4822.54257721]]    Loss_Validation:  [[ 1420.19181482]]\n",
      "Loop  5852 :    Loss_Train:  [[ 4822.54253292]]    Loss_Validation:  [[ 1420.19225615]]\n",
      "Loop  5853 :    Loss_Train:  [[ 4822.54248869]]    Loss_Validation:  [[ 1420.19269717]]\n",
      "Loop  5854 :    Loss_Train:  [[ 4822.54244454]]    Loss_Validation:  [[ 1420.19313788]]\n",
      "Loop  5855 :    Loss_Train:  [[ 4822.54240046]]    Loss_Validation:  [[ 1420.19357828]]\n",
      "Loop  5856 :    Loss_Train:  [[ 4822.54235644]]    Loss_Validation:  [[ 1420.19401837]]\n",
      "Loop  5857 :    Loss_Train:  [[ 4822.5423125]]    Loss_Validation:  [[ 1420.19445815]]\n",
      "Loop  5858 :    Loss_Train:  [[ 4822.54226863]]    Loss_Validation:  [[ 1420.19489762]]\n",
      "Loop  5859 :    Loss_Train:  [[ 4822.54222483]]    Loss_Validation:  [[ 1420.19533678]]\n",
      "Loop  5860 :    Loss_Train:  [[ 4822.54218109]]    Loss_Validation:  [[ 1420.19577564]]\n",
      "Loop  5861 :    Loss_Train:  [[ 4822.54213743]]    Loss_Validation:  [[ 1420.19621418]]\n",
      "Loop  5862 :    Loss_Train:  [[ 4822.54209384]]    Loss_Validation:  [[ 1420.19665242]]\n",
      "Loop  5863 :    Loss_Train:  [[ 4822.54205032]]    Loss_Validation:  [[ 1420.19709035]]\n",
      "Loop  5864 :    Loss_Train:  [[ 4822.54200686]]    Loss_Validation:  [[ 1420.19752797]]\n",
      "Loop  5865 :    Loss_Train:  [[ 4822.54196348]]    Loss_Validation:  [[ 1420.19796529]]\n",
      "Loop  5866 :    Loss_Train:  [[ 4822.54192016]]    Loss_Validation:  [[ 1420.1984023]]\n",
      "Loop  5867 :    Loss_Train:  [[ 4822.54187692]]    Loss_Validation:  [[ 1420.198839]]\n",
      "Loop  5868 :    Loss_Train:  [[ 4822.54183374]]    Loss_Validation:  [[ 1420.19927539]]\n",
      "Loop  5869 :    Loss_Train:  [[ 4822.54179063]]    Loss_Validation:  [[ 1420.19971148]]\n",
      "Loop  5870 :    Loss_Train:  [[ 4822.54174759]]    Loss_Validation:  [[ 1420.20014726]]\n",
      "Loop  5871 :    Loss_Train:  [[ 4822.54170462]]    Loss_Validation:  [[ 1420.20058274]]\n",
      "Loop  5872 :    Loss_Train:  [[ 4822.54166172]]    Loss_Validation:  [[ 1420.20101791]]\n",
      "Loop  5873 :    Loss_Train:  [[ 4822.54161889]]    Loss_Validation:  [[ 1420.20145277]]\n",
      "Loop  5874 :    Loss_Train:  [[ 4822.54157613]]    Loss_Validation:  [[ 1420.20188733]]\n",
      "Loop  5875 :    Loss_Train:  [[ 4822.54153343]]    Loss_Validation:  [[ 1420.20232158]]\n",
      "Loop  5876 :    Loss_Train:  [[ 4822.5414908]]    Loss_Validation:  [[ 1420.20275553]]\n",
      "Loop  5877 :    Loss_Train:  [[ 4822.54144824]]    Loss_Validation:  [[ 1420.20318917]]\n",
      "Loop  5878 :    Loss_Train:  [[ 4822.54140575]]    Loss_Validation:  [[ 1420.20362251]]\n",
      "Loop  5879 :    Loss_Train:  [[ 4822.54136333]]    Loss_Validation:  [[ 1420.20405554]]\n",
      "Loop  5880 :    Loss_Train:  [[ 4822.54132097]]    Loss_Validation:  [[ 1420.20448827]]\n",
      "Loop  5881 :    Loss_Train:  [[ 4822.54127868]]    Loss_Validation:  [[ 1420.2049207]]\n",
      "Loop  5882 :    Loss_Train:  [[ 4822.54123646]]    Loss_Validation:  [[ 1420.20535282]]\n",
      "Loop  5883 :    Loss_Train:  [[ 4822.54119431]]    Loss_Validation:  [[ 1420.20578464]]\n",
      "Loop  5884 :    Loss_Train:  [[ 4822.54115222]]    Loss_Validation:  [[ 1420.20621615]]\n",
      "Loop  5885 :    Loss_Train:  [[ 4822.5411102]]    Loss_Validation:  [[ 1420.20664736]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  5886 :    Loss_Train:  [[ 4822.54106825]]    Loss_Validation:  [[ 1420.20707827]]\n",
      "Loop  5887 :    Loss_Train:  [[ 4822.54102636]]    Loss_Validation:  [[ 1420.20750888]]\n",
      "Loop  5888 :    Loss_Train:  [[ 4822.54098454]]    Loss_Validation:  [[ 1420.20793918]]\n",
      "Loop  5889 :    Loss_Train:  [[ 4822.54094279]]    Loss_Validation:  [[ 1420.20836918]]\n",
      "Loop  5890 :    Loss_Train:  [[ 4822.54090111]]    Loss_Validation:  [[ 1420.20879888]]\n",
      "Loop  5891 :    Loss_Train:  [[ 4822.54085949]]    Loss_Validation:  [[ 1420.20922828]]\n",
      "Loop  5892 :    Loss_Train:  [[ 4822.54081794]]    Loss_Validation:  [[ 1420.20965737]]\n",
      "Loop  5893 :    Loss_Train:  [[ 4822.54077645]]    Loss_Validation:  [[ 1420.21008617]]\n",
      "Loop  5894 :    Loss_Train:  [[ 4822.54073503]]    Loss_Validation:  [[ 1420.21051466]]\n",
      "Loop  5895 :    Loss_Train:  [[ 4822.54069368]]    Loss_Validation:  [[ 1420.21094285]]\n",
      "Loop  5896 :    Loss_Train:  [[ 4822.54065239]]    Loss_Validation:  [[ 1420.21137074]]\n",
      "Loop  5897 :    Loss_Train:  [[ 4822.54061117]]    Loss_Validation:  [[ 1420.21179833]]\n",
      "Loop  5898 :    Loss_Train:  [[ 4822.54057002]]    Loss_Validation:  [[ 1420.21222562]]\n",
      "Loop  5899 :    Loss_Train:  [[ 4822.54052893]]    Loss_Validation:  [[ 1420.21265261]]\n",
      "Loop  5900 :    Loss_Train:  [[ 4822.54048791]]    Loss_Validation:  [[ 1420.2130793]]\n",
      "Loop  5901 :    Loss_Train:  [[ 4822.54044695]]    Loss_Validation:  [[ 1420.21350569]]\n",
      "Loop  5902 :    Loss_Train:  [[ 4822.54040605]]    Loss_Validation:  [[ 1420.21393178]]\n",
      "Loop  5903 :    Loss_Train:  [[ 4822.54036523]]    Loss_Validation:  [[ 1420.21435757]]\n",
      "Loop  5904 :    Loss_Train:  [[ 4822.54032446]]    Loss_Validation:  [[ 1420.21478306]]\n",
      "Loop  5905 :    Loss_Train:  [[ 4822.54028377]]    Loss_Validation:  [[ 1420.21520826]]\n",
      "Loop  5906 :    Loss_Train:  [[ 4822.54024313]]    Loss_Validation:  [[ 1420.21563315]]\n",
      "Loop  5907 :    Loss_Train:  [[ 4822.54020257]]    Loss_Validation:  [[ 1420.21605774]]\n",
      "Loop  5908 :    Loss_Train:  [[ 4822.54016206]]    Loss_Validation:  [[ 1420.21648204]]\n",
      "Loop  5909 :    Loss_Train:  [[ 4822.54012163]]    Loss_Validation:  [[ 1420.21690604]]\n",
      "Loop  5910 :    Loss_Train:  [[ 4822.54008125]]    Loss_Validation:  [[ 1420.21732974]]\n",
      "Loop  5911 :    Loss_Train:  [[ 4822.54004094]]    Loss_Validation:  [[ 1420.21775314]]\n",
      "Loop  5912 :    Loss_Train:  [[ 4822.5400007]]    Loss_Validation:  [[ 1420.21817625]]\n",
      "Loop  5913 :    Loss_Train:  [[ 4822.53996052]]    Loss_Validation:  [[ 1420.21859906]]\n",
      "Loop  5914 :    Loss_Train:  [[ 4822.5399204]]    Loss_Validation:  [[ 1420.21902157]]\n",
      "Loop  5915 :    Loss_Train:  [[ 4822.53988035]]    Loss_Validation:  [[ 1420.21944378]]\n",
      "Loop  5916 :    Loss_Train:  [[ 4822.53984036]]    Loss_Validation:  [[ 1420.2198657]]\n",
      "Loop  5917 :    Loss_Train:  [[ 4822.53980044]]    Loss_Validation:  [[ 1420.22028732]]\n",
      "Loop  5918 :    Loss_Train:  [[ 4822.53976058]]    Loss_Validation:  [[ 1420.22070864]]\n",
      "Loop  5919 :    Loss_Train:  [[ 4822.53972078]]    Loss_Validation:  [[ 1420.22112967]]\n",
      "Loop  5920 :    Loss_Train:  [[ 4822.53968105]]    Loss_Validation:  [[ 1420.2215504]]\n",
      "Loop  5921 :    Loss_Train:  [[ 4822.53964138]]    Loss_Validation:  [[ 1420.22197084]]\n",
      "Loop  5922 :    Loss_Train:  [[ 4822.53960177]]    Loss_Validation:  [[ 1420.22239098]]\n",
      "Loop  5923 :    Loss_Train:  [[ 4822.53956223]]    Loss_Validation:  [[ 1420.22281083]]\n",
      "Loop  5924 :    Loss_Train:  [[ 4822.53952275]]    Loss_Validation:  [[ 1420.22323038]]\n",
      "Loop  5925 :    Loss_Train:  [[ 4822.53948333]]    Loss_Validation:  [[ 1420.22364963]]\n",
      "Loop  5926 :    Loss_Train:  [[ 4822.53944397]]    Loss_Validation:  [[ 1420.2240686]]\n",
      "Loop  5927 :    Loss_Train:  [[ 4822.53940468]]    Loss_Validation:  [[ 1420.22448726]]\n",
      "Loop  5928 :    Loss_Train:  [[ 4822.53936545]]    Loss_Validation:  [[ 1420.22490564]]\n",
      "Loop  5929 :    Loss_Train:  [[ 4822.53932629]]    Loss_Validation:  [[ 1420.22532371]]\n",
      "Loop  5930 :    Loss_Train:  [[ 4822.53928718]]    Loss_Validation:  [[ 1420.2257415]]\n",
      "Loop  5931 :    Loss_Train:  [[ 4822.53924814]]    Loss_Validation:  [[ 1420.22615899]]\n",
      "Loop  5932 :    Loss_Train:  [[ 4822.53920916]]    Loss_Validation:  [[ 1420.22657619]]\n",
      "Loop  5933 :    Loss_Train:  [[ 4822.53917025]]    Loss_Validation:  [[ 1420.22699309]]\n",
      "Loop  5934 :    Loss_Train:  [[ 4822.53913139]]    Loss_Validation:  [[ 1420.2274097]]\n",
      "Loop  5935 :    Loss_Train:  [[ 4822.5390926]]    Loss_Validation:  [[ 1420.22782602]]\n",
      "Loop  5936 :    Loss_Train:  [[ 4822.53905387]]    Loss_Validation:  [[ 1420.22824205]]\n",
      "Loop  5937 :    Loss_Train:  [[ 4822.5390152]]    Loss_Validation:  [[ 1420.22865778]]\n",
      "Loop  5938 :    Loss_Train:  [[ 4822.53897659]]    Loss_Validation:  [[ 1420.22907323]]\n",
      "Loop  5939 :    Loss_Train:  [[ 4822.53893804]]    Loss_Validation:  [[ 1420.22948838]]\n",
      "Loop  5940 :    Loss_Train:  [[ 4822.53889956]]    Loss_Validation:  [[ 1420.22990323]]\n",
      "Loop  5941 :    Loss_Train:  [[ 4822.53886114]]    Loss_Validation:  [[ 1420.2303178]]\n",
      "Loop  5942 :    Loss_Train:  [[ 4822.53882278]]    Loss_Validation:  [[ 1420.23073207]]\n",
      "Loop  5943 :    Loss_Train:  [[ 4822.53878448]]    Loss_Validation:  [[ 1420.23114606]]\n",
      "Loop  5944 :    Loss_Train:  [[ 4822.53874624]]    Loss_Validation:  [[ 1420.23155975]]\n",
      "Loop  5945 :    Loss_Train:  [[ 4822.53870806]]    Loss_Validation:  [[ 1420.23197315]]\n",
      "Loop  5946 :    Loss_Train:  [[ 4822.53866994]]    Loss_Validation:  [[ 1420.23238626]]\n",
      "Loop  5947 :    Loss_Train:  [[ 4822.53863189]]    Loss_Validation:  [[ 1420.23279908]]\n",
      "Loop  5948 :    Loss_Train:  [[ 4822.53859389]]    Loss_Validation:  [[ 1420.23321162]]\n",
      "Loop  5949 :    Loss_Train:  [[ 4822.53855595]]    Loss_Validation:  [[ 1420.23362386]]\n",
      "Loop  5950 :    Loss_Train:  [[ 4822.53851808]]    Loss_Validation:  [[ 1420.23403581]]\n",
      "Loop  5951 :    Loss_Train:  [[ 4822.53848027]]    Loss_Validation:  [[ 1420.23444747]]\n",
      "Loop  5952 :    Loss_Train:  [[ 4822.53844251]]    Loss_Validation:  [[ 1420.23485884]]\n",
      "Loop  5953 :    Loss_Train:  [[ 4822.53840482]]    Loss_Validation:  [[ 1420.23526992]]\n",
      "Loop  5954 :    Loss_Train:  [[ 4822.53836719]]    Loss_Validation:  [[ 1420.23568072]]\n",
      "Loop  5955 :    Loss_Train:  [[ 4822.53832961]]    Loss_Validation:  [[ 1420.23609122]]\n",
      "Loop  5956 :    Loss_Train:  [[ 4822.5382921]]    Loss_Validation:  [[ 1420.23650144]]\n",
      "Loop  5957 :    Loss_Train:  [[ 4822.53825465]]    Loss_Validation:  [[ 1420.23691137]]\n",
      "Loop  5958 :    Loss_Train:  [[ 4822.53821725]]    Loss_Validation:  [[ 1420.23732101]]\n",
      "Loop  5959 :    Loss_Train:  [[ 4822.53817992]]    Loss_Validation:  [[ 1420.23773036]]\n",
      "Loop  5960 :    Loss_Train:  [[ 4822.53814264]]    Loss_Validation:  [[ 1420.23813942]]\n",
      "Loop  5961 :    Loss_Train:  [[ 4822.53810543]]    Loss_Validation:  [[ 1420.2385482]]\n",
      "Loop  5962 :    Loss_Train:  [[ 4822.53806827]]    Loss_Validation:  [[ 1420.23895669]]\n",
      "Loop  5963 :    Loss_Train:  [[ 4822.53803118]]    Loss_Validation:  [[ 1420.23936489]]\n",
      "Loop  5964 :    Loss_Train:  [[ 4822.53799414]]    Loss_Validation:  [[ 1420.23977281]]\n",
      "Loop  5965 :    Loss_Train:  [[ 4822.53795716]]    Loss_Validation:  [[ 1420.24018044]]\n",
      "Loop  5966 :    Loss_Train:  [[ 4822.53792024]]    Loss_Validation:  [[ 1420.24058778]]\n",
      "Loop  5967 :    Loss_Train:  [[ 4822.53788338]]    Loss_Validation:  [[ 1420.24099483]]\n",
      "Loop  5968 :    Loss_Train:  [[ 4822.53784658]]    Loss_Validation:  [[ 1420.2414016]]\n",
      "Loop  5969 :    Loss_Train:  [[ 4822.53780984]]    Loss_Validation:  [[ 1420.24180809]]\n",
      "Loop  5970 :    Loss_Train:  [[ 4822.53777316]]    Loss_Validation:  [[ 1420.24221428]]\n",
      "Loop  5971 :    Loss_Train:  [[ 4822.53773653]]    Loss_Validation:  [[ 1420.2426202]]\n",
      "Loop  5972 :    Loss_Train:  [[ 4822.53769996]]    Loss_Validation:  [[ 1420.24302582]]\n",
      "Loop  5973 :    Loss_Train:  [[ 4822.53766345]]    Loss_Validation:  [[ 1420.24343116]]\n",
      "Loop  5974 :    Loss_Train:  [[ 4822.537627]]    Loss_Validation:  [[ 1420.24383622]]\n",
      "Loop  5975 :    Loss_Train:  [[ 4822.53759061]]    Loss_Validation:  [[ 1420.24424099]]\n",
      "Loop  5976 :    Loss_Train:  [[ 4822.53755428]]    Loss_Validation:  [[ 1420.24464548]]\n",
      "Loop  5977 :    Loss_Train:  [[ 4822.537518]]    Loss_Validation:  [[ 1420.24504968]]\n",
      "Loop  5978 :    Loss_Train:  [[ 4822.53748178]]    Loss_Validation:  [[ 1420.2454536]]\n",
      "Loop  5979 :    Loss_Train:  [[ 4822.53744562]]    Loss_Validation:  [[ 1420.24585724]]\n",
      "Loop  5980 :    Loss_Train:  [[ 4822.53740952]]    Loss_Validation:  [[ 1420.24626059]]\n",
      "Loop  5981 :    Loss_Train:  [[ 4822.53737347]]    Loss_Validation:  [[ 1420.24666365]]\n",
      "Loop  5982 :    Loss_Train:  [[ 4822.53733749]]    Loss_Validation:  [[ 1420.24706644]]\n",
      "Loop  5983 :    Loss_Train:  [[ 4822.53730156]]    Loss_Validation:  [[ 1420.24746894]]\n",
      "Loop  5984 :    Loss_Train:  [[ 4822.53726568]]    Loss_Validation:  [[ 1420.24787116]]\n",
      "Loop  5985 :    Loss_Train:  [[ 4822.53722987]]    Loss_Validation:  [[ 1420.24827309]]\n",
      "Loop  5986 :    Loss_Train:  [[ 4822.53719411]]    Loss_Validation:  [[ 1420.24867474]]\n",
      "Loop  5987 :    Loss_Train:  [[ 4822.53715841]]    Loss_Validation:  [[ 1420.24907611]]\n",
      "Loop  5988 :    Loss_Train:  [[ 4822.53712276]]    Loss_Validation:  [[ 1420.2494772]]\n",
      "Loop  5989 :    Loss_Train:  [[ 4822.53708717]]    Loss_Validation:  [[ 1420.24987801]]\n",
      "Loop  5990 :    Loss_Train:  [[ 4822.53705164]]    Loss_Validation:  [[ 1420.25027853]]\n",
      "Loop  5991 :    Loss_Train:  [[ 4822.53701617]]    Loss_Validation:  [[ 1420.25067877]]\n",
      "Loop  5992 :    Loss_Train:  [[ 4822.53698075]]    Loss_Validation:  [[ 1420.25107873]]\n",
      "Loop  5993 :    Loss_Train:  [[ 4822.53694539]]    Loss_Validation:  [[ 1420.25147841]]\n",
      "Loop  5994 :    Loss_Train:  [[ 4822.53691008]]    Loss_Validation:  [[ 1420.25187781]]\n",
      "Loop  5995 :    Loss_Train:  [[ 4822.53687483]]    Loss_Validation:  [[ 1420.25227693]]\n",
      "Loop  5996 :    Loss_Train:  [[ 4822.53683964]]    Loss_Validation:  [[ 1420.25267577]]\n",
      "Loop  5997 :    Loss_Train:  [[ 4822.53680451]]    Loss_Validation:  [[ 1420.25307432]]\n",
      "Loop  5998 :    Loss_Train:  [[ 4822.53676943]]    Loss_Validation:  [[ 1420.2534726]]\n",
      "Loop  5999 :    Loss_Train:  [[ 4822.5367344]]    Loss_Validation:  [[ 1420.25387059]]\n",
      "Loop  6000 :    Loss_Train:  [[ 4822.53669943]]    Loss_Validation:  [[ 1420.25426831]]\n",
      "Loop  6001 :    Loss_Train:  [[ 4822.53666452]]    Loss_Validation:  [[ 1420.25466575]]\n",
      "Loop  6002 :    Loss_Train:  [[ 4822.53662966]]    Loss_Validation:  [[ 1420.2550629]]\n",
      "Loop  6003 :    Loss_Train:  [[ 4822.53659486]]    Loss_Validation:  [[ 1420.25545978]]\n",
      "Loop  6004 :    Loss_Train:  [[ 4822.53656011]]    Loss_Validation:  [[ 1420.25585638]]\n",
      "Loop  6005 :    Loss_Train:  [[ 4822.53652542]]    Loss_Validation:  [[ 1420.2562527]]\n",
      "Loop  6006 :    Loss_Train:  [[ 4822.53649079]]    Loss_Validation:  [[ 1420.25664874]]\n",
      "Loop  6007 :    Loss_Train:  [[ 4822.53645621]]    Loss_Validation:  [[ 1420.25704451]]\n",
      "Loop  6008 :    Loss_Train:  [[ 4822.53642168]]    Loss_Validation:  [[ 1420.25743999]]\n",
      "Loop  6009 :    Loss_Train:  [[ 4822.53638721]]    Loss_Validation:  [[ 1420.2578352]]\n",
      "Loop  6010 :    Loss_Train:  [[ 4822.5363528]]    Loss_Validation:  [[ 1420.25823012]]\n",
      "Loop  6011 :    Loss_Train:  [[ 4822.53631844]]    Loss_Validation:  [[ 1420.25862477]]\n",
      "Loop  6012 :    Loss_Train:  [[ 4822.53628413]]    Loss_Validation:  [[ 1420.25901915]]\n",
      "Loop  6013 :    Loss_Train:  [[ 4822.53624988]]    Loss_Validation:  [[ 1420.25941324]]\n",
      "Loop  6014 :    Loss_Train:  [[ 4822.53621569]]    Loss_Validation:  [[ 1420.25980706]]\n",
      "Loop  6015 :    Loss_Train:  [[ 4822.53618155]]    Loss_Validation:  [[ 1420.2602006]]\n",
      "Loop  6016 :    Loss_Train:  [[ 4822.53614746]]    Loss_Validation:  [[ 1420.26059387]]\n",
      "Loop  6017 :    Loss_Train:  [[ 4822.53611343]]    Loss_Validation:  [[ 1420.26098686]]\n",
      "Loop  6018 :    Loss_Train:  [[ 4822.53607945]]    Loss_Validation:  [[ 1420.26137957]]\n",
      "Loop  6019 :    Loss_Train:  [[ 4822.53604552]]    Loss_Validation:  [[ 1420.261772]]\n",
      "Loop  6020 :    Loss_Train:  [[ 4822.53601165]]    Loss_Validation:  [[ 1420.26216416]]\n",
      "Loop  6021 :    Loss_Train:  [[ 4822.53597784]]    Loss_Validation:  [[ 1420.26255605]]\n",
      "Loop  6022 :    Loss_Train:  [[ 4822.53594408]]    Loss_Validation:  [[ 1420.26294765]]\n",
      "Loop  6023 :    Loss_Train:  [[ 4822.53591037]]    Loss_Validation:  [[ 1420.26333899]]\n",
      "Loop  6024 :    Loss_Train:  [[ 4822.53587671]]    Loss_Validation:  [[ 1420.26373004]]\n",
      "Loop  6025 :    Loss_Train:  [[ 4822.53584311]]    Loss_Validation:  [[ 1420.26412083]]\n",
      "Loop  6026 :    Loss_Train:  [[ 4822.53580956]]    Loss_Validation:  [[ 1420.26451133]]\n",
      "Loop  6027 :    Loss_Train:  [[ 4822.53577607]]    Loss_Validation:  [[ 1420.26490157]]\n",
      "Loop  6028 :    Loss_Train:  [[ 4822.53574263]]    Loss_Validation:  [[ 1420.26529153]]\n",
      "Loop  6029 :    Loss_Train:  [[ 4822.53570924]]    Loss_Validation:  [[ 1420.26568121]]\n",
      "Loop  6030 :    Loss_Train:  [[ 4822.53567591]]    Loss_Validation:  [[ 1420.26607062]]\n",
      "Loop  6031 :    Loss_Train:  [[ 4822.53564263]]    Loss_Validation:  [[ 1420.26645976]]\n",
      "Loop  6032 :    Loss_Train:  [[ 4822.5356094]]    Loss_Validation:  [[ 1420.26684862]]\n",
      "Loop  6033 :    Loss_Train:  [[ 4822.53557623]]    Loss_Validation:  [[ 1420.26723721]]\n",
      "Loop  6034 :    Loss_Train:  [[ 4822.5355431]]    Loss_Validation:  [[ 1420.26762552]]\n",
      "Loop  6035 :    Loss_Train:  [[ 4822.53551003]]    Loss_Validation:  [[ 1420.26801357]]\n",
      "Loop  6036 :    Loss_Train:  [[ 4822.53547702]]    Loss_Validation:  [[ 1420.26840133]]\n",
      "Loop  6037 :    Loss_Train:  [[ 4822.53544405]]    Loss_Validation:  [[ 1420.26878883]]\n",
      "Loop  6038 :    Loss_Train:  [[ 4822.53541114]]    Loss_Validation:  [[ 1420.26917606]]\n",
      "Loop  6039 :    Loss_Train:  [[ 4822.53537828]]    Loss_Validation:  [[ 1420.26956301]]\n",
      "Loop  6040 :    Loss_Train:  [[ 4822.53534548]]    Loss_Validation:  [[ 1420.26994969]]\n",
      "Loop  6041 :    Loss_Train:  [[ 4822.53531272]]    Loss_Validation:  [[ 1420.27033609]]\n",
      "Loop  6042 :    Loss_Train:  [[ 4822.53528002]]    Loss_Validation:  [[ 1420.27072223]]\n",
      "Loop  6043 :    Loss_Train:  [[ 4822.53524737]]    Loss_Validation:  [[ 1420.27110809]]\n",
      "Loop  6044 :    Loss_Train:  [[ 4822.53521477]]    Loss_Validation:  [[ 1420.27149369]]\n",
      "Loop  6045 :    Loss_Train:  [[ 4822.53518223]]    Loss_Validation:  [[ 1420.27187901]]\n",
      "Loop  6046 :    Loss_Train:  [[ 4822.53514974]]    Loss_Validation:  [[ 1420.27226406]]\n",
      "Loop  6047 :    Loss_Train:  [[ 4822.53511729]]    Loss_Validation:  [[ 1420.27264884]]\n",
      "Loop  6048 :    Loss_Train:  [[ 4822.5350849]]    Loss_Validation:  [[ 1420.27303335]]\n",
      "Loop  6049 :    Loss_Train:  [[ 4822.53505256]]    Loss_Validation:  [[ 1420.27341759]]\n",
      "Loop  6050 :    Loss_Train:  [[ 4822.53502028]]    Loss_Validation:  [[ 1420.27380155]]\n",
      "Loop  6051 :    Loss_Train:  [[ 4822.53498804]]    Loss_Validation:  [[ 1420.27418525]]\n",
      "Loop  6052 :    Loss_Train:  [[ 4822.53495586]]    Loss_Validation:  [[ 1420.27456868]]\n",
      "Loop  6053 :    Loss_Train:  [[ 4822.53492372]]    Loss_Validation:  [[ 1420.27495184]]\n",
      "Loop  6054 :    Loss_Train:  [[ 4822.53489164]]    Loss_Validation:  [[ 1420.27533473]]\n",
      "Loop  6055 :    Loss_Train:  [[ 4822.53485961]]    Loss_Validation:  [[ 1420.27571735]]\n",
      "Loop  6056 :    Loss_Train:  [[ 4822.53482763]]    Loss_Validation:  [[ 1420.2760997]]\n",
      "Loop  6057 :    Loss_Train:  [[ 4822.5347957]]    Loss_Validation:  [[ 1420.27648178]]\n",
      "Loop  6058 :    Loss_Train:  [[ 4822.53476382]]    Loss_Validation:  [[ 1420.27686359]]\n",
      "Loop  6059 :    Loss_Train:  [[ 4822.534732]]    Loss_Validation:  [[ 1420.27724513]]\n",
      "Loop  6060 :    Loss_Train:  [[ 4822.53470022]]    Loss_Validation:  [[ 1420.27762641]]\n",
      "Loop  6061 :    Loss_Train:  [[ 4822.5346685]]    Loss_Validation:  [[ 1420.27800742]]\n",
      "Loop  6062 :    Loss_Train:  [[ 4822.53463682]]    Loss_Validation:  [[ 1420.27838816]]\n",
      "Loop  6063 :    Loss_Train:  [[ 4822.5346052]]    Loss_Validation:  [[ 1420.27876863]]\n",
      "Loop  6064 :    Loss_Train:  [[ 4822.53457362]]    Loss_Validation:  [[ 1420.27914883]]\n",
      "Loop  6065 :    Loss_Train:  [[ 4822.5345421]]    Loss_Validation:  [[ 1420.27952877]]\n",
      "Loop  6066 :    Loss_Train:  [[ 4822.53451062]]    Loss_Validation:  [[ 1420.27990843]]\n",
      "Loop  6067 :    Loss_Train:  [[ 4822.5344792]]    Loss_Validation:  [[ 1420.28028784]]\n",
      "Loop  6068 :    Loss_Train:  [[ 4822.53444783]]    Loss_Validation:  [[ 1420.28066697]]\n",
      "Loop  6069 :    Loss_Train:  [[ 4822.5344165]]    Loss_Validation:  [[ 1420.28104584]]\n",
      "Loop  6070 :    Loss_Train:  [[ 4822.53438523]]    Loss_Validation:  [[ 1420.28142444]]\n",
      "Loop  6071 :    Loss_Train:  [[ 4822.53435401]]    Loss_Validation:  [[ 1420.28180277]]\n",
      "Loop  6072 :    Loss_Train:  [[ 4822.53432283]]    Loss_Validation:  [[ 1420.28218084]]\n",
      "Loop  6073 :    Loss_Train:  [[ 4822.53429171]]    Loss_Validation:  [[ 1420.28255865]]\n",
      "Loop  6074 :    Loss_Train:  [[ 4822.53426063]]    Loss_Validation:  [[ 1420.28293618]]\n",
      "Loop  6075 :    Loss_Train:  [[ 4822.53422961]]    Loss_Validation:  [[ 1420.28331345]]\n",
      "Loop  6076 :    Loss_Train:  [[ 4822.53419863]]    Loss_Validation:  [[ 1420.28369046]]\n",
      "Loop  6077 :    Loss_Train:  [[ 4822.53416771]]    Loss_Validation:  [[ 1420.2840672]]\n",
      "Loop  6078 :    Loss_Train:  [[ 4822.53413683]]    Loss_Validation:  [[ 1420.28444368]]\n",
      "Loop  6079 :    Loss_Train:  [[ 4822.534106]]    Loss_Validation:  [[ 1420.28481989]]\n",
      "Loop  6080 :    Loss_Train:  [[ 4822.53407522]]    Loss_Validation:  [[ 1420.28519583]]\n",
      "Loop  6081 :    Loss_Train:  [[ 4822.53404449]]    Loss_Validation:  [[ 1420.28557151]]\n",
      "Loop  6082 :    Loss_Train:  [[ 4822.53401381]]    Loss_Validation:  [[ 1420.28594693]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  6083 :    Loss_Train:  [[ 4822.53398318]]    Loss_Validation:  [[ 1420.28632208]]\n",
      "Loop  6084 :    Loss_Train:  [[ 4822.5339526]]    Loss_Validation:  [[ 1420.28669697]]\n",
      "Loop  6085 :    Loss_Train:  [[ 4822.53392206]]    Loss_Validation:  [[ 1420.2870716]]\n",
      "Loop  6086 :    Loss_Train:  [[ 4822.53389158]]    Loss_Validation:  [[ 1420.28744596]]\n",
      "Loop  6087 :    Loss_Train:  [[ 4822.53386114]]    Loss_Validation:  [[ 1420.28782005]]\n",
      "Loop  6088 :    Loss_Train:  [[ 4822.53383075]]    Loss_Validation:  [[ 1420.28819389]]\n",
      "Loop  6089 :    Loss_Train:  [[ 4822.53380041]]    Loss_Validation:  [[ 1420.28856746]]\n",
      "Loop  6090 :    Loss_Train:  [[ 4822.53377012]]    Loss_Validation:  [[ 1420.28894077]]\n",
      "Loop  6091 :    Loss_Train:  [[ 4822.53373987]]    Loss_Validation:  [[ 1420.28931382]]\n",
      "Loop  6092 :    Loss_Train:  [[ 4822.53370968]]    Loss_Validation:  [[ 1420.2896866]]\n",
      "Loop  6093 :    Loss_Train:  [[ 4822.53367953]]    Loss_Validation:  [[ 1420.29005912]]\n",
      "Loop  6094 :    Loss_Train:  [[ 4822.53364943]]    Loss_Validation:  [[ 1420.29043138]]\n",
      "Loop  6095 :    Loss_Train:  [[ 4822.53361938]]    Loss_Validation:  [[ 1420.29080338]]\n",
      "Loop  6096 :    Loss_Train:  [[ 4822.53358938]]    Loss_Validation:  [[ 1420.29117511]]\n",
      "Loop  6097 :    Loss_Train:  [[ 4822.53355942]]    Loss_Validation:  [[ 1420.29154658]]\n",
      "Loop  6098 :    Loss_Train:  [[ 4822.53352951]]    Loss_Validation:  [[ 1420.2919178]]\n",
      "Loop  6099 :    Loss_Train:  [[ 4822.53349965]]    Loss_Validation:  [[ 1420.29228875]]\n",
      "Loop  6100 :    Loss_Train:  [[ 4822.53346984]]    Loss_Validation:  [[ 1420.29265944]]\n",
      "Loop  6101 :    Loss_Train:  [[ 4822.53344007]]    Loss_Validation:  [[ 1420.29302987]]\n",
      "Loop  6102 :    Loss_Train:  [[ 4822.53341036]]    Loss_Validation:  [[ 1420.29340003]]\n",
      "Loop  6103 :    Loss_Train:  [[ 4822.53338069]]    Loss_Validation:  [[ 1420.29376994]]\n",
      "Loop  6104 :    Loss_Train:  [[ 4822.53335106]]    Loss_Validation:  [[ 1420.29413959]]\n",
      "Loop  6105 :    Loss_Train:  [[ 4822.53332149]]    Loss_Validation:  [[ 1420.29450898]]\n",
      "Loop  6106 :    Loss_Train:  [[ 4822.53329196]]    Loss_Validation:  [[ 1420.2948781]]\n",
      "Loop  6107 :    Loss_Train:  [[ 4822.53326248]]    Loss_Validation:  [[ 1420.29524697]]\n",
      "Loop  6108 :    Loss_Train:  [[ 4822.53323304]]    Loss_Validation:  [[ 1420.29561558]]\n",
      "Loop  6109 :    Loss_Train:  [[ 4822.53320365]]    Loss_Validation:  [[ 1420.29598393]]\n",
      "Loop  6110 :    Loss_Train:  [[ 4822.53317431]]    Loss_Validation:  [[ 1420.29635202]]\n",
      "Loop  6111 :    Loss_Train:  [[ 4822.53314502]]    Loss_Validation:  [[ 1420.29671985]]\n",
      "Loop  6112 :    Loss_Train:  [[ 4822.53311577]]    Loss_Validation:  [[ 1420.29708742]]\n",
      "Loop  6113 :    Loss_Train:  [[ 4822.53308657]]    Loss_Validation:  [[ 1420.29745473]]\n",
      "Loop  6114 :    Loss_Train:  [[ 4822.53305741]]    Loss_Validation:  [[ 1420.29782178]]\n",
      "Loop  6115 :    Loss_Train:  [[ 4822.5330283]]    Loss_Validation:  [[ 1420.29818858]]\n",
      "Loop  6116 :    Loss_Train:  [[ 4822.53299924]]    Loss_Validation:  [[ 1420.29855512]]\n",
      "Loop  6117 :    Loss_Train:  [[ 4822.53297023]]    Loss_Validation:  [[ 1420.2989214]]\n",
      "Loop  6118 :    Loss_Train:  [[ 4822.53294126]]    Loss_Validation:  [[ 1420.29928742]]\n",
      "Loop  6119 :    Loss_Train:  [[ 4822.53291233]]    Loss_Validation:  [[ 1420.29965318]]\n",
      "Loop  6120 :    Loss_Train:  [[ 4822.53288345]]    Loss_Validation:  [[ 1420.30001869]]\n",
      "Loop  6121 :    Loss_Train:  [[ 4822.53285462]]    Loss_Validation:  [[ 1420.30038394]]\n",
      "Loop  6122 :    Loss_Train:  [[ 4822.53282584]]    Loss_Validation:  [[ 1420.30074893]]\n",
      "Loop  6123 :    Loss_Train:  [[ 4822.5327971]]    Loss_Validation:  [[ 1420.30111367]]\n",
      "Loop  6124 :    Loss_Train:  [[ 4822.5327684]]    Loss_Validation:  [[ 1420.30147814]]\n",
      "Loop  6125 :    Loss_Train:  [[ 4822.53273976]]    Loss_Validation:  [[ 1420.30184237]]\n",
      "Loop  6126 :    Loss_Train:  [[ 4822.53271115]]    Loss_Validation:  [[ 1420.30220633]]\n",
      "Loop  6127 :    Loss_Train:  [[ 4822.5326826]]    Loss_Validation:  [[ 1420.30257004]]\n",
      "Loop  6128 :    Loss_Train:  [[ 4822.53265408]]    Loss_Validation:  [[ 1420.30293349]]\n",
      "Loop  6129 :    Loss_Train:  [[ 4822.53262562]]    Loss_Validation:  [[ 1420.30329669]]\n",
      "Loop  6130 :    Loss_Train:  [[ 4822.5325972]]    Loss_Validation:  [[ 1420.30365963]]\n",
      "Loop  6131 :    Loss_Train:  [[ 4822.53256882]]    Loss_Validation:  [[ 1420.30402232]]\n",
      "Loop  6132 :    Loss_Train:  [[ 4822.53254049]]    Loss_Validation:  [[ 1420.30438475]]\n",
      "Loop  6133 :    Loss_Train:  [[ 4822.53251221]]    Loss_Validation:  [[ 1420.30474693]]\n",
      "Loop  6134 :    Loss_Train:  [[ 4822.53248397]]    Loss_Validation:  [[ 1420.30510885]]\n",
      "Loop  6135 :    Loss_Train:  [[ 4822.53245577]]    Loss_Validation:  [[ 1420.30547051]]\n",
      "Loop  6136 :    Loss_Train:  [[ 4822.53242762]]    Loss_Validation:  [[ 1420.30583193]]\n",
      "Loop  6137 :    Loss_Train:  [[ 4822.53239951]]    Loss_Validation:  [[ 1420.30619308]]\n",
      "Loop  6138 :    Loss_Train:  [[ 4822.53237145]]    Loss_Validation:  [[ 1420.30655399]]\n",
      "Loop  6139 :    Loss_Train:  [[ 4822.53234344]]    Loss_Validation:  [[ 1420.30691464]]\n",
      "Loop  6140 :    Loss_Train:  [[ 4822.53231547]]    Loss_Validation:  [[ 1420.30727503]]\n",
      "Loop  6141 :    Loss_Train:  [[ 4822.53228754]]    Loss_Validation:  [[ 1420.30763517]]\n",
      "Loop  6142 :    Loss_Train:  [[ 4822.53225966]]    Loss_Validation:  [[ 1420.30799506]]\n",
      "Loop  6143 :    Loss_Train:  [[ 4822.53223182]]    Loss_Validation:  [[ 1420.30835469]]\n",
      "Loop  6144 :    Loss_Train:  [[ 4822.53220402]]    Loss_Validation:  [[ 1420.30871407]]\n",
      "Loop  6145 :    Loss_Train:  [[ 4822.53217627]]    Loss_Validation:  [[ 1420.3090732]]\n",
      "Loop  6146 :    Loss_Train:  [[ 4822.53214857]]    Loss_Validation:  [[ 1420.30943208]]\n",
      "Loop  6147 :    Loss_Train:  [[ 4822.53212091]]    Loss_Validation:  [[ 1420.3097907]]\n",
      "Loop  6148 :    Loss_Train:  [[ 4822.53209329]]    Loss_Validation:  [[ 1420.31014907]]\n",
      "Loop  6149 :    Loss_Train:  [[ 4822.53206572]]    Loss_Validation:  [[ 1420.31050719]]\n",
      "Loop  6150 :    Loss_Train:  [[ 4822.53203819]]    Loss_Validation:  [[ 1420.31086505]]\n",
      "Loop  6151 :    Loss_Train:  [[ 4822.5320107]]    Loss_Validation:  [[ 1420.31122267]]\n",
      "Loop  6152 :    Loss_Train:  [[ 4822.53198326]]    Loss_Validation:  [[ 1420.31158003]]\n",
      "Loop  6153 :    Loss_Train:  [[ 4822.53195586]]    Loss_Validation:  [[ 1420.31193714]]\n",
      "Loop  6154 :    Loss_Train:  [[ 4822.53192851]]    Loss_Validation:  [[ 1420.312294]]\n",
      "Loop  6155 :    Loss_Train:  [[ 4822.5319012]]    Loss_Validation:  [[ 1420.31265061]]\n",
      "Loop  6156 :    Loss_Train:  [[ 4822.53187393]]    Loss_Validation:  [[ 1420.31300696]]\n",
      "Loop  6157 :    Loss_Train:  [[ 4822.5318467]]    Loss_Validation:  [[ 1420.31336307]]\n",
      "Loop  6158 :    Loss_Train:  [[ 4822.53181952]]    Loss_Validation:  [[ 1420.31371892]]\n",
      "Loop  6159 :    Loss_Train:  [[ 4822.53179239]]    Loss_Validation:  [[ 1420.31407453]]\n",
      "Loop  6160 :    Loss_Train:  [[ 4822.53176529]]    Loss_Validation:  [[ 1420.31442988]]\n",
      "Loop  6161 :    Loss_Train:  [[ 4822.53173824]]    Loss_Validation:  [[ 1420.31478499]]\n",
      "Loop  6162 :    Loss_Train:  [[ 4822.53171123]]    Loss_Validation:  [[ 1420.31513984]]\n",
      "Loop  6163 :    Loss_Train:  [[ 4822.53168427]]    Loss_Validation:  [[ 1420.31549444]]\n",
      "Loop  6164 :    Loss_Train:  [[ 4822.53165735]]    Loss_Validation:  [[ 1420.3158488]]\n",
      "Loop  6165 :    Loss_Train:  [[ 4822.53163047]]    Loss_Validation:  [[ 1420.3162029]]\n",
      "Loop  6166 :    Loss_Train:  [[ 4822.53160363]]    Loss_Validation:  [[ 1420.31655676]]\n",
      "Loop  6167 :    Loss_Train:  [[ 4822.53157684]]    Loss_Validation:  [[ 1420.31691036]]\n",
      "Loop  6168 :    Loss_Train:  [[ 4822.53155008]]    Loss_Validation:  [[ 1420.31726372]]\n",
      "Loop  6169 :    Loss_Train:  [[ 4822.53152338]]    Loss_Validation:  [[ 1420.31761683]]\n",
      "Loop  6170 :    Loss_Train:  [[ 4822.53149671]]    Loss_Validation:  [[ 1420.31796969]]\n",
      "Loop  6171 :    Loss_Train:  [[ 4822.53147009]]    Loss_Validation:  [[ 1420.3183223]]\n",
      "Loop  6172 :    Loss_Train:  [[ 4822.5314435]]    Loss_Validation:  [[ 1420.31867466]]\n",
      "Loop  6173 :    Loss_Train:  [[ 4822.53141697]]    Loss_Validation:  [[ 1420.31902678]]\n",
      "Loop  6174 :    Loss_Train:  [[ 4822.53139047]]    Loss_Validation:  [[ 1420.31937864]]\n",
      "Loop  6175 :    Loss_Train:  [[ 4822.53136401]]    Loss_Validation:  [[ 1420.31973026]]\n",
      "Loop  6176 :    Loss_Train:  [[ 4822.5313376]]    Loss_Validation:  [[ 1420.32008163]]\n",
      "Loop  6177 :    Loss_Train:  [[ 4822.53131123]]    Loss_Validation:  [[ 1420.32043276]]\n",
      "Loop  6178 :    Loss_Train:  [[ 4822.5312849]]    Loss_Validation:  [[ 1420.32078364]]\n",
      "Loop  6179 :    Loss_Train:  [[ 4822.53125862]]    Loss_Validation:  [[ 1420.32113427]]\n",
      "Loop  6180 :    Loss_Train:  [[ 4822.53123237]]    Loss_Validation:  [[ 1420.32148465]]\n",
      "Loop  6181 :    Loss_Train:  [[ 4822.53120617]]    Loss_Validation:  [[ 1420.32183478]]\n",
      "Loop  6182 :    Loss_Train:  [[ 4822.53118001]]    Loss_Validation:  [[ 1420.32218467]]\n",
      "Loop  6183 :    Loss_Train:  [[ 4822.53115389]]    Loss_Validation:  [[ 1420.32253432]]\n",
      "Loop  6184 :    Loss_Train:  [[ 4822.53112781]]    Loss_Validation:  [[ 1420.32288371]]\n",
      "Loop  6185 :    Loss_Train:  [[ 4822.53110177]]    Loss_Validation:  [[ 1420.32323286]]\n",
      "Loop  6186 :    Loss_Train:  [[ 4822.53107578]]    Loss_Validation:  [[ 1420.32358177]]\n",
      "Loop  6187 :    Loss_Train:  [[ 4822.53104982]]    Loss_Validation:  [[ 1420.32393043]]\n",
      "Loop  6188 :    Loss_Train:  [[ 4822.53102391]]    Loss_Validation:  [[ 1420.32427884]]\n",
      "Loop  6189 :    Loss_Train:  [[ 4822.53099804]]    Loss_Validation:  [[ 1420.32462701]]\n",
      "Loop  6190 :    Loss_Train:  [[ 4822.53097221]]    Loss_Validation:  [[ 1420.32497493]]\n",
      "Loop  6191 :    Loss_Train:  [[ 4822.53094642]]    Loss_Validation:  [[ 1420.32532261]]\n",
      "Loop  6192 :    Loss_Train:  [[ 4822.53092067]]    Loss_Validation:  [[ 1420.32567004]]\n",
      "Loop  6193 :    Loss_Train:  [[ 4822.53089497]]    Loss_Validation:  [[ 1420.32601723]]\n",
      "Loop  6194 :    Loss_Train:  [[ 4822.5308693]]    Loss_Validation:  [[ 1420.32636418]]\n",
      "Loop  6195 :    Loss_Train:  [[ 4822.53084367]]    Loss_Validation:  [[ 1420.32671087]]\n",
      "Loop  6196 :    Loss_Train:  [[ 4822.53081809]]    Loss_Validation:  [[ 1420.32705733]]\n",
      "Loop  6197 :    Loss_Train:  [[ 4822.53079255]]    Loss_Validation:  [[ 1420.32740354]]\n",
      "Loop  6198 :    Loss_Train:  [[ 4822.53076704]]    Loss_Validation:  [[ 1420.32774951]]\n",
      "Loop  6199 :    Loss_Train:  [[ 4822.53074158]]    Loss_Validation:  [[ 1420.32809523]]\n",
      "Loop  6200 :    Loss_Train:  [[ 4822.53071616]]    Loss_Validation:  [[ 1420.32844071]]\n",
      "Loop  6201 :    Loss_Train:  [[ 4822.53069078]]    Loss_Validation:  [[ 1420.32878595]]\n",
      "Loop  6202 :    Loss_Train:  [[ 4822.53066543]]    Loss_Validation:  [[ 1420.32913094]]\n",
      "Loop  6203 :    Loss_Train:  [[ 4822.53064013]]    Loss_Validation:  [[ 1420.32947569]]\n",
      "Loop  6204 :    Loss_Train:  [[ 4822.53061487]]    Loss_Validation:  [[ 1420.3298202]]\n",
      "Loop  6205 :    Loss_Train:  [[ 4822.53058965]]    Loss_Validation:  [[ 1420.33016447]]\n",
      "Loop  6206 :    Loss_Train:  [[ 4822.53056447]]    Loss_Validation:  [[ 1420.33050849]]\n",
      "Loop  6207 :    Loss_Train:  [[ 4822.53053933]]    Loss_Validation:  [[ 1420.33085227]]\n",
      "Loop  6208 :    Loss_Train:  [[ 4822.53051423]]    Loss_Validation:  [[ 1420.33119581]]\n",
      "Loop  6209 :    Loss_Train:  [[ 4822.53048917]]    Loss_Validation:  [[ 1420.3315391]]\n",
      "Loop  6210 :    Loss_Train:  [[ 4822.53046415]]    Loss_Validation:  [[ 1420.33188216]]\n",
      "Loop  6211 :    Loss_Train:  [[ 4822.53043917]]    Loss_Validation:  [[ 1420.33222497]]\n",
      "Loop  6212 :    Loss_Train:  [[ 4822.53041423]]    Loss_Validation:  [[ 1420.33256754]]\n",
      "Loop  6213 :    Loss_Train:  [[ 4822.53038933]]    Loss_Validation:  [[ 1420.33290987]]\n",
      "Loop  6214 :    Loss_Train:  [[ 4822.53036447]]    Loss_Validation:  [[ 1420.33325196]]\n",
      "Loop  6215 :    Loss_Train:  [[ 4822.53033964]]    Loss_Validation:  [[ 1420.33359381]]\n",
      "Loop  6216 :    Loss_Train:  [[ 4822.53031486]]    Loss_Validation:  [[ 1420.33393542]]\n",
      "Loop  6217 :    Loss_Train:  [[ 4822.53029012]]    Loss_Validation:  [[ 1420.33427678]]\n",
      "Loop  6218 :    Loss_Train:  [[ 4822.53026541]]    Loss_Validation:  [[ 1420.33461791]]\n",
      "Loop  6219 :    Loss_Train:  [[ 4822.53024075]]    Loss_Validation:  [[ 1420.3349588]]\n",
      "Loop  6220 :    Loss_Train:  [[ 4822.53021612]]    Loss_Validation:  [[ 1420.33529944]]\n",
      "Loop  6221 :    Loss_Train:  [[ 4822.53019154]]    Loss_Validation:  [[ 1420.33563985]]\n",
      "Loop  6222 :    Loss_Train:  [[ 4822.53016699]]    Loss_Validation:  [[ 1420.33598001]]\n",
      "Loop  6223 :    Loss_Train:  [[ 4822.53014248]]    Loss_Validation:  [[ 1420.33631994]]\n",
      "Loop  6224 :    Loss_Train:  [[ 4822.53011801]]    Loss_Validation:  [[ 1420.33665963]]\n",
      "Loop  6225 :    Loss_Train:  [[ 4822.53009358]]    Loss_Validation:  [[ 1420.33699907]]\n",
      "Loop  6226 :    Loss_Train:  [[ 4822.53006919]]    Loss_Validation:  [[ 1420.33733828]]\n",
      "Loop  6227 :    Loss_Train:  [[ 4822.53004484]]    Loss_Validation:  [[ 1420.33767725]]\n",
      "Loop  6228 :    Loss_Train:  [[ 4822.53002053]]    Loss_Validation:  [[ 1420.33801598]]\n",
      "Loop  6229 :    Loss_Train:  [[ 4822.52999625]]    Loss_Validation:  [[ 1420.33835447]]\n",
      "Loop  6230 :    Loss_Train:  [[ 4822.52997202]]    Loss_Validation:  [[ 1420.33869273]]\n",
      "Loop  6231 :    Loss_Train:  [[ 4822.52994782]]    Loss_Validation:  [[ 1420.33903074]]\n",
      "Loop  6232 :    Loss_Train:  [[ 4822.52992366]]    Loss_Validation:  [[ 1420.33936852]]\n",
      "Loop  6233 :    Loss_Train:  [[ 4822.52989954]]    Loss_Validation:  [[ 1420.33970606]]\n",
      "Loop  6234 :    Loss_Train:  [[ 4822.52987545]]    Loss_Validation:  [[ 1420.34004336]]\n",
      "Loop  6235 :    Loss_Train:  [[ 4822.52985141]]    Loss_Validation:  [[ 1420.34038042]]\n",
      "Loop  6236 :    Loss_Train:  [[ 4822.5298274]]    Loss_Validation:  [[ 1420.34071725]]\n",
      "Loop  6237 :    Loss_Train:  [[ 4822.52980344]]    Loss_Validation:  [[ 1420.34105384]]\n",
      "Loop  6238 :    Loss_Train:  [[ 4822.52977951]]    Loss_Validation:  [[ 1420.34139019]]\n",
      "Loop  6239 :    Loss_Train:  [[ 4822.52975562]]    Loss_Validation:  [[ 1420.3417263]]\n",
      "Loop  6240 :    Loss_Train:  [[ 4822.52973176]]    Loss_Validation:  [[ 1420.34206218]]\n",
      "Loop  6241 :    Loss_Train:  [[ 4822.52970795]]    Loss_Validation:  [[ 1420.34239782]]\n",
      "Loop  6242 :    Loss_Train:  [[ 4822.52968417]]    Loss_Validation:  [[ 1420.34273323]]\n",
      "Loop  6243 :    Loss_Train:  [[ 4822.52966043]]    Loss_Validation:  [[ 1420.34306839]]\n",
      "Loop  6244 :    Loss_Train:  [[ 4822.52963673]]    Loss_Validation:  [[ 1420.34340333]]\n",
      "Loop  6245 :    Loss_Train:  [[ 4822.52961306]]    Loss_Validation:  [[ 1420.34373802]]\n",
      "Loop  6246 :    Loss_Train:  [[ 4822.52958943]]    Loss_Validation:  [[ 1420.34407248]]\n",
      "Loop  6247 :    Loss_Train:  [[ 4822.52956584]]    Loss_Validation:  [[ 1420.34440671]]\n",
      "Loop  6248 :    Loss_Train:  [[ 4822.52954229]]    Loss_Validation:  [[ 1420.3447407]]\n",
      "Loop  6249 :    Loss_Train:  [[ 4822.52951878]]    Loss_Validation:  [[ 1420.34507445]]\n",
      "Loop  6250 :    Loss_Train:  [[ 4822.5294953]]    Loss_Validation:  [[ 1420.34540797]]\n",
      "Loop  6251 :    Loss_Train:  [[ 4822.52947186]]    Loss_Validation:  [[ 1420.34574125]]\n",
      "Loop  6252 :    Loss_Train:  [[ 4822.52944846]]    Loss_Validation:  [[ 1420.3460743]]\n",
      "Loop  6253 :    Loss_Train:  [[ 4822.52942509]]    Loss_Validation:  [[ 1420.34640711]]\n",
      "Loop  6254 :    Loss_Train:  [[ 4822.52940177]]    Loss_Validation:  [[ 1420.34673969]]\n",
      "Loop  6255 :    Loss_Train:  [[ 4822.52937847]]    Loss_Validation:  [[ 1420.34707204]]\n",
      "Loop  6256 :    Loss_Train:  [[ 4822.52935522]]    Loss_Validation:  [[ 1420.34740415]]\n",
      "Loop  6257 :    Loss_Train:  [[ 4822.529332]]    Loss_Validation:  [[ 1420.34773603]]\n",
      "Loop  6258 :    Loss_Train:  [[ 4822.52930882]]    Loss_Validation:  [[ 1420.34806767]]\n",
      "Loop  6259 :    Loss_Train:  [[ 4822.52928568]]    Loss_Validation:  [[ 1420.34839908]]\n",
      "Loop  6260 :    Loss_Train:  [[ 4822.52926257]]    Loss_Validation:  [[ 1420.34873026]]\n",
      "Loop  6261 :    Loss_Train:  [[ 4822.5292395]]    Loss_Validation:  [[ 1420.3490612]]\n",
      "Loop  6262 :    Loss_Train:  [[ 4822.52921647]]    Loss_Validation:  [[ 1420.34939191]]\n",
      "Loop  6263 :    Loss_Train:  [[ 4822.52919347]]    Loss_Validation:  [[ 1420.34972238]]\n",
      "Loop  6264 :    Loss_Train:  [[ 4822.52917051]]    Loss_Validation:  [[ 1420.35005263]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  6265 :    Loss_Train:  [[ 4822.52914759]]    Loss_Validation:  [[ 1420.35038264]]\n",
      "Loop  6266 :    Loss_Train:  [[ 4822.5291247]]    Loss_Validation:  [[ 1420.35071242]]\n",
      "Loop  6267 :    Loss_Train:  [[ 4822.52910185]]    Loss_Validation:  [[ 1420.35104196]]\n",
      "Loop  6268 :    Loss_Train:  [[ 4822.52907904]]    Loss_Validation:  [[ 1420.35137128]]\n",
      "Loop  6269 :    Loss_Train:  [[ 4822.52905626]]    Loss_Validation:  [[ 1420.35170036]]\n",
      "Loop  6270 :    Loss_Train:  [[ 4822.52903352]]    Loss_Validation:  [[ 1420.35202921]]\n",
      "Loop  6271 :    Loss_Train:  [[ 4822.52901081]]    Loss_Validation:  [[ 1420.35235782]]\n",
      "Loop  6272 :    Loss_Train:  [[ 4822.52898815]]    Loss_Validation:  [[ 1420.35268621]]\n",
      "Loop  6273 :    Loss_Train:  [[ 4822.52896551]]    Loss_Validation:  [[ 1420.35301436]]\n",
      "Loop  6274 :    Loss_Train:  [[ 4822.52894291]]    Loss_Validation:  [[ 1420.35334229]]\n",
      "Loop  6275 :    Loss_Train:  [[ 4822.52892035]]    Loss_Validation:  [[ 1420.35366998]]\n",
      "Loop  6276 :    Loss_Train:  [[ 4822.52889783]]    Loss_Validation:  [[ 1420.35399744]]\n",
      "Loop  6277 :    Loss_Train:  [[ 4822.52887534]]    Loss_Validation:  [[ 1420.35432467]]\n",
      "Loop  6278 :    Loss_Train:  [[ 4822.52885288]]    Loss_Validation:  [[ 1420.35465167]]\n",
      "Loop  6279 :    Loss_Train:  [[ 4822.52883046]]    Loss_Validation:  [[ 1420.35497844]]\n",
      "Loop  6280 :    Loss_Train:  [[ 4822.52880808]]    Loss_Validation:  [[ 1420.35530498]]\n",
      "Loop  6281 :    Loss_Train:  [[ 4822.52878574]]    Loss_Validation:  [[ 1420.35563129]]\n",
      "Loop  6282 :    Loss_Train:  [[ 4822.52876342]]    Loss_Validation:  [[ 1420.35595737]]\n",
      "Loop  6283 :    Loss_Train:  [[ 4822.52874115]]    Loss_Validation:  [[ 1420.35628322]]\n",
      "Loop  6284 :    Loss_Train:  [[ 4822.52871891]]    Loss_Validation:  [[ 1420.35660884]]\n",
      "Loop  6285 :    Loss_Train:  [[ 4822.5286967]]    Loss_Validation:  [[ 1420.35693423]]\n",
      "Loop  6286 :    Loss_Train:  [[ 4822.52867453]]    Loss_Validation:  [[ 1420.35725939]]\n",
      "Loop  6287 :    Loss_Train:  [[ 4822.5286524]]    Loss_Validation:  [[ 1420.35758432]]\n",
      "Loop  6288 :    Loss_Train:  [[ 4822.5286303]]    Loss_Validation:  [[ 1420.35790902]]\n",
      "Loop  6289 :    Loss_Train:  [[ 4822.52860823]]    Loss_Validation:  [[ 1420.35823349]]\n",
      "Loop  6290 :    Loss_Train:  [[ 4822.5285862]]    Loss_Validation:  [[ 1420.35855774]]\n",
      "Loop  6291 :    Loss_Train:  [[ 4822.52856421]]    Loss_Validation:  [[ 1420.35888176]]\n",
      "Loop  6292 :    Loss_Train:  [[ 4822.52854225]]    Loss_Validation:  [[ 1420.35920554]]\n",
      "Loop  6293 :    Loss_Train:  [[ 4822.52852032]]    Loss_Validation:  [[ 1420.3595291]]\n",
      "Loop  6294 :    Loss_Train:  [[ 4822.52849843]]    Loss_Validation:  [[ 1420.35985244]]\n",
      "Loop  6295 :    Loss_Train:  [[ 4822.52847658]]    Loss_Validation:  [[ 1420.36017554]]\n",
      "Loop  6296 :    Loss_Train:  [[ 4822.52845476]]    Loss_Validation:  [[ 1420.36049841]]\n",
      "Loop  6297 :    Loss_Train:  [[ 4822.52843297]]    Loss_Validation:  [[ 1420.36082106]]\n",
      "Loop  6298 :    Loss_Train:  [[ 4822.52841122]]    Loss_Validation:  [[ 1420.36114348]]\n",
      "Loop  6299 :    Loss_Train:  [[ 4822.52838951]]    Loss_Validation:  [[ 1420.36146568]]\n",
      "Loop  6300 :    Loss_Train:  [[ 4822.52836782]]    Loss_Validation:  [[ 1420.36178764]]\n",
      "Loop  6301 :    Loss_Train:  [[ 4822.52834618]]    Loss_Validation:  [[ 1420.36210938]]\n",
      "Loop  6302 :    Loss_Train:  [[ 4822.52832456]]    Loss_Validation:  [[ 1420.3624309]]\n",
      "Loop  6303 :    Loss_Train:  [[ 4822.52830298]]    Loss_Validation:  [[ 1420.36275218]]\n",
      "Loop  6304 :    Loss_Train:  [[ 4822.52828144]]    Loss_Validation:  [[ 1420.36307324]]\n",
      "Loop  6305 :    Loss_Train:  [[ 4822.52825993]]    Loss_Validation:  [[ 1420.36339408]]\n",
      "Loop  6306 :    Loss_Train:  [[ 4822.52823845]]    Loss_Validation:  [[ 1420.36371468]]\n",
      "Loop  6307 :    Loss_Train:  [[ 4822.52821701]]    Loss_Validation:  [[ 1420.36403506]]\n",
      "Loop  6308 :    Loss_Train:  [[ 4822.5281956]]    Loss_Validation:  [[ 1420.36435522]]\n",
      "Loop  6309 :    Loss_Train:  [[ 4822.52817423]]    Loss_Validation:  [[ 1420.36467515]]\n",
      "Loop  6310 :    Loss_Train:  [[ 4822.52815289]]    Loss_Validation:  [[ 1420.36499485]]\n",
      "Loop  6311 :    Loss_Train:  [[ 4822.52813159]]    Loss_Validation:  [[ 1420.36531433]]\n",
      "Loop  6312 :    Loss_Train:  [[ 4822.52811031]]    Loss_Validation:  [[ 1420.36563358]]\n",
      "Loop  6313 :    Loss_Train:  [[ 4822.52808908]]    Loss_Validation:  [[ 1420.36595261]]\n",
      "Loop  6314 :    Loss_Train:  [[ 4822.52806787]]    Loss_Validation:  [[ 1420.36627142]]\n",
      "Loop  6315 :    Loss_Train:  [[ 4822.5280467]]    Loss_Validation:  [[ 1420.36658999]]\n",
      "Loop  6316 :    Loss_Train:  [[ 4822.52802556]]    Loss_Validation:  [[ 1420.36690835]]\n",
      "Loop  6317 :    Loss_Train:  [[ 4822.52800446]]    Loss_Validation:  [[ 1420.36722648]]\n",
      "Loop  6318 :    Loss_Train:  [[ 4822.52798339]]    Loss_Validation:  [[ 1420.36754438]]\n",
      "Loop  6319 :    Loss_Train:  [[ 4822.52796235]]    Loss_Validation:  [[ 1420.36786206]]\n",
      "Loop  6320 :    Loss_Train:  [[ 4822.52794135]]    Loss_Validation:  [[ 1420.36817952]]\n",
      "Loop  6321 :    Loss_Train:  [[ 4822.52792038]]    Loss_Validation:  [[ 1420.36849676]]\n",
      "Loop  6322 :    Loss_Train:  [[ 4822.52789944]]    Loss_Validation:  [[ 1420.36881377]]\n",
      "Loop  6323 :    Loss_Train:  [[ 4822.52787854]]    Loss_Validation:  [[ 1420.36913055]]\n",
      "Loop  6324 :    Loss_Train:  [[ 4822.52785767]]    Loss_Validation:  [[ 1420.36944711]]\n",
      "Loop  6325 :    Loss_Train:  [[ 4822.52783683]]    Loss_Validation:  [[ 1420.36976345]]\n",
      "Loop  6326 :    Loss_Train:  [[ 4822.52781603]]    Loss_Validation:  [[ 1420.37007957]]\n",
      "Loop  6327 :    Loss_Train:  [[ 4822.52779526]]    Loss_Validation:  [[ 1420.37039546]]\n",
      "Loop  6328 :    Loss_Train:  [[ 4822.52777452]]    Loss_Validation:  [[ 1420.37071114]]\n",
      "Loop  6329 :    Loss_Train:  [[ 4822.52775382]]    Loss_Validation:  [[ 1420.37102658]]\n",
      "Loop  6330 :    Loss_Train:  [[ 4822.52773315]]    Loss_Validation:  [[ 1420.37134181]]\n",
      "Loop  6331 :    Loss_Train:  [[ 4822.52771251]]    Loss_Validation:  [[ 1420.37165681]]\n",
      "Loop  6332 :    Loss_Train:  [[ 4822.5276919]]    Loss_Validation:  [[ 1420.37197159]]\n",
      "Loop  6333 :    Loss_Train:  [[ 4822.52767133]]    Loss_Validation:  [[ 1420.37228615]]\n",
      "Loop  6334 :    Loss_Train:  [[ 4822.52765079]]    Loss_Validation:  [[ 1420.37260049]]\n",
      "Loop  6335 :    Loss_Train:  [[ 4822.52763028]]    Loss_Validation:  [[ 1420.37291461]]\n",
      "Loop  6336 :    Loss_Train:  [[ 4822.5276098]]    Loss_Validation:  [[ 1420.3732285]]\n",
      "Loop  6337 :    Loss_Train:  [[ 4822.52758936]]    Loss_Validation:  [[ 1420.37354218]]\n",
      "Loop  6338 :    Loss_Train:  [[ 4822.52756895]]    Loss_Validation:  [[ 1420.37385563]]\n",
      "Loop  6339 :    Loss_Train:  [[ 4822.52754857]]    Loss_Validation:  [[ 1420.37416886]]\n",
      "Loop  6340 :    Loss_Train:  [[ 4822.52752823]]    Loss_Validation:  [[ 1420.37448187]]\n",
      "Loop  6341 :    Loss_Train:  [[ 4822.52750791]]    Loss_Validation:  [[ 1420.37479466]]\n",
      "Loop  6342 :    Loss_Train:  [[ 4822.52748763]]    Loss_Validation:  [[ 1420.37510723]]\n",
      "Loop  6343 :    Loss_Train:  [[ 4822.52746738]]    Loss_Validation:  [[ 1420.37541958]]\n",
      "Loop  6344 :    Loss_Train:  [[ 4822.52744717]]    Loss_Validation:  [[ 1420.37573171]]\n",
      "Loop  6345 :    Loss_Train:  [[ 4822.52742698]]    Loss_Validation:  [[ 1420.37604361]]\n",
      "Loop  6346 :    Loss_Train:  [[ 4822.52740683]]    Loss_Validation:  [[ 1420.3763553]]\n",
      "Loop  6347 :    Loss_Train:  [[ 4822.52738671]]    Loss_Validation:  [[ 1420.37666677]]\n",
      "Loop  6348 :    Loss_Train:  [[ 4822.52736662]]    Loss_Validation:  [[ 1420.37697802]]\n",
      "Loop  6349 :    Loss_Train:  [[ 4822.52734656]]    Loss_Validation:  [[ 1420.37728905]]\n",
      "Loop  6350 :    Loss_Train:  [[ 4822.52732654]]    Loss_Validation:  [[ 1420.37759986]]\n",
      "Loop  6351 :    Loss_Train:  [[ 4822.52730655]]    Loss_Validation:  [[ 1420.37791045]]\n",
      "Loop  6352 :    Loss_Train:  [[ 4822.52728658]]    Loss_Validation:  [[ 1420.37822082]]\n",
      "Loop  6353 :    Loss_Train:  [[ 4822.52726666]]    Loss_Validation:  [[ 1420.37853097]]\n",
      "Loop  6354 :    Loss_Train:  [[ 4822.52724676]]    Loss_Validation:  [[ 1420.37884091]]\n",
      "Loop  6355 :    Loss_Train:  [[ 4822.52722689]]    Loss_Validation:  [[ 1420.37915062]]\n",
      "Loop  6356 :    Loss_Train:  [[ 4822.52720706]]    Loss_Validation:  [[ 1420.37946012]]\n",
      "Loop  6357 :    Loss_Train:  [[ 4822.52718725]]    Loss_Validation:  [[ 1420.3797694]]\n",
      "Loop  6358 :    Loss_Train:  [[ 4822.52716748]]    Loss_Validation:  [[ 1420.38007846]]\n",
      "Loop  6359 :    Loss_Train:  [[ 4822.52714774]]    Loss_Validation:  [[ 1420.3803873]]\n",
      "Loop  6360 :    Loss_Train:  [[ 4822.52712803]]    Loss_Validation:  [[ 1420.38069593]]\n",
      "Loop  6361 :    Loss_Train:  [[ 4822.52710835]]    Loss_Validation:  [[ 1420.38100434]]\n",
      "Loop  6362 :    Loss_Train:  [[ 4822.52708871]]    Loss_Validation:  [[ 1420.38131253]]\n",
      "Loop  6363 :    Loss_Train:  [[ 4822.52706909]]    Loss_Validation:  [[ 1420.3816205]]\n",
      "Loop  6364 :    Loss_Train:  [[ 4822.52704951]]    Loss_Validation:  [[ 1420.38192825]]\n",
      "Loop  6365 :    Loss_Train:  [[ 4822.52702996]]    Loss_Validation:  [[ 1420.38223579]]\n",
      "Loop  6366 :    Loss_Train:  [[ 4822.52701043]]    Loss_Validation:  [[ 1420.38254311]]\n",
      "Loop  6367 :    Loss_Train:  [[ 4822.52699094]]    Loss_Validation:  [[ 1420.38285022]]\n",
      "Loop  6368 :    Loss_Train:  [[ 4822.52697148]]    Loss_Validation:  [[ 1420.38315711]]\n",
      "Loop  6369 :    Loss_Train:  [[ 4822.52695205]]    Loss_Validation:  [[ 1420.38346378]]\n",
      "Loop  6370 :    Loss_Train:  [[ 4822.52693266]]    Loss_Validation:  [[ 1420.38377023]]\n",
      "Loop  6371 :    Loss_Train:  [[ 4822.52691329]]    Loss_Validation:  [[ 1420.38407647]]\n",
      "Loop  6372 :    Loss_Train:  [[ 4822.52689395]]    Loss_Validation:  [[ 1420.38438249]]\n",
      "Loop  6373 :    Loss_Train:  [[ 4822.52687465]]    Loss_Validation:  [[ 1420.3846883]]\n",
      "Loop  6374 :    Loss_Train:  [[ 4822.52685537]]    Loss_Validation:  [[ 1420.38499389]]\n",
      "Loop  6375 :    Loss_Train:  [[ 4822.52683613]]    Loss_Validation:  [[ 1420.38529927]]\n",
      "Loop  6376 :    Loss_Train:  [[ 4822.52681691]]    Loss_Validation:  [[ 1420.38560443]]\n",
      "Loop  6377 :    Loss_Train:  [[ 4822.52679773]]    Loss_Validation:  [[ 1420.38590937]]\n",
      "Loop  6378 :    Loss_Train:  [[ 4822.52677857]]    Loss_Validation:  [[ 1420.3862141]]\n",
      "Loop  6379 :    Loss_Train:  [[ 4822.52675945]]    Loss_Validation:  [[ 1420.38651862]]\n",
      "Loop  6380 :    Loss_Train:  [[ 4822.52674036]]    Loss_Validation:  [[ 1420.38682292]]\n",
      "Loop  6381 :    Loss_Train:  [[ 4822.5267213]]    Loss_Validation:  [[ 1420.38712701]]\n",
      "Loop  6382 :    Loss_Train:  [[ 4822.52670227]]    Loss_Validation:  [[ 1420.38743088]]\n",
      "Loop  6383 :    Loss_Train:  [[ 4822.52668326]]    Loss_Validation:  [[ 1420.38773453]]\n",
      "Loop  6384 :    Loss_Train:  [[ 4822.52666429]]    Loss_Validation:  [[ 1420.38803798]]\n",
      "Loop  6385 :    Loss_Train:  [[ 4822.52664535]]    Loss_Validation:  [[ 1420.38834121]]\n",
      "Loop  6386 :    Loss_Train:  [[ 4822.52662644]]    Loss_Validation:  [[ 1420.38864422]]\n",
      "Loop  6387 :    Loss_Train:  [[ 4822.52660756]]    Loss_Validation:  [[ 1420.38894702]]\n",
      "Loop  6388 :    Loss_Train:  [[ 4822.52658871]]    Loss_Validation:  [[ 1420.38924961]]\n",
      "Loop  6389 :    Loss_Train:  [[ 4822.52656989]]    Loss_Validation:  [[ 1420.38955198]]\n",
      "Loop  6390 :    Loss_Train:  [[ 4822.5265511]]    Loss_Validation:  [[ 1420.38985414]]\n",
      "Loop  6391 :    Loss_Train:  [[ 4822.52653233]]    Loss_Validation:  [[ 1420.39015609]]\n",
      "Loop  6392 :    Loss_Train:  [[ 4822.5265136]]    Loss_Validation:  [[ 1420.39045782]]\n",
      "Loop  6393 :    Loss_Train:  [[ 4822.5264949]]    Loss_Validation:  [[ 1420.39075935]]\n",
      "Loop  6394 :    Loss_Train:  [[ 4822.52647623]]    Loss_Validation:  [[ 1420.39106066]]\n",
      "Loop  6395 :    Loss_Train:  [[ 4822.52645759]]    Loss_Validation:  [[ 1420.39136175]]\n",
      "Loop  6396 :    Loss_Train:  [[ 4822.52643897]]    Loss_Validation:  [[ 1420.39166264]]\n",
      "Loop  6397 :    Loss_Train:  [[ 4822.52642039]]    Loss_Validation:  [[ 1420.39196331]]\n",
      "Loop  6398 :    Loss_Train:  [[ 4822.52640183]]    Loss_Validation:  [[ 1420.39226377]]\n",
      "Loop  6399 :    Loss_Train:  [[ 4822.52638331]]    Loss_Validation:  [[ 1420.39256401]]\n",
      "Loop  6400 :    Loss_Train:  [[ 4822.52636481]]    Loss_Validation:  [[ 1420.39286405]]\n",
      "Loop  6401 :    Loss_Train:  [[ 4822.52634635]]    Loss_Validation:  [[ 1420.39316387]]\n",
      "Loop  6402 :    Loss_Train:  [[ 4822.52632791]]    Loss_Validation:  [[ 1420.39346349]]\n",
      "Loop  6403 :    Loss_Train:  [[ 4822.52630951]]    Loss_Validation:  [[ 1420.39376289]]\n",
      "Loop  6404 :    Loss_Train:  [[ 4822.52629113]]    Loss_Validation:  [[ 1420.39406208]]\n",
      "Loop  6405 :    Loss_Train:  [[ 4822.52627278]]    Loss_Validation:  [[ 1420.39436106]]\n",
      "Loop  6406 :    Loss_Train:  [[ 4822.52625446]]    Loss_Validation:  [[ 1420.39465982]]\n",
      "Loop  6407 :    Loss_Train:  [[ 4822.52623617]]    Loss_Validation:  [[ 1420.39495838]]\n",
      "Loop  6408 :    Loss_Train:  [[ 4822.52621791]]    Loss_Validation:  [[ 1420.39525673]]\n",
      "Loop  6409 :    Loss_Train:  [[ 4822.52619967]]    Loss_Validation:  [[ 1420.39555486]]\n",
      "Loop  6410 :    Loss_Train:  [[ 4822.52618147]]    Loss_Validation:  [[ 1420.39585279]]\n",
      "Loop  6411 :    Loss_Train:  [[ 4822.5261633]]    Loss_Validation:  [[ 1420.3961505]]\n",
      "Loop  6412 :    Loss_Train:  [[ 4822.52614515]]    Loss_Validation:  [[ 1420.39644801]]\n",
      "Loop  6413 :    Loss_Train:  [[ 4822.52612703]]    Loss_Validation:  [[ 1420.39674531]]\n",
      "Loop  6414 :    Loss_Train:  [[ 4822.52610894]]    Loss_Validation:  [[ 1420.39704239]]\n",
      "Loop  6415 :    Loss_Train:  [[ 4822.52609089]]    Loss_Validation:  [[ 1420.39733927]]\n",
      "Loop  6416 :    Loss_Train:  [[ 4822.52607285]]    Loss_Validation:  [[ 1420.39763593]]\n",
      "Loop  6417 :    Loss_Train:  [[ 4822.52605485]]    Loss_Validation:  [[ 1420.39793239]]\n",
      "Loop  6418 :    Loss_Train:  [[ 4822.52603688]]    Loss_Validation:  [[ 1420.39822864]]\n",
      "Loop  6419 :    Loss_Train:  [[ 4822.52601893]]    Loss_Validation:  [[ 1420.39852468]]\n",
      "Loop  6420 :    Loss_Train:  [[ 4822.52600102]]    Loss_Validation:  [[ 1420.39882051]]\n",
      "Loop  6421 :    Loss_Train:  [[ 4822.52598313]]    Loss_Validation:  [[ 1420.39911613]]\n",
      "Loop  6422 :    Loss_Train:  [[ 4822.52596527]]    Loss_Validation:  [[ 1420.39941154]]\n",
      "Loop  6423 :    Loss_Train:  [[ 4822.52594744]]    Loss_Validation:  [[ 1420.39970675]]\n",
      "Loop  6424 :    Loss_Train:  [[ 4822.52592963]]    Loss_Validation:  [[ 1420.40000174]]\n",
      "Loop  6425 :    Loss_Train:  [[ 4822.52591186]]    Loss_Validation:  [[ 1420.40029653]]\n",
      "Loop  6426 :    Loss_Train:  [[ 4822.52589411]]    Loss_Validation:  [[ 1420.40059111]]\n",
      "Loop  6427 :    Loss_Train:  [[ 4822.52587639]]    Loss_Validation:  [[ 1420.40088548]]\n",
      "Loop  6428 :    Loss_Train:  [[ 4822.5258587]]    Loss_Validation:  [[ 1420.40117965]]\n",
      "Loop  6429 :    Loss_Train:  [[ 4822.52584104]]    Loss_Validation:  [[ 1420.4014736]]\n",
      "Loop  6430 :    Loss_Train:  [[ 4822.52582341]]    Loss_Validation:  [[ 1420.40176735]]\n",
      "Loop  6431 :    Loss_Train:  [[ 4822.5258058]]    Loss_Validation:  [[ 1420.40206089]]\n",
      "Loop  6432 :    Loss_Train:  [[ 4822.52578822]]    Loss_Validation:  [[ 1420.40235423]]\n",
      "Loop  6433 :    Loss_Train:  [[ 4822.52577067]]    Loss_Validation:  [[ 1420.40264736]]\n",
      "Loop  6434 :    Loss_Train:  [[ 4822.52575315]]    Loss_Validation:  [[ 1420.40294028]]\n",
      "Loop  6435 :    Loss_Train:  [[ 4822.52573565]]    Loss_Validation:  [[ 1420.40323299]]\n",
      "Loop  6436 :    Loss_Train:  [[ 4822.52571819]]    Loss_Validation:  [[ 1420.4035255]]\n",
      "Loop  6437 :    Loss_Train:  [[ 4822.52570075]]    Loss_Validation:  [[ 1420.4038178]]\n",
      "Loop  6438 :    Loss_Train:  [[ 4822.52568333]]    Loss_Validation:  [[ 1420.40410989]]\n",
      "Loop  6439 :    Loss_Train:  [[ 4822.52566595]]    Loss_Validation:  [[ 1420.40440178]]\n",
      "Loop  6440 :    Loss_Train:  [[ 4822.52564859]]    Loss_Validation:  [[ 1420.40469347]]\n",
      "Loop  6441 :    Loss_Train:  [[ 4822.52563126]]    Loss_Validation:  [[ 1420.40498494]]\n",
      "Loop  6442 :    Loss_Train:  [[ 4822.52561396]]    Loss_Validation:  [[ 1420.40527621]]\n",
      "Loop  6443 :    Loss_Train:  [[ 4822.52559669]]    Loss_Validation:  [[ 1420.40556728]]\n",
      "Loop  6444 :    Loss_Train:  [[ 4822.52557944]]    Loss_Validation:  [[ 1420.40585814]]\n",
      "Loop  6445 :    Loss_Train:  [[ 4822.52556222]]    Loss_Validation:  [[ 1420.40614879]]\n",
      "Loop  6446 :    Loss_Train:  [[ 4822.52554503]]    Loss_Validation:  [[ 1420.40643924]]\n",
      "Loop  6447 :    Loss_Train:  [[ 4822.52552787]]    Loss_Validation:  [[ 1420.40672949]]\n",
      "Loop  6448 :    Loss_Train:  [[ 4822.52551073]]    Loss_Validation:  [[ 1420.40701953]]\n",
      "Loop  6449 :    Loss_Train:  [[ 4822.52549362]]    Loss_Validation:  [[ 1420.40730936]]\n",
      "Loop  6450 :    Loss_Train:  [[ 4822.52547654]]    Loss_Validation:  [[ 1420.40759899]]\n",
      "Loop  6451 :    Loss_Train:  [[ 4822.52545948]]    Loss_Validation:  [[ 1420.40788842]]\n",
      "Loop  6452 :    Loss_Train:  [[ 4822.52544245]]    Loss_Validation:  [[ 1420.40817764]]\n",
      "Loop  6453 :    Loss_Train:  [[ 4822.52542545]]    Loss_Validation:  [[ 1420.40846666]]\n",
      "Loop  6454 :    Loss_Train:  [[ 4822.52540847]]    Loss_Validation:  [[ 1420.40875547]]\n",
      "Loop  6455 :    Loss_Train:  [[ 4822.52539153]]    Loss_Validation:  [[ 1420.40904408]]\n",
      "Loop  6456 :    Loss_Train:  [[ 4822.5253746]]    Loss_Validation:  [[ 1420.40933249]]\n",
      "Loop  6457 :    Loss_Train:  [[ 4822.52535771]]    Loss_Validation:  [[ 1420.40962069]]\n",
      "Loop  6458 :    Loss_Train:  [[ 4822.52534084]]    Loss_Validation:  [[ 1420.40990869]]\n",
      "Loop  6459 :    Loss_Train:  [[ 4822.525324]]    Loss_Validation:  [[ 1420.41019649]]\n",
      "Loop  6460 :    Loss_Train:  [[ 4822.52530719]]    Loss_Validation:  [[ 1420.41048408]]\n",
      "Loop  6461 :    Loss_Train:  [[ 4822.5252904]]    Loss_Validation:  [[ 1420.41077147]]\n",
      "Loop  6462 :    Loss_Train:  [[ 4822.52527364]]    Loss_Validation:  [[ 1420.41105866]]\n",
      "Loop  6463 :    Loss_Train:  [[ 4822.52525691]]    Loss_Validation:  [[ 1420.41134564]]\n",
      "Loop  6464 :    Loss_Train:  [[ 4822.5252402]]    Loss_Validation:  [[ 1420.41163242]]\n",
      "Loop  6465 :    Loss_Train:  [[ 4822.52522352]]    Loss_Validation:  [[ 1420.411919]]\n",
      "Loop  6466 :    Loss_Train:  [[ 4822.52520686]]    Loss_Validation:  [[ 1420.41220538]]\n",
      "Loop  6467 :    Loss_Train:  [[ 4822.52519024]]    Loss_Validation:  [[ 1420.41249156]]\n",
      "Loop  6468 :    Loss_Train:  [[ 4822.52517363]]    Loss_Validation:  [[ 1420.41277753]]\n",
      "Loop  6469 :    Loss_Train:  [[ 4822.52515706]]    Loss_Validation:  [[ 1420.4130633]]\n",
      "Loop  6470 :    Loss_Train:  [[ 4822.52514051]]    Loss_Validation:  [[ 1420.41334887]]\n",
      "Loop  6471 :    Loss_Train:  [[ 4822.52512399]]    Loss_Validation:  [[ 1420.41363424]]\n",
      "Loop  6472 :    Loss_Train:  [[ 4822.52510749]]    Loss_Validation:  [[ 1420.4139194]]\n",
      "Loop  6473 :    Loss_Train:  [[ 4822.52509102]]    Loss_Validation:  [[ 1420.41420437]]\n",
      "Loop  6474 :    Loss_Train:  [[ 4822.52507458]]    Loss_Validation:  [[ 1420.41448913]]\n",
      "Loop  6475 :    Loss_Train:  [[ 4822.52505816]]    Loss_Validation:  [[ 1420.41477369]]\n",
      "Loop  6476 :    Loss_Train:  [[ 4822.52504176]]    Loss_Validation:  [[ 1420.41505806]]\n",
      "Loop  6477 :    Loss_Train:  [[ 4822.5250254]]    Loss_Validation:  [[ 1420.41534222]]\n",
      "Loop  6478 :    Loss_Train:  [[ 4822.52500906]]    Loss_Validation:  [[ 1420.41562618]]\n",
      "Loop  6479 :    Loss_Train:  [[ 4822.52499274]]    Loss_Validation:  [[ 1420.41590994]]\n",
      "Loop  6480 :    Loss_Train:  [[ 4822.52497646]]    Loss_Validation:  [[ 1420.4161935]]\n",
      "Loop  6481 :    Loss_Train:  [[ 4822.52496019]]    Loss_Validation:  [[ 1420.41647686]]\n",
      "Loop  6482 :    Loss_Train:  [[ 4822.52494396]]    Loss_Validation:  [[ 1420.41676002]]\n",
      "Loop  6483 :    Loss_Train:  [[ 4822.52492774]]    Loss_Validation:  [[ 1420.41704297]]\n",
      "Loop  6484 :    Loss_Train:  [[ 4822.52491156]]    Loss_Validation:  [[ 1420.41732573]]\n",
      "Loop  6485 :    Loss_Train:  [[ 4822.5248954]]    Loss_Validation:  [[ 1420.41760829]]\n",
      "Loop  6486 :    Loss_Train:  [[ 4822.52487927]]    Loss_Validation:  [[ 1420.41789066]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  6487 :    Loss_Train:  [[ 4822.52486316]]    Loss_Validation:  [[ 1420.41817282]]\n",
      "Loop  6488 :    Loss_Train:  [[ 4822.52484707]]    Loss_Validation:  [[ 1420.41845478]]\n",
      "Loop  6489 :    Loss_Train:  [[ 4822.52483102]]    Loss_Validation:  [[ 1420.41873654]]\n",
      "Loop  6490 :    Loss_Train:  [[ 4822.52481499]]    Loss_Validation:  [[ 1420.41901811]]\n",
      "Loop  6491 :    Loss_Train:  [[ 4822.52479898]]    Loss_Validation:  [[ 1420.41929947]]\n",
      "Loop  6492 :    Loss_Train:  [[ 4822.524783]]    Loss_Validation:  [[ 1420.41958064]]\n",
      "Loop  6493 :    Loss_Train:  [[ 4822.52476704]]    Loss_Validation:  [[ 1420.41986161]]\n",
      "Loop  6494 :    Loss_Train:  [[ 4822.52475111]]    Loss_Validation:  [[ 1420.42014238]]\n",
      "Loop  6495 :    Loss_Train:  [[ 4822.52473521]]    Loss_Validation:  [[ 1420.42042295]]\n",
      "Loop  6496 :    Loss_Train:  [[ 4822.52471933]]    Loss_Validation:  [[ 1420.42070332]]\n",
      "Loop  6497 :    Loss_Train:  [[ 4822.52470347]]    Loss_Validation:  [[ 1420.4209835]]\n",
      "Loop  6498 :    Loss_Train:  [[ 4822.52468764]]    Loss_Validation:  [[ 1420.42126347]]\n",
      "Loop  6499 :    Loss_Train:  [[ 4822.52467184]]    Loss_Validation:  [[ 1420.42154325]]\n",
      "Loop  6500 :    Loss_Train:  [[ 4822.52465606]]    Loss_Validation:  [[ 1420.42182284]]\n",
      "Loop  6501 :    Loss_Train:  [[ 4822.5246403]]    Loss_Validation:  [[ 1420.42210222]]\n",
      "Loop  6502 :    Loss_Train:  [[ 4822.52462457]]    Loss_Validation:  [[ 1420.42238141]]\n",
      "Loop  6503 :    Loss_Train:  [[ 4822.52460887]]    Loss_Validation:  [[ 1420.4226604]]\n",
      "Loop  6504 :    Loss_Train:  [[ 4822.52459319]]    Loss_Validation:  [[ 1420.42293919]]\n",
      "Loop  6505 :    Loss_Train:  [[ 4822.52457754]]    Loss_Validation:  [[ 1420.42321779]]\n",
      "Loop  6506 :    Loss_Train:  [[ 4822.52456191]]    Loss_Validation:  [[ 1420.42349619]]\n",
      "Loop  6507 :    Loss_Train:  [[ 4822.5245463]]    Loss_Validation:  [[ 1420.42377439]]\n",
      "Loop  6508 :    Loss_Train:  [[ 4822.52453072]]    Loss_Validation:  [[ 1420.4240524]]\n",
      "Loop  6509 :    Loss_Train:  [[ 4822.52451516]]    Loss_Validation:  [[ 1420.42433021]]\n",
      "Loop  6510 :    Loss_Train:  [[ 4822.52449963]]    Loss_Validation:  [[ 1420.42460782]]\n",
      "Loop  6511 :    Loss_Train:  [[ 4822.52448413]]    Loss_Validation:  [[ 1420.42488524]]\n",
      "Loop  6512 :    Loss_Train:  [[ 4822.52446864]]    Loss_Validation:  [[ 1420.42516247]]\n",
      "Loop  6513 :    Loss_Train:  [[ 4822.52445319]]    Loss_Validation:  [[ 1420.42543949]]\n",
      "Loop  6514 :    Loss_Train:  [[ 4822.52443775]]    Loss_Validation:  [[ 1420.42571632]]\n",
      "Loop  6515 :    Loss_Train:  [[ 4822.52442235]]    Loss_Validation:  [[ 1420.42599296]]\n",
      "Loop  6516 :    Loss_Train:  [[ 4822.52440696]]    Loss_Validation:  [[ 1420.4262694]]\n",
      "Loop  6517 :    Loss_Train:  [[ 4822.5243916]]    Loss_Validation:  [[ 1420.42654564]]\n",
      "Loop  6518 :    Loss_Train:  [[ 4822.52437627]]    Loss_Validation:  [[ 1420.42682169]]\n",
      "Loop  6519 :    Loss_Train:  [[ 4822.52436096]]    Loss_Validation:  [[ 1420.42709755]]\n",
      "Loop  6520 :    Loss_Train:  [[ 4822.52434567]]    Loss_Validation:  [[ 1420.42737321]]\n",
      "Loop  6521 :    Loss_Train:  [[ 4822.52433041]]    Loss_Validation:  [[ 1420.42764867]]\n",
      "Loop  6522 :    Loss_Train:  [[ 4822.52431517]]    Loss_Validation:  [[ 1420.42792395]]\n",
      "Loop  6523 :    Loss_Train:  [[ 4822.52429996]]    Loss_Validation:  [[ 1420.42819902]]\n",
      "Loop  6524 :    Loss_Train:  [[ 4822.52428477]]    Loss_Validation:  [[ 1420.4284739]]\n",
      "Loop  6525 :    Loss_Train:  [[ 4822.5242696]]    Loss_Validation:  [[ 1420.42874859]]\n",
      "Loop  6526 :    Loss_Train:  [[ 4822.52425446]]    Loss_Validation:  [[ 1420.42902309]]\n",
      "Loop  6527 :    Loss_Train:  [[ 4822.52423934]]    Loss_Validation:  [[ 1420.42929739]]\n",
      "Loop  6528 :    Loss_Train:  [[ 4822.52422425]]    Loss_Validation:  [[ 1420.42957149]]\n",
      "Loop  6529 :    Loss_Train:  [[ 4822.52420918]]    Loss_Validation:  [[ 1420.42984541]]\n",
      "Loop  6530 :    Loss_Train:  [[ 4822.52419413]]    Loss_Validation:  [[ 1420.43011913]]\n",
      "Loop  6531 :    Loss_Train:  [[ 4822.52417911]]    Loss_Validation:  [[ 1420.43039265]]\n",
      "Loop  6532 :    Loss_Train:  [[ 4822.52416411]]    Loss_Validation:  [[ 1420.43066599]]\n",
      "Loop  6533 :    Loss_Train:  [[ 4822.52414914]]    Loss_Validation:  [[ 1420.43093913]]\n",
      "Loop  6534 :    Loss_Train:  [[ 4822.52413419]]    Loss_Validation:  [[ 1420.43121207]]\n",
      "Loop  6535 :    Loss_Train:  [[ 4822.52411926]]    Loss_Validation:  [[ 1420.43148483]]\n",
      "Loop  6536 :    Loss_Train:  [[ 4822.52410436]]    Loss_Validation:  [[ 1420.43175739]]\n",
      "Loop  6537 :    Loss_Train:  [[ 4822.52408948]]    Loss_Validation:  [[ 1420.43202976]]\n",
      "Loop  6538 :    Loss_Train:  [[ 4822.52407462]]    Loss_Validation:  [[ 1420.43230193]]\n",
      "Loop  6539 :    Loss_Train:  [[ 4822.52405979]]    Loss_Validation:  [[ 1420.43257392]]\n",
      "Loop  6540 :    Loss_Train:  [[ 4822.52404498]]    Loss_Validation:  [[ 1420.43284571]]\n",
      "Loop  6541 :    Loss_Train:  [[ 4822.52403019]]    Loss_Validation:  [[ 1420.43311731]]\n",
      "Loop  6542 :    Loss_Train:  [[ 4822.52401543]]    Loss_Validation:  [[ 1420.43338872]]\n",
      "Loop  6543 :    Loss_Train:  [[ 4822.52400069]]    Loss_Validation:  [[ 1420.43365994]]\n",
      "Loop  6544 :    Loss_Train:  [[ 4822.52398598]]    Loss_Validation:  [[ 1420.43393096]]\n",
      "Loop  6545 :    Loss_Train:  [[ 4822.52397129]]    Loss_Validation:  [[ 1420.4342018]]\n",
      "Loop  6546 :    Loss_Train:  [[ 4822.52395662]]    Loss_Validation:  [[ 1420.43447244]]\n",
      "Loop  6547 :    Loss_Train:  [[ 4822.52394197]]    Loss_Validation:  [[ 1420.43474289]]\n",
      "Loop  6548 :    Loss_Train:  [[ 4822.52392735]]    Loss_Validation:  [[ 1420.43501315]]\n",
      "Loop  6549 :    Loss_Train:  [[ 4822.52391275]]    Loss_Validation:  [[ 1420.43528322]]\n",
      "Loop  6550 :    Loss_Train:  [[ 4822.52389818]]    Loss_Validation:  [[ 1420.4355531]]\n",
      "Loop  6551 :    Loss_Train:  [[ 4822.52388362]]    Loss_Validation:  [[ 1420.43582279]]\n",
      "Loop  6552 :    Loss_Train:  [[ 4822.52386909]]    Loss_Validation:  [[ 1420.43609229]]\n",
      "Loop  6553 :    Loss_Train:  [[ 4822.52385459]]    Loss_Validation:  [[ 1420.43636159]]\n",
      "Loop  6554 :    Loss_Train:  [[ 4822.5238401]]    Loss_Validation:  [[ 1420.43663071]]\n",
      "Loop  6555 :    Loss_Train:  [[ 4822.52382564]]    Loss_Validation:  [[ 1420.43689964]]\n",
      "Loop  6556 :    Loss_Train:  [[ 4822.5238112]]    Loss_Validation:  [[ 1420.43716837]]\n",
      "Loop  6557 :    Loss_Train:  [[ 4822.52379679]]    Loss_Validation:  [[ 1420.43743692]]\n",
      "Loop  6558 :    Loss_Train:  [[ 4822.5237824]]    Loss_Validation:  [[ 1420.43770528]]\n",
      "Loop  6559 :    Loss_Train:  [[ 4822.52376803]]    Loss_Validation:  [[ 1420.43797345]]\n",
      "Loop  6560 :    Loss_Train:  [[ 4822.52375368]]    Loss_Validation:  [[ 1420.43824142]]\n",
      "Loop  6561 :    Loss_Train:  [[ 4822.52373936]]    Loss_Validation:  [[ 1420.43850921]]\n",
      "Loop  6562 :    Loss_Train:  [[ 4822.52372506]]    Loss_Validation:  [[ 1420.43877681]]\n",
      "Loop  6563 :    Loss_Train:  [[ 4822.52371078]]    Loss_Validation:  [[ 1420.43904422]]\n",
      "Loop  6564 :    Loss_Train:  [[ 4822.52369652]]    Loss_Validation:  [[ 1420.43931144]]\n",
      "Loop  6565 :    Loss_Train:  [[ 4822.52368229]]    Loss_Validation:  [[ 1420.43957848]]\n",
      "Loop  6566 :    Loss_Train:  [[ 4822.52366808]]    Loss_Validation:  [[ 1420.43984532]]\n",
      "Loop  6567 :    Loss_Train:  [[ 4822.52365389]]    Loss_Validation:  [[ 1420.44011198]]\n",
      "Loop  6568 :    Loss_Train:  [[ 4822.52363972]]    Loss_Validation:  [[ 1420.44037845]]\n",
      "Loop  6569 :    Loss_Train:  [[ 4822.52362558]]    Loss_Validation:  [[ 1420.44064473]]\n",
      "Loop  6570 :    Loss_Train:  [[ 4822.52361146]]    Loss_Validation:  [[ 1420.44091082]]\n",
      "Loop  6571 :    Loss_Train:  [[ 4822.52359736]]    Loss_Validation:  [[ 1420.44117672]]\n",
      "Loop  6572 :    Loss_Train:  [[ 4822.52358329]]    Loss_Validation:  [[ 1420.44144243]]\n",
      "Loop  6573 :    Loss_Train:  [[ 4822.52356923]]    Loss_Validation:  [[ 1420.44170796]]\n",
      "Loop  6574 :    Loss_Train:  [[ 4822.5235552]]    Loss_Validation:  [[ 1420.4419733]]\n",
      "Loop  6575 :    Loss_Train:  [[ 4822.52354119]]    Loss_Validation:  [[ 1420.44223845]]\n",
      "Loop  6576 :    Loss_Train:  [[ 4822.5235272]]    Loss_Validation:  [[ 1420.44250342]]\n",
      "Loop  6577 :    Loss_Train:  [[ 4822.52351324]]    Loss_Validation:  [[ 1420.4427682]]\n",
      "Loop  6578 :    Loss_Train:  [[ 4822.5234993]]    Loss_Validation:  [[ 1420.44303279]]\n",
      "Loop  6579 :    Loss_Train:  [[ 4822.52348538]]    Loss_Validation:  [[ 1420.44329719]]\n",
      "Loop  6580 :    Loss_Train:  [[ 4822.52347148]]    Loss_Validation:  [[ 1420.44356141]]\n",
      "Loop  6581 :    Loss_Train:  [[ 4822.5234576]]    Loss_Validation:  [[ 1420.44382544]]\n",
      "Loop  6582 :    Loss_Train:  [[ 4822.52344375]]    Loss_Validation:  [[ 1420.44408928]]\n",
      "Loop  6583 :    Loss_Train:  [[ 4822.52342991]]    Loss_Validation:  [[ 1420.44435294]]\n",
      "Loop  6584 :    Loss_Train:  [[ 4822.5234161]]    Loss_Validation:  [[ 1420.44461641]]\n",
      "Loop  6585 :    Loss_Train:  [[ 4822.52340231]]    Loss_Validation:  [[ 1420.4448797]]\n",
      "Loop  6586 :    Loss_Train:  [[ 4822.52338855]]    Loss_Validation:  [[ 1420.4451428]]\n",
      "Loop  6587 :    Loss_Train:  [[ 4822.5233748]]    Loss_Validation:  [[ 1420.44540571]]\n",
      "Loop  6588 :    Loss_Train:  [[ 4822.52336108]]    Loss_Validation:  [[ 1420.44566844]]\n",
      "Loop  6589 :    Loss_Train:  [[ 4822.52334738]]    Loss_Validation:  [[ 1420.44593098]]\n",
      "Loop  6590 :    Loss_Train:  [[ 4822.5233337]]    Loss_Validation:  [[ 1420.44619333]]\n",
      "Loop  6591 :    Loss_Train:  [[ 4822.52332004]]    Loss_Validation:  [[ 1420.4464555]]\n",
      "Loop  6592 :    Loss_Train:  [[ 4822.5233064]]    Loss_Validation:  [[ 1420.44671749]]\n",
      "Loop  6593 :    Loss_Train:  [[ 4822.52329279]]    Loss_Validation:  [[ 1420.44697929]]\n",
      "Loop  6594 :    Loss_Train:  [[ 4822.52327919]]    Loss_Validation:  [[ 1420.44724091]]\n",
      "Loop  6595 :    Loss_Train:  [[ 4822.52326562]]    Loss_Validation:  [[ 1420.44750234]]\n",
      "Loop  6596 :    Loss_Train:  [[ 4822.52325207]]    Loss_Validation:  [[ 1420.44776358]]\n",
      "Loop  6597 :    Loss_Train:  [[ 4822.52323854]]    Loss_Validation:  [[ 1420.44802464]]\n",
      "Loop  6598 :    Loss_Train:  [[ 4822.52322504]]    Loss_Validation:  [[ 1420.44828552]]\n",
      "Loop  6599 :    Loss_Train:  [[ 4822.52321155]]    Loss_Validation:  [[ 1420.44854621]]\n",
      "Loop  6600 :    Loss_Train:  [[ 4822.52319808]]    Loss_Validation:  [[ 1420.44880672]]\n",
      "Loop  6601 :    Loss_Train:  [[ 4822.52318464]]    Loss_Validation:  [[ 1420.44906704]]\n",
      "Loop  6602 :    Loss_Train:  [[ 4822.52317122]]    Loss_Validation:  [[ 1420.44932718]]\n",
      "Loop  6603 :    Loss_Train:  [[ 4822.52315782]]    Loss_Validation:  [[ 1420.44958714]]\n",
      "Loop  6604 :    Loss_Train:  [[ 4822.52314444]]    Loss_Validation:  [[ 1420.44984691]]\n",
      "Loop  6605 :    Loss_Train:  [[ 4822.52313108]]    Loss_Validation:  [[ 1420.4501065]]\n",
      "Loop  6606 :    Loss_Train:  [[ 4822.52311774]]    Loss_Validation:  [[ 1420.45036591]]\n",
      "Loop  6607 :    Loss_Train:  [[ 4822.52310443]]    Loss_Validation:  [[ 1420.45062513]]\n",
      "Loop  6608 :    Loss_Train:  [[ 4822.52309113]]    Loss_Validation:  [[ 1420.45088417]]\n",
      "Loop  6609 :    Loss_Train:  [[ 4822.52307786]]    Loss_Validation:  [[ 1420.45114302]]\n",
      "Loop  6610 :    Loss_Train:  [[ 4822.52306461]]    Loss_Validation:  [[ 1420.4514017]]\n",
      "Loop  6611 :    Loss_Train:  [[ 4822.52305137]]    Loss_Validation:  [[ 1420.45166019]]\n",
      "Loop  6612 :    Loss_Train:  [[ 4822.52303816]]    Loss_Validation:  [[ 1420.45191849]]\n",
      "Loop  6613 :    Loss_Train:  [[ 4822.52302497]]    Loss_Validation:  [[ 1420.45217662]]\n",
      "Loop  6614 :    Loss_Train:  [[ 4822.5230118]]    Loss_Validation:  [[ 1420.45243456]]\n",
      "Loop  6615 :    Loss_Train:  [[ 4822.52299865]]    Loss_Validation:  [[ 1420.45269232]]\n",
      "Loop  6616 :    Loss_Train:  [[ 4822.52298553]]    Loss_Validation:  [[ 1420.4529499]]\n",
      "Loop  6617 :    Loss_Train:  [[ 4822.52297242]]    Loss_Validation:  [[ 1420.45320729]]\n",
      "Loop  6618 :    Loss_Train:  [[ 4822.52295933]]    Loss_Validation:  [[ 1420.45346451]]\n",
      "Loop  6619 :    Loss_Train:  [[ 4822.52294627]]    Loss_Validation:  [[ 1420.45372154]]\n",
      "Loop  6620 :    Loss_Train:  [[ 4822.52293323]]    Loss_Validation:  [[ 1420.45397839]]\n",
      "Loop  6621 :    Loss_Train:  [[ 4822.5229202]]    Loss_Validation:  [[ 1420.45423506]]\n",
      "Loop  6622 :    Loss_Train:  [[ 4822.5229072]]    Loss_Validation:  [[ 1420.45449155]]\n",
      "Loop  6623 :    Loss_Train:  [[ 4822.52289422]]    Loss_Validation:  [[ 1420.45474785]]\n",
      "Loop  6624 :    Loss_Train:  [[ 4822.52288125]]    Loss_Validation:  [[ 1420.45500398]]\n",
      "Loop  6625 :    Loss_Train:  [[ 4822.52286831]]    Loss_Validation:  [[ 1420.45525992]]\n",
      "Loop  6626 :    Loss_Train:  [[ 4822.52285539]]    Loss_Validation:  [[ 1420.45551569]]\n",
      "Loop  6627 :    Loss_Train:  [[ 4822.52284249]]    Loss_Validation:  [[ 1420.45577127]]\n",
      "Loop  6628 :    Loss_Train:  [[ 4822.52282961]]    Loss_Validation:  [[ 1420.45602667]]\n",
      "Loop  6629 :    Loss_Train:  [[ 4822.52281675]]    Loss_Validation:  [[ 1420.45628189]]\n",
      "Loop  6630 :    Loss_Train:  [[ 4822.52280391]]    Loss_Validation:  [[ 1420.45653693]]\n",
      "Loop  6631 :    Loss_Train:  [[ 4822.52279109]]    Loss_Validation:  [[ 1420.45679179]]\n",
      "Loop  6632 :    Loss_Train:  [[ 4822.52277829]]    Loss_Validation:  [[ 1420.45704647]]\n",
      "Loop  6633 :    Loss_Train:  [[ 4822.52276552]]    Loss_Validation:  [[ 1420.45730097]]\n",
      "Loop  6634 :    Loss_Train:  [[ 4822.52275276]]    Loss_Validation:  [[ 1420.45755529]]\n",
      "Loop  6635 :    Loss_Train:  [[ 4822.52274002]]    Loss_Validation:  [[ 1420.45780943]]\n",
      "Loop  6636 :    Loss_Train:  [[ 4822.5227273]]    Loss_Validation:  [[ 1420.45806339]]\n",
      "Loop  6637 :    Loss_Train:  [[ 4822.5227146]]    Loss_Validation:  [[ 1420.45831718]]\n",
      "Loop  6638 :    Loss_Train:  [[ 4822.52270193]]    Loss_Validation:  [[ 1420.45857078]]\n",
      "Loop  6639 :    Loss_Train:  [[ 4822.52268927]]    Loss_Validation:  [[ 1420.4588242]]\n",
      "Loop  6640 :    Loss_Train:  [[ 4822.52267663]]    Loss_Validation:  [[ 1420.45907744]]\n",
      "Loop  6641 :    Loss_Train:  [[ 4822.52266401]]    Loss_Validation:  [[ 1420.45933051]]\n",
      "Loop  6642 :    Loss_Train:  [[ 4822.52265142]]    Loss_Validation:  [[ 1420.45958339]]\n",
      "Loop  6643 :    Loss_Train:  [[ 4822.52263884]]    Loss_Validation:  [[ 1420.4598361]]\n",
      "Loop  6644 :    Loss_Train:  [[ 4822.52262628]]    Loss_Validation:  [[ 1420.46008863]]\n",
      "Loop  6645 :    Loss_Train:  [[ 4822.52261374]]    Loss_Validation:  [[ 1420.46034098]]\n",
      "Loop  6646 :    Loss_Train:  [[ 4822.52260123]]    Loss_Validation:  [[ 1420.46059315]]\n",
      "Loop  6647 :    Loss_Train:  [[ 4822.52258873]]    Loss_Validation:  [[ 1420.46084514]]\n",
      "Loop  6648 :    Loss_Train:  [[ 4822.52257625]]    Loss_Validation:  [[ 1420.46109696]]\n",
      "Loop  6649 :    Loss_Train:  [[ 4822.52256379]]    Loss_Validation:  [[ 1420.4613486]]\n",
      "Loop  6650 :    Loss_Train:  [[ 4822.52255135]]    Loss_Validation:  [[ 1420.46160005]]\n",
      "Loop  6651 :    Loss_Train:  [[ 4822.52253893]]    Loss_Validation:  [[ 1420.46185134]]\n",
      "Loop  6652 :    Loss_Train:  [[ 4822.52252653]]    Loss_Validation:  [[ 1420.46210244]]\n",
      "Loop  6653 :    Loss_Train:  [[ 4822.52251415]]    Loss_Validation:  [[ 1420.46235337]]\n",
      "Loop  6654 :    Loss_Train:  [[ 4822.52250179]]    Loss_Validation:  [[ 1420.46260411]]\n",
      "Loop  6655 :    Loss_Train:  [[ 4822.52248945]]    Loss_Validation:  [[ 1420.46285469]]\n",
      "Loop  6656 :    Loss_Train:  [[ 4822.52247713]]    Loss_Validation:  [[ 1420.46310508]]\n",
      "Loop  6657 :    Loss_Train:  [[ 4822.52246483]]    Loss_Validation:  [[ 1420.4633553]]\n",
      "Loop  6658 :    Loss_Train:  [[ 4822.52245255]]    Loss_Validation:  [[ 1420.46360534]]\n",
      "Loop  6659 :    Loss_Train:  [[ 4822.52244029]]    Loss_Validation:  [[ 1420.4638552]]\n",
      "Loop  6660 :    Loss_Train:  [[ 4822.52242804]]    Loss_Validation:  [[ 1420.46410489]]\n",
      "Loop  6661 :    Loss_Train:  [[ 4822.52241582]]    Loss_Validation:  [[ 1420.4643544]]\n",
      "Loop  6662 :    Loss_Train:  [[ 4822.52240362]]    Loss_Validation:  [[ 1420.46460373]]\n",
      "Loop  6663 :    Loss_Train:  [[ 4822.52239143]]    Loss_Validation:  [[ 1420.46485289]]\n",
      "Loop  6664 :    Loss_Train:  [[ 4822.52237927]]    Loss_Validation:  [[ 1420.46510187]]\n",
      "Loop  6665 :    Loss_Train:  [[ 4822.52236712]]    Loss_Validation:  [[ 1420.46535068]]\n",
      "Loop  6666 :    Loss_Train:  [[ 4822.52235499]]    Loss_Validation:  [[ 1420.46559931]]\n",
      "Loop  6667 :    Loss_Train:  [[ 4822.52234288]]    Loss_Validation:  [[ 1420.46584776]]\n",
      "Loop  6668 :    Loss_Train:  [[ 4822.52233079]]    Loss_Validation:  [[ 1420.46609604]]\n",
      "Loop  6669 :    Loss_Train:  [[ 4822.52231872]]    Loss_Validation:  [[ 1420.46634414]]\n",
      "Loop  6670 :    Loss_Train:  [[ 4822.52230667]]    Loss_Validation:  [[ 1420.46659207]]\n",
      "Loop  6671 :    Loss_Train:  [[ 4822.52229464]]    Loss_Validation:  [[ 1420.46683982]]\n",
      "Loop  6672 :    Loss_Train:  [[ 4822.52228263]]    Loss_Validation:  [[ 1420.46708739]]\n",
      "Loop  6673 :    Loss_Train:  [[ 4822.52227064]]    Loss_Validation:  [[ 1420.4673348]]\n",
      "Loop  6674 :    Loss_Train:  [[ 4822.52225866]]    Loss_Validation:  [[ 1420.46758202]]\n",
      "Loop  6675 :    Loss_Train:  [[ 4822.52224671]]    Loss_Validation:  [[ 1420.46782907]]\n",
      "Loop  6676 :    Loss_Train:  [[ 4822.52223477]]    Loss_Validation:  [[ 1420.46807595]]\n",
      "Loop  6677 :    Loss_Train:  [[ 4822.52222285]]    Loss_Validation:  [[ 1420.46832265]]\n",
      "Loop  6678 :    Loss_Train:  [[ 4822.52221095]]    Loss_Validation:  [[ 1420.46856918]]\n",
      "Loop  6679 :    Loss_Train:  [[ 4822.52219907]]    Loss_Validation:  [[ 1420.46881554]]\n",
      "Loop  6680 :    Loss_Train:  [[ 4822.52218721]]    Loss_Validation:  [[ 1420.46906171]]\n",
      "Loop  6681 :    Loss_Train:  [[ 4822.52217537]]    Loss_Validation:  [[ 1420.46930772]]\n",
      "Loop  6682 :    Loss_Train:  [[ 4822.52216355]]    Loss_Validation:  [[ 1420.46955355]]\n",
      "Loop  6683 :    Loss_Train:  [[ 4822.52215174]]    Loss_Validation:  [[ 1420.46979921]]\n",
      "Loop  6684 :    Loss_Train:  [[ 4822.52213995]]    Loss_Validation:  [[ 1420.47004469]]\n",
      "Loop  6685 :    Loss_Train:  [[ 4822.52212819]]    Loss_Validation:  [[ 1420.47029]]\n",
      "Loop  6686 :    Loss_Train:  [[ 4822.52211644]]    Loss_Validation:  [[ 1420.47053514]]\n",
      "Loop  6687 :    Loss_Train:  [[ 4822.52210471]]    Loss_Validation:  [[ 1420.4707801]]\n",
      "Loop  6688 :    Loss_Train:  [[ 4822.522093]]    Loss_Validation:  [[ 1420.47102489]]\n",
      "Loop  6689 :    Loss_Train:  [[ 4822.5220813]]    Loss_Validation:  [[ 1420.47126951]]\n",
      "Loop  6690 :    Loss_Train:  [[ 4822.52206963]]    Loss_Validation:  [[ 1420.47151395]]\n",
      "Loop  6691 :    Loss_Train:  [[ 4822.52205797]]    Loss_Validation:  [[ 1420.47175823]]\n",
      "Loop  6692 :    Loss_Train:  [[ 4822.52204633]]    Loss_Validation:  [[ 1420.47200232]]\n",
      "Loop  6693 :    Loss_Train:  [[ 4822.52203471]]    Loss_Validation:  [[ 1420.47224625]]\n",
      "Loop  6694 :    Loss_Train:  [[ 4822.52202311]]    Loss_Validation:  [[ 1420.47249]]\n",
      "Loop  6695 :    Loss_Train:  [[ 4822.52201153]]    Loss_Validation:  [[ 1420.47273358]]\n",
      "Loop  6696 :    Loss_Train:  [[ 4822.52199997]]    Loss_Validation:  [[ 1420.47297699]]\n",
      "Loop  6697 :    Loss_Train:  [[ 4822.52198842]]    Loss_Validation:  [[ 1420.47322023]]\n",
      "Loop  6698 :    Loss_Train:  [[ 4822.52197689]]    Loss_Validation:  [[ 1420.47346329]]\n",
      "Loop  6699 :    Loss_Train:  [[ 4822.52196538]]    Loss_Validation:  [[ 1420.47370619]]\n",
      "Loop  6700 :    Loss_Train:  [[ 4822.52195389]]    Loss_Validation:  [[ 1420.47394891]]\n",
      "Loop  6701 :    Loss_Train:  [[ 4822.52194242]]    Loss_Validation:  [[ 1420.47419146]]\n",
      "Loop  6702 :    Loss_Train:  [[ 4822.52193096]]    Loss_Validation:  [[ 1420.47443383]]\n",
      "Loop  6703 :    Loss_Train:  [[ 4822.52191953]]    Loss_Validation:  [[ 1420.47467604]]\n",
      "Loop  6704 :    Loss_Train:  [[ 4822.52190811]]    Loss_Validation:  [[ 1420.47491807]]\n",
      "Loop  6705 :    Loss_Train:  [[ 4822.52189671]]    Loss_Validation:  [[ 1420.47515994]]\n",
      "Loop  6706 :    Loss_Train:  [[ 4822.52188532]]    Loss_Validation:  [[ 1420.47540163]]\n",
      "Loop  6707 :    Loss_Train:  [[ 4822.52187396]]    Loss_Validation:  [[ 1420.47564315]]\n",
      "Loop  6708 :    Loss_Train:  [[ 4822.52186261]]    Loss_Validation:  [[ 1420.4758845]]\n",
      "Loop  6709 :    Loss_Train:  [[ 4822.52185128]]    Loss_Validation:  [[ 1420.47612568]]\n",
      "Loop  6710 :    Loss_Train:  [[ 4822.52183997]]    Loss_Validation:  [[ 1420.47636669]]\n",
      "Loop  6711 :    Loss_Train:  [[ 4822.52182868]]    Loss_Validation:  [[ 1420.47660753]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  6712 :    Loss_Train:  [[ 4822.52181741]]    Loss_Validation:  [[ 1420.4768482]]\n",
      "Loop  6713 :    Loss_Train:  [[ 4822.52180615]]    Loss_Validation:  [[ 1420.4770887]]\n",
      "Loop  6714 :    Loss_Train:  [[ 4822.52179491]]    Loss_Validation:  [[ 1420.47732903]]\n",
      "Loop  6715 :    Loss_Train:  [[ 4822.52178369]]    Loss_Validation:  [[ 1420.47756919]]\n",
      "Loop  6716 :    Loss_Train:  [[ 4822.52177248]]    Loss_Validation:  [[ 1420.47780917]]\n",
      "Loop  6717 :    Loss_Train:  [[ 4822.5217613]]    Loss_Validation:  [[ 1420.47804899]]\n",
      "Loop  6718 :    Loss_Train:  [[ 4822.52175013]]    Loss_Validation:  [[ 1420.47828864]]\n",
      "Loop  6719 :    Loss_Train:  [[ 4822.52173898]]    Loss_Validation:  [[ 1420.47852812]]\n",
      "Loop  6720 :    Loss_Train:  [[ 4822.52172785]]    Loss_Validation:  [[ 1420.47876743]]\n",
      "Loop  6721 :    Loss_Train:  [[ 4822.52171673]]    Loss_Validation:  [[ 1420.47900657]]\n",
      "Loop  6722 :    Loss_Train:  [[ 4822.52170563]]    Loss_Validation:  [[ 1420.47924554]]\n",
      "Loop  6723 :    Loss_Train:  [[ 4822.52169455]]    Loss_Validation:  [[ 1420.47948435]]\n",
      "Loop  6724 :    Loss_Train:  [[ 4822.52168349]]    Loss_Validation:  [[ 1420.47972298]]\n",
      "Loop  6725 :    Loss_Train:  [[ 4822.52167244]]    Loss_Validation:  [[ 1420.47996144]]\n",
      "Loop  6726 :    Loss_Train:  [[ 4822.52166142]]    Loss_Validation:  [[ 1420.48019974]]\n",
      "Loop  6727 :    Loss_Train:  [[ 4822.52165041]]    Loss_Validation:  [[ 1420.48043787]]\n",
      "Loop  6728 :    Loss_Train:  [[ 4822.52163941]]    Loss_Validation:  [[ 1420.48067583]]\n",
      "Loop  6729 :    Loss_Train:  [[ 4822.52162844]]    Loss_Validation:  [[ 1420.48091362]]\n",
      "Loop  6730 :    Loss_Train:  [[ 4822.52161748]]    Loss_Validation:  [[ 1420.48115124]]\n",
      "Loop  6731 :    Loss_Train:  [[ 4822.52160654]]    Loss_Validation:  [[ 1420.4813887]]\n",
      "Loop  6732 :    Loss_Train:  [[ 4822.52159562]]    Loss_Validation:  [[ 1420.48162598]]\n",
      "Loop  6733 :    Loss_Train:  [[ 4822.52158471]]    Loss_Validation:  [[ 1420.4818631]]\n",
      "Loop  6734 :    Loss_Train:  [[ 4822.52157382]]    Loss_Validation:  [[ 1420.48210005]]\n",
      "Loop  6735 :    Loss_Train:  [[ 4822.52156295]]    Loss_Validation:  [[ 1420.48233683]]\n",
      "Loop  6736 :    Loss_Train:  [[ 4822.52155209]]    Loss_Validation:  [[ 1420.48257345]]\n",
      "Loop  6737 :    Loss_Train:  [[ 4822.52154126]]    Loss_Validation:  [[ 1420.4828099]]\n",
      "Loop  6738 :    Loss_Train:  [[ 4822.52153044]]    Loss_Validation:  [[ 1420.48304618]]\n",
      "Loop  6739 :    Loss_Train:  [[ 4822.52151963]]    Loss_Validation:  [[ 1420.48328229]]\n",
      "Loop  6740 :    Loss_Train:  [[ 4822.52150885]]    Loss_Validation:  [[ 1420.48351824]]\n",
      "Loop  6741 :    Loss_Train:  [[ 4822.52149808]]    Loss_Validation:  [[ 1420.48375402]]\n",
      "Loop  6742 :    Loss_Train:  [[ 4822.52148733]]    Loss_Validation:  [[ 1420.48398963]]\n",
      "Loop  6743 :    Loss_Train:  [[ 4822.52147659]]    Loss_Validation:  [[ 1420.48422508]]\n",
      "Loop  6744 :    Loss_Train:  [[ 4822.52146587]]    Loss_Validation:  [[ 1420.48446036]]\n",
      "Loop  6745 :    Loss_Train:  [[ 4822.52145517]]    Loss_Validation:  [[ 1420.48469547]]\n",
      "Loop  6746 :    Loss_Train:  [[ 4822.52144449]]    Loss_Validation:  [[ 1420.48493042]]\n",
      "Loop  6747 :    Loss_Train:  [[ 4822.52143382]]    Loss_Validation:  [[ 1420.4851652]]\n",
      "Loop  6748 :    Loss_Train:  [[ 4822.52142317]]    Loss_Validation:  [[ 1420.48539982]]\n",
      "Loop  6749 :    Loss_Train:  [[ 4822.52141254]]    Loss_Validation:  [[ 1420.48563426]]\n",
      "Loop  6750 :    Loss_Train:  [[ 4822.52140192]]    Loss_Validation:  [[ 1420.48586855]]\n",
      "Loop  6751 :    Loss_Train:  [[ 4822.52139132]]    Loss_Validation:  [[ 1420.48610266]]\n",
      "Loop  6752 :    Loss_Train:  [[ 4822.52138074]]    Loss_Validation:  [[ 1420.48633661]]\n",
      "Loop  6753 :    Loss_Train:  [[ 4822.52137017]]    Loss_Validation:  [[ 1420.4865704]]\n",
      "Loop  6754 :    Loss_Train:  [[ 4822.52135962]]    Loss_Validation:  [[ 1420.48680402]]\n",
      "Loop  6755 :    Loss_Train:  [[ 4822.52134909]]    Loss_Validation:  [[ 1420.48703748]]\n",
      "Loop  6756 :    Loss_Train:  [[ 4822.52133858]]    Loss_Validation:  [[ 1420.48727077]]\n",
      "Loop  6757 :    Loss_Train:  [[ 4822.52132808]]    Loss_Validation:  [[ 1420.48750389]]\n",
      "Loop  6758 :    Loss_Train:  [[ 4822.52131759]]    Loss_Validation:  [[ 1420.48773685]]\n",
      "Loop  6759 :    Loss_Train:  [[ 4822.52130713]]    Loss_Validation:  [[ 1420.48796965]]\n",
      "Loop  6760 :    Loss_Train:  [[ 4822.52129668]]    Loss_Validation:  [[ 1420.48820228]]\n",
      "Loop  6761 :    Loss_Train:  [[ 4822.52128624]]    Loss_Validation:  [[ 1420.48843474]]\n",
      "Loop  6762 :    Loss_Train:  [[ 4822.52127583]]    Loss_Validation:  [[ 1420.48866704]]\n",
      "Loop  6763 :    Loss_Train:  [[ 4822.52126543]]    Loss_Validation:  [[ 1420.48889918]]\n",
      "Loop  6764 :    Loss_Train:  [[ 4822.52125504]]    Loss_Validation:  [[ 1420.48913115]]\n",
      "Loop  6765 :    Loss_Train:  [[ 4822.52124468]]    Loss_Validation:  [[ 1420.48936296]]\n",
      "Loop  6766 :    Loss_Train:  [[ 4822.52123432]]    Loss_Validation:  [[ 1420.4895946]]\n",
      "Loop  6767 :    Loss_Train:  [[ 4822.52122399]]    Loss_Validation:  [[ 1420.48982608]]\n",
      "Loop  6768 :    Loss_Train:  [[ 4822.52121367]]    Loss_Validation:  [[ 1420.4900574]]\n",
      "Loop  6769 :    Loss_Train:  [[ 4822.52120337]]    Loss_Validation:  [[ 1420.49028855]]\n",
      "Loop  6770 :    Loss_Train:  [[ 4822.52119308]]    Loss_Validation:  [[ 1420.49051954]]\n",
      "Loop  6771 :    Loss_Train:  [[ 4822.52118282]]    Loss_Validation:  [[ 1420.49075037]]\n",
      "Loop  6772 :    Loss_Train:  [[ 4822.52117256]]    Loss_Validation:  [[ 1420.49098103]]\n",
      "Loop  6773 :    Loss_Train:  [[ 4822.52116233]]    Loss_Validation:  [[ 1420.49121153]]\n",
      "Loop  6774 :    Loss_Train:  [[ 4822.5211521]]    Loss_Validation:  [[ 1420.49144187]]\n",
      "Loop  6775 :    Loss_Train:  [[ 4822.5211419]]    Loss_Validation:  [[ 1420.49167204]]\n",
      "Loop  6776 :    Loss_Train:  [[ 4822.52113171]]    Loss_Validation:  [[ 1420.49190205]]\n",
      "Loop  6777 :    Loss_Train:  [[ 4822.52112154]]    Loss_Validation:  [[ 1420.4921319]]\n",
      "Loop  6778 :    Loss_Train:  [[ 4822.52111138]]    Loss_Validation:  [[ 1420.49236158]]\n",
      "Loop  6779 :    Loss_Train:  [[ 4822.52110124]]    Loss_Validation:  [[ 1420.4925911]]\n",
      "Loop  6780 :    Loss_Train:  [[ 4822.52109112]]    Loss_Validation:  [[ 1420.49282046]]\n",
      "Loop  6781 :    Loss_Train:  [[ 4822.52108101]]    Loss_Validation:  [[ 1420.49304966]]\n",
      "Loop  6782 :    Loss_Train:  [[ 4822.52107092]]    Loss_Validation:  [[ 1420.4932787]]\n",
      "Loop  6783 :    Loss_Train:  [[ 4822.52106084]]    Loss_Validation:  [[ 1420.49350757]]\n",
      "Loop  6784 :    Loss_Train:  [[ 4822.52105078]]    Loss_Validation:  [[ 1420.49373628]]\n",
      "Loop  6785 :    Loss_Train:  [[ 4822.52104074]]    Loss_Validation:  [[ 1420.49396483]]\n",
      "Loop  6786 :    Loss_Train:  [[ 4822.52103071]]    Loss_Validation:  [[ 1420.49419322]]\n",
      "Loop  6787 :    Loss_Train:  [[ 4822.5210207]]    Loss_Validation:  [[ 1420.49442144]]\n",
      "Loop  6788 :    Loss_Train:  [[ 4822.5210107]]    Loss_Validation:  [[ 1420.49464951]]\n",
      "Loop  6789 :    Loss_Train:  [[ 4822.52100072]]    Loss_Validation:  [[ 1420.49487741]]\n",
      "Loop  6790 :    Loss_Train:  [[ 4822.52099075]]    Loss_Validation:  [[ 1420.49510515]]\n",
      "Loop  6791 :    Loss_Train:  [[ 4822.52098081]]    Loss_Validation:  [[ 1420.49533273]]\n",
      "Loop  6792 :    Loss_Train:  [[ 4822.52097087]]    Loss_Validation:  [[ 1420.49556015]]\n",
      "Loop  6793 :    Loss_Train:  [[ 4822.52096095]]    Loss_Validation:  [[ 1420.49578741]]\n",
      "Loop  6794 :    Loss_Train:  [[ 4822.52095105]]    Loss_Validation:  [[ 1420.49601451]]\n",
      "Loop  6795 :    Loss_Train:  [[ 4822.52094116]]    Loss_Validation:  [[ 1420.49624144]]\n",
      "Loop  6796 :    Loss_Train:  [[ 4822.52093129]]    Loss_Validation:  [[ 1420.49646822]]\n",
      "Loop  6797 :    Loss_Train:  [[ 4822.52092144]]    Loss_Validation:  [[ 1420.49669484]]\n",
      "Loop  6798 :    Loss_Train:  [[ 4822.5209116]]    Loss_Validation:  [[ 1420.49692129]]\n",
      "Loop  6799 :    Loss_Train:  [[ 4822.52090177]]    Loss_Validation:  [[ 1420.49714759]]\n",
      "Loop  6800 :    Loss_Train:  [[ 4822.52089197]]    Loss_Validation:  [[ 1420.49737372]]\n",
      "Loop  6801 :    Loss_Train:  [[ 4822.52088217]]    Loss_Validation:  [[ 1420.4975997]]\n",
      "Loop  6802 :    Loss_Train:  [[ 4822.5208724]]    Loss_Validation:  [[ 1420.49782551]]\n",
      "Loop  6803 :    Loss_Train:  [[ 4822.52086263]]    Loss_Validation:  [[ 1420.49805116]]\n",
      "Loop  6804 :    Loss_Train:  [[ 4822.52085289]]    Loss_Validation:  [[ 1420.49827666]]\n",
      "Loop  6805 :    Loss_Train:  [[ 4822.52084316]]    Loss_Validation:  [[ 1420.498502]]\n",
      "Loop  6806 :    Loss_Train:  [[ 4822.52083344]]    Loss_Validation:  [[ 1420.49872717]]\n",
      "Loop  6807 :    Loss_Train:  [[ 4822.52082374]]    Loss_Validation:  [[ 1420.49895219]]\n",
      "Loop  6808 :    Loss_Train:  [[ 4822.52081405]]    Loss_Validation:  [[ 1420.49917705]]\n",
      "Loop  6809 :    Loss_Train:  [[ 4822.52080438]]    Loss_Validation:  [[ 1420.49940174]]\n",
      "Loop  6810 :    Loss_Train:  [[ 4822.52079473]]    Loss_Validation:  [[ 1420.49962628]]\n",
      "Loop  6811 :    Loss_Train:  [[ 4822.52078509]]    Loss_Validation:  [[ 1420.49985066]]\n",
      "Loop  6812 :    Loss_Train:  [[ 4822.52077547]]    Loss_Validation:  [[ 1420.50007488]]\n",
      "Loop  6813 :    Loss_Train:  [[ 4822.52076586]]    Loss_Validation:  [[ 1420.50029895]]\n",
      "Loop  6814 :    Loss_Train:  [[ 4822.52075626]]    Loss_Validation:  [[ 1420.50052285]]\n",
      "Loop  6815 :    Loss_Train:  [[ 4822.52074668]]    Loss_Validation:  [[ 1420.5007466]]\n",
      "Loop  6816 :    Loss_Train:  [[ 4822.52073712]]    Loss_Validation:  [[ 1420.50097018]]\n",
      "Loop  6817 :    Loss_Train:  [[ 4822.52072757]]    Loss_Validation:  [[ 1420.50119361]]\n",
      "Loop  6818 :    Loss_Train:  [[ 4822.52071804]]    Loss_Validation:  [[ 1420.50141688]]\n",
      "Loop  6819 :    Loss_Train:  [[ 4822.52070852]]    Loss_Validation:  [[ 1420.50163999]]\n",
      "Loop  6820 :    Loss_Train:  [[ 4822.52069902]]    Loss_Validation:  [[ 1420.50186295]]\n",
      "Loop  6821 :    Loss_Train:  [[ 4822.52068953]]    Loss_Validation:  [[ 1420.50208575]]\n",
      "Loop  6822 :    Loss_Train:  [[ 4822.52068006]]    Loss_Validation:  [[ 1420.50230838]]\n",
      "Loop  6823 :    Loss_Train:  [[ 4822.5206706]]    Loss_Validation:  [[ 1420.50253087]]\n",
      "Loop  6824 :    Loss_Train:  [[ 4822.52066116]]    Loss_Validation:  [[ 1420.50275319]]\n",
      "Loop  6825 :    Loss_Train:  [[ 4822.52065173]]    Loss_Validation:  [[ 1420.50297536]]\n",
      "Loop  6826 :    Loss_Train:  [[ 4822.52064231]]    Loss_Validation:  [[ 1420.50319736]]\n",
      "Loop  6827 :    Loss_Train:  [[ 4822.52063292]]    Loss_Validation:  [[ 1420.50341922]]\n",
      "Loop  6828 :    Loss_Train:  [[ 4822.52062353]]    Loss_Validation:  [[ 1420.50364091]]\n",
      "Loop  6829 :    Loss_Train:  [[ 4822.52061416]]    Loss_Validation:  [[ 1420.50386245]]\n",
      "Loop  6830 :    Loss_Train:  [[ 4822.52060481]]    Loss_Validation:  [[ 1420.50408383]]\n",
      "Loop  6831 :    Loss_Train:  [[ 4822.52059547]]    Loss_Validation:  [[ 1420.50430505]]\n",
      "Loop  6832 :    Loss_Train:  [[ 4822.52058615]]    Loss_Validation:  [[ 1420.50452612]]\n",
      "Loop  6833 :    Loss_Train:  [[ 4822.52057684]]    Loss_Validation:  [[ 1420.50474703]]\n",
      "Loop  6834 :    Loss_Train:  [[ 4822.52056754]]    Loss_Validation:  [[ 1420.50496779]]\n",
      "Loop  6835 :    Loss_Train:  [[ 4822.52055826]]    Loss_Validation:  [[ 1420.50518839]]\n",
      "Loop  6836 :    Loss_Train:  [[ 4822.520549]]    Loss_Validation:  [[ 1420.50540883]]\n",
      "Loop  6837 :    Loss_Train:  [[ 4822.52053975]]    Loss_Validation:  [[ 1420.50562911]]\n",
      "Loop  6838 :    Loss_Train:  [[ 4822.52053051]]    Loss_Validation:  [[ 1420.50584924]]\n",
      "Loop  6839 :    Loss_Train:  [[ 4822.52052129]]    Loss_Validation:  [[ 1420.50606922]]\n",
      "Loop  6840 :    Loss_Train:  [[ 4822.52051208]]    Loss_Validation:  [[ 1420.50628904]]\n",
      "Loop  6841 :    Loss_Train:  [[ 4822.52050289]]    Loss_Validation:  [[ 1420.5065087]]\n",
      "Loop  6842 :    Loss_Train:  [[ 4822.52049371]]    Loss_Validation:  [[ 1420.50672821]]\n",
      "Loop  6843 :    Loss_Train:  [[ 4822.52048455]]    Loss_Validation:  [[ 1420.50694756]]\n",
      "Loop  6844 :    Loss_Train:  [[ 4822.5204754]]    Loss_Validation:  [[ 1420.50716676]]\n",
      "Loop  6845 :    Loss_Train:  [[ 4822.52046626]]    Loss_Validation:  [[ 1420.5073858]]\n",
      "Loop  6846 :    Loss_Train:  [[ 4822.52045714]]    Loss_Validation:  [[ 1420.50760468]]\n",
      "Loop  6847 :    Loss_Train:  [[ 4822.52044804]]    Loss_Validation:  [[ 1420.50782341]]\n",
      "Loop  6848 :    Loss_Train:  [[ 4822.52043895]]    Loss_Validation:  [[ 1420.50804199]]\n",
      "Loop  6849 :    Loss_Train:  [[ 4822.52042987]]    Loss_Validation:  [[ 1420.50826041]]\n",
      "Loop  6850 :    Loss_Train:  [[ 4822.52042081]]    Loss_Validation:  [[ 1420.50847868]]\n",
      "Loop  6851 :    Loss_Train:  [[ 4822.52041176]]    Loss_Validation:  [[ 1420.50869679]]\n",
      "Loop  6852 :    Loss_Train:  [[ 4822.52040272]]    Loss_Validation:  [[ 1420.50891475]]\n",
      "Loop  6853 :    Loss_Train:  [[ 4822.5203937]]    Loss_Validation:  [[ 1420.50913255]]\n",
      "Loop  6854 :    Loss_Train:  [[ 4822.5203847]]    Loss_Validation:  [[ 1420.5093502]]\n",
      "Loop  6855 :    Loss_Train:  [[ 4822.52037571]]    Loss_Validation:  [[ 1420.5095677]]\n",
      "Loop  6856 :    Loss_Train:  [[ 4822.52036673]]    Loss_Validation:  [[ 1420.50978504]]\n",
      "Loop  6857 :    Loss_Train:  [[ 4822.52035777]]    Loss_Validation:  [[ 1420.51000223]]\n",
      "Loop  6858 :    Loss_Train:  [[ 4822.52034882]]    Loss_Validation:  [[ 1420.51021926]]\n",
      "Loop  6859 :    Loss_Train:  [[ 4822.52033988]]    Loss_Validation:  [[ 1420.51043614]]\n",
      "Loop  6860 :    Loss_Train:  [[ 4822.52033096]]    Loss_Validation:  [[ 1420.51065286]]\n",
      "Loop  6861 :    Loss_Train:  [[ 4822.52032206]]    Loss_Validation:  [[ 1420.51086944]]\n",
      "Loop  6862 :    Loss_Train:  [[ 4822.52031317]]    Loss_Validation:  [[ 1420.51108586]]\n",
      "Loop  6863 :    Loss_Train:  [[ 4822.52030429]]    Loss_Validation:  [[ 1420.51130212]]\n",
      "Loop  6864 :    Loss_Train:  [[ 4822.52029542]]    Loss_Validation:  [[ 1420.51151824]]\n",
      "Loop  6865 :    Loss_Train:  [[ 4822.52028657]]    Loss_Validation:  [[ 1420.51173419]]\n",
      "Loop  6866 :    Loss_Train:  [[ 4822.52027774]]    Loss_Validation:  [[ 1420.51195]]\n",
      "Loop  6867 :    Loss_Train:  [[ 4822.52026892]]    Loss_Validation:  [[ 1420.51216566]]\n",
      "Loop  6868 :    Loss_Train:  [[ 4822.52026011]]    Loss_Validation:  [[ 1420.51238116]]\n",
      "Loop  6869 :    Loss_Train:  [[ 4822.52025131]]    Loss_Validation:  [[ 1420.51259651]]\n",
      "Loop  6870 :    Loss_Train:  [[ 4822.52024253]]    Loss_Validation:  [[ 1420.5128117]]\n",
      "Loop  6871 :    Loss_Train:  [[ 4822.52023377]]    Loss_Validation:  [[ 1420.51302674]]\n",
      "Loop  6872 :    Loss_Train:  [[ 4822.52022501]]    Loss_Validation:  [[ 1420.51324164]]\n",
      "Loop  6873 :    Loss_Train:  [[ 4822.52021627]]    Loss_Validation:  [[ 1420.51345638]]\n",
      "Loop  6874 :    Loss_Train:  [[ 4822.52020755]]    Loss_Validation:  [[ 1420.51367096]]\n",
      "Loop  6875 :    Loss_Train:  [[ 4822.52019884]]    Loss_Validation:  [[ 1420.5138854]]\n",
      "Loop  6876 :    Loss_Train:  [[ 4822.52019014]]    Loss_Validation:  [[ 1420.51409968]]\n",
      "Loop  6877 :    Loss_Train:  [[ 4822.52018146]]    Loss_Validation:  [[ 1420.51431381]]\n",
      "Loop  6878 :    Loss_Train:  [[ 4822.52017279]]    Loss_Validation:  [[ 1420.51452779]]\n",
      "Loop  6879 :    Loss_Train:  [[ 4822.52016413]]    Loss_Validation:  [[ 1420.51474162]]\n",
      "Loop  6880 :    Loss_Train:  [[ 4822.52015549]]    Loss_Validation:  [[ 1420.5149553]]\n",
      "Loop  6881 :    Loss_Train:  [[ 4822.52014686]]    Loss_Validation:  [[ 1420.51516882]]\n",
      "Loop  6882 :    Loss_Train:  [[ 4822.52013824]]    Loss_Validation:  [[ 1420.5153822]]\n",
      "Loop  6883 :    Loss_Train:  [[ 4822.52012964]]    Loss_Validation:  [[ 1420.51559542]]\n",
      "Loop  6884 :    Loss_Train:  [[ 4822.52012105]]    Loss_Validation:  [[ 1420.51580849]]\n",
      "Loop  6885 :    Loss_Train:  [[ 4822.52011248]]    Loss_Validation:  [[ 1420.51602141]]\n",
      "Loop  6886 :    Loss_Train:  [[ 4822.52010392]]    Loss_Validation:  [[ 1420.51623418]]\n",
      "Loop  6887 :    Loss_Train:  [[ 4822.52009537]]    Loss_Validation:  [[ 1420.5164468]]\n",
      "Loop  6888 :    Loss_Train:  [[ 4822.52008684]]    Loss_Validation:  [[ 1420.51665927]]\n",
      "Loop  6889 :    Loss_Train:  [[ 4822.52007832]]    Loss_Validation:  [[ 1420.51687159]]\n",
      "Loop  6890 :    Loss_Train:  [[ 4822.52006981]]    Loss_Validation:  [[ 1420.51708376]]\n",
      "Loop  6891 :    Loss_Train:  [[ 4822.52006132]]    Loss_Validation:  [[ 1420.51729577]]\n",
      "Loop  6892 :    Loss_Train:  [[ 4822.52005284]]    Loss_Validation:  [[ 1420.51750764]]\n",
      "Loop  6893 :    Loss_Train:  [[ 4822.52004437]]    Loss_Validation:  [[ 1420.51771936]]\n",
      "Loop  6894 :    Loss_Train:  [[ 4822.52003592]]    Loss_Validation:  [[ 1420.51793093]]\n",
      "Loop  6895 :    Loss_Train:  [[ 4822.52002748]]    Loss_Validation:  [[ 1420.51814234]]\n",
      "Loop  6896 :    Loss_Train:  [[ 4822.52001905]]    Loss_Validation:  [[ 1420.51835361]]\n",
      "Loop  6897 :    Loss_Train:  [[ 4822.52001064]]    Loss_Validation:  [[ 1420.51856473]]\n",
      "Loop  6898 :    Loss_Train:  [[ 4822.52000224]]    Loss_Validation:  [[ 1420.5187757]]\n",
      "Loop  6899 :    Loss_Train:  [[ 4822.51999385]]    Loss_Validation:  [[ 1420.51898652]]\n",
      "Loop  6900 :    Loss_Train:  [[ 4822.51998547]]    Loss_Validation:  [[ 1420.51919719]]\n",
      "Loop  6901 :    Loss_Train:  [[ 4822.51997711]]    Loss_Validation:  [[ 1420.51940771]]\n",
      "Loop  6902 :    Loss_Train:  [[ 4822.51996877]]    Loss_Validation:  [[ 1420.51961808]]\n",
      "Loop  6903 :    Loss_Train:  [[ 4822.51996043]]    Loss_Validation:  [[ 1420.5198283]]\n",
      "Loop  6904 :    Loss_Train:  [[ 4822.51995211]]    Loss_Validation:  [[ 1420.52003837]]\n",
      "Loop  6905 :    Loss_Train:  [[ 4822.51994381]]    Loss_Validation:  [[ 1420.5202483]]\n",
      "Loop  6906 :    Loss_Train:  [[ 4822.51993551]]    Loss_Validation:  [[ 1420.52045807]]\n",
      "Loop  6907 :    Loss_Train:  [[ 4822.51992723]]    Loss_Validation:  [[ 1420.5206677]]\n",
      "Loop  6908 :    Loss_Train:  [[ 4822.51991896]]    Loss_Validation:  [[ 1420.52087718]]\n",
      "Loop  6909 :    Loss_Train:  [[ 4822.51991071]]    Loss_Validation:  [[ 1420.52108651]]\n",
      "Loop  6910 :    Loss_Train:  [[ 4822.51990246]]    Loss_Validation:  [[ 1420.52129569]]\n",
      "Loop  6911 :    Loss_Train:  [[ 4822.51989423]]    Loss_Validation:  [[ 1420.52150473]]\n",
      "Loop  6912 :    Loss_Train:  [[ 4822.51988602]]    Loss_Validation:  [[ 1420.52171361]]\n",
      "Loop  6913 :    Loss_Train:  [[ 4822.51987781]]    Loss_Validation:  [[ 1420.52192235]]\n",
      "Loop  6914 :    Loss_Train:  [[ 4822.51986962]]    Loss_Validation:  [[ 1420.52213094]]\n",
      "Loop  6915 :    Loss_Train:  [[ 4822.51986145]]    Loss_Validation:  [[ 1420.52233938]]\n",
      "Loop  6916 :    Loss_Train:  [[ 4822.51985328]]    Loss_Validation:  [[ 1420.52254767]]\n",
      "Loop  6917 :    Loss_Train:  [[ 4822.51984513]]    Loss_Validation:  [[ 1420.52275582]]\n",
      "Loop  6918 :    Loss_Train:  [[ 4822.51983699]]    Loss_Validation:  [[ 1420.52296382]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  6919 :    Loss_Train:  [[ 4822.51982887]]    Loss_Validation:  [[ 1420.52317167]]\n",
      "Loop  6920 :    Loss_Train:  [[ 4822.51982075]]    Loss_Validation:  [[ 1420.52337938]]\n",
      "Loop  6921 :    Loss_Train:  [[ 4822.51981265]]    Loss_Validation:  [[ 1420.52358693]]\n",
      "Loop  6922 :    Loss_Train:  [[ 4822.51980457]]    Loss_Validation:  [[ 1420.52379434]]\n",
      "Loop  6923 :    Loss_Train:  [[ 4822.51979649]]    Loss_Validation:  [[ 1420.52400161]]\n",
      "Loop  6924 :    Loss_Train:  [[ 4822.51978843]]    Loss_Validation:  [[ 1420.52420872]]\n",
      "Loop  6925 :    Loss_Train:  [[ 4822.51978038]]    Loss_Validation:  [[ 1420.52441569]]\n",
      "Loop  6926 :    Loss_Train:  [[ 4822.51977234]]    Loss_Validation:  [[ 1420.52462252]]\n",
      "Loop  6927 :    Loss_Train:  [[ 4822.51976432]]    Loss_Validation:  [[ 1420.52482919]]\n",
      "Loop  6928 :    Loss_Train:  [[ 4822.51975631]]    Loss_Validation:  [[ 1420.52503572]]\n",
      "Loop  6929 :    Loss_Train:  [[ 4822.51974831]]    Loss_Validation:  [[ 1420.52524211]]\n",
      "Loop  6930 :    Loss_Train:  [[ 4822.51974033]]    Loss_Validation:  [[ 1420.52544834]]\n",
      "Loop  6931 :    Loss_Train:  [[ 4822.51973235]]    Loss_Validation:  [[ 1420.52565444]]\n",
      "Loop  6932 :    Loss_Train:  [[ 4822.51972439]]    Loss_Validation:  [[ 1420.52586038]]\n",
      "Loop  6933 :    Loss_Train:  [[ 4822.51971644]]    Loss_Validation:  [[ 1420.52606618]]\n",
      "Loop  6934 :    Loss_Train:  [[ 4822.51970851]]    Loss_Validation:  [[ 1420.52627183]]\n",
      "Loop  6935 :    Loss_Train:  [[ 4822.51970059]]    Loss_Validation:  [[ 1420.52647734]]\n",
      "Loop  6936 :    Loss_Train:  [[ 4822.51969268]]    Loss_Validation:  [[ 1420.5266827]]\n",
      "Loop  6937 :    Loss_Train:  [[ 4822.51968478]]    Loss_Validation:  [[ 1420.52688792]]\n",
      "Loop  6938 :    Loss_Train:  [[ 4822.51967689]]    Loss_Validation:  [[ 1420.52709299]]\n",
      "Loop  6939 :    Loss_Train:  [[ 4822.51966902]]    Loss_Validation:  [[ 1420.52729792]]\n",
      "Loop  6940 :    Loss_Train:  [[ 4822.51966116]]    Loss_Validation:  [[ 1420.5275027]]\n",
      "Loop  6941 :    Loss_Train:  [[ 4822.51965331]]    Loss_Validation:  [[ 1420.52770733]]\n",
      "Loop  6942 :    Loss_Train:  [[ 4822.51964548]]    Loss_Validation:  [[ 1420.52791182]]\n",
      "Loop  6943 :    Loss_Train:  [[ 4822.51963765]]    Loss_Validation:  [[ 1420.52811617]]\n",
      "Loop  6944 :    Loss_Train:  [[ 4822.51962984]]    Loss_Validation:  [[ 1420.52832037]]\n",
      "Loop  6945 :    Loss_Train:  [[ 4822.51962204]]    Loss_Validation:  [[ 1420.52852443]]\n",
      "Loop  6946 :    Loss_Train:  [[ 4822.51961426]]    Loss_Validation:  [[ 1420.52872834]]\n",
      "Loop  6947 :    Loss_Train:  [[ 4822.51960648]]    Loss_Validation:  [[ 1420.5289321]]\n",
      "Loop  6948 :    Loss_Train:  [[ 4822.51959872]]    Loss_Validation:  [[ 1420.52913573]]\n",
      "Loop  6949 :    Loss_Train:  [[ 4822.51959097]]    Loss_Validation:  [[ 1420.52933921]]\n",
      "Loop  6950 :    Loss_Train:  [[ 4822.51958323]]    Loss_Validation:  [[ 1420.52954254]]\n",
      "Loop  6951 :    Loss_Train:  [[ 4822.51957551]]    Loss_Validation:  [[ 1420.52974573]]\n",
      "Loop  6952 :    Loss_Train:  [[ 4822.5195678]]    Loss_Validation:  [[ 1420.52994878]]\n",
      "Loop  6953 :    Loss_Train:  [[ 4822.5195601]]    Loss_Validation:  [[ 1420.53015168]]\n",
      "Loop  6954 :    Loss_Train:  [[ 4822.51955241]]    Loss_Validation:  [[ 1420.53035444]]\n",
      "Loop  6955 :    Loss_Train:  [[ 4822.51954473]]    Loss_Validation:  [[ 1420.53055705]]\n",
      "Loop  6956 :    Loss_Train:  [[ 4822.51953707]]    Loss_Validation:  [[ 1420.53075952]]\n",
      "Loop  6957 :    Loss_Train:  [[ 4822.51952941]]    Loss_Validation:  [[ 1420.53096185]]\n",
      "Loop  6958 :    Loss_Train:  [[ 4822.51952177]]    Loss_Validation:  [[ 1420.53116403]]\n",
      "Loop  6959 :    Loss_Train:  [[ 4822.51951415]]    Loss_Validation:  [[ 1420.53136607]]\n",
      "Loop  6960 :    Loss_Train:  [[ 4822.51950653]]    Loss_Validation:  [[ 1420.53156797]]\n",
      "Loop  6961 :    Loss_Train:  [[ 4822.51949893]]    Loss_Validation:  [[ 1420.53176972]]\n",
      "Loop  6962 :    Loss_Train:  [[ 4822.51949133]]    Loss_Validation:  [[ 1420.53197134]]\n",
      "Loop  6963 :    Loss_Train:  [[ 4822.51948376]]    Loss_Validation:  [[ 1420.5321728]]\n",
      "Loop  6964 :    Loss_Train:  [[ 4822.51947619]]    Loss_Validation:  [[ 1420.53237413]]\n",
      "Loop  6965 :    Loss_Train:  [[ 4822.51946863]]    Loss_Validation:  [[ 1420.53257531]]\n",
      "Loop  6966 :    Loss_Train:  [[ 4822.51946109]]    Loss_Validation:  [[ 1420.53277635]]\n",
      "Loop  6967 :    Loss_Train:  [[ 4822.51945356]]    Loss_Validation:  [[ 1420.53297725]]\n",
      "Loop  6968 :    Loss_Train:  [[ 4822.51944603]]    Loss_Validation:  [[ 1420.53317801]]\n",
      "Loop  6969 :    Loss_Train:  [[ 4822.51943853]]    Loss_Validation:  [[ 1420.53337862]]\n",
      "Loop  6970 :    Loss_Train:  [[ 4822.51943103]]    Loss_Validation:  [[ 1420.53357909]]\n",
      "Loop  6971 :    Loss_Train:  [[ 4822.51942355]]    Loss_Validation:  [[ 1420.53377942]]\n",
      "Loop  6972 :    Loss_Train:  [[ 4822.51941607]]    Loss_Validation:  [[ 1420.53397961]]\n",
      "Loop  6973 :    Loss_Train:  [[ 4822.51940861]]    Loss_Validation:  [[ 1420.53417965]]\n",
      "Loop  6974 :    Loss_Train:  [[ 4822.51940116]]    Loss_Validation:  [[ 1420.53437955]]\n",
      "Loop  6975 :    Loss_Train:  [[ 4822.51939372]]    Loss_Validation:  [[ 1420.53457931]]\n",
      "Loop  6976 :    Loss_Train:  [[ 4822.5193863]]    Loss_Validation:  [[ 1420.53477893]]\n",
      "Loop  6977 :    Loss_Train:  [[ 4822.51937888]]    Loss_Validation:  [[ 1420.53497841]]\n",
      "Loop  6978 :    Loss_Train:  [[ 4822.51937148]]    Loss_Validation:  [[ 1420.53517775]]\n",
      "Loop  6979 :    Loss_Train:  [[ 4822.51936409]]    Loss_Validation:  [[ 1420.53537694]]\n",
      "Loop  6980 :    Loss_Train:  [[ 4822.51935671]]    Loss_Validation:  [[ 1420.535576]]\n",
      "Loop  6981 :    Loss_Train:  [[ 4822.51934935]]    Loss_Validation:  [[ 1420.53577491]]\n",
      "Loop  6982 :    Loss_Train:  [[ 4822.51934199]]    Loss_Validation:  [[ 1420.53597368]]\n",
      "Loop  6983 :    Loss_Train:  [[ 4822.51933465]]    Loss_Validation:  [[ 1420.53617232]]\n",
      "Loop  6984 :    Loss_Train:  [[ 4822.51932731]]    Loss_Validation:  [[ 1420.53637081]]\n",
      "Loop  6985 :    Loss_Train:  [[ 4822.51931999]]    Loss_Validation:  [[ 1420.53656916]]\n",
      "Loop  6986 :    Loss_Train:  [[ 4822.51931268]]    Loss_Validation:  [[ 1420.53676737]]\n",
      "Loop  6987 :    Loss_Train:  [[ 4822.51930539]]    Loss_Validation:  [[ 1420.53696543]]\n",
      "Loop  6988 :    Loss_Train:  [[ 4822.5192981]]    Loss_Validation:  [[ 1420.53716336]]\n",
      "Loop  6989 :    Loss_Train:  [[ 4822.51929082]]    Loss_Validation:  [[ 1420.53736115]]\n",
      "Loop  6990 :    Loss_Train:  [[ 4822.51928356]]    Loss_Validation:  [[ 1420.5375588]]\n",
      "Loop  6991 :    Loss_Train:  [[ 4822.51927631]]    Loss_Validation:  [[ 1420.5377563]]\n",
      "Loop  6992 :    Loss_Train:  [[ 4822.51926907]]    Loss_Validation:  [[ 1420.53795367]]\n",
      "Loop  6993 :    Loss_Train:  [[ 4822.51926184]]    Loss_Validation:  [[ 1420.5381509]]\n",
      "Loop  6994 :    Loss_Train:  [[ 4822.51925462]]    Loss_Validation:  [[ 1420.53834799]]\n",
      "Loop  6995 :    Loss_Train:  [[ 4822.51924742]]    Loss_Validation:  [[ 1420.53854494]]\n",
      "Loop  6996 :    Loss_Train:  [[ 4822.51924022]]    Loss_Validation:  [[ 1420.53874174]]\n",
      "Loop  6997 :    Loss_Train:  [[ 4822.51923304]]    Loss_Validation:  [[ 1420.53893841]]\n",
      "Loop  6998 :    Loss_Train:  [[ 4822.51922587]]    Loss_Validation:  [[ 1420.53913494]]\n",
      "Loop  6999 :    Loss_Train:  [[ 4822.5192187]]    Loss_Validation:  [[ 1420.53933133]]\n",
      "Loop  7000 :    Loss_Train:  [[ 4822.51921156]]    Loss_Validation:  [[ 1420.53952758]]\n",
      "Loop  7001 :    Loss_Train:  [[ 4822.51920442]]    Loss_Validation:  [[ 1420.53972369]]\n",
      "Loop  7002 :    Loss_Train:  [[ 4822.51919729]]    Loss_Validation:  [[ 1420.53991967]]\n",
      "Loop  7003 :    Loss_Train:  [[ 4822.51919017]]    Loss_Validation:  [[ 1420.5401155]]\n",
      "Loop  7004 :    Loss_Train:  [[ 4822.51918307]]    Loss_Validation:  [[ 1420.5403112]]\n",
      "Loop  7005 :    Loss_Train:  [[ 4822.51917598]]    Loss_Validation:  [[ 1420.54050675]]\n",
      "Loop  7006 :    Loss_Train:  [[ 4822.51916889]]    Loss_Validation:  [[ 1420.54070217]]\n",
      "Loop  7007 :    Loss_Train:  [[ 4822.51916182]]    Loss_Validation:  [[ 1420.54089745]]\n",
      "Loop  7008 :    Loss_Train:  [[ 4822.51915476]]    Loss_Validation:  [[ 1420.54109259]]\n",
      "Loop  7009 :    Loss_Train:  [[ 4822.51914772]]    Loss_Validation:  [[ 1420.54128759]]\n",
      "Loop  7010 :    Loss_Train:  [[ 4822.51914068]]    Loss_Validation:  [[ 1420.54148245]]\n",
      "Loop  7011 :    Loss_Train:  [[ 4822.51913365]]    Loss_Validation:  [[ 1420.54167718]]\n",
      "Loop  7012 :    Loss_Train:  [[ 4822.51912664]]    Loss_Validation:  [[ 1420.54187177]]\n",
      "Loop  7013 :    Loss_Train:  [[ 4822.51911963]]    Loss_Validation:  [[ 1420.54206622]]\n",
      "Loop  7014 :    Loss_Train:  [[ 4822.51911264]]    Loss_Validation:  [[ 1420.54226053]]\n",
      "Loop  7015 :    Loss_Train:  [[ 4822.51910566]]    Loss_Validation:  [[ 1420.5424547]]\n",
      "Loop  7016 :    Loss_Train:  [[ 4822.51909869]]    Loss_Validation:  [[ 1420.54264874]]\n",
      "Loop  7017 :    Loss_Train:  [[ 4822.51909173]]    Loss_Validation:  [[ 1420.54284264]]\n",
      "Loop  7018 :    Loss_Train:  [[ 4822.51908478]]    Loss_Validation:  [[ 1420.5430364]]\n",
      "Loop  7019 :    Loss_Train:  [[ 4822.51907784]]    Loss_Validation:  [[ 1420.54323002]]\n",
      "Loop  7020 :    Loss_Train:  [[ 4822.51907091]]    Loss_Validation:  [[ 1420.54342351]]\n",
      "Loop  7021 :    Loss_Train:  [[ 4822.519064]]    Loss_Validation:  [[ 1420.54361686]]\n",
      "Loop  7022 :    Loss_Train:  [[ 4822.51905709]]    Loss_Validation:  [[ 1420.54381007]]\n",
      "Loop  7023 :    Loss_Train:  [[ 4822.5190502]]    Loss_Validation:  [[ 1420.54400314]]\n",
      "Loop  7024 :    Loss_Train:  [[ 4822.51904331]]    Loss_Validation:  [[ 1420.54419608]]\n",
      "Loop  7025 :    Loss_Train:  [[ 4822.51903644]]    Loss_Validation:  [[ 1420.54438888]]\n",
      "Loop  7026 :    Loss_Train:  [[ 4822.51902958]]    Loss_Validation:  [[ 1420.54458155]]\n",
      "Loop  7027 :    Loss_Train:  [[ 4822.51902273]]    Loss_Validation:  [[ 1420.54477408]]\n",
      "Loop  7028 :    Loss_Train:  [[ 4822.51901589]]    Loss_Validation:  [[ 1420.54496647]]\n",
      "Loop  7029 :    Loss_Train:  [[ 4822.51900906]]    Loss_Validation:  [[ 1420.54515872]]\n",
      "Loop  7030 :    Loss_Train:  [[ 4822.51900224]]    Loss_Validation:  [[ 1420.54535084]]\n",
      "Loop  7031 :    Loss_Train:  [[ 4822.51899543]]    Loss_Validation:  [[ 1420.54554282]]\n",
      "Loop  7032 :    Loss_Train:  [[ 4822.51898863]]    Loss_Validation:  [[ 1420.54573467]]\n",
      "Loop  7033 :    Loss_Train:  [[ 4822.51898185]]    Loss_Validation:  [[ 1420.54592638]]\n",
      "Loop  7034 :    Loss_Train:  [[ 4822.51897507]]    Loss_Validation:  [[ 1420.54611795]]\n",
      "Loop  7035 :    Loss_Train:  [[ 4822.51896831]]    Loss_Validation:  [[ 1420.54630939]]\n",
      "Loop  7036 :    Loss_Train:  [[ 4822.51896155]]    Loss_Validation:  [[ 1420.54650069]]\n",
      "Loop  7037 :    Loss_Train:  [[ 4822.51895481]]    Loss_Validation:  [[ 1420.54669186]]\n",
      "Loop  7038 :    Loss_Train:  [[ 4822.51894808]]    Loss_Validation:  [[ 1420.54688289]]\n",
      "Loop  7039 :    Loss_Train:  [[ 4822.51894135]]    Loss_Validation:  [[ 1420.54707379]]\n",
      "Loop  7040 :    Loss_Train:  [[ 4822.51893464]]    Loss_Validation:  [[ 1420.54726455]]\n",
      "Loop  7041 :    Loss_Train:  [[ 4822.51892794]]    Loss_Validation:  [[ 1420.54745517]]\n",
      "Loop  7042 :    Loss_Train:  [[ 4822.51892125]]    Loss_Validation:  [[ 1420.54764566]]\n",
      "Loop  7043 :    Loss_Train:  [[ 4822.51891457]]    Loss_Validation:  [[ 1420.54783602]]\n",
      "Loop  7044 :    Loss_Train:  [[ 4822.5189079]]    Loss_Validation:  [[ 1420.54802624]]\n",
      "Loop  7045 :    Loss_Train:  [[ 4822.51890124]]    Loss_Validation:  [[ 1420.54821632]]\n",
      "Loop  7046 :    Loss_Train:  [[ 4822.51889459]]    Loss_Validation:  [[ 1420.54840627]]\n",
      "Loop  7047 :    Loss_Train:  [[ 4822.51888796]]    Loss_Validation:  [[ 1420.54859609]]\n",
      "Loop  7048 :    Loss_Train:  [[ 4822.51888133]]    Loss_Validation:  [[ 1420.54878577]]\n",
      "Loop  7049 :    Loss_Train:  [[ 4822.51887471]]    Loss_Validation:  [[ 1420.54897531]]\n",
      "Loop  7050 :    Loss_Train:  [[ 4822.5188681]]    Loss_Validation:  [[ 1420.54916473]]\n",
      "Loop  7051 :    Loss_Train:  [[ 4822.51886151]]    Loss_Validation:  [[ 1420.549354]]\n",
      "Loop  7052 :    Loss_Train:  [[ 4822.51885492]]    Loss_Validation:  [[ 1420.54954315]]\n",
      "Loop  7053 :    Loss_Train:  [[ 4822.51884835]]    Loss_Validation:  [[ 1420.54973216]]\n",
      "Loop  7054 :    Loss_Train:  [[ 4822.51884178]]    Loss_Validation:  [[ 1420.54992103]]\n",
      "Loop  7055 :    Loss_Train:  [[ 4822.51883523]]    Loss_Validation:  [[ 1420.55010977]]\n",
      "Loop  7056 :    Loss_Train:  [[ 4822.51882868]]    Loss_Validation:  [[ 1420.55029838]]\n",
      "Loop  7057 :    Loss_Train:  [[ 4822.51882215]]    Loss_Validation:  [[ 1420.55048685]]\n",
      "Loop  7058 :    Loss_Train:  [[ 4822.51881563]]    Loss_Validation:  [[ 1420.55067519]]\n",
      "Loop  7059 :    Loss_Train:  [[ 4822.51880911]]    Loss_Validation:  [[ 1420.5508634]]\n",
      "Loop  7060 :    Loss_Train:  [[ 4822.51880261]]    Loss_Validation:  [[ 1420.55105147]]\n",
      "Loop  7061 :    Loss_Train:  [[ 4822.51879612]]    Loss_Validation:  [[ 1420.55123941]]\n",
      "Loop  7062 :    Loss_Train:  [[ 4822.51878963]]    Loss_Validation:  [[ 1420.55142721]]\n",
      "Loop  7063 :    Loss_Train:  [[ 4822.51878316]]    Loss_Validation:  [[ 1420.55161489]]\n",
      "Loop  7064 :    Loss_Train:  [[ 4822.5187767]]    Loss_Validation:  [[ 1420.55180242]]\n",
      "Loop  7065 :    Loss_Train:  [[ 4822.51877025]]    Loss_Validation:  [[ 1420.55198983]]\n",
      "Loop  7066 :    Loss_Train:  [[ 4822.51876381]]    Loss_Validation:  [[ 1420.5521771]]\n",
      "Loop  7067 :    Loss_Train:  [[ 4822.51875737]]    Loss_Validation:  [[ 1420.55236424]]\n",
      "Loop  7068 :    Loss_Train:  [[ 4822.51875095]]    Loss_Validation:  [[ 1420.55255125]]\n",
      "Loop  7069 :    Loss_Train:  [[ 4822.51874454]]    Loss_Validation:  [[ 1420.55273813]]\n",
      "Loop  7070 :    Loss_Train:  [[ 4822.51873814]]    Loss_Validation:  [[ 1420.55292487]]\n",
      "Loop  7071 :    Loss_Train:  [[ 4822.51873175]]    Loss_Validation:  [[ 1420.55311148]]\n",
      "Loop  7072 :    Loss_Train:  [[ 4822.51872537]]    Loss_Validation:  [[ 1420.55329796]]\n",
      "Loop  7073 :    Loss_Train:  [[ 4822.518719]]    Loss_Validation:  [[ 1420.5534843]]\n",
      "Loop  7074 :    Loss_Train:  [[ 4822.51871264]]    Loss_Validation:  [[ 1420.55367052]]\n",
      "Loop  7075 :    Loss_Train:  [[ 4822.51870628]]    Loss_Validation:  [[ 1420.5538566]]\n",
      "Loop  7076 :    Loss_Train:  [[ 4822.51869994]]    Loss_Validation:  [[ 1420.55404255]]\n",
      "Loop  7077 :    Loss_Train:  [[ 4822.51869361]]    Loss_Validation:  [[ 1420.55422836]]\n",
      "Loop  7078 :    Loss_Train:  [[ 4822.51868729]]    Loss_Validation:  [[ 1420.55441405]]\n",
      "Loop  7079 :    Loss_Train:  [[ 4822.51868098]]    Loss_Validation:  [[ 1420.5545996]]\n",
      "Loop  7080 :    Loss_Train:  [[ 4822.51867468]]    Loss_Validation:  [[ 1420.55478502]]\n",
      "Loop  7081 :    Loss_Train:  [[ 4822.51866839]]    Loss_Validation:  [[ 1420.55497031]]\n",
      "Loop  7082 :    Loss_Train:  [[ 4822.51866211]]    Loss_Validation:  [[ 1420.55515547]]\n",
      "Loop  7083 :    Loss_Train:  [[ 4822.51865584]]    Loss_Validation:  [[ 1420.5553405]]\n",
      "Loop  7084 :    Loss_Train:  [[ 4822.51864958]]    Loss_Validation:  [[ 1420.5555254]]\n",
      "Loop  7085 :    Loss_Train:  [[ 4822.51864332]]    Loss_Validation:  [[ 1420.55571016]]\n",
      "Loop  7086 :    Loss_Train:  [[ 4822.51863708]]    Loss_Validation:  [[ 1420.55589479]]\n",
      "Loop  7087 :    Loss_Train:  [[ 4822.51863085]]    Loss_Validation:  [[ 1420.5560793]]\n",
      "Loop  7088 :    Loss_Train:  [[ 4822.51862463]]    Loss_Validation:  [[ 1420.55626367]]\n",
      "Loop  7089 :    Loss_Train:  [[ 4822.51861842]]    Loss_Validation:  [[ 1420.55644791]]\n",
      "Loop  7090 :    Loss_Train:  [[ 4822.51861221]]    Loss_Validation:  [[ 1420.55663202]]\n",
      "Loop  7091 :    Loss_Train:  [[ 4822.51860602]]    Loss_Validation:  [[ 1420.556816]]\n",
      "Loop  7092 :    Loss_Train:  [[ 4822.51859984]]    Loss_Validation:  [[ 1420.55699985]]\n",
      "Loop  7093 :    Loss_Train:  [[ 4822.51859367]]    Loss_Validation:  [[ 1420.55718357]]\n",
      "Loop  7094 :    Loss_Train:  [[ 4822.5185875]]    Loss_Validation:  [[ 1420.55736716]]\n",
      "Loop  7095 :    Loss_Train:  [[ 4822.51858135]]    Loss_Validation:  [[ 1420.55755061]]\n",
      "Loop  7096 :    Loss_Train:  [[ 4822.51857521]]    Loss_Validation:  [[ 1420.55773394]]\n",
      "Loop  7097 :    Loss_Train:  [[ 4822.51856907]]    Loss_Validation:  [[ 1420.55791714]]\n",
      "Loop  7098 :    Loss_Train:  [[ 4822.51856295]]    Loss_Validation:  [[ 1420.55810021]]\n",
      "Loop  7099 :    Loss_Train:  [[ 4822.51855683]]    Loss_Validation:  [[ 1420.55828315]]\n",
      "Loop  7100 :    Loss_Train:  [[ 4822.51855073]]    Loss_Validation:  [[ 1420.55846595]]\n",
      "Loop  7101 :    Loss_Train:  [[ 4822.51854463]]    Loss_Validation:  [[ 1420.55864863]]\n",
      "Loop  7102 :    Loss_Train:  [[ 4822.51853855]]    Loss_Validation:  [[ 1420.55883118]]\n",
      "Loop  7103 :    Loss_Train:  [[ 4822.51853247]]    Loss_Validation:  [[ 1420.5590136]]\n",
      "Loop  7104 :    Loss_Train:  [[ 4822.5185264]]    Loss_Validation:  [[ 1420.55919589]]\n",
      "Loop  7105 :    Loss_Train:  [[ 4822.51852035]]    Loss_Validation:  [[ 1420.55937805]]\n",
      "Loop  7106 :    Loss_Train:  [[ 4822.5185143]]    Loss_Validation:  [[ 1420.55956008]]\n",
      "Loop  7107 :    Loss_Train:  [[ 4822.51850826]]    Loss_Validation:  [[ 1420.55974198]]\n",
      "Loop  7108 :    Loss_Train:  [[ 4822.51850223]]    Loss_Validation:  [[ 1420.55992376]]\n",
      "Loop  7109 :    Loss_Train:  [[ 4822.51849621]]    Loss_Validation:  [[ 1420.5601054]]\n",
      "Loop  7110 :    Loss_Train:  [[ 4822.5184902]]    Loss_Validation:  [[ 1420.56028692]]\n",
      "Loop  7111 :    Loss_Train:  [[ 4822.5184842]]    Loss_Validation:  [[ 1420.5604683]]\n",
      "Loop  7112 :    Loss_Train:  [[ 4822.51847821]]    Loss_Validation:  [[ 1420.56064956]]\n",
      "Loop  7113 :    Loss_Train:  [[ 4822.51847223]]    Loss_Validation:  [[ 1420.56083069]]\n",
      "Loop  7114 :    Loss_Train:  [[ 4822.51846626]]    Loss_Validation:  [[ 1420.56101169]]\n",
      "Loop  7115 :    Loss_Train:  [[ 4822.5184603]]    Loss_Validation:  [[ 1420.56119256]]\n",
      "Loop  7116 :    Loss_Train:  [[ 4822.51845434]]    Loss_Validation:  [[ 1420.5613733]]\n",
      "Loop  7117 :    Loss_Train:  [[ 4822.5184484]]    Loss_Validation:  [[ 1420.56155392]]\n",
      "Loop  7118 :    Loss_Train:  [[ 4822.51844247]]    Loss_Validation:  [[ 1420.56173441]]\n",
      "Loop  7119 :    Loss_Train:  [[ 4822.51843654]]    Loss_Validation:  [[ 1420.56191477]]\n",
      "Loop  7120 :    Loss_Train:  [[ 4822.51843063]]    Loss_Validation:  [[ 1420.562095]]\n",
      "Loop  7121 :    Loss_Train:  [[ 4822.51842472]]    Loss_Validation:  [[ 1420.5622751]]\n",
      "Loop  7122 :    Loss_Train:  [[ 4822.51841882]]    Loss_Validation:  [[ 1420.56245507]]\n",
      "Loop  7123 :    Loss_Train:  [[ 4822.51841294]]    Loss_Validation:  [[ 1420.56263492]]\n",
      "Loop  7124 :    Loss_Train:  [[ 4822.51840706]]    Loss_Validation:  [[ 1420.56281464]]\n",
      "Loop  7125 :    Loss_Train:  [[ 4822.51840119]]    Loss_Validation:  [[ 1420.56299423]]\n",
      "Loop  7126 :    Loss_Train:  [[ 4822.51839533]]    Loss_Validation:  [[ 1420.5631737]]\n",
      "Loop  7127 :    Loss_Train:  [[ 4822.51838948]]    Loss_Validation:  [[ 1420.56335304]]\n",
      "Loop  7128 :    Loss_Train:  [[ 4822.51838364]]    Loss_Validation:  [[ 1420.56353225]]\n",
      "Loop  7129 :    Loss_Train:  [[ 4822.51837781]]    Loss_Validation:  [[ 1420.56371133]]\n",
      "Loop  7130 :    Loss_Train:  [[ 4822.51837198]]    Loss_Validation:  [[ 1420.56389029]]\n",
      "Loop  7131 :    Loss_Train:  [[ 4822.51836617]]    Loss_Validation:  [[ 1420.56406911]]\n",
      "Loop  7132 :    Loss_Train:  [[ 4822.51836036]]    Loss_Validation:  [[ 1420.56424782]]\n",
      "Loop  7133 :    Loss_Train:  [[ 4822.51835457]]    Loss_Validation:  [[ 1420.56442639]]\n",
      "Loop  7134 :    Loss_Train:  [[ 4822.51834878]]    Loss_Validation:  [[ 1420.56460484]]\n",
      "Loop  7135 :    Loss_Train:  [[ 4822.51834301]]    Loss_Validation:  [[ 1420.56478316]]\n",
      "Loop  7136 :    Loss_Train:  [[ 4822.51833724]]    Loss_Validation:  [[ 1420.56496136]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  7137 :    Loss_Train:  [[ 4822.51833148]]    Loss_Validation:  [[ 1420.56513942]]\n",
      "Loop  7138 :    Loss_Train:  [[ 4822.51832573]]    Loss_Validation:  [[ 1420.56531737]]\n",
      "Loop  7139 :    Loss_Train:  [[ 4822.51831999]]    Loss_Validation:  [[ 1420.56549518]]\n",
      "Loop  7140 :    Loss_Train:  [[ 4822.51831426]]    Loss_Validation:  [[ 1420.56567287]]\n",
      "Loop  7141 :    Loss_Train:  [[ 4822.51830853]]    Loss_Validation:  [[ 1420.56585044]]\n",
      "Loop  7142 :    Loss_Train:  [[ 4822.51830282]]    Loss_Validation:  [[ 1420.56602787]]\n",
      "Loop  7143 :    Loss_Train:  [[ 4822.51829712]]    Loss_Validation:  [[ 1420.56620518]]\n",
      "Loop  7144 :    Loss_Train:  [[ 4822.51829142]]    Loss_Validation:  [[ 1420.56638237]]\n",
      "Loop  7145 :    Loss_Train:  [[ 4822.51828573]]    Loss_Validation:  [[ 1420.56655943]]\n",
      "Loop  7146 :    Loss_Train:  [[ 4822.51828006]]    Loss_Validation:  [[ 1420.56673636]]\n",
      "Loop  7147 :    Loss_Train:  [[ 4822.51827439]]    Loss_Validation:  [[ 1420.56691317]]\n",
      "Loop  7148 :    Loss_Train:  [[ 4822.51826873]]    Loss_Validation:  [[ 1420.56708986]]\n",
      "Loop  7149 :    Loss_Train:  [[ 4822.51826308]]    Loss_Validation:  [[ 1420.56726641]]\n",
      "Loop  7150 :    Loss_Train:  [[ 4822.51825743]]    Loss_Validation:  [[ 1420.56744285]]\n",
      "Loop  7151 :    Loss_Train:  [[ 4822.5182518]]    Loss_Validation:  [[ 1420.56761915]]\n",
      "Loop  7152 :    Loss_Train:  [[ 4822.51824618]]    Loss_Validation:  [[ 1420.56779534]]\n",
      "Loop  7153 :    Loss_Train:  [[ 4822.51824056]]    Loss_Validation:  [[ 1420.56797139]]\n",
      "Loop  7154 :    Loss_Train:  [[ 4822.51823496]]    Loss_Validation:  [[ 1420.56814732]]\n",
      "Loop  7155 :    Loss_Train:  [[ 4822.51822936]]    Loss_Validation:  [[ 1420.56832313]]\n",
      "Loop  7156 :    Loss_Train:  [[ 4822.51822377]]    Loss_Validation:  [[ 1420.56849881]]\n",
      "Loop  7157 :    Loss_Train:  [[ 4822.51821819]]    Loss_Validation:  [[ 1420.56867437]]\n",
      "Loop  7158 :    Loss_Train:  [[ 4822.51821262]]    Loss_Validation:  [[ 1420.5688498]]\n",
      "Loop  7159 :    Loss_Train:  [[ 4822.51820706]]    Loss_Validation:  [[ 1420.56902511]]\n",
      "Loop  7160 :    Loss_Train:  [[ 4822.5182015]]    Loss_Validation:  [[ 1420.5692003]]\n",
      "Loop  7161 :    Loss_Train:  [[ 4822.51819596]]    Loss_Validation:  [[ 1420.56937535]]\n",
      "Loop  7162 :    Loss_Train:  [[ 4822.51819042]]    Loss_Validation:  [[ 1420.56955029]]\n",
      "Loop  7163 :    Loss_Train:  [[ 4822.51818489]]    Loss_Validation:  [[ 1420.5697251]]\n",
      "Loop  7164 :    Loss_Train:  [[ 4822.51817937]]    Loss_Validation:  [[ 1420.56989979]]\n",
      "Loop  7165 :    Loss_Train:  [[ 4822.51817386]]    Loss_Validation:  [[ 1420.57007435]]\n",
      "Loop  7166 :    Loss_Train:  [[ 4822.51816836]]    Loss_Validation:  [[ 1420.57024879]]\n",
      "Loop  7167 :    Loss_Train:  [[ 4822.51816287]]    Loss_Validation:  [[ 1420.5704231]]\n",
      "Loop  7168 :    Loss_Train:  [[ 4822.51815739]]    Loss_Validation:  [[ 1420.5705973]]\n",
      "Loop  7169 :    Loss_Train:  [[ 4822.51815191]]    Loss_Validation:  [[ 1420.57077136]]\n",
      "Loop  7170 :    Loss_Train:  [[ 4822.51814644]]    Loss_Validation:  [[ 1420.57094531]]\n",
      "Loop  7171 :    Loss_Train:  [[ 4822.51814099]]    Loss_Validation:  [[ 1420.57111913]]\n",
      "Loop  7172 :    Loss_Train:  [[ 4822.51813554]]    Loss_Validation:  [[ 1420.57129282]]\n",
      "Loop  7173 :    Loss_Train:  [[ 4822.5181301]]    Loss_Validation:  [[ 1420.5714664]]\n",
      "Loop  7174 :    Loss_Train:  [[ 4822.51812466]]    Loss_Validation:  [[ 1420.57163985]]\n",
      "Loop  7175 :    Loss_Train:  [[ 4822.51811924]]    Loss_Validation:  [[ 1420.57181318]]\n",
      "Loop  7176 :    Loss_Train:  [[ 4822.51811383]]    Loss_Validation:  [[ 1420.57198638]]\n",
      "Loop  7177 :    Loss_Train:  [[ 4822.51810842]]    Loss_Validation:  [[ 1420.57215946]]\n",
      "Loop  7178 :    Loss_Train:  [[ 4822.51810302]]    Loss_Validation:  [[ 1420.57233242]]\n",
      "Loop  7179 :    Loss_Train:  [[ 4822.51809763]]    Loss_Validation:  [[ 1420.57250526]]\n",
      "Loop  7180 :    Loss_Train:  [[ 4822.51809225]]    Loss_Validation:  [[ 1420.57267797]]\n",
      "Loop  7181 :    Loss_Train:  [[ 4822.51808688]]    Loss_Validation:  [[ 1420.57285056]]\n",
      "Loop  7182 :    Loss_Train:  [[ 4822.51808151]]    Loss_Validation:  [[ 1420.57302303]]\n",
      "Loop  7183 :    Loss_Train:  [[ 4822.51807616]]    Loss_Validation:  [[ 1420.57319537]]\n",
      "Loop  7184 :    Loss_Train:  [[ 4822.51807081]]    Loss_Validation:  [[ 1420.57336759]]\n",
      "Loop  7185 :    Loss_Train:  [[ 4822.51806547]]    Loss_Validation:  [[ 1420.57353969]]\n",
      "Loop  7186 :    Loss_Train:  [[ 4822.51806014]]    Loss_Validation:  [[ 1420.57371167]]\n",
      "Loop  7187 :    Loss_Train:  [[ 4822.51805482]]    Loss_Validation:  [[ 1420.57388353]]\n",
      "Loop  7188 :    Loss_Train:  [[ 4822.5180495]]    Loss_Validation:  [[ 1420.57405526]]\n",
      "Loop  7189 :    Loss_Train:  [[ 4822.5180442]]    Loss_Validation:  [[ 1420.57422688]]\n",
      "Loop  7190 :    Loss_Train:  [[ 4822.5180389]]    Loss_Validation:  [[ 1420.57439837]]\n",
      "Loop  7191 :    Loss_Train:  [[ 4822.51803361]]    Loss_Validation:  [[ 1420.57456973]]\n",
      "Loop  7192 :    Loss_Train:  [[ 4822.51802833]]    Loss_Validation:  [[ 1420.57474098]]\n",
      "Loop  7193 :    Loss_Train:  [[ 4822.51802306]]    Loss_Validation:  [[ 1420.57491211]]\n",
      "Loop  7194 :    Loss_Train:  [[ 4822.5180178]]    Loss_Validation:  [[ 1420.57508311]]\n",
      "Loop  7195 :    Loss_Train:  [[ 4822.51801254]]    Loss_Validation:  [[ 1420.57525399]]\n",
      "Loop  7196 :    Loss_Train:  [[ 4822.5180073]]    Loss_Validation:  [[ 1420.57542475]]\n",
      "Loop  7197 :    Loss_Train:  [[ 4822.51800206]]    Loss_Validation:  [[ 1420.57559539]]\n",
      "Loop  7198 :    Loss_Train:  [[ 4822.51799683]]    Loss_Validation:  [[ 1420.57576591]]\n",
      "Loop  7199 :    Loss_Train:  [[ 4822.5179916]]    Loss_Validation:  [[ 1420.57593631]]\n",
      "Loop  7200 :    Loss_Train:  [[ 4822.51798639]]    Loss_Validation:  [[ 1420.57610659]]\n",
      "Loop  7201 :    Loss_Train:  [[ 4822.51798118]]    Loss_Validation:  [[ 1420.57627674]]\n",
      "Loop  7202 :    Loss_Train:  [[ 4822.51797599]]    Loss_Validation:  [[ 1420.57644678]]\n",
      "Loop  7203 :    Loss_Train:  [[ 4822.5179708]]    Loss_Validation:  [[ 1420.57661669]]\n",
      "Loop  7204 :    Loss_Train:  [[ 4822.51796562]]    Loss_Validation:  [[ 1420.57678648]]\n",
      "Loop  7205 :    Loss_Train:  [[ 4822.51796044]]    Loss_Validation:  [[ 1420.57695616]]\n",
      "Loop  7206 :    Loss_Train:  [[ 4822.51795528]]    Loss_Validation:  [[ 1420.57712571]]\n",
      "Loop  7207 :    Loss_Train:  [[ 4822.51795012]]    Loss_Validation:  [[ 1420.57729514]]\n",
      "Loop  7208 :    Loss_Train:  [[ 4822.51794497]]    Loss_Validation:  [[ 1420.57746445]]\n",
      "Loop  7209 :    Loss_Train:  [[ 4822.51793983]]    Loss_Validation:  [[ 1420.57763364]]\n",
      "Loop  7210 :    Loss_Train:  [[ 4822.5179347]]    Loss_Validation:  [[ 1420.57780271]]\n",
      "Loop  7211 :    Loss_Train:  [[ 4822.51792957]]    Loss_Validation:  [[ 1420.57797166]]\n",
      "Loop  7212 :    Loss_Train:  [[ 4822.51792446]]    Loss_Validation:  [[ 1420.57814049]]\n",
      "Loop  7213 :    Loss_Train:  [[ 4822.51791935]]    Loss_Validation:  [[ 1420.57830921]]\n",
      "Loop  7214 :    Loss_Train:  [[ 4822.51791425]]    Loss_Validation:  [[ 1420.5784778]]\n",
      "Loop  7215 :    Loss_Train:  [[ 4822.51790916]]    Loss_Validation:  [[ 1420.57864627]]\n",
      "Loop  7216 :    Loss_Train:  [[ 4822.51790407]]    Loss_Validation:  [[ 1420.57881462]]\n",
      "Loop  7217 :    Loss_Train:  [[ 4822.517899]]    Loss_Validation:  [[ 1420.57898285]]\n",
      "Loop  7218 :    Loss_Train:  [[ 4822.51789393]]    Loss_Validation:  [[ 1420.57915096]]\n",
      "Loop  7219 :    Loss_Train:  [[ 4822.51788887]]    Loss_Validation:  [[ 1420.57931896]]\n",
      "Loop  7220 :    Loss_Train:  [[ 4822.51788382]]    Loss_Validation:  [[ 1420.57948683]]\n",
      "Loop  7221 :    Loss_Train:  [[ 4822.51787877]]    Loss_Validation:  [[ 1420.57965459]]\n",
      "Loop  7222 :    Loss_Train:  [[ 4822.51787374]]    Loss_Validation:  [[ 1420.57982222]]\n",
      "Loop  7223 :    Loss_Train:  [[ 4822.51786871]]    Loss_Validation:  [[ 1420.57998974]]\n",
      "Loop  7224 :    Loss_Train:  [[ 4822.51786369]]    Loss_Validation:  [[ 1420.58015714]]\n",
      "Loop  7225 :    Loss_Train:  [[ 4822.51785868]]    Loss_Validation:  [[ 1420.58032441]]\n",
      "Loop  7226 :    Loss_Train:  [[ 4822.51785367]]    Loss_Validation:  [[ 1420.58049157]]\n",
      "Loop  7227 :    Loss_Train:  [[ 4822.51784867]]    Loss_Validation:  [[ 1420.58065861]]\n",
      "Loop  7228 :    Loss_Train:  [[ 4822.51784369]]    Loss_Validation:  [[ 1420.58082554]]\n",
      "Loop  7229 :    Loss_Train:  [[ 4822.5178387]]    Loss_Validation:  [[ 1420.58099234]]\n",
      "Loop  7230 :    Loss_Train:  [[ 4822.51783373]]    Loss_Validation:  [[ 1420.58115903]]\n",
      "Loop  7231 :    Loss_Train:  [[ 4822.51782877]]    Loss_Validation:  [[ 1420.58132559]]\n",
      "Loop  7232 :    Loss_Train:  [[ 4822.51782381]]    Loss_Validation:  [[ 1420.58149204]]\n",
      "Loop  7233 :    Loss_Train:  [[ 4822.51781886]]    Loss_Validation:  [[ 1420.58165837]]\n",
      "Loop  7234 :    Loss_Train:  [[ 4822.51781392]]    Loss_Validation:  [[ 1420.58182458]]\n",
      "Loop  7235 :    Loss_Train:  [[ 4822.51780898]]    Loss_Validation:  [[ 1420.58199068]]\n",
      "Loop  7236 :    Loss_Train:  [[ 4822.51780406]]    Loss_Validation:  [[ 1420.58215665]]\n",
      "Loop  7237 :    Loss_Train:  [[ 4822.51779914]]    Loss_Validation:  [[ 1420.58232251]]\n",
      "Loop  7238 :    Loss_Train:  [[ 4822.51779423]]    Loss_Validation:  [[ 1420.58248825]]\n",
      "Loop  7239 :    Loss_Train:  [[ 4822.51778932]]    Loss_Validation:  [[ 1420.58265388]]\n",
      "Loop  7240 :    Loss_Train:  [[ 4822.51778443]]    Loss_Validation:  [[ 1420.58281938]]\n",
      "Loop  7241 :    Loss_Train:  [[ 4822.51777954]]    Loss_Validation:  [[ 1420.58298477]]\n",
      "Loop  7242 :    Loss_Train:  [[ 4822.51777466]]    Loss_Validation:  [[ 1420.58315004]]\n",
      "Loop  7243 :    Loss_Train:  [[ 4822.51776979]]    Loss_Validation:  [[ 1420.58331519]]\n",
      "Loop  7244 :    Loss_Train:  [[ 4822.51776492]]    Loss_Validation:  [[ 1420.58348022]]\n",
      "Loop  7245 :    Loss_Train:  [[ 4822.51776007]]    Loss_Validation:  [[ 1420.58364514]]\n",
      "Loop  7246 :    Loss_Train:  [[ 4822.51775522]]    Loss_Validation:  [[ 1420.58380994]]\n",
      "Loop  7247 :    Loss_Train:  [[ 4822.51775038]]    Loss_Validation:  [[ 1420.58397463]]\n",
      "Loop  7248 :    Loss_Train:  [[ 4822.51774554]]    Loss_Validation:  [[ 1420.58413919]]\n",
      "Loop  7249 :    Loss_Train:  [[ 4822.51774072]]    Loss_Validation:  [[ 1420.58430364]]\n",
      "Loop  7250 :    Loss_Train:  [[ 4822.5177359]]    Loss_Validation:  [[ 1420.58446798]]\n",
      "Loop  7251 :    Loss_Train:  [[ 4822.51773109]]    Loss_Validation:  [[ 1420.58463219]]\n",
      "Loop  7252 :    Loss_Train:  [[ 4822.51772628]]    Loss_Validation:  [[ 1420.58479629]]\n",
      "Loop  7253 :    Loss_Train:  [[ 4822.51772149]]    Loss_Validation:  [[ 1420.58496027]]\n",
      "Loop  7254 :    Loss_Train:  [[ 4822.5177167]]    Loss_Validation:  [[ 1420.58512414]]\n",
      "Loop  7255 :    Loss_Train:  [[ 4822.51771192]]    Loss_Validation:  [[ 1420.58528789]]\n",
      "Loop  7256 :    Loss_Train:  [[ 4822.51770714]]    Loss_Validation:  [[ 1420.58545152]]\n",
      "Loop  7257 :    Loss_Train:  [[ 4822.51770238]]    Loss_Validation:  [[ 1420.58561504]]\n",
      "Loop  7258 :    Loss_Train:  [[ 4822.51769762]]    Loss_Validation:  [[ 1420.58577844]]\n",
      "Loop  7259 :    Loss_Train:  [[ 4822.51769287]]    Loss_Validation:  [[ 1420.58594173]]\n",
      "Loop  7260 :    Loss_Train:  [[ 4822.51768813]]    Loss_Validation:  [[ 1420.5861049]]\n",
      "Loop  7261 :    Loss_Train:  [[ 4822.51768339]]    Loss_Validation:  [[ 1420.58626795]]\n",
      "Loop  7262 :    Loss_Train:  [[ 4822.51767866]]    Loss_Validation:  [[ 1420.58643089]]\n",
      "Loop  7263 :    Loss_Train:  [[ 4822.51767394]]    Loss_Validation:  [[ 1420.58659371]]\n",
      "Loop  7264 :    Loss_Train:  [[ 4822.51766923]]    Loss_Validation:  [[ 1420.58675641]]\n",
      "Loop  7265 :    Loss_Train:  [[ 4822.51766452]]    Loss_Validation:  [[ 1420.58691901]]\n",
      "Loop  7266 :    Loss_Train:  [[ 4822.51765982]]    Loss_Validation:  [[ 1420.58708148]]\n",
      "Loop  7267 :    Loss_Train:  [[ 4822.51765513]]    Loss_Validation:  [[ 1420.58724384]]\n",
      "Loop  7268 :    Loss_Train:  [[ 4822.51765045]]    Loss_Validation:  [[ 1420.58740608]]\n",
      "Loop  7269 :    Loss_Train:  [[ 4822.51764577]]    Loss_Validation:  [[ 1420.58756821]]\n",
      "Loop  7270 :    Loss_Train:  [[ 4822.5176411]]    Loss_Validation:  [[ 1420.58773022]]\n",
      "Loop  7271 :    Loss_Train:  [[ 4822.51763644]]    Loss_Validation:  [[ 1420.58789212]]\n",
      "Loop  7272 :    Loss_Train:  [[ 4822.51763178]]    Loss_Validation:  [[ 1420.58805391]]\n",
      "Loop  7273 :    Loss_Train:  [[ 4822.51762714]]    Loss_Validation:  [[ 1420.58821557]]\n",
      "Loop  7274 :    Loss_Train:  [[ 4822.5176225]]    Loss_Validation:  [[ 1420.58837713]]\n",
      "Loop  7275 :    Loss_Train:  [[ 4822.51761786]]    Loss_Validation:  [[ 1420.58853857]]\n",
      "Loop  7276 :    Loss_Train:  [[ 4822.51761324]]    Loss_Validation:  [[ 1420.58869989]]\n",
      "Loop  7277 :    Loss_Train:  [[ 4822.51760862]]    Loss_Validation:  [[ 1420.5888611]]\n",
      "Loop  7278 :    Loss_Train:  [[ 4822.51760401]]    Loss_Validation:  [[ 1420.58902219]]\n",
      "Loop  7279 :    Loss_Train:  [[ 4822.51759941]]    Loss_Validation:  [[ 1420.58918317]]\n",
      "Loop  7280 :    Loss_Train:  [[ 4822.51759481]]    Loss_Validation:  [[ 1420.58934404]]\n",
      "Loop  7281 :    Loss_Train:  [[ 4822.51759022]]    Loss_Validation:  [[ 1420.58950479]]\n",
      "Loop  7282 :    Loss_Train:  [[ 4822.51758564]]    Loss_Validation:  [[ 1420.58966543]]\n",
      "Loop  7283 :    Loss_Train:  [[ 4822.51758107]]    Loss_Validation:  [[ 1420.58982595]]\n",
      "Loop  7284 :    Loss_Train:  [[ 4822.5175765]]    Loss_Validation:  [[ 1420.58998636]]\n",
      "Loop  7285 :    Loss_Train:  [[ 4822.51757194]]    Loss_Validation:  [[ 1420.59014665]]\n",
      "Loop  7286 :    Loss_Train:  [[ 4822.51756738]]    Loss_Validation:  [[ 1420.59030684]]\n",
      "Loop  7287 :    Loss_Train:  [[ 4822.51756284]]    Loss_Validation:  [[ 1420.5904669]]\n",
      "Loop  7288 :    Loss_Train:  [[ 4822.5175583]]    Loss_Validation:  [[ 1420.59062686]]\n",
      "Loop  7289 :    Loss_Train:  [[ 4822.51755377]]    Loss_Validation:  [[ 1420.5907867]]\n",
      "Loop  7290 :    Loss_Train:  [[ 4822.51754924]]    Loss_Validation:  [[ 1420.59094642]]\n",
      "Loop  7291 :    Loss_Train:  [[ 4822.51754473]]    Loss_Validation:  [[ 1420.59110603]]\n",
      "Loop  7292 :    Loss_Train:  [[ 4822.51754022]]    Loss_Validation:  [[ 1420.59126553]]\n",
      "Loop  7293 :    Loss_Train:  [[ 4822.51753571]]    Loss_Validation:  [[ 1420.59142492]]\n",
      "Loop  7294 :    Loss_Train:  [[ 4822.51753122]]    Loss_Validation:  [[ 1420.59158419]]\n",
      "Loop  7295 :    Loss_Train:  [[ 4822.51752673]]    Loss_Validation:  [[ 1420.59174335]]\n",
      "Loop  7296 :    Loss_Train:  [[ 4822.51752225]]    Loss_Validation:  [[ 1420.5919024]]\n",
      "Loop  7297 :    Loss_Train:  [[ 4822.51751777]]    Loss_Validation:  [[ 1420.59206133]]\n",
      "Loop  7298 :    Loss_Train:  [[ 4822.51751331]]    Loss_Validation:  [[ 1420.59222015]]\n",
      "Loop  7299 :    Loss_Train:  [[ 4822.51750885]]    Loss_Validation:  [[ 1420.59237886]]\n",
      "Loop  7300 :    Loss_Train:  [[ 4822.51750439]]    Loss_Validation:  [[ 1420.59253745]]\n",
      "Loop  7301 :    Loss_Train:  [[ 4822.51749994]]    Loss_Validation:  [[ 1420.59269593]]\n",
      "Loop  7302 :    Loss_Train:  [[ 4822.51749551]]    Loss_Validation:  [[ 1420.5928543]]\n",
      "Loop  7303 :    Loss_Train:  [[ 4822.51749107]]    Loss_Validation:  [[ 1420.59301256]]\n",
      "Loop  7304 :    Loss_Train:  [[ 4822.51748665]]    Loss_Validation:  [[ 1420.5931707]]\n",
      "Loop  7305 :    Loss_Train:  [[ 4822.51748223]]    Loss_Validation:  [[ 1420.59332874]]\n",
      "Loop  7306 :    Loss_Train:  [[ 4822.51747782]]    Loss_Validation:  [[ 1420.59348666]]\n",
      "Loop  7307 :    Loss_Train:  [[ 4822.51747341]]    Loss_Validation:  [[ 1420.59364446]]\n",
      "Loop  7308 :    Loss_Train:  [[ 4822.51746901]]    Loss_Validation:  [[ 1420.59380216]]\n",
      "Loop  7309 :    Loss_Train:  [[ 4822.51746462]]    Loss_Validation:  [[ 1420.59395974]]\n",
      "Loop  7310 :    Loss_Train:  [[ 4822.51746024]]    Loss_Validation:  [[ 1420.59411721]]\n",
      "Loop  7311 :    Loss_Train:  [[ 4822.51745586]]    Loss_Validation:  [[ 1420.59427457]]\n",
      "Loop  7312 :    Loss_Train:  [[ 4822.51745149]]    Loss_Validation:  [[ 1420.59443182]]\n",
      "Loop  7313 :    Loss_Train:  [[ 4822.51744713]]    Loss_Validation:  [[ 1420.59458895]]\n",
      "Loop  7314 :    Loss_Train:  [[ 4822.51744277]]    Loss_Validation:  [[ 1420.59474598]]\n",
      "Loop  7315 :    Loss_Train:  [[ 4822.51743842]]    Loss_Validation:  [[ 1420.59490289]]\n",
      "Loop  7316 :    Loss_Train:  [[ 4822.51743408]]    Loss_Validation:  [[ 1420.59505969]]\n",
      "Loop  7317 :    Loss_Train:  [[ 4822.51742974]]    Loss_Validation:  [[ 1420.59521638]]\n",
      "Loop  7318 :    Loss_Train:  [[ 4822.51742542]]    Loss_Validation:  [[ 1420.59537296]]\n",
      "Loop  7319 :    Loss_Train:  [[ 4822.51742109]]    Loss_Validation:  [[ 1420.59552942]]\n",
      "Loop  7320 :    Loss_Train:  [[ 4822.51741678]]    Loss_Validation:  [[ 1420.59568578]]\n",
      "Loop  7321 :    Loss_Train:  [[ 4822.51741247]]    Loss_Validation:  [[ 1420.59584202]]\n",
      "Loop  7322 :    Loss_Train:  [[ 4822.51740817]]    Loss_Validation:  [[ 1420.59599815]]\n",
      "Loop  7323 :    Loss_Train:  [[ 4822.51740387]]    Loss_Validation:  [[ 1420.59615418]]\n",
      "Loop  7324 :    Loss_Train:  [[ 4822.51739958]]    Loss_Validation:  [[ 1420.59631009]]\n",
      "Loop  7325 :    Loss_Train:  [[ 4822.5173953]]    Loss_Validation:  [[ 1420.59646589]]\n",
      "Loop  7326 :    Loss_Train:  [[ 4822.51739103]]    Loss_Validation:  [[ 1420.59662158]]\n",
      "Loop  7327 :    Loss_Train:  [[ 4822.51738676]]    Loss_Validation:  [[ 1420.59677715]]\n",
      "Loop  7328 :    Loss_Train:  [[ 4822.5173825]]    Loss_Validation:  [[ 1420.59693262]]\n",
      "Loop  7329 :    Loss_Train:  [[ 4822.51737824]]    Loss_Validation:  [[ 1420.59708798]]\n",
      "Loop  7330 :    Loss_Train:  [[ 4822.517374]]    Loss_Validation:  [[ 1420.59724323]]\n",
      "Loop  7331 :    Loss_Train:  [[ 4822.51736975]]    Loss_Validation:  [[ 1420.59739836]]\n",
      "Loop  7332 :    Loss_Train:  [[ 4822.51736552]]    Loss_Validation:  [[ 1420.59755339]]\n",
      "Loop  7333 :    Loss_Train:  [[ 4822.51736129]]    Loss_Validation:  [[ 1420.59770831]]\n",
      "Loop  7334 :    Loss_Train:  [[ 4822.51735707]]    Loss_Validation:  [[ 1420.59786311]]\n",
      "Loop  7335 :    Loss_Train:  [[ 4822.51735286]]    Loss_Validation:  [[ 1420.59801781]]\n",
      "Loop  7336 :    Loss_Train:  [[ 4822.51734865]]    Loss_Validation:  [[ 1420.5981724]]\n",
      "Loop  7337 :    Loss_Train:  [[ 4822.51734445]]    Loss_Validation:  [[ 1420.59832687]]\n",
      "Loop  7338 :    Loss_Train:  [[ 4822.51734025]]    Loss_Validation:  [[ 1420.59848124]]\n",
      "Loop  7339 :    Loss_Train:  [[ 4822.51733606]]    Loss_Validation:  [[ 1420.59863549]]\n",
      "Loop  7340 :    Loss_Train:  [[ 4822.51733188]]    Loss_Validation:  [[ 1420.59878964]]\n",
      "Loop  7341 :    Loss_Train:  [[ 4822.51732771]]    Loss_Validation:  [[ 1420.59894368]]\n",
      "Loop  7342 :    Loss_Train:  [[ 4822.51732354]]    Loss_Validation:  [[ 1420.59909761]]\n",
      "Loop  7343 :    Loss_Train:  [[ 4822.51731938]]    Loss_Validation:  [[ 1420.59925142]]\n",
      "Loop  7344 :    Loss_Train:  [[ 4822.51731522]]    Loss_Validation:  [[ 1420.59940513]]\n",
      "Loop  7345 :    Loss_Train:  [[ 4822.51731107]]    Loss_Validation:  [[ 1420.59955873]]\n",
      "Loop  7346 :    Loss_Train:  [[ 4822.51730693]]    Loss_Validation:  [[ 1420.59971222]]\n",
      "Loop  7347 :    Loss_Train:  [[ 4822.51730279]]    Loss_Validation:  [[ 1420.59986561]]\n",
      "Loop  7348 :    Loss_Train:  [[ 4822.51729867]]    Loss_Validation:  [[ 1420.60001888]]\n",
      "Loop  7349 :    Loss_Train:  [[ 4822.51729454]]    Loss_Validation:  [[ 1420.60017204]]\n",
      "Loop  7350 :    Loss_Train:  [[ 4822.51729043]]    Loss_Validation:  [[ 1420.60032509]]\n",
      "Loop  7351 :    Loss_Train:  [[ 4822.51728632]]    Loss_Validation:  [[ 1420.60047804]]\n",
      "Loop  7352 :    Loss_Train:  [[ 4822.51728221]]    Loss_Validation:  [[ 1420.60063088]]\n",
      "Loop  7353 :    Loss_Train:  [[ 4822.51727812]]    Loss_Validation:  [[ 1420.60078361]]\n",
      "Loop  7354 :    Loss_Train:  [[ 4822.51727403]]    Loss_Validation:  [[ 1420.60093622]]\n",
      "Loop  7355 :    Loss_Train:  [[ 4822.51726994]]    Loss_Validation:  [[ 1420.60108874]]\n",
      "Loop  7356 :    Loss_Train:  [[ 4822.51726587]]    Loss_Validation:  [[ 1420.60124114]]\n",
      "Loop  7357 :    Loss_Train:  [[ 4822.51726179]]    Loss_Validation:  [[ 1420.60139343]]\n",
      "Loop  7358 :    Loss_Train:  [[ 4822.51725773]]    Loss_Validation:  [[ 1420.60154562]]\n",
      "Loop  7359 :    Loss_Train:  [[ 4822.51725367]]    Loss_Validation:  [[ 1420.6016977]]\n",
      "Loop  7360 :    Loss_Train:  [[ 4822.51724962]]    Loss_Validation:  [[ 1420.60184967]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  7361 :    Loss_Train:  [[ 4822.51724557]]    Loss_Validation:  [[ 1420.60200153]]\n",
      "Loop  7362 :    Loss_Train:  [[ 4822.51724153]]    Loss_Validation:  [[ 1420.60215328]]\n",
      "Loop  7363 :    Loss_Train:  [[ 4822.5172375]]    Loss_Validation:  [[ 1420.60230493]]\n",
      "Loop  7364 :    Loss_Train:  [[ 4822.51723348]]    Loss_Validation:  [[ 1420.60245646]]\n",
      "Loop  7365 :    Loss_Train:  [[ 4822.51722946]]    Loss_Validation:  [[ 1420.60260789]]\n",
      "Loop  7366 :    Loss_Train:  [[ 4822.51722544]]    Loss_Validation:  [[ 1420.60275922]]\n",
      "Loop  7367 :    Loss_Train:  [[ 4822.51722143]]    Loss_Validation:  [[ 1420.60291043]]\n",
      "Loop  7368 :    Loss_Train:  [[ 4822.51721743]]    Loss_Validation:  [[ 1420.60306154]]\n",
      "Loop  7369 :    Loss_Train:  [[ 4822.51721344]]    Loss_Validation:  [[ 1420.60321254]]\n",
      "Loop  7370 :    Loss_Train:  [[ 4822.51720945]]    Loss_Validation:  [[ 1420.60336343]]\n",
      "Loop  7371 :    Loss_Train:  [[ 4822.51720547]]    Loss_Validation:  [[ 1420.60351422]]\n",
      "Loop  7372 :    Loss_Train:  [[ 4822.51720149]]    Loss_Validation:  [[ 1420.60366489]]\n",
      "Loop  7373 :    Loss_Train:  [[ 4822.51719752]]    Loss_Validation:  [[ 1420.60381546]]\n",
      "Loop  7374 :    Loss_Train:  [[ 4822.51719356]]    Loss_Validation:  [[ 1420.60396593]]\n",
      "Loop  7375 :    Loss_Train:  [[ 4822.5171896]]    Loss_Validation:  [[ 1420.60411628]]\n",
      "Loop  7376 :    Loss_Train:  [[ 4822.51718565]]    Loss_Validation:  [[ 1420.60426653]]\n",
      "Loop  7377 :    Loss_Train:  [[ 4822.5171817]]    Loss_Validation:  [[ 1420.60441668]]\n",
      "Loop  7378 :    Loss_Train:  [[ 4822.51717777]]    Loss_Validation:  [[ 1420.60456671]]\n",
      "Loop  7379 :    Loss_Train:  [[ 4822.51717383]]    Loss_Validation:  [[ 1420.60471664]]\n",
      "Loop  7380 :    Loss_Train:  [[ 4822.51716991]]    Loss_Validation:  [[ 1420.60486646]]\n",
      "Loop  7381 :    Loss_Train:  [[ 4822.51716599]]    Loss_Validation:  [[ 1420.60501618]]\n",
      "Loop  7382 :    Loss_Train:  [[ 4822.51716207]]    Loss_Validation:  [[ 1420.60516579]]\n",
      "Loop  7383 :    Loss_Train:  [[ 4822.51715817]]    Loss_Validation:  [[ 1420.60531529]]\n",
      "Loop  7384 :    Loss_Train:  [[ 4822.51715426]]    Loss_Validation:  [[ 1420.60546469]]\n",
      "Loop  7385 :    Loss_Train:  [[ 4822.51715037]]    Loss_Validation:  [[ 1420.60561398]]\n",
      "Loop  7386 :    Loss_Train:  [[ 4822.51714648]]    Loss_Validation:  [[ 1420.60576316]]\n",
      "Loop  7387 :    Loss_Train:  [[ 4822.5171426]]    Loss_Validation:  [[ 1420.60591224]]\n",
      "Loop  7388 :    Loss_Train:  [[ 4822.51713872]]    Loss_Validation:  [[ 1420.60606121]]\n",
      "Loop  7389 :    Loss_Train:  [[ 4822.51713485]]    Loss_Validation:  [[ 1420.60621008]]\n",
      "Loop  7390 :    Loss_Train:  [[ 4822.51713098]]    Loss_Validation:  [[ 1420.60635884]]\n",
      "Loop  7391 :    Loss_Train:  [[ 4822.51712712]]    Loss_Validation:  [[ 1420.6065075]]\n",
      "Loop  7392 :    Loss_Train:  [[ 4822.51712327]]    Loss_Validation:  [[ 1420.60665604]]\n",
      "Loop  7393 :    Loss_Train:  [[ 4822.51711943]]    Loss_Validation:  [[ 1420.60680449]]\n",
      "Loop  7394 :    Loss_Train:  [[ 4822.51711558]]    Loss_Validation:  [[ 1420.60695283]]\n",
      "Loop  7395 :    Loss_Train:  [[ 4822.51711175]]    Loss_Validation:  [[ 1420.60710106]]\n",
      "Loop  7396 :    Loss_Train:  [[ 4822.51710792]]    Loss_Validation:  [[ 1420.60724918]]\n",
      "Loop  7397 :    Loss_Train:  [[ 4822.5171041]]    Loss_Validation:  [[ 1420.60739721]]\n",
      "Loop  7398 :    Loss_Train:  [[ 4822.51710028]]    Loss_Validation:  [[ 1420.60754512]]\n",
      "Loop  7399 :    Loss_Train:  [[ 4822.51709647]]    Loss_Validation:  [[ 1420.60769293]]\n",
      "Loop  7400 :    Loss_Train:  [[ 4822.51709267]]    Loss_Validation:  [[ 1420.60784064]]\n",
      "Loop  7401 :    Loss_Train:  [[ 4822.51708887]]    Loss_Validation:  [[ 1420.60798824]]\n",
      "Loop  7402 :    Loss_Train:  [[ 4822.51708508]]    Loss_Validation:  [[ 1420.60813573]]\n",
      "Loop  7403 :    Loss_Train:  [[ 4822.51708129]]    Loss_Validation:  [[ 1420.60828312]]\n",
      "Loop  7404 :    Loss_Train:  [[ 4822.51707751]]    Loss_Validation:  [[ 1420.60843041]]\n",
      "Loop  7405 :    Loss_Train:  [[ 4822.51707373]]    Loss_Validation:  [[ 1420.60857759]]\n",
      "Loop  7406 :    Loss_Train:  [[ 4822.51706997]]    Loss_Validation:  [[ 1420.60872467]]\n",
      "Loop  7407 :    Loss_Train:  [[ 4822.5170662]]    Loss_Validation:  [[ 1420.60887164]]\n",
      "Loop  7408 :    Loss_Train:  [[ 4822.51706245]]    Loss_Validation:  [[ 1420.60901851]]\n",
      "Loop  7409 :    Loss_Train:  [[ 4822.5170587]]    Loss_Validation:  [[ 1420.60916527]]\n",
      "Loop  7410 :    Loss_Train:  [[ 4822.51705495]]    Loss_Validation:  [[ 1420.60931193]]\n",
      "Loop  7411 :    Loss_Train:  [[ 4822.51705121]]    Loss_Validation:  [[ 1420.60945848]]\n",
      "Loop  7412 :    Loss_Train:  [[ 4822.51704748]]    Loss_Validation:  [[ 1420.60960493]]\n",
      "Loop  7413 :    Loss_Train:  [[ 4822.51704375]]    Loss_Validation:  [[ 1420.60975128]]\n",
      "Loop  7414 :    Loss_Train:  [[ 4822.51704003]]    Loss_Validation:  [[ 1420.60989752]]\n",
      "Loop  7415 :    Loss_Train:  [[ 4822.51703631]]    Loss_Validation:  [[ 1420.61004366]]\n",
      "Loop  7416 :    Loss_Train:  [[ 4822.5170326]]    Loss_Validation:  [[ 1420.61018969]]\n",
      "Loop  7417 :    Loss_Train:  [[ 4822.5170289]]    Loss_Validation:  [[ 1420.61033562]]\n",
      "Loop  7418 :    Loss_Train:  [[ 4822.5170252]]    Loss_Validation:  [[ 1420.61048144]]\n",
      "Loop  7419 :    Loss_Train:  [[ 4822.51702151]]    Loss_Validation:  [[ 1420.61062717]]\n",
      "Loop  7420 :    Loss_Train:  [[ 4822.51701782]]    Loss_Validation:  [[ 1420.61077278]]\n",
      "Loop  7421 :    Loss_Train:  [[ 4822.51701414]]    Loss_Validation:  [[ 1420.6109183]]\n",
      "Loop  7422 :    Loss_Train:  [[ 4822.51701047]]    Loss_Validation:  [[ 1420.61106371]]\n",
      "Loop  7423 :    Loss_Train:  [[ 4822.5170068]]    Loss_Validation:  [[ 1420.61120902]]\n",
      "Loop  7424 :    Loss_Train:  [[ 4822.51700313]]    Loss_Validation:  [[ 1420.61135422]]\n",
      "Loop  7425 :    Loss_Train:  [[ 4822.51699948]]    Loss_Validation:  [[ 1420.61149932]]\n",
      "Loop  7426 :    Loss_Train:  [[ 4822.51699582]]    Loss_Validation:  [[ 1420.61164432]]\n",
      "Loop  7427 :    Loss_Train:  [[ 4822.51699218]]    Loss_Validation:  [[ 1420.61178922]]\n",
      "Loop  7428 :    Loss_Train:  [[ 4822.51698854]]    Loss_Validation:  [[ 1420.61193401]]\n",
      "Loop  7429 :    Loss_Train:  [[ 4822.5169849]]    Loss_Validation:  [[ 1420.6120787]]\n",
      "Loop  7430 :    Loss_Train:  [[ 4822.51698127]]    Loss_Validation:  [[ 1420.61222328]]\n",
      "Loop  7431 :    Loss_Train:  [[ 4822.51697765]]    Loss_Validation:  [[ 1420.61236776]]\n",
      "Loop  7432 :    Loss_Train:  [[ 4822.51697403]]    Loss_Validation:  [[ 1420.61251214]]\n",
      "Loop  7433 :    Loss_Train:  [[ 4822.51697042]]    Loss_Validation:  [[ 1420.61265642]]\n",
      "Loop  7434 :    Loss_Train:  [[ 4822.51696682]]    Loss_Validation:  [[ 1420.6128006]]\n",
      "Loop  7435 :    Loss_Train:  [[ 4822.51696321]]    Loss_Validation:  [[ 1420.61294467]]\n",
      "Loop  7436 :    Loss_Train:  [[ 4822.51695962]]    Loss_Validation:  [[ 1420.61308864]]\n",
      "Loop  7437 :    Loss_Train:  [[ 4822.51695603]]    Loss_Validation:  [[ 1420.6132325]]\n",
      "Loop  7438 :    Loss_Train:  [[ 4822.51695245]]    Loss_Validation:  [[ 1420.61337627]]\n",
      "Loop  7439 :    Loss_Train:  [[ 4822.51694887]]    Loss_Validation:  [[ 1420.61351993]]\n",
      "Loop  7440 :    Loss_Train:  [[ 4822.5169453]]    Loss_Validation:  [[ 1420.61366349]]\n",
      "Loop  7441 :    Loss_Train:  [[ 4822.51694173]]    Loss_Validation:  [[ 1420.61380695]]\n",
      "Loop  7442 :    Loss_Train:  [[ 4822.51693817]]    Loss_Validation:  [[ 1420.6139503]]\n",
      "Loop  7443 :    Loss_Train:  [[ 4822.51693461]]    Loss_Validation:  [[ 1420.61409356]]\n",
      "Loop  7444 :    Loss_Train:  [[ 4822.51693106]]    Loss_Validation:  [[ 1420.61423671]]\n",
      "Loop  7445 :    Loss_Train:  [[ 4822.51692752]]    Loss_Validation:  [[ 1420.61437976]]\n",
      "Loop  7446 :    Loss_Train:  [[ 4822.51692398]]    Loss_Validation:  [[ 1420.61452271]]\n",
      "Loop  7447 :    Loss_Train:  [[ 4822.51692045]]    Loss_Validation:  [[ 1420.61466556]]\n",
      "Loop  7448 :    Loss_Train:  [[ 4822.51691692]]    Loss_Validation:  [[ 1420.6148083]]\n",
      "Loop  7449 :    Loss_Train:  [[ 4822.5169134]]    Loss_Validation:  [[ 1420.61495094]]\n",
      "Loop  7450 :    Loss_Train:  [[ 4822.51690988]]    Loss_Validation:  [[ 1420.61509349]]\n",
      "Loop  7451 :    Loss_Train:  [[ 4822.51690637]]    Loss_Validation:  [[ 1420.61523593]]\n",
      "Loop  7452 :    Loss_Train:  [[ 4822.51690287]]    Loss_Validation:  [[ 1420.61537826]]\n",
      "Loop  7453 :    Loss_Train:  [[ 4822.51689937]]    Loss_Validation:  [[ 1420.6155205]]\n",
      "Loop  7454 :    Loss_Train:  [[ 4822.51689587]]    Loss_Validation:  [[ 1420.61566264]]\n",
      "Loop  7455 :    Loss_Train:  [[ 4822.51689238]]    Loss_Validation:  [[ 1420.61580467]]\n",
      "Loop  7456 :    Loss_Train:  [[ 4822.5168889]]    Loss_Validation:  [[ 1420.61594661]]\n",
      "Loop  7457 :    Loss_Train:  [[ 4822.51688542]]    Loss_Validation:  [[ 1420.61608844]]\n",
      "Loop  7458 :    Loss_Train:  [[ 4822.51688195]]    Loss_Validation:  [[ 1420.61623017]]\n",
      "Loop  7459 :    Loss_Train:  [[ 4822.51687848]]    Loss_Validation:  [[ 1420.61637181]]\n",
      "Loop  7460 :    Loss_Train:  [[ 4822.51687502]]    Loss_Validation:  [[ 1420.61651334]]\n",
      "Loop  7461 :    Loss_Train:  [[ 4822.51687156]]    Loss_Validation:  [[ 1420.61665477]]\n",
      "Loop  7462 :    Loss_Train:  [[ 4822.51686811]]    Loss_Validation:  [[ 1420.61679609]]\n",
      "Loop  7463 :    Loss_Train:  [[ 4822.51686467]]    Loss_Validation:  [[ 1420.61693732]]\n",
      "Loop  7464 :    Loss_Train:  [[ 4822.51686123]]    Loss_Validation:  [[ 1420.61707845]]\n",
      "Loop  7465 :    Loss_Train:  [[ 4822.51685779]]    Loss_Validation:  [[ 1420.61721948]]\n",
      "Loop  7466 :    Loss_Train:  [[ 4822.51685436]]    Loss_Validation:  [[ 1420.61736041]]\n",
      "Loop  7467 :    Loss_Train:  [[ 4822.51685094]]    Loss_Validation:  [[ 1420.61750123]]\n",
      "Loop  7468 :    Loss_Train:  [[ 4822.51684752]]    Loss_Validation:  [[ 1420.61764196]]\n",
      "Loop  7469 :    Loss_Train:  [[ 4822.51684411]]    Loss_Validation:  [[ 1420.61778259]]\n",
      "Loop  7470 :    Loss_Train:  [[ 4822.5168407]]    Loss_Validation:  [[ 1420.61792311]]\n",
      "Loop  7471 :    Loss_Train:  [[ 4822.5168373]]    Loss_Validation:  [[ 1420.61806354]]\n",
      "Loop  7472 :    Loss_Train:  [[ 4822.5168339]]    Loss_Validation:  [[ 1420.61820387]]\n",
      "Loop  7473 :    Loss_Train:  [[ 4822.51683051]]    Loss_Validation:  [[ 1420.61834409]]\n",
      "Loop  7474 :    Loss_Train:  [[ 4822.51682713]]    Loss_Validation:  [[ 1420.61848422]]\n",
      "Loop  7475 :    Loss_Train:  [[ 4822.51682374]]    Loss_Validation:  [[ 1420.61862425]]\n",
      "Loop  7476 :    Loss_Train:  [[ 4822.51682037]]    Loss_Validation:  [[ 1420.61876418]]\n",
      "Loop  7477 :    Loss_Train:  [[ 4822.516817]]    Loss_Validation:  [[ 1420.618904]]\n",
      "Loop  7478 :    Loss_Train:  [[ 4822.51681363]]    Loss_Validation:  [[ 1420.61904373]]\n",
      "Loop  7479 :    Loss_Train:  [[ 4822.51681027]]    Loss_Validation:  [[ 1420.61918336]]\n",
      "Loop  7480 :    Loss_Train:  [[ 4822.51680692]]    Loss_Validation:  [[ 1420.61932289]]\n",
      "Loop  7481 :    Loss_Train:  [[ 4822.51680357]]    Loss_Validation:  [[ 1420.61946232]]\n",
      "Loop  7482 :    Loss_Train:  [[ 4822.51680023]]    Loss_Validation:  [[ 1420.61960165]]\n",
      "Loop  7483 :    Loss_Train:  [[ 4822.51679689]]    Loss_Validation:  [[ 1420.61974088]]\n",
      "Loop  7484 :    Loss_Train:  [[ 4822.51679356]]    Loss_Validation:  [[ 1420.61988002]]\n",
      "Loop  7485 :    Loss_Train:  [[ 4822.51679023]]    Loss_Validation:  [[ 1420.62001905]]\n",
      "Loop  7486 :    Loss_Train:  [[ 4822.5167869]]    Loss_Validation:  [[ 1420.62015799]]\n",
      "Loop  7487 :    Loss_Train:  [[ 4822.51678359]]    Loss_Validation:  [[ 1420.62029682]]\n",
      "Loop  7488 :    Loss_Train:  [[ 4822.51678027]]    Loss_Validation:  [[ 1420.62043556]]\n",
      "Loop  7489 :    Loss_Train:  [[ 4822.51677697]]    Loss_Validation:  [[ 1420.6205742]]\n",
      "Loop  7490 :    Loss_Train:  [[ 4822.51677367]]    Loss_Validation:  [[ 1420.62071274]]\n",
      "Loop  7491 :    Loss_Train:  [[ 4822.51677037]]    Loss_Validation:  [[ 1420.62085118]]\n",
      "Loop  7492 :    Loss_Train:  [[ 4822.51676708]]    Loss_Validation:  [[ 1420.62098952]]\n",
      "Loop  7493 :    Loss_Train:  [[ 4822.51676379]]    Loss_Validation:  [[ 1420.62112776]]\n",
      "Loop  7494 :    Loss_Train:  [[ 4822.51676051]]    Loss_Validation:  [[ 1420.62126591]]\n",
      "Loop  7495 :    Loss_Train:  [[ 4822.51675723]]    Loss_Validation:  [[ 1420.62140396]]\n",
      "Loop  7496 :    Loss_Train:  [[ 4822.51675396]]    Loss_Validation:  [[ 1420.6215419]]\n",
      "Loop  7497 :    Loss_Train:  [[ 4822.5167507]]    Loss_Validation:  [[ 1420.62167976]]\n",
      "Loop  7498 :    Loss_Train:  [[ 4822.51674744]]    Loss_Validation:  [[ 1420.62181751]]\n",
      "Loop  7499 :    Loss_Train:  [[ 4822.51674418]]    Loss_Validation:  [[ 1420.62195516]]\n",
      "Loop  7500 :    Loss_Train:  [[ 4822.51674093]]    Loss_Validation:  [[ 1420.62209272]]\n",
      "Loop  7501 :    Loss_Train:  [[ 4822.51673768]]    Loss_Validation:  [[ 1420.62223018]]\n",
      "Loop  7502 :    Loss_Train:  [[ 4822.51673444]]    Loss_Validation:  [[ 1420.62236754]]\n",
      "Loop  7503 :    Loss_Train:  [[ 4822.51673121]]    Loss_Validation:  [[ 1420.6225048]]\n",
      "Loop  7504 :    Loss_Train:  [[ 4822.51672798]]    Loss_Validation:  [[ 1420.62264197]]\n",
      "Loop  7505 :    Loss_Train:  [[ 4822.51672475]]    Loss_Validation:  [[ 1420.62277903]]\n",
      "Loop  7506 :    Loss_Train:  [[ 4822.51672153]]    Loss_Validation:  [[ 1420.622916]]\n",
      "Loop  7507 :    Loss_Train:  [[ 4822.51671832]]    Loss_Validation:  [[ 1420.62305288]]\n",
      "Loop  7508 :    Loss_Train:  [[ 4822.51671511]]    Loss_Validation:  [[ 1420.62318965]]\n",
      "Loop  7509 :    Loss_Train:  [[ 4822.51671191]]    Loss_Validation:  [[ 1420.62332633]]\n",
      "Loop  7510 :    Loss_Train:  [[ 4822.51670871]]    Loss_Validation:  [[ 1420.62346291]]\n",
      "Loop  7511 :    Loss_Train:  [[ 4822.51670551]]    Loss_Validation:  [[ 1420.62359939]]\n",
      "Loop  7512 :    Loss_Train:  [[ 4822.51670232]]    Loss_Validation:  [[ 1420.62373578]]\n",
      "Loop  7513 :    Loss_Train:  [[ 4822.51669914]]    Loss_Validation:  [[ 1420.62387207]]\n",
      "Loop  7514 :    Loss_Train:  [[ 4822.51669596]]    Loss_Validation:  [[ 1420.62400826]]\n",
      "Loop  7515 :    Loss_Train:  [[ 4822.51669278]]    Loss_Validation:  [[ 1420.62414435]]\n",
      "Loop  7516 :    Loss_Train:  [[ 4822.51668961]]    Loss_Validation:  [[ 1420.62428035]]\n",
      "Loop  7517 :    Loss_Train:  [[ 4822.51668645]]    Loss_Validation:  [[ 1420.62441625]]\n",
      "Loop  7518 :    Loss_Train:  [[ 4822.51668329]]    Loss_Validation:  [[ 1420.62455206]]\n",
      "Loop  7519 :    Loss_Train:  [[ 4822.51668013]]    Loss_Validation:  [[ 1420.62468776]]\n",
      "Loop  7520 :    Loss_Train:  [[ 4822.51667698]]    Loss_Validation:  [[ 1420.62482338]]\n",
      "Loop  7521 :    Loss_Train:  [[ 4822.51667384]]    Loss_Validation:  [[ 1420.62495889]]\n",
      "Loop  7522 :    Loss_Train:  [[ 4822.5166707]]    Loss_Validation:  [[ 1420.62509431]]\n",
      "Loop  7523 :    Loss_Train:  [[ 4822.51666757]]    Loss_Validation:  [[ 1420.62522963]]\n",
      "Loop  7524 :    Loss_Train:  [[ 4822.51666444]]    Loss_Validation:  [[ 1420.62536486]]\n",
      "Loop  7525 :    Loss_Train:  [[ 4822.51666131]]    Loss_Validation:  [[ 1420.62549998]]\n",
      "Loop  7526 :    Loss_Train:  [[ 4822.51665819]]    Loss_Validation:  [[ 1420.62563502]]\n",
      "Loop  7527 :    Loss_Train:  [[ 4822.51665507]]    Loss_Validation:  [[ 1420.62576995]]\n",
      "Loop  7528 :    Loss_Train:  [[ 4822.51665196]]    Loss_Validation:  [[ 1420.62590479]]\n",
      "Loop  7529 :    Loss_Train:  [[ 4822.51664886]]    Loss_Validation:  [[ 1420.62603954]]\n",
      "Loop  7530 :    Loss_Train:  [[ 4822.51664576]]    Loss_Validation:  [[ 1420.62617419]]\n",
      "Loop  7531 :    Loss_Train:  [[ 4822.51664266]]    Loss_Validation:  [[ 1420.62630874]]\n",
      "Loop  7532 :    Loss_Train:  [[ 4822.51663957]]    Loss_Validation:  [[ 1420.6264432]]\n",
      "Loop  7533 :    Loss_Train:  [[ 4822.51663649]]    Loss_Validation:  [[ 1420.62657756]]\n",
      "Loop  7534 :    Loss_Train:  [[ 4822.51663341]]    Loss_Validation:  [[ 1420.62671182]]\n",
      "Loop  7535 :    Loss_Train:  [[ 4822.51663033]]    Loss_Validation:  [[ 1420.62684599]]\n",
      "Loop  7536 :    Loss_Train:  [[ 4822.51662726]]    Loss_Validation:  [[ 1420.62698007]]\n",
      "Loop  7537 :    Loss_Train:  [[ 4822.51662419]]    Loss_Validation:  [[ 1420.62711405]]\n",
      "Loop  7538 :    Loss_Train:  [[ 4822.51662113]]    Loss_Validation:  [[ 1420.62724793]]\n",
      "Loop  7539 :    Loss_Train:  [[ 4822.51661807]]    Loss_Validation:  [[ 1420.62738172]]\n",
      "Loop  7540 :    Loss_Train:  [[ 4822.51661502]]    Loss_Validation:  [[ 1420.62751541]]\n",
      "Loop  7541 :    Loss_Train:  [[ 4822.51661197]]    Loss_Validation:  [[ 1420.62764901]]\n",
      "Loop  7542 :    Loss_Train:  [[ 4822.51660893]]    Loss_Validation:  [[ 1420.62778251]]\n",
      "Loop  7543 :    Loss_Train:  [[ 4822.51660589]]    Loss_Validation:  [[ 1420.62791592]]\n",
      "Loop  7544 :    Loss_Train:  [[ 4822.51660286]]    Loss_Validation:  [[ 1420.62804923]]\n",
      "Loop  7545 :    Loss_Train:  [[ 4822.51659983]]    Loss_Validation:  [[ 1420.62818245]]\n",
      "Loop  7546 :    Loss_Train:  [[ 4822.51659681]]    Loss_Validation:  [[ 1420.62831557]]\n",
      "Loop  7547 :    Loss_Train:  [[ 4822.51659379]]    Loss_Validation:  [[ 1420.6284486]]\n",
      "Loop  7548 :    Loss_Train:  [[ 4822.51659078]]    Loss_Validation:  [[ 1420.62858153]]\n",
      "Loop  7549 :    Loss_Train:  [[ 4822.51658777]]    Loss_Validation:  [[ 1420.62871437]]\n",
      "Loop  7550 :    Loss_Train:  [[ 4822.51658476]]    Loss_Validation:  [[ 1420.62884711]]\n",
      "Loop  7551 :    Loss_Train:  [[ 4822.51658176]]    Loss_Validation:  [[ 1420.62897976]]\n",
      "Loop  7552 :    Loss_Train:  [[ 4822.51657877]]    Loss_Validation:  [[ 1420.62911232]]\n",
      "Loop  7553 :    Loss_Train:  [[ 4822.51657578]]    Loss_Validation:  [[ 1420.62924478]]\n",
      "Loop  7554 :    Loss_Train:  [[ 4822.51657279]]    Loss_Validation:  [[ 1420.62937714]]\n",
      "Loop  7555 :    Loss_Train:  [[ 4822.51656981]]    Loss_Validation:  [[ 1420.62950941]]\n",
      "Loop  7556 :    Loss_Train:  [[ 4822.51656683]]    Loss_Validation:  [[ 1420.62964159]]\n",
      "Loop  7557 :    Loss_Train:  [[ 4822.51656386]]    Loss_Validation:  [[ 1420.62977367]]\n",
      "Loop  7558 :    Loss_Train:  [[ 4822.51656089]]    Loss_Validation:  [[ 1420.62990566]]\n",
      "Loop  7559 :    Loss_Train:  [[ 4822.51655793]]    Loss_Validation:  [[ 1420.63003756]]\n",
      "Loop  7560 :    Loss_Train:  [[ 4822.51655497]]    Loss_Validation:  [[ 1420.63016936]]\n",
      "Loop  7561 :    Loss_Train:  [[ 4822.51655202]]    Loss_Validation:  [[ 1420.63030107]]\n",
      "Loop  7562 :    Loss_Train:  [[ 4822.51654907]]    Loss_Validation:  [[ 1420.63043268]]\n",
      "Loop  7563 :    Loss_Train:  [[ 4822.51654613]]    Loss_Validation:  [[ 1420.6305642]]\n",
      "Loop  7564 :    Loss_Train:  [[ 4822.51654319]]    Loss_Validation:  [[ 1420.63069563]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  7565 :    Loss_Train:  [[ 4822.51654026]]    Loss_Validation:  [[ 1420.63082696]]\n",
      "Loop  7566 :    Loss_Train:  [[ 4822.51653733]]    Loss_Validation:  [[ 1420.6309582]]\n",
      "Loop  7567 :    Loss_Train:  [[ 4822.5165344]]    Loss_Validation:  [[ 1420.63108934]]\n",
      "Loop  7568 :    Loss_Train:  [[ 4822.51653148]]    Loss_Validation:  [[ 1420.6312204]]\n",
      "Loop  7569 :    Loss_Train:  [[ 4822.51652856]]    Loss_Validation:  [[ 1420.63135136]]\n",
      "Loop  7570 :    Loss_Train:  [[ 4822.51652565]]    Loss_Validation:  [[ 1420.63148222]]\n",
      "Loop  7571 :    Loss_Train:  [[ 4822.51652275]]    Loss_Validation:  [[ 1420.63161299]]\n",
      "Loop  7572 :    Loss_Train:  [[ 4822.51651984]]    Loss_Validation:  [[ 1420.63174367]]\n",
      "Loop  7573 :    Loss_Train:  [[ 4822.51651695]]    Loss_Validation:  [[ 1420.63187426]]\n",
      "Loop  7574 :    Loss_Train:  [[ 4822.51651405]]    Loss_Validation:  [[ 1420.63200475]]\n",
      "Loop  7575 :    Loss_Train:  [[ 4822.51651116]]    Loss_Validation:  [[ 1420.63213515]]\n",
      "Loop  7576 :    Loss_Train:  [[ 4822.51650828]]    Loss_Validation:  [[ 1420.63226546]]\n",
      "Loop  7577 :    Loss_Train:  [[ 4822.5165054]]    Loss_Validation:  [[ 1420.63239567]]\n",
      "Loop  7578 :    Loss_Train:  [[ 4822.51650253]]    Loss_Validation:  [[ 1420.63252579]]\n",
      "Loop  7579 :    Loss_Train:  [[ 4822.51649965]]    Loss_Validation:  [[ 1420.63265582]]\n",
      "Loop  7580 :    Loss_Train:  [[ 4822.51649679]]    Loss_Validation:  [[ 1420.63278576]]\n",
      "Loop  7581 :    Loss_Train:  [[ 4822.51649393]]    Loss_Validation:  [[ 1420.6329156]]\n",
      "Loop  7582 :    Loss_Train:  [[ 4822.51649107]]    Loss_Validation:  [[ 1420.63304536]]\n",
      "Loop  7583 :    Loss_Train:  [[ 4822.51648822]]    Loss_Validation:  [[ 1420.63317501]]\n",
      "Loop  7584 :    Loss_Train:  [[ 4822.51648537]]    Loss_Validation:  [[ 1420.63330458]]\n",
      "Loop  7585 :    Loss_Train:  [[ 4822.51648253]]    Loss_Validation:  [[ 1420.63343405]]\n",
      "Loop  7586 :    Loss_Train:  [[ 4822.51647969]]    Loss_Validation:  [[ 1420.63356344]]\n",
      "Loop  7587 :    Loss_Train:  [[ 4822.51647685]]    Loss_Validation:  [[ 1420.63369273]]\n",
      "Loop  7588 :    Loss_Train:  [[ 4822.51647402]]    Loss_Validation:  [[ 1420.63382192]]\n",
      "Loop  7589 :    Loss_Train:  [[ 4822.5164712]]    Loss_Validation:  [[ 1420.63395103]]\n",
      "Loop  7590 :    Loss_Train:  [[ 4822.51646837]]    Loss_Validation:  [[ 1420.63408004]]\n",
      "Loop  7591 :    Loss_Train:  [[ 4822.51646556]]    Loss_Validation:  [[ 1420.63420897]]\n",
      "Loop  7592 :    Loss_Train:  [[ 4822.51646275]]    Loss_Validation:  [[ 1420.6343378]]\n",
      "Loop  7593 :    Loss_Train:  [[ 4822.51645994]]    Loss_Validation:  [[ 1420.63446653]]\n",
      "Loop  7594 :    Loss_Train:  [[ 4822.51645713]]    Loss_Validation:  [[ 1420.63459518]]\n",
      "Loop  7595 :    Loss_Train:  [[ 4822.51645433]]    Loss_Validation:  [[ 1420.63472373]]\n",
      "Loop  7596 :    Loss_Train:  [[ 4822.51645154]]    Loss_Validation:  [[ 1420.6348522]]\n",
      "Loop  7597 :    Loss_Train:  [[ 4822.51644875]]    Loss_Validation:  [[ 1420.63498057]]\n",
      "Loop  7598 :    Loss_Train:  [[ 4822.51644596]]    Loss_Validation:  [[ 1420.63510885]]\n",
      "Loop  7599 :    Loss_Train:  [[ 4822.51644318]]    Loss_Validation:  [[ 1420.63523704]]\n",
      "Loop  7600 :    Loss_Train:  [[ 4822.5164404]]    Loss_Validation:  [[ 1420.63536514]]\n",
      "Loop  7601 :    Loss_Train:  [[ 4822.51643763]]    Loss_Validation:  [[ 1420.63549314]]\n",
      "Loop  7602 :    Loss_Train:  [[ 4822.51643486]]    Loss_Validation:  [[ 1420.63562106]]\n",
      "Loop  7603 :    Loss_Train:  [[ 4822.5164321]]    Loss_Validation:  [[ 1420.63574888]]\n",
      "Loop  7604 :    Loss_Train:  [[ 4822.51642934]]    Loss_Validation:  [[ 1420.63587661]]\n",
      "Loop  7605 :    Loss_Train:  [[ 4822.51642658]]    Loss_Validation:  [[ 1420.63600426]]\n",
      "Loop  7606 :    Loss_Train:  [[ 4822.51642383]]    Loss_Validation:  [[ 1420.63613181]]\n",
      "Loop  7607 :    Loss_Train:  [[ 4822.51642108]]    Loss_Validation:  [[ 1420.63625927]]\n",
      "Loop  7608 :    Loss_Train:  [[ 4822.51641834]]    Loss_Validation:  [[ 1420.63638664]]\n",
      "Loop  7609 :    Loss_Train:  [[ 4822.5164156]]    Loss_Validation:  [[ 1420.63651391]]\n",
      "Loop  7610 :    Loss_Train:  [[ 4822.51641287]]    Loss_Validation:  [[ 1420.6366411]]\n",
      "Loop  7611 :    Loss_Train:  [[ 4822.51641014]]    Loss_Validation:  [[ 1420.6367682]]\n",
      "Loop  7612 :    Loss_Train:  [[ 4822.51640741]]    Loss_Validation:  [[ 1420.6368952]]\n",
      "Loop  7613 :    Loss_Train:  [[ 4822.51640469]]    Loss_Validation:  [[ 1420.63702212]]\n",
      "Loop  7614 :    Loss_Train:  [[ 4822.51640198]]    Loss_Validation:  [[ 1420.63714895]]\n",
      "Loop  7615 :    Loss_Train:  [[ 4822.51639926]]    Loss_Validation:  [[ 1420.63727568]]\n",
      "Loop  7616 :    Loss_Train:  [[ 4822.51639656]]    Loss_Validation:  [[ 1420.63740233]]\n",
      "Loop  7617 :    Loss_Train:  [[ 4822.51639385]]    Loss_Validation:  [[ 1420.63752888]]\n",
      "Loop  7618 :    Loss_Train:  [[ 4822.51639115]]    Loss_Validation:  [[ 1420.63765535]]\n",
      "Loop  7619 :    Loss_Train:  [[ 4822.51638846]]    Loss_Validation:  [[ 1420.63778172]]\n",
      "Loop  7620 :    Loss_Train:  [[ 4822.51638577]]    Loss_Validation:  [[ 1420.637908]]\n",
      "Loop  7621 :    Loss_Train:  [[ 4822.51638308]]    Loss_Validation:  [[ 1420.6380342]]\n",
      "Loop  7622 :    Loss_Train:  [[ 4822.5163804]]    Loss_Validation:  [[ 1420.6381603]]\n",
      "Loop  7623 :    Loss_Train:  [[ 4822.51637772]]    Loss_Validation:  [[ 1420.63828632]]\n",
      "Loop  7624 :    Loss_Train:  [[ 4822.51637504]]    Loss_Validation:  [[ 1420.63841224]]\n",
      "Loop  7625 :    Loss_Train:  [[ 4822.51637237]]    Loss_Validation:  [[ 1420.63853808]]\n",
      "Loop  7626 :    Loss_Train:  [[ 4822.51636971]]    Loss_Validation:  [[ 1420.63866382]]\n",
      "Loop  7627 :    Loss_Train:  [[ 4822.51636704]]    Loss_Validation:  [[ 1420.63878948]]\n",
      "Loop  7628 :    Loss_Train:  [[ 4822.51636439]]    Loss_Validation:  [[ 1420.63891504]]\n",
      "Loop  7629 :    Loss_Train:  [[ 4822.51636173]]    Loss_Validation:  [[ 1420.63904052]]\n",
      "Loop  7630 :    Loss_Train:  [[ 4822.51635908]]    Loss_Validation:  [[ 1420.63916591]]\n",
      "Loop  7631 :    Loss_Train:  [[ 4822.51635644]]    Loss_Validation:  [[ 1420.63929121]]\n",
      "Loop  7632 :    Loss_Train:  [[ 4822.5163538]]    Loss_Validation:  [[ 1420.63941642]]\n",
      "Loop  7633 :    Loss_Train:  [[ 4822.51635116]]    Loss_Validation:  [[ 1420.63954154]]\n",
      "Loop  7634 :    Loss_Train:  [[ 4822.51634853]]    Loss_Validation:  [[ 1420.63966657]]\n",
      "Loop  7635 :    Loss_Train:  [[ 4822.5163459]]    Loss_Validation:  [[ 1420.63979151]]\n",
      "Loop  7636 :    Loss_Train:  [[ 4822.51634327]]    Loss_Validation:  [[ 1420.63991636]]\n",
      "Loop  7637 :    Loss_Train:  [[ 4822.51634065]]    Loss_Validation:  [[ 1420.64004112]]\n",
      "Loop  7638 :    Loss_Train:  [[ 4822.51633804]]    Loss_Validation:  [[ 1420.6401658]]\n",
      "Loop  7639 :    Loss_Train:  [[ 4822.51633543]]    Loss_Validation:  [[ 1420.64029038]]\n",
      "Loop  7640 :    Loss_Train:  [[ 4822.51633282]]    Loss_Validation:  [[ 1420.64041488]]\n",
      "Loop  7641 :    Loss_Train:  [[ 4822.51633021]]    Loss_Validation:  [[ 1420.64053929]]\n",
      "Loop  7642 :    Loss_Train:  [[ 4822.51632761]]    Loss_Validation:  [[ 1420.6406636]]\n",
      "Loop  7643 :    Loss_Train:  [[ 4822.51632502]]    Loss_Validation:  [[ 1420.64078784]]\n",
      "Loop  7644 :    Loss_Train:  [[ 4822.51632243]]    Loss_Validation:  [[ 1420.64091198]]\n",
      "Loop  7645 :    Loss_Train:  [[ 4822.51631984]]    Loss_Validation:  [[ 1420.64103603]]\n",
      "Loop  7646 :    Loss_Train:  [[ 4822.51631726]]    Loss_Validation:  [[ 1420.64116]]\n",
      "Loop  7647 :    Loss_Train:  [[ 4822.51631468]]    Loss_Validation:  [[ 1420.64128387]]\n",
      "Loop  7648 :    Loss_Train:  [[ 4822.5163121]]    Loss_Validation:  [[ 1420.64140766]]\n",
      "Loop  7649 :    Loss_Train:  [[ 4822.51630953]]    Loss_Validation:  [[ 1420.64153136]]\n",
      "Loop  7650 :    Loss_Train:  [[ 4822.51630696]]    Loss_Validation:  [[ 1420.64165497]]\n",
      "Loop  7651 :    Loss_Train:  [[ 4822.5163044]]    Loss_Validation:  [[ 1420.6417785]]\n",
      "Loop  7652 :    Loss_Train:  [[ 4822.51630184]]    Loss_Validation:  [[ 1420.64190193]]\n",
      "Loop  7653 :    Loss_Train:  [[ 4822.51629928]]    Loss_Validation:  [[ 1420.64202528]]\n",
      "Loop  7654 :    Loss_Train:  [[ 4822.51629673]]    Loss_Validation:  [[ 1420.64214854]]\n",
      "Loop  7655 :    Loss_Train:  [[ 4822.51629419]]    Loss_Validation:  [[ 1420.64227171]]\n",
      "Loop  7656 :    Loss_Train:  [[ 4822.51629164]]    Loss_Validation:  [[ 1420.6423948]]\n",
      "Loop  7657 :    Loss_Train:  [[ 4822.5162891]]    Loss_Validation:  [[ 1420.6425178]]\n",
      "Loop  7658 :    Loss_Train:  [[ 4822.51628657]]    Loss_Validation:  [[ 1420.6426407]]\n",
      "Loop  7659 :    Loss_Train:  [[ 4822.51628404]]    Loss_Validation:  [[ 1420.64276353]]\n",
      "Loop  7660 :    Loss_Train:  [[ 4822.51628151]]    Loss_Validation:  [[ 1420.64288626]]\n",
      "Loop  7661 :    Loss_Train:  [[ 4822.51627899]]    Loss_Validation:  [[ 1420.64300891]]\n",
      "Loop  7662 :    Loss_Train:  [[ 4822.51627647]]    Loss_Validation:  [[ 1420.64313146]]\n",
      "Loop  7663 :    Loss_Train:  [[ 4822.51627395]]    Loss_Validation:  [[ 1420.64325394]]\n",
      "Loop  7664 :    Loss_Train:  [[ 4822.51627144]]    Loss_Validation:  [[ 1420.64337632]]\n",
      "Loop  7665 :    Loss_Train:  [[ 4822.51626893]]    Loss_Validation:  [[ 1420.64349862]]\n",
      "Loop  7666 :    Loss_Train:  [[ 4822.51626643]]    Loss_Validation:  [[ 1420.64362083]]\n",
      "Loop  7667 :    Loss_Train:  [[ 4822.51626393]]    Loss_Validation:  [[ 1420.64374295]]\n",
      "Loop  7668 :    Loss_Train:  [[ 4822.51626143]]    Loss_Validation:  [[ 1420.64386499]]\n",
      "Loop  7669 :    Loss_Train:  [[ 4822.51625894]]    Loss_Validation:  [[ 1420.64398693]]\n",
      "Loop  7670 :    Loss_Train:  [[ 4822.51625645]]    Loss_Validation:  [[ 1420.6441088]]\n",
      "Loop  7671 :    Loss_Train:  [[ 4822.51625397]]    Loss_Validation:  [[ 1420.64423057]]\n",
      "Loop  7672 :    Loss_Train:  [[ 4822.51625149]]    Loss_Validation:  [[ 1420.64435226]]\n",
      "Loop  7673 :    Loss_Train:  [[ 4822.51624901]]    Loss_Validation:  [[ 1420.64447386]]\n",
      "Loop  7674 :    Loss_Train:  [[ 4822.51624654]]    Loss_Validation:  [[ 1420.64459538]]\n",
      "Loop  7675 :    Loss_Train:  [[ 4822.51624407]]    Loss_Validation:  [[ 1420.6447168]]\n",
      "Loop  7676 :    Loss_Train:  [[ 4822.51624161]]    Loss_Validation:  [[ 1420.64483815]]\n",
      "Loop  7677 :    Loss_Train:  [[ 4822.51623915]]    Loss_Validation:  [[ 1420.6449594]]\n",
      "Loop  7678 :    Loss_Train:  [[ 4822.51623669]]    Loss_Validation:  [[ 1420.64508057]]\n",
      "Loop  7679 :    Loss_Train:  [[ 4822.51623424]]    Loss_Validation:  [[ 1420.64520165]]\n",
      "Loop  7680 :    Loss_Train:  [[ 4822.51623179]]    Loss_Validation:  [[ 1420.64532265]]\n",
      "Loop  7681 :    Loss_Train:  [[ 4822.51622934]]    Loss_Validation:  [[ 1420.64544356]]\n",
      "Loop  7682 :    Loss_Train:  [[ 4822.5162269]]    Loss_Validation:  [[ 1420.64556438]]\n",
      "Loop  7683 :    Loss_Train:  [[ 4822.51622446]]    Loss_Validation:  [[ 1420.64568512]]\n",
      "Loop  7684 :    Loss_Train:  [[ 4822.51622203]]    Loss_Validation:  [[ 1420.64580577]]\n",
      "Loop  7685 :    Loss_Train:  [[ 4822.5162196]]    Loss_Validation:  [[ 1420.64592633]]\n",
      "Loop  7686 :    Loss_Train:  [[ 4822.51621717]]    Loss_Validation:  [[ 1420.64604681]]\n",
      "Loop  7687 :    Loss_Train:  [[ 4822.51621475]]    Loss_Validation:  [[ 1420.64616721]]\n",
      "Loop  7688 :    Loss_Train:  [[ 4822.51621233]]    Loss_Validation:  [[ 1420.64628751]]\n",
      "Loop  7689 :    Loss_Train:  [[ 4822.51620992]]    Loss_Validation:  [[ 1420.64640773]]\n",
      "Loop  7690 :    Loss_Train:  [[ 4822.51620751]]    Loss_Validation:  [[ 1420.64652787]]\n",
      "Loop  7691 :    Loss_Train:  [[ 4822.5162051]]    Loss_Validation:  [[ 1420.64664792]]\n",
      "Loop  7692 :    Loss_Train:  [[ 4822.5162027]]    Loss_Validation:  [[ 1420.64676789]]\n",
      "Loop  7693 :    Loss_Train:  [[ 4822.5162003]]    Loss_Validation:  [[ 1420.64688776]]\n",
      "Loop  7694 :    Loss_Train:  [[ 4822.5161979]]    Loss_Validation:  [[ 1420.64700756]]\n",
      "Loop  7695 :    Loss_Train:  [[ 4822.51619551]]    Loss_Validation:  [[ 1420.64712727]]\n",
      "Loop  7696 :    Loss_Train:  [[ 4822.51619312]]    Loss_Validation:  [[ 1420.64724689]]\n",
      "Loop  7697 :    Loss_Train:  [[ 4822.51619074]]    Loss_Validation:  [[ 1420.64736643]]\n",
      "Loop  7698 :    Loss_Train:  [[ 4822.51618836]]    Loss_Validation:  [[ 1420.64748588]]\n",
      "Loop  7699 :    Loss_Train:  [[ 4822.51618598]]    Loss_Validation:  [[ 1420.64760525]]\n",
      "Loop  7700 :    Loss_Train:  [[ 4822.51618361]]    Loss_Validation:  [[ 1420.64772453]]\n",
      "Loop  7701 :    Loss_Train:  [[ 4822.51618124]]    Loss_Validation:  [[ 1420.64784373]]\n",
      "Loop  7702 :    Loss_Train:  [[ 4822.51617887]]    Loss_Validation:  [[ 1420.64796284]]\n",
      "Loop  7703 :    Loss_Train:  [[ 4822.51617651]]    Loss_Validation:  [[ 1420.64808187]]\n",
      "Loop  7704 :    Loss_Train:  [[ 4822.51617415]]    Loss_Validation:  [[ 1420.64820081]]\n",
      "Loop  7705 :    Loss_Train:  [[ 4822.51617179]]    Loss_Validation:  [[ 1420.64831967]]\n",
      "Loop  7706 :    Loss_Train:  [[ 4822.51616944]]    Loss_Validation:  [[ 1420.64843844]]\n",
      "Loop  7707 :    Loss_Train:  [[ 4822.5161671]]    Loss_Validation:  [[ 1420.64855713]]\n",
      "Loop  7708 :    Loss_Train:  [[ 4822.51616475]]    Loss_Validation:  [[ 1420.64867573]]\n",
      "Loop  7709 :    Loss_Train:  [[ 4822.51616241]]    Loss_Validation:  [[ 1420.64879425]]\n",
      "Loop  7710 :    Loss_Train:  [[ 4822.51616008]]    Loss_Validation:  [[ 1420.64891268]]\n",
      "Loop  7711 :    Loss_Train:  [[ 4822.51615774]]    Loss_Validation:  [[ 1420.64903103]]\n",
      "Loop  7712 :    Loss_Train:  [[ 4822.51615541]]    Loss_Validation:  [[ 1420.6491493]]\n",
      "Loop  7713 :    Loss_Train:  [[ 4822.51615309]]    Loss_Validation:  [[ 1420.64926748]]\n",
      "Loop  7714 :    Loss_Train:  [[ 4822.51615077]]    Loss_Validation:  [[ 1420.64938558]]\n",
      "Loop  7715 :    Loss_Train:  [[ 4822.51614845]]    Loss_Validation:  [[ 1420.64950359]]\n",
      "Loop  7716 :    Loss_Train:  [[ 4822.51614613]]    Loss_Validation:  [[ 1420.64962152]]\n",
      "Loop  7717 :    Loss_Train:  [[ 4822.51614382]]    Loss_Validation:  [[ 1420.64973936]]\n",
      "Loop  7718 :    Loss_Train:  [[ 4822.51614152]]    Loss_Validation:  [[ 1420.64985712]]\n",
      "Loop  7719 :    Loss_Train:  [[ 4822.51613921]]    Loss_Validation:  [[ 1420.6499748]]\n",
      "Loop  7720 :    Loss_Train:  [[ 4822.51613691]]    Loss_Validation:  [[ 1420.65009239]]\n",
      "Loop  7721 :    Loss_Train:  [[ 4822.51613462]]    Loss_Validation:  [[ 1420.6502099]]\n",
      "Loop  7722 :    Loss_Train:  [[ 4822.51613232]]    Loss_Validation:  [[ 1420.65032732]]\n",
      "Loop  7723 :    Loss_Train:  [[ 4822.51613003]]    Loss_Validation:  [[ 1420.65044467]]\n",
      "Loop  7724 :    Loss_Train:  [[ 4822.51612775]]    Loss_Validation:  [[ 1420.65056192]]\n",
      "Loop  7725 :    Loss_Train:  [[ 4822.51612547]]    Loss_Validation:  [[ 1420.6506791]]\n",
      "Loop  7726 :    Loss_Train:  [[ 4822.51612319]]    Loss_Validation:  [[ 1420.65079619]]\n",
      "Loop  7727 :    Loss_Train:  [[ 4822.51612091]]    Loss_Validation:  [[ 1420.65091319]]\n",
      "Loop  7728 :    Loss_Train:  [[ 4822.51611864]]    Loss_Validation:  [[ 1420.65103012]]\n",
      "Loop  7729 :    Loss_Train:  [[ 4822.51611638]]    Loss_Validation:  [[ 1420.65114696]]\n",
      "Loop  7730 :    Loss_Train:  [[ 4822.51611411]]    Loss_Validation:  [[ 1420.65126371]]\n",
      "Loop  7731 :    Loss_Train:  [[ 4822.51611185]]    Loss_Validation:  [[ 1420.65138039]]\n",
      "Loop  7732 :    Loss_Train:  [[ 4822.51610959]]    Loss_Validation:  [[ 1420.65149698]]\n",
      "Loop  7733 :    Loss_Train:  [[ 4822.51610734]]    Loss_Validation:  [[ 1420.65161348]]\n",
      "Loop  7734 :    Loss_Train:  [[ 4822.51610509]]    Loss_Validation:  [[ 1420.65172991]]\n",
      "Loop  7735 :    Loss_Train:  [[ 4822.51610284]]    Loss_Validation:  [[ 1420.65184625]]\n",
      "Loop  7736 :    Loss_Train:  [[ 4822.5161006]]    Loss_Validation:  [[ 1420.65196251]]\n",
      "Loop  7737 :    Loss_Train:  [[ 4822.51609836]]    Loss_Validation:  [[ 1420.65207868]]\n",
      "Loop  7738 :    Loss_Train:  [[ 4822.51609613]]    Loss_Validation:  [[ 1420.65219477]]\n",
      "Loop  7739 :    Loss_Train:  [[ 4822.51609389]]    Loss_Validation:  [[ 1420.65231078]]\n",
      "Loop  7740 :    Loss_Train:  [[ 4822.51609167]]    Loss_Validation:  [[ 1420.65242671]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  7741 :    Loss_Train:  [[ 4822.51608944]]    Loss_Validation:  [[ 1420.65254255]]\n",
      "Loop  7742 :    Loss_Train:  [[ 4822.51608722]]    Loss_Validation:  [[ 1420.65265831]]\n",
      "Loop  7743 :    Loss_Train:  [[ 4822.516085]]    Loss_Validation:  [[ 1420.65277399]]\n",
      "Loop  7744 :    Loss_Train:  [[ 4822.51608279]]    Loss_Validation:  [[ 1420.65288959]]\n",
      "Loop  7745 :    Loss_Train:  [[ 4822.51608057]]    Loss_Validation:  [[ 1420.6530051]]\n",
      "Loop  7746 :    Loss_Train:  [[ 4822.51607837]]    Loss_Validation:  [[ 1420.65312053]]\n",
      "Loop  7747 :    Loss_Train:  [[ 4822.51607616]]    Loss_Validation:  [[ 1420.65323588]]\n",
      "Loop  7748 :    Loss_Train:  [[ 4822.51607396]]    Loss_Validation:  [[ 1420.65335115]]\n",
      "Loop  7749 :    Loss_Train:  [[ 4822.51607176]]    Loss_Validation:  [[ 1420.65346633]]\n",
      "Loop  7750 :    Loss_Train:  [[ 4822.51606957]]    Loss_Validation:  [[ 1420.65358143]]\n",
      "Loop  7751 :    Loss_Train:  [[ 4822.51606738]]    Loss_Validation:  [[ 1420.65369645]]\n",
      "Loop  7752 :    Loss_Train:  [[ 4822.51606519]]    Loss_Validation:  [[ 1420.65381139]]\n",
      "Loop  7753 :    Loss_Train:  [[ 4822.51606301]]    Loss_Validation:  [[ 1420.65392625]]\n",
      "Loop  7754 :    Loss_Train:  [[ 4822.51606083]]    Loss_Validation:  [[ 1420.65404102]]\n",
      "Loop  7755 :    Loss_Train:  [[ 4822.51605865]]    Loss_Validation:  [[ 1420.65415572]]\n",
      "Loop  7756 :    Loss_Train:  [[ 4822.51605648]]    Loss_Validation:  [[ 1420.65427033]]\n",
      "Loop  7757 :    Loss_Train:  [[ 4822.51605431]]    Loss_Validation:  [[ 1420.65438485]]\n",
      "Loop  7758 :    Loss_Train:  [[ 4822.51605214]]    Loss_Validation:  [[ 1420.6544993]]\n",
      "Loop  7759 :    Loss_Train:  [[ 4822.51604998]]    Loss_Validation:  [[ 1420.65461367]]\n",
      "Loop  7760 :    Loss_Train:  [[ 4822.51604782]]    Loss_Validation:  [[ 1420.65472795]]\n",
      "Loop  7761 :    Loss_Train:  [[ 4822.51604566]]    Loss_Validation:  [[ 1420.65484215]]\n",
      "Loop  7762 :    Loss_Train:  [[ 4822.51604351]]    Loss_Validation:  [[ 1420.65495627]]\n",
      "Loop  7763 :    Loss_Train:  [[ 4822.51604136]]    Loss_Validation:  [[ 1420.65507031]]\n",
      "Loop  7764 :    Loss_Train:  [[ 4822.51603921]]    Loss_Validation:  [[ 1420.65518427]]\n",
      "Loop  7765 :    Loss_Train:  [[ 4822.51603707]]    Loss_Validation:  [[ 1420.65529815]]\n",
      "Loop  7766 :    Loss_Train:  [[ 4822.51603493]]    Loss_Validation:  [[ 1420.65541194]]\n",
      "Loop  7767 :    Loss_Train:  [[ 4822.51603279]]    Loss_Validation:  [[ 1420.65552566]]\n",
      "Loop  7768 :    Loss_Train:  [[ 4822.51603066]]    Loss_Validation:  [[ 1420.65563929]]\n",
      "Loop  7769 :    Loss_Train:  [[ 4822.51602853]]    Loss_Validation:  [[ 1420.65575284]]\n",
      "Loop  7770 :    Loss_Train:  [[ 4822.5160264]]    Loss_Validation:  [[ 1420.65586631]]\n",
      "Loop  7771 :    Loss_Train:  [[ 4822.51602428]]    Loss_Validation:  [[ 1420.6559797]]\n",
      "Loop  7772 :    Loss_Train:  [[ 4822.51602216]]    Loss_Validation:  [[ 1420.65609301]]\n",
      "Loop  7773 :    Loss_Train:  [[ 4822.51602005]]    Loss_Validation:  [[ 1420.65620624]]\n",
      "Loop  7774 :    Loss_Train:  [[ 4822.51601793]]    Loss_Validation:  [[ 1420.65631939]]\n",
      "Loop  7775 :    Loss_Train:  [[ 4822.51601582]]    Loss_Validation:  [[ 1420.65643246]]\n",
      "Loop  7776 :    Loss_Train:  [[ 4822.51601372]]    Loss_Validation:  [[ 1420.65654544]]\n",
      "Loop  7777 :    Loss_Train:  [[ 4822.51601161]]    Loss_Validation:  [[ 1420.65665835]]\n",
      "Loop  7778 :    Loss_Train:  [[ 4822.51600951]]    Loss_Validation:  [[ 1420.65677117]]\n",
      "Loop  7779 :    Loss_Train:  [[ 4822.51600742]]    Loss_Validation:  [[ 1420.65688392]]\n",
      "Loop  7780 :    Loss_Train:  [[ 4822.51600532]]    Loss_Validation:  [[ 1420.65699658]]\n",
      "Loop  7781 :    Loss_Train:  [[ 4822.51600324]]    Loss_Validation:  [[ 1420.65710917]]\n",
      "Loop  7782 :    Loss_Train:  [[ 4822.51600115]]    Loss_Validation:  [[ 1420.65722167]]\n",
      "Loop  7783 :    Loss_Train:  [[ 4822.51599907]]    Loss_Validation:  [[ 1420.65733409]]\n",
      "Loop  7784 :    Loss_Train:  [[ 4822.51599699]]    Loss_Validation:  [[ 1420.65744644]]\n",
      "Loop  7785 :    Loss_Train:  [[ 4822.51599491]]    Loss_Validation:  [[ 1420.6575587]]\n",
      "Loop  7786 :    Loss_Train:  [[ 4822.51599284]]    Loss_Validation:  [[ 1420.65767088]]\n",
      "Loop  7787 :    Loss_Train:  [[ 4822.51599077]]    Loss_Validation:  [[ 1420.65778298]]\n",
      "Loop  7788 :    Loss_Train:  [[ 4822.5159887]]    Loss_Validation:  [[ 1420.65789501]]\n",
      "Loop  7789 :    Loss_Train:  [[ 4822.51598663]]    Loss_Validation:  [[ 1420.65800695]]\n",
      "Loop  7790 :    Loss_Train:  [[ 4822.51598457]]    Loss_Validation:  [[ 1420.65811881]]\n",
      "Loop  7791 :    Loss_Train:  [[ 4822.51598252]]    Loss_Validation:  [[ 1420.6582306]]\n",
      "Loop  7792 :    Loss_Train:  [[ 4822.51598046]]    Loss_Validation:  [[ 1420.6583423]]\n",
      "Loop  7793 :    Loss_Train:  [[ 4822.51597841]]    Loss_Validation:  [[ 1420.65845392]]\n",
      "Loop  7794 :    Loss_Train:  [[ 4822.51597636]]    Loss_Validation:  [[ 1420.65856547]]\n",
      "Loop  7795 :    Loss_Train:  [[ 4822.51597432]]    Loss_Validation:  [[ 1420.65867693]]\n",
      "Loop  7796 :    Loss_Train:  [[ 4822.51597228]]    Loss_Validation:  [[ 1420.65878832]]\n",
      "Loop  7797 :    Loss_Train:  [[ 4822.51597024]]    Loss_Validation:  [[ 1420.65889962]]\n",
      "Loop  7798 :    Loss_Train:  [[ 4822.51596821]]    Loss_Validation:  [[ 1420.65901085]]\n",
      "Loop  7799 :    Loss_Train:  [[ 4822.51596618]]    Loss_Validation:  [[ 1420.65912199]]\n",
      "Loop  7800 :    Loss_Train:  [[ 4822.51596415]]    Loss_Validation:  [[ 1420.65923306]]\n",
      "Loop  7801 :    Loss_Train:  [[ 4822.51596212]]    Loss_Validation:  [[ 1420.65934405]]\n",
      "Loop  7802 :    Loss_Train:  [[ 4822.5159601]]    Loss_Validation:  [[ 1420.65945496]]\n",
      "Loop  7803 :    Loss_Train:  [[ 4822.51595808]]    Loss_Validation:  [[ 1420.65956579]]\n",
      "Loop  7804 :    Loss_Train:  [[ 4822.51595607]]    Loss_Validation:  [[ 1420.65967654]]\n",
      "Loop  7805 :    Loss_Train:  [[ 4822.51595405]]    Loss_Validation:  [[ 1420.65978721]]\n",
      "Loop  7806 :    Loss_Train:  [[ 4822.51595204]]    Loss_Validation:  [[ 1420.6598978]]\n",
      "Loop  7807 :    Loss_Train:  [[ 4822.51595004]]    Loss_Validation:  [[ 1420.66000832]]\n",
      "Loop  7808 :    Loss_Train:  [[ 4822.51594803]]    Loss_Validation:  [[ 1420.66011875]]\n",
      "Loop  7809 :    Loss_Train:  [[ 4822.51594603]]    Loss_Validation:  [[ 1420.66022911]]\n",
      "Loop  7810 :    Loss_Train:  [[ 4822.51594404]]    Loss_Validation:  [[ 1420.66033938]]\n",
      "Loop  7811 :    Loss_Train:  [[ 4822.51594204]]    Loss_Validation:  [[ 1420.66044958]]\n",
      "Loop  7812 :    Loss_Train:  [[ 4822.51594005]]    Loss_Validation:  [[ 1420.6605597]]\n",
      "Loop  7813 :    Loss_Train:  [[ 4822.51593807]]    Loss_Validation:  [[ 1420.66066974]]\n",
      "Loop  7814 :    Loss_Train:  [[ 4822.51593608]]    Loss_Validation:  [[ 1420.66077971]]\n",
      "Loop  7815 :    Loss_Train:  [[ 4822.5159341]]    Loss_Validation:  [[ 1420.66088959]]\n",
      "Loop  7816 :    Loss_Train:  [[ 4822.51593212]]    Loss_Validation:  [[ 1420.6609994]]\n",
      "Loop  7817 :    Loss_Train:  [[ 4822.51593015]]    Loss_Validation:  [[ 1420.66110912]]\n",
      "Loop  7818 :    Loss_Train:  [[ 4822.51592818]]    Loss_Validation:  [[ 1420.66121877]]\n",
      "Loop  7819 :    Loss_Train:  [[ 4822.51592621]]    Loss_Validation:  [[ 1420.66132834]]\n",
      "Loop  7820 :    Loss_Train:  [[ 4822.51592424]]    Loss_Validation:  [[ 1420.66143784]]\n",
      "Loop  7821 :    Loss_Train:  [[ 4822.51592228]]    Loss_Validation:  [[ 1420.66154725]]\n",
      "Loop  7822 :    Loss_Train:  [[ 4822.51592032]]    Loss_Validation:  [[ 1420.66165659]]\n",
      "Loop  7823 :    Loss_Train:  [[ 4822.51591836]]    Loss_Validation:  [[ 1420.66176585]]\n",
      "Loop  7824 :    Loss_Train:  [[ 4822.51591641]]    Loss_Validation:  [[ 1420.66187503]]\n",
      "Loop  7825 :    Loss_Train:  [[ 4822.51591446]]    Loss_Validation:  [[ 1420.66198413]]\n",
      "Loop  7826 :    Loss_Train:  [[ 4822.51591251]]    Loss_Validation:  [[ 1420.66209315]]\n",
      "Loop  7827 :    Loss_Train:  [[ 4822.51591057]]    Loss_Validation:  [[ 1420.6622021]]\n",
      "Loop  7828 :    Loss_Train:  [[ 4822.51590863]]    Loss_Validation:  [[ 1420.66231097]]\n",
      "Loop  7829 :    Loss_Train:  [[ 4822.51590669]]    Loss_Validation:  [[ 1420.66241976]]\n",
      "Loop  7830 :    Loss_Train:  [[ 4822.51590475]]    Loss_Validation:  [[ 1420.66252847]]\n",
      "Loop  7831 :    Loss_Train:  [[ 4822.51590282]]    Loss_Validation:  [[ 1420.66263711]]\n",
      "Loop  7832 :    Loss_Train:  [[ 4822.51590089]]    Loss_Validation:  [[ 1420.66274567]]\n",
      "Loop  7833 :    Loss_Train:  [[ 4822.51589897]]    Loss_Validation:  [[ 1420.66285415]]\n",
      "Loop  7834 :    Loss_Train:  [[ 4822.51589704]]    Loss_Validation:  [[ 1420.66296255]]\n",
      "Loop  7835 :    Loss_Train:  [[ 4822.51589512]]    Loss_Validation:  [[ 1420.66307088]]\n",
      "Loop  7836 :    Loss_Train:  [[ 4822.51589321]]    Loss_Validation:  [[ 1420.66317913]]\n",
      "Loop  7837 :    Loss_Train:  [[ 4822.51589129]]    Loss_Validation:  [[ 1420.6632873]]\n",
      "Loop  7838 :    Loss_Train:  [[ 4822.51588938]]    Loss_Validation:  [[ 1420.66339539]]\n",
      "Loop  7839 :    Loss_Train:  [[ 4822.51588747]]    Loss_Validation:  [[ 1420.66350341]]\n",
      "Loop  7840 :    Loss_Train:  [[ 4822.51588557]]    Loss_Validation:  [[ 1420.66361135]]\n",
      "Loop  7841 :    Loss_Train:  [[ 4822.51588367]]    Loss_Validation:  [[ 1420.66371922]]\n",
      "Loop  7842 :    Loss_Train:  [[ 4822.51588177]]    Loss_Validation:  [[ 1420.663827]]\n",
      "Loop  7843 :    Loss_Train:  [[ 4822.51587987]]    Loss_Validation:  [[ 1420.66393471]]\n",
      "Loop  7844 :    Loss_Train:  [[ 4822.51587798]]    Loss_Validation:  [[ 1420.66404234]]\n",
      "Loop  7845 :    Loss_Train:  [[ 4822.51587609]]    Loss_Validation:  [[ 1420.6641499]]\n",
      "Loop  7846 :    Loss_Train:  [[ 4822.5158742]]    Loss_Validation:  [[ 1420.66425738]]\n",
      "Loop  7847 :    Loss_Train:  [[ 4822.51587232]]    Loss_Validation:  [[ 1420.66436478]]\n",
      "Loop  7848 :    Loss_Train:  [[ 4822.51587044]]    Loss_Validation:  [[ 1420.66447211]]\n",
      "Loop  7849 :    Loss_Train:  [[ 4822.51586856]]    Loss_Validation:  [[ 1420.66457935]]\n",
      "Loop  7850 :    Loss_Train:  [[ 4822.51586668]]    Loss_Validation:  [[ 1420.66468653]]\n",
      "Loop  7851 :    Loss_Train:  [[ 4822.51586481]]    Loss_Validation:  [[ 1420.66479362]]\n",
      "Loop  7852 :    Loss_Train:  [[ 4822.51586294]]    Loss_Validation:  [[ 1420.66490064]]\n",
      "Loop  7853 :    Loss_Train:  [[ 4822.51586108]]    Loss_Validation:  [[ 1420.66500758]]\n",
      "Loop  7854 :    Loss_Train:  [[ 4822.51585921]]    Loss_Validation:  [[ 1420.66511445]]\n",
      "Loop  7855 :    Loss_Train:  [[ 4822.51585735]]    Loss_Validation:  [[ 1420.66522124]]\n",
      "Loop  7856 :    Loss_Train:  [[ 4822.5158555]]    Loss_Validation:  [[ 1420.66532795]]\n",
      "Loop  7857 :    Loss_Train:  [[ 4822.51585364]]    Loss_Validation:  [[ 1420.66543459]]\n",
      "Loop  7858 :    Loss_Train:  [[ 4822.51585179]]    Loss_Validation:  [[ 1420.66554115]]\n",
      "Loop  7859 :    Loss_Train:  [[ 4822.51584994]]    Loss_Validation:  [[ 1420.66564764]]\n",
      "Loop  7860 :    Loss_Train:  [[ 4822.51584809]]    Loss_Validation:  [[ 1420.66575405]]\n",
      "Loop  7861 :    Loss_Train:  [[ 4822.51584625]]    Loss_Validation:  [[ 1420.66586038]]\n",
      "Loop  7862 :    Loss_Train:  [[ 4822.51584441]]    Loss_Validation:  [[ 1420.66596664]]\n",
      "Loop  7863 :    Loss_Train:  [[ 4822.51584257]]    Loss_Validation:  [[ 1420.66607282]]\n",
      "Loop  7864 :    Loss_Train:  [[ 4822.51584074]]    Loss_Validation:  [[ 1420.66617893]]\n",
      "Loop  7865 :    Loss_Train:  [[ 4822.51583891]]    Loss_Validation:  [[ 1420.66628496]]\n",
      "Loop  7866 :    Loss_Train:  [[ 4822.51583708]]    Loss_Validation:  [[ 1420.66639091]]\n",
      "Loop  7867 :    Loss_Train:  [[ 4822.51583525]]    Loss_Validation:  [[ 1420.66649679]]\n",
      "Loop  7868 :    Loss_Train:  [[ 4822.51583343]]    Loss_Validation:  [[ 1420.6666026]]\n",
      "Loop  7869 :    Loss_Train:  [[ 4822.51583161]]    Loss_Validation:  [[ 1420.66670832]]\n",
      "Loop  7870 :    Loss_Train:  [[ 4822.51582979]]    Loss_Validation:  [[ 1420.66681398]]\n",
      "Loop  7871 :    Loss_Train:  [[ 4822.51582798]]    Loss_Validation:  [[ 1420.66691955]]\n",
      "Loop  7872 :    Loss_Train:  [[ 4822.51582617]]    Loss_Validation:  [[ 1420.66702505]]\n",
      "Loop  7873 :    Loss_Train:  [[ 4822.51582436]]    Loss_Validation:  [[ 1420.66713048]]\n",
      "Loop  7874 :    Loss_Train:  [[ 4822.51582255]]    Loss_Validation:  [[ 1420.66723583]]\n",
      "Loop  7875 :    Loss_Train:  [[ 4822.51582075]]    Loss_Validation:  [[ 1420.66734111]]\n",
      "Loop  7876 :    Loss_Train:  [[ 4822.51581895]]    Loss_Validation:  [[ 1420.66744631]]\n",
      "Loop  7877 :    Loss_Train:  [[ 4822.51581715]]    Loss_Validation:  [[ 1420.66755143]]\n",
      "Loop  7878 :    Loss_Train:  [[ 4822.51581536]]    Loss_Validation:  [[ 1420.66765648]]\n",
      "Loop  7879 :    Loss_Train:  [[ 4822.51581356]]    Loss_Validation:  [[ 1420.66776146]]\n",
      "Loop  7880 :    Loss_Train:  [[ 4822.51581178]]    Loss_Validation:  [[ 1420.66786636]]\n",
      "Loop  7881 :    Loss_Train:  [[ 4822.51580999]]    Loss_Validation:  [[ 1420.66797118]]\n",
      "Loop  7882 :    Loss_Train:  [[ 4822.51580821]]    Loss_Validation:  [[ 1420.66807593]]\n",
      "Loop  7883 :    Loss_Train:  [[ 4822.51580643]]    Loss_Validation:  [[ 1420.66818061]]\n",
      "Loop  7884 :    Loss_Train:  [[ 4822.51580465]]    Loss_Validation:  [[ 1420.66828521]]\n",
      "Loop  7885 :    Loss_Train:  [[ 4822.51580287]]    Loss_Validation:  [[ 1420.66838974]]\n",
      "Loop  7886 :    Loss_Train:  [[ 4822.5158011]]    Loss_Validation:  [[ 1420.66849419]]\n",
      "Loop  7887 :    Loss_Train:  [[ 4822.51579933]]    Loss_Validation:  [[ 1420.66859857]]\n",
      "Loop  7888 :    Loss_Train:  [[ 4822.51579756]]    Loss_Validation:  [[ 1420.66870287]]\n",
      "Loop  7889 :    Loss_Train:  [[ 4822.5157958]]    Loss_Validation:  [[ 1420.6688071]]\n",
      "Loop  7890 :    Loss_Train:  [[ 4822.51579404]]    Loss_Validation:  [[ 1420.66891125]]\n",
      "Loop  7891 :    Loss_Train:  [[ 4822.51579228]]    Loss_Validation:  [[ 1420.66901533]]\n",
      "Loop  7892 :    Loss_Train:  [[ 4822.51579053]]    Loss_Validation:  [[ 1420.66911934]]\n",
      "Loop  7893 :    Loss_Train:  [[ 4822.51578877]]    Loss_Validation:  [[ 1420.66922327]]\n",
      "Loop  7894 :    Loss_Train:  [[ 4822.51578702]]    Loss_Validation:  [[ 1420.66932712]]\n",
      "Loop  7895 :    Loss_Train:  [[ 4822.51578528]]    Loss_Validation:  [[ 1420.66943091]]\n",
      "Loop  7896 :    Loss_Train:  [[ 4822.51578353]]    Loss_Validation:  [[ 1420.66953461]]\n",
      "Loop  7897 :    Loss_Train:  [[ 4822.51578179]]    Loss_Validation:  [[ 1420.66963825]]\n",
      "Loop  7898 :    Loss_Train:  [[ 4822.51578005]]    Loss_Validation:  [[ 1420.66974181]]\n",
      "Loop  7899 :    Loss_Train:  [[ 4822.51577831]]    Loss_Validation:  [[ 1420.66984529]]\n",
      "Loop  7900 :    Loss_Train:  [[ 4822.51577658]]    Loss_Validation:  [[ 1420.66994871]]\n",
      "Loop  7901 :    Loss_Train:  [[ 4822.51577485]]    Loss_Validation:  [[ 1420.67005205]]\n",
      "Loop  7902 :    Loss_Train:  [[ 4822.51577312]]    Loss_Validation:  [[ 1420.67015531]]\n",
      "Loop  7903 :    Loss_Train:  [[ 4822.5157714]]    Loss_Validation:  [[ 1420.6702585]]\n",
      "Loop  7904 :    Loss_Train:  [[ 4822.51576967]]    Loss_Validation:  [[ 1420.67036162]]\n",
      "Loop  7905 :    Loss_Train:  [[ 4822.51576795]]    Loss_Validation:  [[ 1420.67046466]]\n",
      "Loop  7906 :    Loss_Train:  [[ 4822.51576623]]    Loss_Validation:  [[ 1420.67056763]]\n",
      "Loop  7907 :    Loss_Train:  [[ 4822.51576452]]    Loss_Validation:  [[ 1420.67067053]]\n",
      "Loop  7908 :    Loss_Train:  [[ 4822.51576281]]    Loss_Validation:  [[ 1420.67077335]]\n",
      "Loop  7909 :    Loss_Train:  [[ 4822.5157611]]    Loss_Validation:  [[ 1420.6708761]]\n",
      "Loop  7910 :    Loss_Train:  [[ 4822.51575939]]    Loss_Validation:  [[ 1420.67097878]]\n",
      "Loop  7911 :    Loss_Train:  [[ 4822.51575769]]    Loss_Validation:  [[ 1420.67108138]]\n",
      "Loop  7912 :    Loss_Train:  [[ 4822.51575599]]    Loss_Validation:  [[ 1420.67118391]]\n",
      "Loop  7913 :    Loss_Train:  [[ 4822.51575429]]    Loss_Validation:  [[ 1420.67128637]]\n",
      "Loop  7914 :    Loss_Train:  [[ 4822.51575259]]    Loss_Validation:  [[ 1420.67138875]]\n",
      "Loop  7915 :    Loss_Train:  [[ 4822.5157509]]    Loss_Validation:  [[ 1420.67149106]]\n",
      "Loop  7916 :    Loss_Train:  [[ 4822.51574921]]    Loss_Validation:  [[ 1420.6715933]]\n",
      "Loop  7917 :    Loss_Train:  [[ 4822.51574752]]    Loss_Validation:  [[ 1420.67169546]]\n",
      "Loop  7918 :    Loss_Train:  [[ 4822.51574583]]    Loss_Validation:  [[ 1420.67179755]]\n",
      "Loop  7919 :    Loss_Train:  [[ 4822.51574415]]    Loss_Validation:  [[ 1420.67189957]]\n",
      "Loop  7920 :    Loss_Train:  [[ 4822.51574247]]    Loss_Validation:  [[ 1420.67200151]]\n",
      "Loop  7921 :    Loss_Train:  [[ 4822.51574079]]    Loss_Validation:  [[ 1420.67210339]]\n",
      "Loop  7922 :    Loss_Train:  [[ 4822.51573912]]    Loss_Validation:  [[ 1420.67220519]]\n",
      "Loop  7923 :    Loss_Train:  [[ 4822.51573745]]    Loss_Validation:  [[ 1420.67230691]]\n",
      "Loop  7924 :    Loss_Train:  [[ 4822.51573578]]    Loss_Validation:  [[ 1420.67240857]]\n",
      "Loop  7925 :    Loss_Train:  [[ 4822.51573411]]    Loss_Validation:  [[ 1420.67251015]]\n",
      "Loop  7926 :    Loss_Train:  [[ 4822.51573245]]    Loss_Validation:  [[ 1420.67261166]]\n",
      "Loop  7927 :    Loss_Train:  [[ 4822.51573078]]    Loss_Validation:  [[ 1420.67271309]]\n",
      "Loop  7928 :    Loss_Train:  [[ 4822.51572913]]    Loss_Validation:  [[ 1420.67281446]]\n",
      "Loop  7929 :    Loss_Train:  [[ 4822.51572747]]    Loss_Validation:  [[ 1420.67291575]]\n",
      "Loop  7930 :    Loss_Train:  [[ 4822.51572581]]    Loss_Validation:  [[ 1420.67301697]]\n",
      "Loop  7931 :    Loss_Train:  [[ 4822.51572416]]    Loss_Validation:  [[ 1420.67311812]]\n",
      "Loop  7932 :    Loss_Train:  [[ 4822.51572251]]    Loss_Validation:  [[ 1420.67321919]]\n",
      "Loop  7933 :    Loss_Train:  [[ 4822.51572087]]    Loss_Validation:  [[ 1420.67332019]]\n",
      "Loop  7934 :    Loss_Train:  [[ 4822.51571922]]    Loss_Validation:  [[ 1420.67342112]]\n",
      "Loop  7935 :    Loss_Train:  [[ 4822.51571758]]    Loss_Validation:  [[ 1420.67352198]]\n",
      "Loop  7936 :    Loss_Train:  [[ 4822.51571595]]    Loss_Validation:  [[ 1420.67362277]]\n",
      "Loop  7937 :    Loss_Train:  [[ 4822.51571431]]    Loss_Validation:  [[ 1420.67372348]]\n",
      "Loop  7938 :    Loss_Train:  [[ 4822.51571268]]    Loss_Validation:  [[ 1420.67382413]]\n",
      "Loop  7939 :    Loss_Train:  [[ 4822.51571105]]    Loss_Validation:  [[ 1420.6739247]]\n",
      "Loop  7940 :    Loss_Train:  [[ 4822.51570942]]    Loss_Validation:  [[ 1420.6740252]]\n",
      "Loop  7941 :    Loss_Train:  [[ 4822.51570779]]    Loss_Validation:  [[ 1420.67412562]]\n",
      "Loop  7942 :    Loss_Train:  [[ 4822.51570617]]    Loss_Validation:  [[ 1420.67422598]]\n",
      "Loop  7943 :    Loss_Train:  [[ 4822.51570455]]    Loss_Validation:  [[ 1420.67432626]]\n",
      "Loop  7944 :    Loss_Train:  [[ 4822.51570293]]    Loss_Validation:  [[ 1420.67442647]]\n",
      "Loop  7945 :    Loss_Train:  [[ 4822.51570131]]    Loss_Validation:  [[ 1420.67452661]]\n",
      "Loop  7946 :    Loss_Train:  [[ 4822.5156997]]    Loss_Validation:  [[ 1420.67462668]]\n",
      "Loop  7947 :    Loss_Train:  [[ 4822.51569809]]    Loss_Validation:  [[ 1420.67472668]]\n",
      "Loop  7948 :    Loss_Train:  [[ 4822.51569648]]    Loss_Validation:  [[ 1420.6748266]]\n",
      "Loop  7949 :    Loss_Train:  [[ 4822.51569488]]    Loss_Validation:  [[ 1420.67492646]]\n",
      "Loop  7950 :    Loss_Train:  [[ 4822.51569327]]    Loss_Validation:  [[ 1420.67502624]]\n",
      "Loop  7951 :    Loss_Train:  [[ 4822.51569167]]    Loss_Validation:  [[ 1420.67512595]]\n",
      "Loop  7952 :    Loss_Train:  [[ 4822.51569008]]    Loss_Validation:  [[ 1420.67522559]]\n",
      "Loop  7953 :    Loss_Train:  [[ 4822.51568848]]    Loss_Validation:  [[ 1420.67532516]]\n",
      "Loop  7954 :    Loss_Train:  [[ 4822.51568689]]    Loss_Validation:  [[ 1420.67542466]]\n",
      "Loop  7955 :    Loss_Train:  [[ 4822.5156853]]    Loss_Validation:  [[ 1420.67552409]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  7956 :    Loss_Train:  [[ 4822.51568371]]    Loss_Validation:  [[ 1420.67562344]]\n",
      "Loop  7957 :    Loss_Train:  [[ 4822.51568212]]    Loss_Validation:  [[ 1420.67572273]]\n",
      "Loop  7958 :    Loss_Train:  [[ 4822.51568054]]    Loss_Validation:  [[ 1420.67582194]]\n",
      "Loop  7959 :    Loss_Train:  [[ 4822.51567896]]    Loss_Validation:  [[ 1420.67592109]]\n",
      "Loop  7960 :    Loss_Train:  [[ 4822.51567738]]    Loss_Validation:  [[ 1420.67602016]]\n",
      "Loop  7961 :    Loss_Train:  [[ 4822.51567581]]    Loss_Validation:  [[ 1420.67611916]]\n",
      "Loop  7962 :    Loss_Train:  [[ 4822.51567424]]    Loss_Validation:  [[ 1420.67621809]]\n",
      "Loop  7963 :    Loss_Train:  [[ 4822.51567266]]    Loss_Validation:  [[ 1420.67631695]]\n",
      "Loop  7964 :    Loss_Train:  [[ 4822.5156711]]    Loss_Validation:  [[ 1420.67641574]]\n",
      "Loop  7965 :    Loss_Train:  [[ 4822.51566953]]    Loss_Validation:  [[ 1420.67651446]]\n",
      "Loop  7966 :    Loss_Train:  [[ 4822.51566797]]    Loss_Validation:  [[ 1420.67661311]]\n",
      "Loop  7967 :    Loss_Train:  [[ 4822.51566641]]    Loss_Validation:  [[ 1420.67671169]]\n",
      "Loop  7968 :    Loss_Train:  [[ 4822.51566485]]    Loss_Validation:  [[ 1420.67681019]]\n",
      "Loop  7969 :    Loss_Train:  [[ 4822.51566329]]    Loss_Validation:  [[ 1420.67690863]]\n",
      "Loop  7970 :    Loss_Train:  [[ 4822.51566174]]    Loss_Validation:  [[ 1420.677007]]\n",
      "Loop  7971 :    Loss_Train:  [[ 4822.51566019]]    Loss_Validation:  [[ 1420.67710529]]\n",
      "Loop  7972 :    Loss_Train:  [[ 4822.51565864]]    Loss_Validation:  [[ 1420.67720352]]\n",
      "Loop  7973 :    Loss_Train:  [[ 4822.51565709]]    Loss_Validation:  [[ 1420.67730168]]\n",
      "Loop  7974 :    Loss_Train:  [[ 4822.51565555]]    Loss_Validation:  [[ 1420.67739976]]\n",
      "Loop  7975 :    Loss_Train:  [[ 4822.51565401]]    Loss_Validation:  [[ 1420.67749778]]\n",
      "Loop  7976 :    Loss_Train:  [[ 4822.51565247]]    Loss_Validation:  [[ 1420.67759572]]\n",
      "Loop  7977 :    Loss_Train:  [[ 4822.51565093]]    Loss_Validation:  [[ 1420.6776936]]\n",
      "Loop  7978 :    Loss_Train:  [[ 4822.5156494]]    Loss_Validation:  [[ 1420.67779141]]\n",
      "Loop  7979 :    Loss_Train:  [[ 4822.51564787]]    Loss_Validation:  [[ 1420.67788914]]\n",
      "Loop  7980 :    Loss_Train:  [[ 4822.51564634]]    Loss_Validation:  [[ 1420.67798681]]\n",
      "Loop  7981 :    Loss_Train:  [[ 4822.51564481]]    Loss_Validation:  [[ 1420.6780844]]\n",
      "Loop  7982 :    Loss_Train:  [[ 4822.51564329]]    Loss_Validation:  [[ 1420.67818193]]\n",
      "Loop  7983 :    Loss_Train:  [[ 4822.51564177]]    Loss_Validation:  [[ 1420.67827939]]\n",
      "Loop  7984 :    Loss_Train:  [[ 4822.51564025]]    Loss_Validation:  [[ 1420.67837678]]\n",
      "Loop  7985 :    Loss_Train:  [[ 4822.51563873]]    Loss_Validation:  [[ 1420.67847409]]\n",
      "Loop  7986 :    Loss_Train:  [[ 4822.51563721]]    Loss_Validation:  [[ 1420.67857134]]\n",
      "Loop  7987 :    Loss_Train:  [[ 4822.5156357]]    Loss_Validation:  [[ 1420.67866852]]\n",
      "Loop  7988 :    Loss_Train:  [[ 4822.51563419]]    Loss_Validation:  [[ 1420.67876563]]\n",
      "Loop  7989 :    Loss_Train:  [[ 4822.51563268]]    Loss_Validation:  [[ 1420.67886267]]\n",
      "Loop  7990 :    Loss_Train:  [[ 4822.51563118]]    Loss_Validation:  [[ 1420.67895964]]\n",
      "Loop  7991 :    Loss_Train:  [[ 4822.51562968]]    Loss_Validation:  [[ 1420.67905654]]\n",
      "Loop  7992 :    Loss_Train:  [[ 4822.51562818]]    Loss_Validation:  [[ 1420.67915337]]\n",
      "Loop  7993 :    Loss_Train:  [[ 4822.51562668]]    Loss_Validation:  [[ 1420.67925014]]\n",
      "Loop  7994 :    Loss_Train:  [[ 4822.51562518]]    Loss_Validation:  [[ 1420.67934683]]\n",
      "Loop  7995 :    Loss_Train:  [[ 4822.51562369]]    Loss_Validation:  [[ 1420.67944345]]\n",
      "Loop  7996 :    Loss_Train:  [[ 4822.5156222]]    Loss_Validation:  [[ 1420.67954001]]\n",
      "Loop  7997 :    Loss_Train:  [[ 4822.51562071]]    Loss_Validation:  [[ 1420.6796365]]\n",
      "Loop  7998 :    Loss_Train:  [[ 4822.51561922]]    Loss_Validation:  [[ 1420.67973291]]\n",
      "Loop  7999 :    Loss_Train:  [[ 4822.51561774]]    Loss_Validation:  [[ 1420.67982926]]\n",
      "Loop  8000 :    Loss_Train:  [[ 4822.51561625]]    Loss_Validation:  [[ 1420.67992554]]\n",
      "Loop  8001 :    Loss_Train:  [[ 4822.51561477]]    Loss_Validation:  [[ 1420.68002175]]\n",
      "Loop  8002 :    Loss_Train:  [[ 4822.5156133]]    Loss_Validation:  [[ 1420.68011789]]\n",
      "Loop  8003 :    Loss_Train:  [[ 4822.51561182]]    Loss_Validation:  [[ 1420.68021397]]\n",
      "Loop  8004 :    Loss_Train:  [[ 4822.51561035]]    Loss_Validation:  [[ 1420.68030997]]\n",
      "Loop  8005 :    Loss_Train:  [[ 4822.51560888]]    Loss_Validation:  [[ 1420.68040591]]\n",
      "Loop  8006 :    Loss_Train:  [[ 4822.51560741]]    Loss_Validation:  [[ 1420.68050178]]\n",
      "Loop  8007 :    Loss_Train:  [[ 4822.51560595]]    Loss_Validation:  [[ 1420.68059758]]\n",
      "Loop  8008 :    Loss_Train:  [[ 4822.51560448]]    Loss_Validation:  [[ 1420.68069331]]\n",
      "Loop  8009 :    Loss_Train:  [[ 4822.51560302]]    Loss_Validation:  [[ 1420.68078897]]\n",
      "Loop  8010 :    Loss_Train:  [[ 4822.51560156]]    Loss_Validation:  [[ 1420.68088456]]\n",
      "Loop  8011 :    Loss_Train:  [[ 4822.51560011]]    Loss_Validation:  [[ 1420.68098009]]\n",
      "Loop  8012 :    Loss_Train:  [[ 4822.51559865]]    Loss_Validation:  [[ 1420.68107554]]\n",
      "Loop  8013 :    Loss_Train:  [[ 4822.5155972]]    Loss_Validation:  [[ 1420.68117093]]\n",
      "Loop  8014 :    Loss_Train:  [[ 4822.51559575]]    Loss_Validation:  [[ 1420.68126625]]\n",
      "Loop  8015 :    Loss_Train:  [[ 4822.5155943]]    Loss_Validation:  [[ 1420.68136151]]\n",
      "Loop  8016 :    Loss_Train:  [[ 4822.51559286]]    Loss_Validation:  [[ 1420.68145669]]\n",
      "Loop  8017 :    Loss_Train:  [[ 4822.51559141]]    Loss_Validation:  [[ 1420.68155181]]\n",
      "Loop  8018 :    Loss_Train:  [[ 4822.51558997]]    Loss_Validation:  [[ 1420.68164686]]\n",
      "Loop  8019 :    Loss_Train:  [[ 4822.51558853]]    Loss_Validation:  [[ 1420.68174184]]\n",
      "Loop  8020 :    Loss_Train:  [[ 4822.5155871]]    Loss_Validation:  [[ 1420.68183675]]\n",
      "Loop  8021 :    Loss_Train:  [[ 4822.51558566]]    Loss_Validation:  [[ 1420.68193159]]\n",
      "Loop  8022 :    Loss_Train:  [[ 4822.51558423]]    Loss_Validation:  [[ 1420.68202637]]\n",
      "Loop  8023 :    Loss_Train:  [[ 4822.5155828]]    Loss_Validation:  [[ 1420.68212108]]\n",
      "Loop  8024 :    Loss_Train:  [[ 4822.51558138]]    Loss_Validation:  [[ 1420.68221572]]\n",
      "Loop  8025 :    Loss_Train:  [[ 4822.51557995]]    Loss_Validation:  [[ 1420.6823103]]\n",
      "Loop  8026 :    Loss_Train:  [[ 4822.51557853]]    Loss_Validation:  [[ 1420.6824048]]\n",
      "Loop  8027 :    Loss_Train:  [[ 4822.51557711]]    Loss_Validation:  [[ 1420.68249924]]\n",
      "Loop  8028 :    Loss_Train:  [[ 4822.51557569]]    Loss_Validation:  [[ 1420.68259361]]\n",
      "Loop  8029 :    Loss_Train:  [[ 4822.51557427]]    Loss_Validation:  [[ 1420.68268792]]\n",
      "Loop  8030 :    Loss_Train:  [[ 4822.51557286]]    Loss_Validation:  [[ 1420.68278215]]\n",
      "Loop  8031 :    Loss_Train:  [[ 4822.51557145]]    Loss_Validation:  [[ 1420.68287632]]\n",
      "Loop  8032 :    Loss_Train:  [[ 4822.51557004]]    Loss_Validation:  [[ 1420.68297042]]\n",
      "Loop  8033 :    Loss_Train:  [[ 4822.51556863]]    Loss_Validation:  [[ 1420.68306446]]\n",
      "Loop  8034 :    Loss_Train:  [[ 4822.51556723]]    Loss_Validation:  [[ 1420.68315843]]\n",
      "Loop  8035 :    Loss_Train:  [[ 4822.51556582]]    Loss_Validation:  [[ 1420.68325233]]\n",
      "Loop  8036 :    Loss_Train:  [[ 4822.51556442]]    Loss_Validation:  [[ 1420.68334616]]\n",
      "Loop  8037 :    Loss_Train:  [[ 4822.51556302]]    Loss_Validation:  [[ 1420.68343992]]\n",
      "Loop  8038 :    Loss_Train:  [[ 4822.51556163]]    Loss_Validation:  [[ 1420.68353362]]\n",
      "Loop  8039 :    Loss_Train:  [[ 4822.51556023]]    Loss_Validation:  [[ 1420.68362726]]\n",
      "Loop  8040 :    Loss_Train:  [[ 4822.51555884]]    Loss_Validation:  [[ 1420.68372082]]\n",
      "Loop  8041 :    Loss_Train:  [[ 4822.51555745]]    Loss_Validation:  [[ 1420.68381432]]\n",
      "Loop  8042 :    Loss_Train:  [[ 4822.51555606]]    Loss_Validation:  [[ 1420.68390775]]\n",
      "Loop  8043 :    Loss_Train:  [[ 4822.51555468]]    Loss_Validation:  [[ 1420.68400111]]\n",
      "Loop  8044 :    Loss_Train:  [[ 4822.5155533]]    Loss_Validation:  [[ 1420.68409441]]\n",
      "Loop  8045 :    Loss_Train:  [[ 4822.51555192]]    Loss_Validation:  [[ 1420.68418764]]\n",
      "Loop  8046 :    Loss_Train:  [[ 4822.51555054]]    Loss_Validation:  [[ 1420.68428081]]\n",
      "Loop  8047 :    Loss_Train:  [[ 4822.51554916]]    Loss_Validation:  [[ 1420.6843739]]\n",
      "Loop  8048 :    Loss_Train:  [[ 4822.51554779]]    Loss_Validation:  [[ 1420.68446694]]\n",
      "Loop  8049 :    Loss_Train:  [[ 4822.51554641]]    Loss_Validation:  [[ 1420.6845599]]\n",
      "Loop  8050 :    Loss_Train:  [[ 4822.51554504]]    Loss_Validation:  [[ 1420.6846528]]\n",
      "Loop  8051 :    Loss_Train:  [[ 4822.51554367]]    Loss_Validation:  [[ 1420.68474563]]\n",
      "Loop  8052 :    Loss_Train:  [[ 4822.51554231]]    Loss_Validation:  [[ 1420.68483839]]\n",
      "Loop  8053 :    Loss_Train:  [[ 4822.51554094]]    Loss_Validation:  [[ 1420.68493109]]\n",
      "Loop  8054 :    Loss_Train:  [[ 4822.51553958]]    Loss_Validation:  [[ 1420.68502373]]\n",
      "Loop  8055 :    Loss_Train:  [[ 4822.51553822]]    Loss_Validation:  [[ 1420.68511629]]\n",
      "Loop  8056 :    Loss_Train:  [[ 4822.51553687]]    Loss_Validation:  [[ 1420.68520879]]\n",
      "Loop  8057 :    Loss_Train:  [[ 4822.51553551]]    Loss_Validation:  [[ 1420.68530123]]\n",
      "Loop  8058 :    Loss_Train:  [[ 4822.51553416]]    Loss_Validation:  [[ 1420.6853936]]\n",
      "Loop  8059 :    Loss_Train:  [[ 4822.51553281]]    Loss_Validation:  [[ 1420.6854859]]\n",
      "Loop  8060 :    Loss_Train:  [[ 4822.51553146]]    Loss_Validation:  [[ 1420.68557813]]\n",
      "Loop  8061 :    Loss_Train:  [[ 4822.51553011]]    Loss_Validation:  [[ 1420.6856703]]\n",
      "Loop  8062 :    Loss_Train:  [[ 4822.51552877]]    Loss_Validation:  [[ 1420.68576241]]\n",
      "Loop  8063 :    Loss_Train:  [[ 4822.51552742]]    Loss_Validation:  [[ 1420.68585445]]\n",
      "Loop  8064 :    Loss_Train:  [[ 4822.51552608]]    Loss_Validation:  [[ 1420.68594642]]\n",
      "Loop  8065 :    Loss_Train:  [[ 4822.51552475]]    Loss_Validation:  [[ 1420.68603833]]\n",
      "Loop  8066 :    Loss_Train:  [[ 4822.51552341]]    Loss_Validation:  [[ 1420.68613017]]\n",
      "Loop  8067 :    Loss_Train:  [[ 4822.51552207]]    Loss_Validation:  [[ 1420.68622194]]\n",
      "Loop  8068 :    Loss_Train:  [[ 4822.51552074]]    Loss_Validation:  [[ 1420.68631365]]\n",
      "Loop  8069 :    Loss_Train:  [[ 4822.51551941]]    Loss_Validation:  [[ 1420.6864053]]\n",
      "Loop  8070 :    Loss_Train:  [[ 4822.51551808]]    Loss_Validation:  [[ 1420.68649687]]\n",
      "Loop  8071 :    Loss_Train:  [[ 4822.51551676]]    Loss_Validation:  [[ 1420.68658839]]\n",
      "Loop  8072 :    Loss_Train:  [[ 4822.51551544]]    Loss_Validation:  [[ 1420.68667984]]\n",
      "Loop  8073 :    Loss_Train:  [[ 4822.51551411]]    Loss_Validation:  [[ 1420.68677122]]\n",
      "Loop  8074 :    Loss_Train:  [[ 4822.51551279]]    Loss_Validation:  [[ 1420.68686253]]\n",
      "Loop  8075 :    Loss_Train:  [[ 4822.51551148]]    Loss_Validation:  [[ 1420.68695379]]\n",
      "Loop  8076 :    Loss_Train:  [[ 4822.51551016]]    Loss_Validation:  [[ 1420.68704497]]\n",
      "Loop  8077 :    Loss_Train:  [[ 4822.51550885]]    Loss_Validation:  [[ 1420.68713609]]\n",
      "Loop  8078 :    Loss_Train:  [[ 4822.51550754]]    Loss_Validation:  [[ 1420.68722715]]\n",
      "Loop  8079 :    Loss_Train:  [[ 4822.51550623]]    Loss_Validation:  [[ 1420.68731814]]\n",
      "Loop  8080 :    Loss_Train:  [[ 4822.51550492]]    Loss_Validation:  [[ 1420.68740907]]\n",
      "Loop  8081 :    Loss_Train:  [[ 4822.51550361]]    Loss_Validation:  [[ 1420.68749993]]\n",
      "Loop  8082 :    Loss_Train:  [[ 4822.51550231]]    Loss_Validation:  [[ 1420.68759072]]\n",
      "Loop  8083 :    Loss_Train:  [[ 4822.51550101]]    Loss_Validation:  [[ 1420.68768145]]\n",
      "Loop  8084 :    Loss_Train:  [[ 4822.51549971]]    Loss_Validation:  [[ 1420.68777212]]\n",
      "Loop  8085 :    Loss_Train:  [[ 4822.51549841]]    Loss_Validation:  [[ 1420.68786272]]\n",
      "Loop  8086 :    Loss_Train:  [[ 4822.51549712]]    Loss_Validation:  [[ 1420.68795326]]\n",
      "Loop  8087 :    Loss_Train:  [[ 4822.51549583]]    Loss_Validation:  [[ 1420.68804373]]\n",
      "Loop  8088 :    Loss_Train:  [[ 4822.51549453]]    Loss_Validation:  [[ 1420.68813414]]\n",
      "Loop  8089 :    Loss_Train:  [[ 4822.51549325]]    Loss_Validation:  [[ 1420.68822448]]\n",
      "Loop  8090 :    Loss_Train:  [[ 4822.51549196]]    Loss_Validation:  [[ 1420.68831476]]\n",
      "Loop  8091 :    Loss_Train:  [[ 4822.51549067]]    Loss_Validation:  [[ 1420.68840497]]\n",
      "Loop  8092 :    Loss_Train:  [[ 4822.51548939]]    Loss_Validation:  [[ 1420.68849512]]\n",
      "Loop  8093 :    Loss_Train:  [[ 4822.51548811]]    Loss_Validation:  [[ 1420.6885852]]\n",
      "Loop  8094 :    Loss_Train:  [[ 4822.51548683]]    Loss_Validation:  [[ 1420.68867522]]\n",
      "Loop  8095 :    Loss_Train:  [[ 4822.51548555]]    Loss_Validation:  [[ 1420.68876518]]\n",
      "Loop  8096 :    Loss_Train:  [[ 4822.51548428]]    Loss_Validation:  [[ 1420.68885507]]\n",
      "Loop  8097 :    Loss_Train:  [[ 4822.51548301]]    Loss_Validation:  [[ 1420.6889449]]\n",
      "Loop  8098 :    Loss_Train:  [[ 4822.51548174]]    Loss_Validation:  [[ 1420.68903466]]\n",
      "Loop  8099 :    Loss_Train:  [[ 4822.51548047]]    Loss_Validation:  [[ 1420.68912436]]\n",
      "Loop  8100 :    Loss_Train:  [[ 4822.5154792]]    Loss_Validation:  [[ 1420.68921399]]\n",
      "Loop  8101 :    Loss_Train:  [[ 4822.51547794]]    Loss_Validation:  [[ 1420.68930356]]\n",
      "Loop  8102 :    Loss_Train:  [[ 4822.51547667]]    Loss_Validation:  [[ 1420.68939307]]\n",
      "Loop  8103 :    Loss_Train:  [[ 4822.51547541]]    Loss_Validation:  [[ 1420.68948251]]\n",
      "Loop  8104 :    Loss_Train:  [[ 4822.51547415]]    Loss_Validation:  [[ 1420.68957189]]\n",
      "Loop  8105 :    Loss_Train:  [[ 4822.5154729]]    Loss_Validation:  [[ 1420.6896612]]\n",
      "Loop  8106 :    Loss_Train:  [[ 4822.51547164]]    Loss_Validation:  [[ 1420.68975045]]\n",
      "Loop  8107 :    Loss_Train:  [[ 4822.51547039]]    Loss_Validation:  [[ 1420.68983964]]\n",
      "Loop  8108 :    Loss_Train:  [[ 4822.51546914]]    Loss_Validation:  [[ 1420.68992876]]\n",
      "Loop  8109 :    Loss_Train:  [[ 4822.51546789]]    Loss_Validation:  [[ 1420.69001782]]\n",
      "Loop  8110 :    Loss_Train:  [[ 4822.51546664]]    Loss_Validation:  [[ 1420.69010681]]\n",
      "Loop  8111 :    Loss_Train:  [[ 4822.51546539]]    Loss_Validation:  [[ 1420.69019574]]\n",
      "Loop  8112 :    Loss_Train:  [[ 4822.51546415]]    Loss_Validation:  [[ 1420.69028461]]\n",
      "Loop  8113 :    Loss_Train:  [[ 4822.51546291]]    Loss_Validation:  [[ 1420.69037342]]\n",
      "Loop  8114 :    Loss_Train:  [[ 4822.51546167]]    Loss_Validation:  [[ 1420.69046216]]\n",
      "Loop  8115 :    Loss_Train:  [[ 4822.51546043]]    Loss_Validation:  [[ 1420.69055083]]\n",
      "Loop  8116 :    Loss_Train:  [[ 4822.5154592]]    Loss_Validation:  [[ 1420.69063945]]\n",
      "Loop  8117 :    Loss_Train:  [[ 4822.51545796]]    Loss_Validation:  [[ 1420.690728]]\n",
      "Loop  8118 :    Loss_Train:  [[ 4822.51545673]]    Loss_Validation:  [[ 1420.69081649]]\n",
      "Loop  8119 :    Loss_Train:  [[ 4822.5154555]]    Loss_Validation:  [[ 1420.69090491]]\n",
      "Loop  8120 :    Loss_Train:  [[ 4822.51545427]]    Loss_Validation:  [[ 1420.69099327]]\n",
      "Loop  8121 :    Loss_Train:  [[ 4822.51545305]]    Loss_Validation:  [[ 1420.69108157]]\n",
      "Loop  8122 :    Loss_Train:  [[ 4822.51545182]]    Loss_Validation:  [[ 1420.6911698]]\n",
      "Loop  8123 :    Loss_Train:  [[ 4822.5154506]]    Loss_Validation:  [[ 1420.69125797]]\n",
      "Loop  8124 :    Loss_Train:  [[ 4822.51544938]]    Loss_Validation:  [[ 1420.69134608]]\n",
      "Loop  8125 :    Loss_Train:  [[ 4822.51544816]]    Loss_Validation:  [[ 1420.69143412]]\n",
      "Loop  8126 :    Loss_Train:  [[ 4822.51544695]]    Loss_Validation:  [[ 1420.69152211]]\n",
      "Loop  8127 :    Loss_Train:  [[ 4822.51544573]]    Loss_Validation:  [[ 1420.69161003]]\n",
      "Loop  8128 :    Loss_Train:  [[ 4822.51544452]]    Loss_Validation:  [[ 1420.69169788]]\n",
      "Loop  8129 :    Loss_Train:  [[ 4822.51544331]]    Loss_Validation:  [[ 1420.69178567]]\n",
      "Loop  8130 :    Loss_Train:  [[ 4822.5154421]]    Loss_Validation:  [[ 1420.69187341]]\n",
      "Loop  8131 :    Loss_Train:  [[ 4822.51544089]]    Loss_Validation:  [[ 1420.69196107]]\n",
      "Loop  8132 :    Loss_Train:  [[ 4822.51543969]]    Loss_Validation:  [[ 1420.69204868]]\n",
      "Loop  8133 :    Loss_Train:  [[ 4822.51543849]]    Loss_Validation:  [[ 1420.69213622]]\n",
      "Loop  8134 :    Loss_Train:  [[ 4822.51543729]]    Loss_Validation:  [[ 1420.6922237]]\n",
      "Loop  8135 :    Loss_Train:  [[ 4822.51543609]]    Loss_Validation:  [[ 1420.69231112]]\n",
      "Loop  8136 :    Loss_Train:  [[ 4822.51543489]]    Loss_Validation:  [[ 1420.69239847]]\n",
      "Loop  8137 :    Loss_Train:  [[ 4822.51543369]]    Loss_Validation:  [[ 1420.69248576]]\n",
      "Loop  8138 :    Loss_Train:  [[ 4822.5154325]]    Loss_Validation:  [[ 1420.69257299]]\n",
      "Loop  8139 :    Loss_Train:  [[ 4822.51543131]]    Loss_Validation:  [[ 1420.69266016]]\n",
      "Loop  8140 :    Loss_Train:  [[ 4822.51543012]]    Loss_Validation:  [[ 1420.69274726]]\n",
      "Loop  8141 :    Loss_Train:  [[ 4822.51542893]]    Loss_Validation:  [[ 1420.69283431]]\n",
      "Loop  8142 :    Loss_Train:  [[ 4822.51542774]]    Loss_Validation:  [[ 1420.69292129]]\n",
      "Loop  8143 :    Loss_Train:  [[ 4822.51542656]]    Loss_Validation:  [[ 1420.69300821]]\n",
      "Loop  8144 :    Loss_Train:  [[ 4822.51542538]]    Loss_Validation:  [[ 1420.69309506]]\n",
      "Loop  8145 :    Loss_Train:  [[ 4822.5154242]]    Loss_Validation:  [[ 1420.69318185]]\n",
      "Loop  8146 :    Loss_Train:  [[ 4822.51542302]]    Loss_Validation:  [[ 1420.69326859]]\n",
      "Loop  8147 :    Loss_Train:  [[ 4822.51542184]]    Loss_Validation:  [[ 1420.69335526]]\n",
      "Loop  8148 :    Loss_Train:  [[ 4822.51542067]]    Loss_Validation:  [[ 1420.69344186]]\n",
      "Loop  8149 :    Loss_Train:  [[ 4822.51541949]]    Loss_Validation:  [[ 1420.69352841]]\n",
      "Loop  8150 :    Loss_Train:  [[ 4822.51541832]]    Loss_Validation:  [[ 1420.69361489]]\n",
      "Loop  8151 :    Loss_Train:  [[ 4822.51541715]]    Loss_Validation:  [[ 1420.69370131]]\n",
      "Loop  8152 :    Loss_Train:  [[ 4822.51541598]]    Loss_Validation:  [[ 1420.69378767]]\n",
      "Loop  8153 :    Loss_Train:  [[ 4822.51541482]]    Loss_Validation:  [[ 1420.69387397]]\n",
      "Loop  8154 :    Loss_Train:  [[ 4822.51541365]]    Loss_Validation:  [[ 1420.69396021]]\n",
      "Loop  8155 :    Loss_Train:  [[ 4822.51541249]]    Loss_Validation:  [[ 1420.69404638]]\n",
      "Loop  8156 :    Loss_Train:  [[ 4822.51541133]]    Loss_Validation:  [[ 1420.6941325]]\n",
      "Loop  8157 :    Loss_Train:  [[ 4822.51541017]]    Loss_Validation:  [[ 1420.69421855]]\n",
      "Loop  8158 :    Loss_Train:  [[ 4822.51540901]]    Loss_Validation:  [[ 1420.69430454]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  8159 :    Loss_Train:  [[ 4822.51540786]]    Loss_Validation:  [[ 1420.69439047]]\n",
      "Loop  8160 :    Loss_Train:  [[ 4822.51540671]]    Loss_Validation:  [[ 1420.69447633]]\n",
      "Loop  8161 :    Loss_Train:  [[ 4822.51540556]]    Loss_Validation:  [[ 1420.69456214]]\n",
      "Loop  8162 :    Loss_Train:  [[ 4822.51540441]]    Loss_Validation:  [[ 1420.69464788]]\n",
      "Loop  8163 :    Loss_Train:  [[ 4822.51540326]]    Loss_Validation:  [[ 1420.69473356]]\n",
      "Loop  8164 :    Loss_Train:  [[ 4822.51540211]]    Loss_Validation:  [[ 1420.69481919]]\n",
      "Loop  8165 :    Loss_Train:  [[ 4822.51540097]]    Loss_Validation:  [[ 1420.69490474]]\n",
      "Loop  8166 :    Loss_Train:  [[ 4822.51539982]]    Loss_Validation:  [[ 1420.69499024]]\n",
      "Loop  8167 :    Loss_Train:  [[ 4822.51539868]]    Loss_Validation:  [[ 1420.69507568]]\n",
      "Loop  8168 :    Loss_Train:  [[ 4822.51539755]]    Loss_Validation:  [[ 1420.69516106]]\n",
      "Loop  8169 :    Loss_Train:  [[ 4822.51539641]]    Loss_Validation:  [[ 1420.69524637]]\n",
      "Loop  8170 :    Loss_Train:  [[ 4822.51539527]]    Loss_Validation:  [[ 1420.69533163]]\n",
      "Loop  8171 :    Loss_Train:  [[ 4822.51539414]]    Loss_Validation:  [[ 1420.69541682]]\n",
      "Loop  8172 :    Loss_Train:  [[ 4822.51539301]]    Loss_Validation:  [[ 1420.69550195]]\n",
      "Loop  8173 :    Loss_Train:  [[ 4822.51539188]]    Loss_Validation:  [[ 1420.69558702]]\n",
      "Loop  8174 :    Loss_Train:  [[ 4822.51539075]]    Loss_Validation:  [[ 1420.69567203]]\n",
      "Loop  8175 :    Loss_Train:  [[ 4822.51538962]]    Loss_Validation:  [[ 1420.69575698]]\n",
      "Loop  8176 :    Loss_Train:  [[ 4822.5153885]]    Loss_Validation:  [[ 1420.69584187]]\n",
      "Loop  8177 :    Loss_Train:  [[ 4822.51538738]]    Loss_Validation:  [[ 1420.6959267]]\n",
      "Loop  8178 :    Loss_Train:  [[ 4822.51538625]]    Loss_Validation:  [[ 1420.69601147]]\n",
      "Loop  8179 :    Loss_Train:  [[ 4822.51538514]]    Loss_Validation:  [[ 1420.69609618]]\n",
      "Loop  8180 :    Loss_Train:  [[ 4822.51538402]]    Loss_Validation:  [[ 1420.69618082]]\n",
      "Loop  8181 :    Loss_Train:  [[ 4822.5153829]]    Loss_Validation:  [[ 1420.69626541]]\n",
      "Loop  8182 :    Loss_Train:  [[ 4822.51538179]]    Loss_Validation:  [[ 1420.69634993]]\n",
      "Loop  8183 :    Loss_Train:  [[ 4822.51538067]]    Loss_Validation:  [[ 1420.6964344]]\n",
      "Loop  8184 :    Loss_Train:  [[ 4822.51537956]]    Loss_Validation:  [[ 1420.6965188]]\n",
      "Loop  8185 :    Loss_Train:  [[ 4822.51537846]]    Loss_Validation:  [[ 1420.69660314]]\n",
      "Loop  8186 :    Loss_Train:  [[ 4822.51537735]]    Loss_Validation:  [[ 1420.69668743]]\n",
      "Loop  8187 :    Loss_Train:  [[ 4822.51537624]]    Loss_Validation:  [[ 1420.69677165]]\n",
      "Loop  8188 :    Loss_Train:  [[ 4822.51537514]]    Loss_Validation:  [[ 1420.69685581]]\n",
      "Loop  8189 :    Loss_Train:  [[ 4822.51537404]]    Loss_Validation:  [[ 1420.69693992]]\n",
      "Loop  8190 :    Loss_Train:  [[ 4822.51537294]]    Loss_Validation:  [[ 1420.69702396]]\n",
      "Loop  8191 :    Loss_Train:  [[ 4822.51537184]]    Loss_Validation:  [[ 1420.69710794]]\n",
      "Loop  8192 :    Loss_Train:  [[ 4822.51537074]]    Loss_Validation:  [[ 1420.69719186]]\n",
      "Loop  8193 :    Loss_Train:  [[ 4822.51536965]]    Loss_Validation:  [[ 1420.69727572]]\n",
      "Loop  8194 :    Loss_Train:  [[ 4822.51536855]]    Loss_Validation:  [[ 1420.69735953]]\n",
      "Loop  8195 :    Loss_Train:  [[ 4822.51536746]]    Loss_Validation:  [[ 1420.69744327]]\n",
      "Loop  8196 :    Loss_Train:  [[ 4822.51536637]]    Loss_Validation:  [[ 1420.69752695]]\n",
      "Loop  8197 :    Loss_Train:  [[ 4822.51536528]]    Loss_Validation:  [[ 1420.69761057]]\n",
      "Loop  8198 :    Loss_Train:  [[ 4822.5153642]]    Loss_Validation:  [[ 1420.69769413]]\n",
      "Loop  8199 :    Loss_Train:  [[ 4822.51536311]]    Loss_Validation:  [[ 1420.69777764]]\n",
      "Loop  8200 :    Loss_Train:  [[ 4822.51536203]]    Loss_Validation:  [[ 1420.69786108]]\n",
      "Loop  8201 :    Loss_Train:  [[ 4822.51536095]]    Loss_Validation:  [[ 1420.69794446]]\n",
      "Loop  8202 :    Loss_Train:  [[ 4822.51535987]]    Loss_Validation:  [[ 1420.69802779]]\n",
      "Loop  8203 :    Loss_Train:  [[ 4822.51535879]]    Loss_Validation:  [[ 1420.69811105]]\n",
      "Loop  8204 :    Loss_Train:  [[ 4822.51535771]]    Loss_Validation:  [[ 1420.69819425]]\n",
      "Loop  8205 :    Loss_Train:  [[ 4822.51535664]]    Loss_Validation:  [[ 1420.6982774]]\n",
      "Loop  8206 :    Loss_Train:  [[ 4822.51535556]]    Loss_Validation:  [[ 1420.69836048]]\n",
      "Loop  8207 :    Loss_Train:  [[ 4822.51535449]]    Loss_Validation:  [[ 1420.69844351]]\n",
      "Loop  8208 :    Loss_Train:  [[ 4822.51535342]]    Loss_Validation:  [[ 1420.69852647]]\n",
      "Loop  8209 :    Loss_Train:  [[ 4822.51535236]]    Loss_Validation:  [[ 1420.69860938]]\n",
      "Loop  8210 :    Loss_Train:  [[ 4822.51535129]]    Loss_Validation:  [[ 1420.69869223]]\n",
      "Loop  8211 :    Loss_Train:  [[ 4822.51535022]]    Loss_Validation:  [[ 1420.69877502]]\n",
      "Loop  8212 :    Loss_Train:  [[ 4822.51534916]]    Loss_Validation:  [[ 1420.69885774]]\n",
      "Loop  8213 :    Loss_Train:  [[ 4822.5153481]]    Loss_Validation:  [[ 1420.69894041]]\n",
      "Loop  8214 :    Loss_Train:  [[ 4822.51534704]]    Loss_Validation:  [[ 1420.69902302]]\n",
      "Loop  8215 :    Loss_Train:  [[ 4822.51534598]]    Loss_Validation:  [[ 1420.69910558]]\n",
      "Loop  8216 :    Loss_Train:  [[ 4822.51534493]]    Loss_Validation:  [[ 1420.69918807]]\n",
      "Loop  8217 :    Loss_Train:  [[ 4822.51534387]]    Loss_Validation:  [[ 1420.6992705]]\n",
      "Loop  8218 :    Loss_Train:  [[ 4822.51534282]]    Loss_Validation:  [[ 1420.69935287]]\n",
      "Loop  8219 :    Loss_Train:  [[ 4822.51534177]]    Loss_Validation:  [[ 1420.69943519]]\n",
      "Loop  8220 :    Loss_Train:  [[ 4822.51534072]]    Loss_Validation:  [[ 1420.69951745]]\n",
      "Loop  8221 :    Loss_Train:  [[ 4822.51533967]]    Loss_Validation:  [[ 1420.69959964]]\n",
      "Loop  8222 :    Loss_Train:  [[ 4822.51533862]]    Loss_Validation:  [[ 1420.69968178]]\n",
      "Loop  8223 :    Loss_Train:  [[ 4822.51533758]]    Loss_Validation:  [[ 1420.69976386]]\n",
      "Loop  8224 :    Loss_Train:  [[ 4822.51533653]]    Loss_Validation:  [[ 1420.69984588]]\n",
      "Loop  8225 :    Loss_Train:  [[ 4822.51533549]]    Loss_Validation:  [[ 1420.69992784]]\n",
      "Loop  8226 :    Loss_Train:  [[ 4822.51533445]]    Loss_Validation:  [[ 1420.70000975]]\n",
      "Loop  8227 :    Loss_Train:  [[ 4822.51533341]]    Loss_Validation:  [[ 1420.70009159]]\n",
      "Loop  8228 :    Loss_Train:  [[ 4822.51533238]]    Loss_Validation:  [[ 1420.70017338]]\n",
      "Loop  8229 :    Loss_Train:  [[ 4822.51533134]]    Loss_Validation:  [[ 1420.70025511]]\n",
      "Loop  8230 :    Loss_Train:  [[ 4822.51533031]]    Loss_Validation:  [[ 1420.70033678]]\n",
      "Loop  8231 :    Loss_Train:  [[ 4822.51532928]]    Loss_Validation:  [[ 1420.70041839]]\n",
      "Loop  8232 :    Loss_Train:  [[ 4822.51532825]]    Loss_Validation:  [[ 1420.70049994]]\n",
      "Loop  8233 :    Loss_Train:  [[ 4822.51532722]]    Loss_Validation:  [[ 1420.70058143]]\n",
      "Loop  8234 :    Loss_Train:  [[ 4822.51532619]]    Loss_Validation:  [[ 1420.70066287]]\n",
      "Loop  8235 :    Loss_Train:  [[ 4822.51532517]]    Loss_Validation:  [[ 1420.70074424]]\n",
      "Loop  8236 :    Loss_Train:  [[ 4822.51532414]]    Loss_Validation:  [[ 1420.70082556]]\n",
      "Loop  8237 :    Loss_Train:  [[ 4822.51532312]]    Loss_Validation:  [[ 1420.70090682]]\n",
      "Loop  8238 :    Loss_Train:  [[ 4822.5153221]]    Loss_Validation:  [[ 1420.70098803]]\n",
      "Loop  8239 :    Loss_Train:  [[ 4822.51532108]]    Loss_Validation:  [[ 1420.70106917]]\n",
      "Loop  8240 :    Loss_Train:  [[ 4822.51532006]]    Loss_Validation:  [[ 1420.70115026]]\n",
      "Loop  8241 :    Loss_Train:  [[ 4822.51531905]]    Loss_Validation:  [[ 1420.70123129]]\n",
      "Loop  8242 :    Loss_Train:  [[ 4822.51531803]]    Loss_Validation:  [[ 1420.70131226]]\n",
      "Loop  8243 :    Loss_Train:  [[ 4822.51531702]]    Loss_Validation:  [[ 1420.70139317]]\n",
      "Loop  8244 :    Loss_Train:  [[ 4822.51531601]]    Loss_Validation:  [[ 1420.70147402]]\n",
      "Loop  8245 :    Loss_Train:  [[ 4822.515315]]    Loss_Validation:  [[ 1420.70155482]]\n",
      "Loop  8246 :    Loss_Train:  [[ 4822.51531399]]    Loss_Validation:  [[ 1420.70163556]]\n",
      "Loop  8247 :    Loss_Train:  [[ 4822.51531299]]    Loss_Validation:  [[ 1420.70171624]]\n",
      "Loop  8248 :    Loss_Train:  [[ 4822.51531198]]    Loss_Validation:  [[ 1420.70179686]]\n",
      "Loop  8249 :    Loss_Train:  [[ 4822.51531098]]    Loss_Validation:  [[ 1420.70187743]]\n",
      "Loop  8250 :    Loss_Train:  [[ 4822.51530998]]    Loss_Validation:  [[ 1420.70195793]]\n",
      "Loop  8251 :    Loss_Train:  [[ 4822.51530898]]    Loss_Validation:  [[ 1420.70203838]]\n",
      "Loop  8252 :    Loss_Train:  [[ 4822.51530798]]    Loss_Validation:  [[ 1420.70211878]]\n",
      "Loop  8253 :    Loss_Train:  [[ 4822.51530698]]    Loss_Validation:  [[ 1420.70219911]]\n",
      "Loop  8254 :    Loss_Train:  [[ 4822.51530599]]    Loss_Validation:  [[ 1420.70227939]]\n",
      "Loop  8255 :    Loss_Train:  [[ 4822.51530499]]    Loss_Validation:  [[ 1420.70235961]]\n",
      "Loop  8256 :    Loss_Train:  [[ 4822.515304]]    Loss_Validation:  [[ 1420.70243977]]\n",
      "Loop  8257 :    Loss_Train:  [[ 4822.51530301]]    Loss_Validation:  [[ 1420.70251988]]\n",
      "Loop  8258 :    Loss_Train:  [[ 4822.51530202]]    Loss_Validation:  [[ 1420.70259992]]\n",
      "Loop  8259 :    Loss_Train:  [[ 4822.51530103]]    Loss_Validation:  [[ 1420.70267991]]\n",
      "Loop  8260 :    Loss_Train:  [[ 4822.51530005]]    Loss_Validation:  [[ 1420.70275985]]\n",
      "Loop  8261 :    Loss_Train:  [[ 4822.51529906]]    Loss_Validation:  [[ 1420.70283972]]\n",
      "Loop  8262 :    Loss_Train:  [[ 4822.51529808]]    Loss_Validation:  [[ 1420.70291954]]\n",
      "Loop  8263 :    Loss_Train:  [[ 4822.5152971]]    Loss_Validation:  [[ 1420.7029993]]\n",
      "Loop  8264 :    Loss_Train:  [[ 4822.51529612]]    Loss_Validation:  [[ 1420.70307901]]\n",
      "Loop  8265 :    Loss_Train:  [[ 4822.51529514]]    Loss_Validation:  [[ 1420.70315865]]\n",
      "Loop  8266 :    Loss_Train:  [[ 4822.51529416]]    Loss_Validation:  [[ 1420.70323824]]\n",
      "Loop  8267 :    Loss_Train:  [[ 4822.51529319]]    Loss_Validation:  [[ 1420.70331778]]\n",
      "Loop  8268 :    Loss_Train:  [[ 4822.51529221]]    Loss_Validation:  [[ 1420.70339725]]\n",
      "Loop  8269 :    Loss_Train:  [[ 4822.51529124]]    Loss_Validation:  [[ 1420.70347667]]\n",
      "Loop  8270 :    Loss_Train:  [[ 4822.51529027]]    Loss_Validation:  [[ 1420.70355603]]\n",
      "Loop  8271 :    Loss_Train:  [[ 4822.5152893]]    Loss_Validation:  [[ 1420.70363534]]\n",
      "Loop  8272 :    Loss_Train:  [[ 4822.51528833]]    Loss_Validation:  [[ 1420.70371459]]\n",
      "Loop  8273 :    Loss_Train:  [[ 4822.51528737]]    Loss_Validation:  [[ 1420.70379378]]\n",
      "Loop  8274 :    Loss_Train:  [[ 4822.5152864]]    Loss_Validation:  [[ 1420.70387292]]\n",
      "Loop  8275 :    Loss_Train:  [[ 4822.51528544]]    Loss_Validation:  [[ 1420.70395199]]\n",
      "Loop  8276 :    Loss_Train:  [[ 4822.51528448]]    Loss_Validation:  [[ 1420.70403102]]\n",
      "Loop  8277 :    Loss_Train:  [[ 4822.51528352]]    Loss_Validation:  [[ 1420.70410998]]\n",
      "Loop  8278 :    Loss_Train:  [[ 4822.51528256]]    Loss_Validation:  [[ 1420.70418889]]\n",
      "Loop  8279 :    Loss_Train:  [[ 4822.5152816]]    Loss_Validation:  [[ 1420.70426774]]\n",
      "Loop  8280 :    Loss_Train:  [[ 4822.51528065]]    Loss_Validation:  [[ 1420.70434654]]\n",
      "Loop  8281 :    Loss_Train:  [[ 4822.51527969]]    Loss_Validation:  [[ 1420.70442528]]\n",
      "Loop  8282 :    Loss_Train:  [[ 4822.51527874]]    Loss_Validation:  [[ 1420.70450396]]\n",
      "Loop  8283 :    Loss_Train:  [[ 4822.51527779]]    Loss_Validation:  [[ 1420.70458259]]\n",
      "Loop  8284 :    Loss_Train:  [[ 4822.51527684]]    Loss_Validation:  [[ 1420.70466116]]\n",
      "Loop  8285 :    Loss_Train:  [[ 4822.51527589]]    Loss_Validation:  [[ 1420.70473967]]\n",
      "Loop  8286 :    Loss_Train:  [[ 4822.51527494]]    Loss_Validation:  [[ 1420.70481813]]\n",
      "Loop  8287 :    Loss_Train:  [[ 4822.515274]]    Loss_Validation:  [[ 1420.70489653]]\n",
      "Loop  8288 :    Loss_Train:  [[ 4822.51527306]]    Loss_Validation:  [[ 1420.70497488]]\n",
      "Loop  8289 :    Loss_Train:  [[ 4822.51527211]]    Loss_Validation:  [[ 1420.70505317]]\n",
      "Loop  8290 :    Loss_Train:  [[ 4822.51527117]]    Loss_Validation:  [[ 1420.7051314]]\n",
      "Loop  8291 :    Loss_Train:  [[ 4822.51527023]]    Loss_Validation:  [[ 1420.70520958]]\n",
      "Loop  8292 :    Loss_Train:  [[ 4822.5152693]]    Loss_Validation:  [[ 1420.7052877]]\n",
      "Loop  8293 :    Loss_Train:  [[ 4822.51526836]]    Loss_Validation:  [[ 1420.70536576]]\n",
      "Loop  8294 :    Loss_Train:  [[ 4822.51526742]]    Loss_Validation:  [[ 1420.70544377]]\n",
      "Loop  8295 :    Loss_Train:  [[ 4822.51526649]]    Loss_Validation:  [[ 1420.70552172]]\n",
      "Loop  8296 :    Loss_Train:  [[ 4822.51526556]]    Loss_Validation:  [[ 1420.70559962]]\n",
      "Loop  8297 :    Loss_Train:  [[ 4822.51526463]]    Loss_Validation:  [[ 1420.70567746]]\n",
      "Loop  8298 :    Loss_Train:  [[ 4822.5152637]]    Loss_Validation:  [[ 1420.70575525]]\n",
      "Loop  8299 :    Loss_Train:  [[ 4822.51526277]]    Loss_Validation:  [[ 1420.70583298]]\n",
      "Loop  8300 :    Loss_Train:  [[ 4822.51526185]]    Loss_Validation:  [[ 1420.70591066]]\n",
      "Loop  8301 :    Loss_Train:  [[ 4822.51526092]]    Loss_Validation:  [[ 1420.70598827]]\n",
      "Loop  8302 :    Loss_Train:  [[ 4822.51526]]    Loss_Validation:  [[ 1420.70606584]]\n",
      "Loop  8303 :    Loss_Train:  [[ 4822.51525908]]    Loss_Validation:  [[ 1420.70614335]]\n",
      "Loop  8304 :    Loss_Train:  [[ 4822.51525816]]    Loss_Validation:  [[ 1420.7062208]]\n",
      "Loop  8305 :    Loss_Train:  [[ 4822.51525724]]    Loss_Validation:  [[ 1420.7062982]]\n",
      "Loop  8306 :    Loss_Train:  [[ 4822.51525632]]    Loss_Validation:  [[ 1420.70637554]]\n",
      "Loop  8307 :    Loss_Train:  [[ 4822.5152554]]    Loss_Validation:  [[ 1420.70645282]]\n",
      "Loop  8308 :    Loss_Train:  [[ 4822.51525449]]    Loss_Validation:  [[ 1420.70653005]]\n",
      "Loop  8309 :    Loss_Train:  [[ 4822.51525358]]    Loss_Validation:  [[ 1420.70660723]]\n",
      "Loop  8310 :    Loss_Train:  [[ 4822.51525266]]    Loss_Validation:  [[ 1420.70668435]]\n",
      "Loop  8311 :    Loss_Train:  [[ 4822.51525175]]    Loss_Validation:  [[ 1420.70676141]]\n",
      "Loop  8312 :    Loss_Train:  [[ 4822.51525084]]    Loss_Validation:  [[ 1420.70683842]]\n",
      "Loop  8313 :    Loss_Train:  [[ 4822.51524994]]    Loss_Validation:  [[ 1420.70691538]]\n",
      "Loop  8314 :    Loss_Train:  [[ 4822.51524903]]    Loss_Validation:  [[ 1420.70699228]]\n",
      "Loop  8315 :    Loss_Train:  [[ 4822.51524813]]    Loss_Validation:  [[ 1420.70706912]]\n",
      "Loop  8316 :    Loss_Train:  [[ 4822.51524722]]    Loss_Validation:  [[ 1420.70714591]]\n",
      "Loop  8317 :    Loss_Train:  [[ 4822.51524632]]    Loss_Validation:  [[ 1420.70722264]]\n",
      "Loop  8318 :    Loss_Train:  [[ 4822.51524542]]    Loss_Validation:  [[ 1420.70729932]]\n",
      "Loop  8319 :    Loss_Train:  [[ 4822.51524452]]    Loss_Validation:  [[ 1420.70737595]]\n",
      "Loop  8320 :    Loss_Train:  [[ 4822.51524362]]    Loss_Validation:  [[ 1420.70745252]]\n",
      "Loop  8321 :    Loss_Train:  [[ 4822.51524273]]    Loss_Validation:  [[ 1420.70752903]]\n",
      "Loop  8322 :    Loss_Train:  [[ 4822.51524183]]    Loss_Validation:  [[ 1420.70760549]]\n",
      "Loop  8323 :    Loss_Train:  [[ 4822.51524094]]    Loss_Validation:  [[ 1420.7076819]]\n",
      "Loop  8324 :    Loss_Train:  [[ 4822.51524005]]    Loss_Validation:  [[ 1420.70775825]]\n",
      "Loop  8325 :    Loss_Train:  [[ 4822.51523916]]    Loss_Validation:  [[ 1420.70783454]]\n",
      "Loop  8326 :    Loss_Train:  [[ 4822.51523827]]    Loss_Validation:  [[ 1420.70791078]]\n",
      "Loop  8327 :    Loss_Train:  [[ 4822.51523738]]    Loss_Validation:  [[ 1420.70798697]]\n",
      "Loop  8328 :    Loss_Train:  [[ 4822.51523649]]    Loss_Validation:  [[ 1420.7080631]]\n",
      "Loop  8329 :    Loss_Train:  [[ 4822.51523561]]    Loss_Validation:  [[ 1420.70813918]]\n",
      "Loop  8330 :    Loss_Train:  [[ 4822.51523472]]    Loss_Validation:  [[ 1420.7082152]]\n",
      "Loop  8331 :    Loss_Train:  [[ 4822.51523384]]    Loss_Validation:  [[ 1420.70829117]]\n",
      "Loop  8332 :    Loss_Train:  [[ 4822.51523296]]    Loss_Validation:  [[ 1420.70836708]]\n",
      "Loop  8333 :    Loss_Train:  [[ 4822.51523208]]    Loss_Validation:  [[ 1420.70844294]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  8334 :    Loss_Train:  [[ 4822.5152312]]    Loss_Validation:  [[ 1420.70851875]]\n",
      "Loop  8335 :    Loss_Train:  [[ 4822.51523033]]    Loss_Validation:  [[ 1420.7085945]]\n",
      "Loop  8336 :    Loss_Train:  [[ 4822.51522945]]    Loss_Validation:  [[ 1420.70867019]]\n",
      "Loop  8337 :    Loss_Train:  [[ 4822.51522858]]    Loss_Validation:  [[ 1420.70874583]]\n",
      "Loop  8338 :    Loss_Train:  [[ 4822.5152277]]    Loss_Validation:  [[ 1420.70882142]]\n",
      "Loop  8339 :    Loss_Train:  [[ 4822.51522683]]    Loss_Validation:  [[ 1420.70889696]]\n",
      "Loop  8340 :    Loss_Train:  [[ 4822.51522596]]    Loss_Validation:  [[ 1420.70897244]]\n",
      "Loop  8341 :    Loss_Train:  [[ 4822.51522509]]    Loss_Validation:  [[ 1420.70904786]]\n",
      "Loop  8342 :    Loss_Train:  [[ 4822.51522423]]    Loss_Validation:  [[ 1420.70912323]]\n",
      "Loop  8343 :    Loss_Train:  [[ 4822.51522336]]    Loss_Validation:  [[ 1420.70919855]]\n",
      "Loop  8344 :    Loss_Train:  [[ 4822.5152225]]    Loss_Validation:  [[ 1420.70927381]]\n",
      "Loop  8345 :    Loss_Train:  [[ 4822.51522163]]    Loss_Validation:  [[ 1420.70934902]]\n",
      "Loop  8346 :    Loss_Train:  [[ 4822.51522077]]    Loss_Validation:  [[ 1420.70942418]]\n",
      "Loop  8347 :    Loss_Train:  [[ 4822.51521991]]    Loss_Validation:  [[ 1420.70949928]]\n",
      "Loop  8348 :    Loss_Train:  [[ 4822.51521905]]    Loss_Validation:  [[ 1420.70957433]]\n",
      "Loop  8349 :    Loss_Train:  [[ 4822.5152182]]    Loss_Validation:  [[ 1420.70964932]]\n",
      "Loop  8350 :    Loss_Train:  [[ 4822.51521734]]    Loss_Validation:  [[ 1420.70972426]]\n",
      "Loop  8351 :    Loss_Train:  [[ 4822.51521648]]    Loss_Validation:  [[ 1420.70979915]]\n",
      "Loop  8352 :    Loss_Train:  [[ 4822.51521563]]    Loss_Validation:  [[ 1420.70987398]]\n",
      "Loop  8353 :    Loss_Train:  [[ 4822.51521478]]    Loss_Validation:  [[ 1420.70994876]]\n",
      "Loop  8354 :    Loss_Train:  [[ 4822.51521393]]    Loss_Validation:  [[ 1420.71002349]]\n",
      "Loop  8355 :    Loss_Train:  [[ 4822.51521308]]    Loss_Validation:  [[ 1420.71009816]]\n",
      "Loop  8356 :    Loss_Train:  [[ 4822.51521223]]    Loss_Validation:  [[ 1420.71017278]]\n",
      "Loop  8357 :    Loss_Train:  [[ 4822.51521138]]    Loss_Validation:  [[ 1420.71024734]]\n",
      "Loop  8358 :    Loss_Train:  [[ 4822.51521054]]    Loss_Validation:  [[ 1420.71032186]]\n",
      "Loop  8359 :    Loss_Train:  [[ 4822.51520969]]    Loss_Validation:  [[ 1420.71039632]]\n",
      "Loop  8360 :    Loss_Train:  [[ 4822.51520885]]    Loss_Validation:  [[ 1420.71047072]]\n",
      "Loop  8361 :    Loss_Train:  [[ 4822.51520801]]    Loss_Validation:  [[ 1420.71054507]]\n",
      "Loop  8362 :    Loss_Train:  [[ 4822.51520717]]    Loss_Validation:  [[ 1420.71061937]]\n",
      "Loop  8363 :    Loss_Train:  [[ 4822.51520633]]    Loss_Validation:  [[ 1420.71069362]]\n",
      "Loop  8364 :    Loss_Train:  [[ 4822.51520549]]    Loss_Validation:  [[ 1420.71076781]]\n",
      "Loop  8365 :    Loss_Train:  [[ 4822.51520465]]    Loss_Validation:  [[ 1420.71084195]]\n",
      "Loop  8366 :    Loss_Train:  [[ 4822.51520382]]    Loss_Validation:  [[ 1420.71091603]]\n",
      "Loop  8367 :    Loss_Train:  [[ 4822.51520298]]    Loss_Validation:  [[ 1420.71099007]]\n",
      "Loop  8368 :    Loss_Train:  [[ 4822.51520215]]    Loss_Validation:  [[ 1420.71106405]]\n",
      "Loop  8369 :    Loss_Train:  [[ 4822.51520132]]    Loss_Validation:  [[ 1420.71113797]]\n",
      "Loop  8370 :    Loss_Train:  [[ 4822.51520049]]    Loss_Validation:  [[ 1420.71121185]]\n",
      "Loop  8371 :    Loss_Train:  [[ 4822.51519966]]    Loss_Validation:  [[ 1420.71128567]]\n",
      "Loop  8372 :    Loss_Train:  [[ 4822.51519883]]    Loss_Validation:  [[ 1420.71135943]]\n",
      "Loop  8373 :    Loss_Train:  [[ 4822.51519801]]    Loss_Validation:  [[ 1420.71143315]]\n",
      "Loop  8374 :    Loss_Train:  [[ 4822.51519718]]    Loss_Validation:  [[ 1420.71150681]]\n",
      "Loop  8375 :    Loss_Train:  [[ 4822.51519636]]    Loss_Validation:  [[ 1420.71158042]]\n",
      "Loop  8376 :    Loss_Train:  [[ 4822.51519554]]    Loss_Validation:  [[ 1420.71165398]]\n",
      "Loop  8377 :    Loss_Train:  [[ 4822.51519471]]    Loss_Validation:  [[ 1420.71172748]]\n",
      "Loop  8378 :    Loss_Train:  [[ 4822.51519389]]    Loss_Validation:  [[ 1420.71180093]]\n",
      "Loop  8379 :    Loss_Train:  [[ 4822.51519308]]    Loss_Validation:  [[ 1420.71187433]]\n",
      "Loop  8380 :    Loss_Train:  [[ 4822.51519226]]    Loss_Validation:  [[ 1420.71194768]]\n",
      "Loop  8381 :    Loss_Train:  [[ 4822.51519144]]    Loss_Validation:  [[ 1420.71202097]]\n",
      "Loop  8382 :    Loss_Train:  [[ 4822.51519063]]    Loss_Validation:  [[ 1420.71209421]]\n",
      "Loop  8383 :    Loss_Train:  [[ 4822.51518982]]    Loss_Validation:  [[ 1420.7121674]]\n",
      "Loop  8384 :    Loss_Train:  [[ 4822.515189]]    Loss_Validation:  [[ 1420.71224053]]\n",
      "Loop  8385 :    Loss_Train:  [[ 4822.51518819]]    Loss_Validation:  [[ 1420.71231362]]\n",
      "Loop  8386 :    Loss_Train:  [[ 4822.51518738]]    Loss_Validation:  [[ 1420.71238665]]\n",
      "Loop  8387 :    Loss_Train:  [[ 4822.51518657]]    Loss_Validation:  [[ 1420.71245963]]\n",
      "Loop  8388 :    Loss_Train:  [[ 4822.51518577]]    Loss_Validation:  [[ 1420.71253255]]\n",
      "Loop  8389 :    Loss_Train:  [[ 4822.51518496]]    Loss_Validation:  [[ 1420.71260543]]\n",
      "Loop  8390 :    Loss_Train:  [[ 4822.51518416]]    Loss_Validation:  [[ 1420.71267825]]\n",
      "Loop  8391 :    Loss_Train:  [[ 4822.51518335]]    Loss_Validation:  [[ 1420.71275102]]\n",
      "Loop  8392 :    Loss_Train:  [[ 4822.51518255]]    Loss_Validation:  [[ 1420.71282374]]\n",
      "Loop  8393 :    Loss_Train:  [[ 4822.51518175]]    Loss_Validation:  [[ 1420.7128964]]\n",
      "Loop  8394 :    Loss_Train:  [[ 4822.51518095]]    Loss_Validation:  [[ 1420.71296902]]\n",
      "Loop  8395 :    Loss_Train:  [[ 4822.51518015]]    Loss_Validation:  [[ 1420.71304158]]\n",
      "Loop  8396 :    Loss_Train:  [[ 4822.51517936]]    Loss_Validation:  [[ 1420.71311409]]\n",
      "Loop  8397 :    Loss_Train:  [[ 4822.51517856]]    Loss_Validation:  [[ 1420.71318654]]\n",
      "Loop  8398 :    Loss_Train:  [[ 4822.51517777]]    Loss_Validation:  [[ 1420.71325895]]\n",
      "Loop  8399 :    Loss_Train:  [[ 4822.51517697]]    Loss_Validation:  [[ 1420.7133313]]\n",
      "Loop  8400 :    Loss_Train:  [[ 4822.51517618]]    Loss_Validation:  [[ 1420.7134036]]\n",
      "Loop  8401 :    Loss_Train:  [[ 4822.51517539]]    Loss_Validation:  [[ 1420.71347585]]\n",
      "Loop  8402 :    Loss_Train:  [[ 4822.5151746]]    Loss_Validation:  [[ 1420.71354805]]\n",
      "Loop  8403 :    Loss_Train:  [[ 4822.51517381]]    Loss_Validation:  [[ 1420.7136202]]\n",
      "Loop  8404 :    Loss_Train:  [[ 4822.51517303]]    Loss_Validation:  [[ 1420.71369229]]\n",
      "Loop  8405 :    Loss_Train:  [[ 4822.51517224]]    Loss_Validation:  [[ 1420.71376433]]\n",
      "Loop  8406 :    Loss_Train:  [[ 4822.51517146]]    Loss_Validation:  [[ 1420.71383633]]\n",
      "Loop  8407 :    Loss_Train:  [[ 4822.51517067]]    Loss_Validation:  [[ 1420.71390826]]\n",
      "Loop  8408 :    Loss_Train:  [[ 4822.51516989]]    Loss_Validation:  [[ 1420.71398015]]\n",
      "Loop  8409 :    Loss_Train:  [[ 4822.51516911]]    Loss_Validation:  [[ 1420.71405199]]\n",
      "Loop  8410 :    Loss_Train:  [[ 4822.51516833]]    Loss_Validation:  [[ 1420.71412377]]\n",
      "Loop  8411 :    Loss_Train:  [[ 4822.51516755]]    Loss_Validation:  [[ 1420.71419551]]\n",
      "Loop  8412 :    Loss_Train:  [[ 4822.51516677]]    Loss_Validation:  [[ 1420.71426719]]\n",
      "Loop  8413 :    Loss_Train:  [[ 4822.515166]]    Loss_Validation:  [[ 1420.71433882]]\n",
      "Loop  8414 :    Loss_Train:  [[ 4822.51516522]]    Loss_Validation:  [[ 1420.7144104]]\n",
      "Loop  8415 :    Loss_Train:  [[ 4822.51516445]]    Loss_Validation:  [[ 1420.71448193]]\n",
      "Loop  8416 :    Loss_Train:  [[ 4822.51516368]]    Loss_Validation:  [[ 1420.7145534]]\n",
      "Loop  8417 :    Loss_Train:  [[ 4822.51516291]]    Loss_Validation:  [[ 1420.71462483]]\n",
      "Loop  8418 :    Loss_Train:  [[ 4822.51516214]]    Loss_Validation:  [[ 1420.7146962]]\n",
      "Loop  8419 :    Loss_Train:  [[ 4822.51516137]]    Loss_Validation:  [[ 1420.71476753]]\n",
      "Loop  8420 :    Loss_Train:  [[ 4822.5151606]]    Loss_Validation:  [[ 1420.7148388]]\n",
      "Loop  8421 :    Loss_Train:  [[ 4822.51515983]]    Loss_Validation:  [[ 1420.71491002]]\n",
      "Loop  8422 :    Loss_Train:  [[ 4822.51515907]]    Loss_Validation:  [[ 1420.71498119]]\n",
      "Loop  8423 :    Loss_Train:  [[ 4822.5151583]]    Loss_Validation:  [[ 1420.71505231]]\n",
      "Loop  8424 :    Loss_Train:  [[ 4822.51515754]]    Loss_Validation:  [[ 1420.71512338]]\n",
      "Loop  8425 :    Loss_Train:  [[ 4822.51515678]]    Loss_Validation:  [[ 1420.71519439]]\n",
      "Loop  8426 :    Loss_Train:  [[ 4822.51515602]]    Loss_Validation:  [[ 1420.71526536]]\n",
      "Loop  8427 :    Loss_Train:  [[ 4822.51515526]]    Loss_Validation:  [[ 1420.71533627]]\n",
      "Loop  8428 :    Loss_Train:  [[ 4822.5151545]]    Loss_Validation:  [[ 1420.71540714]]\n",
      "Loop  8429 :    Loss_Train:  [[ 4822.51515375]]    Loss_Validation:  [[ 1420.71547795]]\n",
      "Loop  8430 :    Loss_Train:  [[ 4822.51515299]]    Loss_Validation:  [[ 1420.71554871]]\n",
      "Loop  8431 :    Loss_Train:  [[ 4822.51515224]]    Loss_Validation:  [[ 1420.71561942]]\n",
      "Loop  8432 :    Loss_Train:  [[ 4822.51515148]]    Loss_Validation:  [[ 1420.71569009]]\n",
      "Loop  8433 :    Loss_Train:  [[ 4822.51515073]]    Loss_Validation:  [[ 1420.7157607]]\n",
      "Loop  8434 :    Loss_Train:  [[ 4822.51514998]]    Loss_Validation:  [[ 1420.71583126]]\n",
      "Loop  8435 :    Loss_Train:  [[ 4822.51514923]]    Loss_Validation:  [[ 1420.71590177]]\n",
      "Loop  8436 :    Loss_Train:  [[ 4822.51514848]]    Loss_Validation:  [[ 1420.71597222]]\n",
      "Loop  8437 :    Loss_Train:  [[ 4822.51514773]]    Loss_Validation:  [[ 1420.71604263]]\n",
      "Loop  8438 :    Loss_Train:  [[ 4822.51514699]]    Loss_Validation:  [[ 1420.71611299]]\n",
      "Loop  8439 :    Loss_Train:  [[ 4822.51514624]]    Loss_Validation:  [[ 1420.7161833]]\n",
      "Loop  8440 :    Loss_Train:  [[ 4822.5151455]]    Loss_Validation:  [[ 1420.71625355]]\n",
      "Loop  8441 :    Loss_Train:  [[ 4822.51514475]]    Loss_Validation:  [[ 1420.71632376]]\n",
      "Loop  8442 :    Loss_Train:  [[ 4822.51514401]]    Loss_Validation:  [[ 1420.71639392]]\n",
      "Loop  8443 :    Loss_Train:  [[ 4822.51514327]]    Loss_Validation:  [[ 1420.71646402]]\n",
      "Loop  8444 :    Loss_Train:  [[ 4822.51514253]]    Loss_Validation:  [[ 1420.71653408]]\n",
      "Loop  8445 :    Loss_Train:  [[ 4822.5151418]]    Loss_Validation:  [[ 1420.71660408]]\n",
      "Loop  8446 :    Loss_Train:  [[ 4822.51514106]]    Loss_Validation:  [[ 1420.71667404]]\n",
      "Loop  8447 :    Loss_Train:  [[ 4822.51514032]]    Loss_Validation:  [[ 1420.71674394]]\n",
      "Loop  8448 :    Loss_Train:  [[ 4822.51513959]]    Loss_Validation:  [[ 1420.7168138]]\n",
      "Loop  8449 :    Loss_Train:  [[ 4822.51513885]]    Loss_Validation:  [[ 1420.7168836]]\n",
      "Loop  8450 :    Loss_Train:  [[ 4822.51513812]]    Loss_Validation:  [[ 1420.71695336]]\n",
      "Loop  8451 :    Loss_Train:  [[ 4822.51513739]]    Loss_Validation:  [[ 1420.71702306]]\n",
      "Loop  8452 :    Loss_Train:  [[ 4822.51513666]]    Loss_Validation:  [[ 1420.71709272]]\n",
      "Loop  8453 :    Loss_Train:  [[ 4822.51513593]]    Loss_Validation:  [[ 1420.71716232]]\n",
      "Loop  8454 :    Loss_Train:  [[ 4822.5151352]]    Loss_Validation:  [[ 1420.71723187]]\n",
      "Loop  8455 :    Loss_Train:  [[ 4822.51513448]]    Loss_Validation:  [[ 1420.71730138]]\n",
      "Loop  8456 :    Loss_Train:  [[ 4822.51513375]]    Loss_Validation:  [[ 1420.71737083]]\n",
      "Loop  8457 :    Loss_Train:  [[ 4822.51513303]]    Loss_Validation:  [[ 1420.71744024]]\n",
      "Loop  8458 :    Loss_Train:  [[ 4822.5151323]]    Loss_Validation:  [[ 1420.7175096]]\n",
      "Loop  8459 :    Loss_Train:  [[ 4822.51513158]]    Loss_Validation:  [[ 1420.7175789]]\n",
      "Loop  8460 :    Loss_Train:  [[ 4822.51513086]]    Loss_Validation:  [[ 1420.71764816]]\n",
      "Loop  8461 :    Loss_Train:  [[ 4822.51513014]]    Loss_Validation:  [[ 1420.71771736]]\n",
      "Loop  8462 :    Loss_Train:  [[ 4822.51512942]]    Loss_Validation:  [[ 1420.71778652]]\n",
      "Loop  8463 :    Loss_Train:  [[ 4822.5151287]]    Loss_Validation:  [[ 1420.71785563]]\n",
      "Loop  8464 :    Loss_Train:  [[ 4822.51512799]]    Loss_Validation:  [[ 1420.71792468]]\n",
      "Loop  8465 :    Loss_Train:  [[ 4822.51512727]]    Loss_Validation:  [[ 1420.71799369]]\n",
      "Loop  8466 :    Loss_Train:  [[ 4822.51512656]]    Loss_Validation:  [[ 1420.71806265]]\n",
      "Loop  8467 :    Loss_Train:  [[ 4822.51512585]]    Loss_Validation:  [[ 1420.71813156]]\n",
      "Loop  8468 :    Loss_Train:  [[ 4822.51512513]]    Loss_Validation:  [[ 1420.71820042]]\n",
      "Loop  8469 :    Loss_Train:  [[ 4822.51512442]]    Loss_Validation:  [[ 1420.71826923]]\n",
      "Loop  8470 :    Loss_Train:  [[ 4822.51512371]]    Loss_Validation:  [[ 1420.71833799]]\n",
      "Loop  8471 :    Loss_Train:  [[ 4822.515123]]    Loss_Validation:  [[ 1420.7184067]]\n",
      "Loop  8472 :    Loss_Train:  [[ 4822.5151223]]    Loss_Validation:  [[ 1420.71847536]]\n",
      "Loop  8473 :    Loss_Train:  [[ 4822.51512159]]    Loss_Validation:  [[ 1420.71854398]]\n",
      "Loop  8474 :    Loss_Train:  [[ 4822.51512088]]    Loss_Validation:  [[ 1420.71861254]]\n",
      "Loop  8475 :    Loss_Train:  [[ 4822.51512018]]    Loss_Validation:  [[ 1420.71868106]]\n",
      "Loop  8476 :    Loss_Train:  [[ 4822.51511948]]    Loss_Validation:  [[ 1420.71874952]]\n",
      "Loop  8477 :    Loss_Train:  [[ 4822.51511877]]    Loss_Validation:  [[ 1420.71881794]]\n",
      "Loop  8478 :    Loss_Train:  [[ 4822.51511807]]    Loss_Validation:  [[ 1420.7188863]]\n",
      "Loop  8479 :    Loss_Train:  [[ 4822.51511737]]    Loss_Validation:  [[ 1420.71895462]]\n",
      "Loop  8480 :    Loss_Train:  [[ 4822.51511667]]    Loss_Validation:  [[ 1420.71902289]]\n",
      "Loop  8481 :    Loss_Train:  [[ 4822.51511598]]    Loss_Validation:  [[ 1420.71909111]]\n",
      "Loop  8482 :    Loss_Train:  [[ 4822.51511528]]    Loss_Validation:  [[ 1420.71915928]]\n",
      "Loop  8483 :    Loss_Train:  [[ 4822.51511458]]    Loss_Validation:  [[ 1420.71922741]]\n",
      "Loop  8484 :    Loss_Train:  [[ 4822.51511389]]    Loss_Validation:  [[ 1420.71929548]]\n",
      "Loop  8485 :    Loss_Train:  [[ 4822.5151132]]    Loss_Validation:  [[ 1420.7193635]]\n",
      "Loop  8486 :    Loss_Train:  [[ 4822.5151125]]    Loss_Validation:  [[ 1420.71943148]]\n",
      "Loop  8487 :    Loss_Train:  [[ 4822.51511181]]    Loss_Validation:  [[ 1420.71949941]]\n",
      "Loop  8488 :    Loss_Train:  [[ 4822.51511112]]    Loss_Validation:  [[ 1420.71956729]]\n",
      "Loop  8489 :    Loss_Train:  [[ 4822.51511043]]    Loss_Validation:  [[ 1420.71963512]]\n",
      "Loop  8490 :    Loss_Train:  [[ 4822.51510975]]    Loss_Validation:  [[ 1420.7197029]]\n",
      "Loop  8491 :    Loss_Train:  [[ 4822.51510906]]    Loss_Validation:  [[ 1420.71977063]]\n",
      "Loop  8492 :    Loss_Train:  [[ 4822.51510837]]    Loss_Validation:  [[ 1420.71983831]]\n",
      "Loop  8493 :    Loss_Train:  [[ 4822.51510769]]    Loss_Validation:  [[ 1420.71990595]]\n",
      "Loop  8494 :    Loss_Train:  [[ 4822.51510701]]    Loss_Validation:  [[ 1420.71997354]]\n",
      "Loop  8495 :    Loss_Train:  [[ 4822.51510632]]    Loss_Validation:  [[ 1420.72004107]]\n",
      "Loop  8496 :    Loss_Train:  [[ 4822.51510564]]    Loss_Validation:  [[ 1420.72010856]]\n",
      "Loop  8497 :    Loss_Train:  [[ 4822.51510496]]    Loss_Validation:  [[ 1420.72017601]]\n",
      "Loop  8498 :    Loss_Train:  [[ 4822.51510428]]    Loss_Validation:  [[ 1420.7202434]]\n",
      "Loop  8499 :    Loss_Train:  [[ 4822.5151036]]    Loss_Validation:  [[ 1420.72031074]]\n",
      "Loop  8500 :    Loss_Train:  [[ 4822.51510293]]    Loss_Validation:  [[ 1420.72037804]]\n",
      "Loop  8501 :    Loss_Train:  [[ 4822.51510225]]    Loss_Validation:  [[ 1420.72044529]]\n",
      "Loop  8502 :    Loss_Train:  [[ 4822.51510157]]    Loss_Validation:  [[ 1420.72051249]]\n",
      "Loop  8503 :    Loss_Train:  [[ 4822.5151009]]    Loss_Validation:  [[ 1420.72057964]]\n",
      "Loop  8504 :    Loss_Train:  [[ 4822.51510023]]    Loss_Validation:  [[ 1420.72064674]]\n",
      "Loop  8505 :    Loss_Train:  [[ 4822.51509956]]    Loss_Validation:  [[ 1420.7207138]]\n",
      "Loop  8506 :    Loss_Train:  [[ 4822.51509888]]    Loss_Validation:  [[ 1420.72078081]]\n",
      "Loop  8507 :    Loss_Train:  [[ 4822.51509821]]    Loss_Validation:  [[ 1420.72084777]]\n",
      "Loop  8508 :    Loss_Train:  [[ 4822.51509755]]    Loss_Validation:  [[ 1420.72091468]]\n",
      "Loop  8509 :    Loss_Train:  [[ 4822.51509688]]    Loss_Validation:  [[ 1420.72098154]]\n",
      "Loop  8510 :    Loss_Train:  [[ 4822.51509621]]    Loss_Validation:  [[ 1420.72104836]]\n",
      "Loop  8511 :    Loss_Train:  [[ 4822.51509555]]    Loss_Validation:  [[ 1420.72111512]]\n",
      "Loop  8512 :    Loss_Train:  [[ 4822.51509488]]    Loss_Validation:  [[ 1420.72118184]]\n",
      "Loop  8513 :    Loss_Train:  [[ 4822.51509422]]    Loss_Validation:  [[ 1420.72124851]]\n",
      "Loop  8514 :    Loss_Train:  [[ 4822.51509355]]    Loss_Validation:  [[ 1420.72131514]]\n",
      "Loop  8515 :    Loss_Train:  [[ 4822.51509289]]    Loss_Validation:  [[ 1420.72138171]]\n",
      "Loop  8516 :    Loss_Train:  [[ 4822.51509223]]    Loss_Validation:  [[ 1420.72144824]]\n",
      "Loop  8517 :    Loss_Train:  [[ 4822.51509157]]    Loss_Validation:  [[ 1420.72151472]]\n",
      "Loop  8518 :    Loss_Train:  [[ 4822.51509091]]    Loss_Validation:  [[ 1420.72158115]]\n",
      "Loop  8519 :    Loss_Train:  [[ 4822.51509026]]    Loss_Validation:  [[ 1420.72164754]]\n",
      "Loop  8520 :    Loss_Train:  [[ 4822.5150896]]    Loss_Validation:  [[ 1420.72171388]]\n",
      "Loop  8521 :    Loss_Train:  [[ 4822.51508894]]    Loss_Validation:  [[ 1420.72178017]]\n",
      "Loop  8522 :    Loss_Train:  [[ 4822.51508829]]    Loss_Validation:  [[ 1420.72184641]]\n",
      "Loop  8523 :    Loss_Train:  [[ 4822.51508764]]    Loss_Validation:  [[ 1420.7219126]]\n",
      "Loop  8524 :    Loss_Train:  [[ 4822.51508698]]    Loss_Validation:  [[ 1420.72197875]]\n",
      "Loop  8525 :    Loss_Train:  [[ 4822.51508633]]    Loss_Validation:  [[ 1420.72204485]]\n",
      "Loop  8526 :    Loss_Train:  [[ 4822.51508568]]    Loss_Validation:  [[ 1420.7221109]]\n",
      "Loop  8527 :    Loss_Train:  [[ 4822.51508503]]    Loss_Validation:  [[ 1420.72217691]]\n",
      "Loop  8528 :    Loss_Train:  [[ 4822.51508439]]    Loss_Validation:  [[ 1420.72224287]]\n",
      "Loop  8529 :    Loss_Train:  [[ 4822.51508374]]    Loss_Validation:  [[ 1420.72230878]]\n",
      "Loop  8530 :    Loss_Train:  [[ 4822.51508309]]    Loss_Validation:  [[ 1420.72237464]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  8531 :    Loss_Train:  [[ 4822.51508245]]    Loss_Validation:  [[ 1420.72244045]]\n",
      "Loop  8532 :    Loss_Train:  [[ 4822.5150818]]    Loss_Validation:  [[ 1420.72250622]]\n",
      "Loop  8533 :    Loss_Train:  [[ 4822.51508116]]    Loss_Validation:  [[ 1420.72257194]]\n",
      "Loop  8534 :    Loss_Train:  [[ 4822.51508052]]    Loss_Validation:  [[ 1420.72263762]]\n",
      "Loop  8535 :    Loss_Train:  [[ 4822.51507988]]    Loss_Validation:  [[ 1420.72270325]]\n",
      "Loop  8536 :    Loss_Train:  [[ 4822.51507924]]    Loss_Validation:  [[ 1420.72276883]]\n",
      "Loop  8537 :    Loss_Train:  [[ 4822.5150786]]    Loss_Validation:  [[ 1420.72283436]]\n",
      "Loop  8538 :    Loss_Train:  [[ 4822.51507796]]    Loss_Validation:  [[ 1420.72289984]]\n",
      "Loop  8539 :    Loss_Train:  [[ 4822.51507732]]    Loss_Validation:  [[ 1420.72296528]]\n",
      "Loop  8540 :    Loss_Train:  [[ 4822.51507668]]    Loss_Validation:  [[ 1420.72303067]]\n",
      "Loop  8541 :    Loss_Train:  [[ 4822.51507605]]    Loss_Validation:  [[ 1420.72309602]]\n",
      "Loop  8542 :    Loss_Train:  [[ 4822.51507542]]    Loss_Validation:  [[ 1420.72316132]]\n",
      "Loop  8543 :    Loss_Train:  [[ 4822.51507478]]    Loss_Validation:  [[ 1420.72322657]]\n",
      "Loop  8544 :    Loss_Train:  [[ 4822.51507415]]    Loss_Validation:  [[ 1420.72329177]]\n",
      "Loop  8545 :    Loss_Train:  [[ 4822.51507352]]    Loss_Validation:  [[ 1420.72335693]]\n",
      "Loop  8546 :    Loss_Train:  [[ 4822.51507289]]    Loss_Validation:  [[ 1420.72342204]]\n",
      "Loop  8547 :    Loss_Train:  [[ 4822.51507226]]    Loss_Validation:  [[ 1420.72348711]]\n",
      "Loop  8548 :    Loss_Train:  [[ 4822.51507163]]    Loss_Validation:  [[ 1420.72355212]]\n",
      "Loop  8549 :    Loss_Train:  [[ 4822.515071]]    Loss_Validation:  [[ 1420.72361709]]\n",
      "Loop  8550 :    Loss_Train:  [[ 4822.51507038]]    Loss_Validation:  [[ 1420.72368202]]\n",
      "Loop  8551 :    Loss_Train:  [[ 4822.51506975]]    Loss_Validation:  [[ 1420.7237469]]\n",
      "Loop  8552 :    Loss_Train:  [[ 4822.51506913]]    Loss_Validation:  [[ 1420.72381173]]\n",
      "Loop  8553 :    Loss_Train:  [[ 4822.5150685]]    Loss_Validation:  [[ 1420.72387651]]\n",
      "Loop  8554 :    Loss_Train:  [[ 4822.51506788]]    Loss_Validation:  [[ 1420.72394125]]\n",
      "Loop  8555 :    Loss_Train:  [[ 4822.51506726]]    Loss_Validation:  [[ 1420.72400594]]\n",
      "Loop  8556 :    Loss_Train:  [[ 4822.51506664]]    Loss_Validation:  [[ 1420.72407059]]\n",
      "Loop  8557 :    Loss_Train:  [[ 4822.51506602]]    Loss_Validation:  [[ 1420.72413518]]\n",
      "Loop  8558 :    Loss_Train:  [[ 4822.5150654]]    Loss_Validation:  [[ 1420.72419974]]\n",
      "Loop  8559 :    Loss_Train:  [[ 4822.51506478]]    Loss_Validation:  [[ 1420.72426424]]\n",
      "Loop  8560 :    Loss_Train:  [[ 4822.51506417]]    Loss_Validation:  [[ 1420.7243287]]\n",
      "Loop  8561 :    Loss_Train:  [[ 4822.51506355]]    Loss_Validation:  [[ 1420.72439312]]\n",
      "Loop  8562 :    Loss_Train:  [[ 4822.51506294]]    Loss_Validation:  [[ 1420.72445748]]\n",
      "Loop  8563 :    Loss_Train:  [[ 4822.51506232]]    Loss_Validation:  [[ 1420.7245218]]\n",
      "Loop  8564 :    Loss_Train:  [[ 4822.51506171]]    Loss_Validation:  [[ 1420.72458608]]\n",
      "Loop  8565 :    Loss_Train:  [[ 4822.5150611]]    Loss_Validation:  [[ 1420.72465031]]\n",
      "Loop  8566 :    Loss_Train:  [[ 4822.51506049]]    Loss_Validation:  [[ 1420.72471449]]\n",
      "Loop  8567 :    Loss_Train:  [[ 4822.51505988]]    Loss_Validation:  [[ 1420.72477863]]\n",
      "Loop  8568 :    Loss_Train:  [[ 4822.51505927]]    Loss_Validation:  [[ 1420.72484272]]\n",
      "Loop  8569 :    Loss_Train:  [[ 4822.51505866]]    Loss_Validation:  [[ 1420.72490676]]\n",
      "Loop  8570 :    Loss_Train:  [[ 4822.51505805]]    Loss_Validation:  [[ 1420.72497076]]\n",
      "Loop  8571 :    Loss_Train:  [[ 4822.51505745]]    Loss_Validation:  [[ 1420.72503471]]\n",
      "Loop  8572 :    Loss_Train:  [[ 4822.51505684]]    Loss_Validation:  [[ 1420.72509862]]\n",
      "Loop  8573 :    Loss_Train:  [[ 4822.51505624]]    Loss_Validation:  [[ 1420.72516248]]\n",
      "Loop  8574 :    Loss_Train:  [[ 4822.51505563]]    Loss_Validation:  [[ 1420.7252263]]\n",
      "Loop  8575 :    Loss_Train:  [[ 4822.51505503]]    Loss_Validation:  [[ 1420.72529006]]\n",
      "Loop  8576 :    Loss_Train:  [[ 4822.51505443]]    Loss_Validation:  [[ 1420.72535379]]\n",
      "Loop  8577 :    Loss_Train:  [[ 4822.51505383]]    Loss_Validation:  [[ 1420.72541747]]\n",
      "Loop  8578 :    Loss_Train:  [[ 4822.51505323]]    Loss_Validation:  [[ 1420.7254811]]\n",
      "Loop  8579 :    Loss_Train:  [[ 4822.51505263]]    Loss_Validation:  [[ 1420.72554468]]\n",
      "Loop  8580 :    Loss_Train:  [[ 4822.51505203]]    Loss_Validation:  [[ 1420.72560822]]\n",
      "Loop  8581 :    Loss_Train:  [[ 4822.51505144]]    Loss_Validation:  [[ 1420.72567172]]\n",
      "Loop  8582 :    Loss_Train:  [[ 4822.51505084]]    Loss_Validation:  [[ 1420.72573517]]\n",
      "Loop  8583 :    Loss_Train:  [[ 4822.51505025]]    Loss_Validation:  [[ 1420.72579857]]\n",
      "Loop  8584 :    Loss_Train:  [[ 4822.51504965]]    Loss_Validation:  [[ 1420.72586193]]\n",
      "Loop  8585 :    Loss_Train:  [[ 4822.51504906]]    Loss_Validation:  [[ 1420.72592524]]\n",
      "Loop  8586 :    Loss_Train:  [[ 4822.51504847]]    Loss_Validation:  [[ 1420.72598851]]\n",
      "Loop  8587 :    Loss_Train:  [[ 4822.51504788]]    Loss_Validation:  [[ 1420.72605173]]\n",
      "Loop  8588 :    Loss_Train:  [[ 4822.51504729]]    Loss_Validation:  [[ 1420.72611491]]\n",
      "Loop  8589 :    Loss_Train:  [[ 4822.5150467]]    Loss_Validation:  [[ 1420.72617804]]\n",
      "Loop  8590 :    Loss_Train:  [[ 4822.51504611]]    Loss_Validation:  [[ 1420.72624113]]\n",
      "Loop  8591 :    Loss_Train:  [[ 4822.51504552]]    Loss_Validation:  [[ 1420.72630417]]\n",
      "Loop  8592 :    Loss_Train:  [[ 4822.51504494]]    Loss_Validation:  [[ 1420.72636716]]\n",
      "Loop  8593 :    Loss_Train:  [[ 4822.51504435]]    Loss_Validation:  [[ 1420.72643011]]\n",
      "Loop  8594 :    Loss_Train:  [[ 4822.51504376]]    Loss_Validation:  [[ 1420.72649302]]\n",
      "Loop  8595 :    Loss_Train:  [[ 4822.51504318]]    Loss_Validation:  [[ 1420.72655588]]\n",
      "Loop  8596 :    Loss_Train:  [[ 4822.5150426]]    Loss_Validation:  [[ 1420.72661869]]\n",
      "Loop  8597 :    Loss_Train:  [[ 4822.51504202]]    Loss_Validation:  [[ 1420.72668146]]\n",
      "Loop  8598 :    Loss_Train:  [[ 4822.51504144]]    Loss_Validation:  [[ 1420.72674419]]\n",
      "Loop  8599 :    Loss_Train:  [[ 4822.51504085]]    Loss_Validation:  [[ 1420.72680687]]\n",
      "Loop  8600 :    Loss_Train:  [[ 4822.51504028]]    Loss_Validation:  [[ 1420.7268695]]\n",
      "Loop  8601 :    Loss_Train:  [[ 4822.5150397]]    Loss_Validation:  [[ 1420.72693209]]\n",
      "Loop  8602 :    Loss_Train:  [[ 4822.51503912]]    Loss_Validation:  [[ 1420.72699464]]\n",
      "Loop  8603 :    Loss_Train:  [[ 4822.51503854]]    Loss_Validation:  [[ 1420.72705714]]\n",
      "Loop  8604 :    Loss_Train:  [[ 4822.51503797]]    Loss_Validation:  [[ 1420.72711959]]\n",
      "Loop  8605 :    Loss_Train:  [[ 4822.51503739]]    Loss_Validation:  [[ 1420.727182]]\n",
      "Loop  8606 :    Loss_Train:  [[ 4822.51503682]]    Loss_Validation:  [[ 1420.72724437]]\n",
      "Loop  8607 :    Loss_Train:  [[ 4822.51503625]]    Loss_Validation:  [[ 1420.72730669]]\n",
      "Loop  8608 :    Loss_Train:  [[ 4822.51503567]]    Loss_Validation:  [[ 1420.72736896]]\n",
      "Loop  8609 :    Loss_Train:  [[ 4822.5150351]]    Loss_Validation:  [[ 1420.72743119]]\n",
      "Loop  8610 :    Loss_Train:  [[ 4822.51503453]]    Loss_Validation:  [[ 1420.72749338]]\n",
      "Loop  8611 :    Loss_Train:  [[ 4822.51503396]]    Loss_Validation:  [[ 1420.72755552]]\n",
      "Loop  8612 :    Loss_Train:  [[ 4822.51503339]]    Loss_Validation:  [[ 1420.72761762]]\n",
      "Loop  8613 :    Loss_Train:  [[ 4822.51503283]]    Loss_Validation:  [[ 1420.72767967]]\n",
      "Loop  8614 :    Loss_Train:  [[ 4822.51503226]]    Loss_Validation:  [[ 1420.72774168]]\n",
      "Loop  8615 :    Loss_Train:  [[ 4822.51503169]]    Loss_Validation:  [[ 1420.72780364]]\n",
      "Loop  8616 :    Loss_Train:  [[ 4822.51503113]]    Loss_Validation:  [[ 1420.72786556]]\n",
      "Loop  8617 :    Loss_Train:  [[ 4822.51503057]]    Loss_Validation:  [[ 1420.72792744]]\n",
      "Loop  8618 :    Loss_Train:  [[ 4822.51503]]    Loss_Validation:  [[ 1420.72798927]]\n",
      "Loop  8619 :    Loss_Train:  [[ 4822.51502944]]    Loss_Validation:  [[ 1420.72805105]]\n",
      "Loop  8620 :    Loss_Train:  [[ 4822.51502888]]    Loss_Validation:  [[ 1420.72811279]]\n",
      "Loop  8621 :    Loss_Train:  [[ 4822.51502832]]    Loss_Validation:  [[ 1420.72817449]]\n",
      "Loop  8622 :    Loss_Train:  [[ 4822.51502776]]    Loss_Validation:  [[ 1420.72823614]]\n",
      "Loop  8623 :    Loss_Train:  [[ 4822.5150272]]    Loss_Validation:  [[ 1420.72829775]]\n",
      "Loop  8624 :    Loss_Train:  [[ 4822.51502664]]    Loss_Validation:  [[ 1420.72835932]]\n",
      "Loop  8625 :    Loss_Train:  [[ 4822.51502608]]    Loss_Validation:  [[ 1420.72842084]]\n",
      "Loop  8626 :    Loss_Train:  [[ 4822.51502553]]    Loss_Validation:  [[ 1420.72848231]]\n",
      "Loop  8627 :    Loss_Train:  [[ 4822.51502497]]    Loss_Validation:  [[ 1420.72854374]]\n",
      "Loop  8628 :    Loss_Train:  [[ 4822.51502442]]    Loss_Validation:  [[ 1420.72860513]]\n",
      "Loop  8629 :    Loss_Train:  [[ 4822.51502387]]    Loss_Validation:  [[ 1420.72866647]]\n",
      "Loop  8630 :    Loss_Train:  [[ 4822.51502331]]    Loss_Validation:  [[ 1420.72872777]]\n",
      "Loop  8631 :    Loss_Train:  [[ 4822.51502276]]    Loss_Validation:  [[ 1420.72878903]]\n",
      "Loop  8632 :    Loss_Train:  [[ 4822.51502221]]    Loss_Validation:  [[ 1420.72885024]]\n",
      "Loop  8633 :    Loss_Train:  [[ 4822.51502166]]    Loss_Validation:  [[ 1420.72891141]]\n",
      "Loop  8634 :    Loss_Train:  [[ 4822.51502111]]    Loss_Validation:  [[ 1420.72897253]]\n",
      "Loop  8635 :    Loss_Train:  [[ 4822.51502056]]    Loss_Validation:  [[ 1420.72903361]]\n",
      "Loop  8636 :    Loss_Train:  [[ 4822.51502001]]    Loss_Validation:  [[ 1420.72909465]]\n",
      "Loop  8637 :    Loss_Train:  [[ 4822.51501947]]    Loss_Validation:  [[ 1420.72915564]]\n",
      "Loop  8638 :    Loss_Train:  [[ 4822.51501892]]    Loss_Validation:  [[ 1420.72921659]]\n",
      "Loop  8639 :    Loss_Train:  [[ 4822.51501838]]    Loss_Validation:  [[ 1420.72927749]]\n",
      "Loop  8640 :    Loss_Train:  [[ 4822.51501783]]    Loss_Validation:  [[ 1420.72933835]]\n",
      "Loop  8641 :    Loss_Train:  [[ 4822.51501729]]    Loss_Validation:  [[ 1420.72939917]]\n",
      "Loop  8642 :    Loss_Train:  [[ 4822.51501675]]    Loss_Validation:  [[ 1420.72945994]]\n",
      "Loop  8643 :    Loss_Train:  [[ 4822.51501621]]    Loss_Validation:  [[ 1420.72952067]]\n",
      "Loop  8644 :    Loss_Train:  [[ 4822.51501566]]    Loss_Validation:  [[ 1420.72958136]]\n",
      "Loop  8645 :    Loss_Train:  [[ 4822.51501512]]    Loss_Validation:  [[ 1420.729642]]\n",
      "Loop  8646 :    Loss_Train:  [[ 4822.51501459]]    Loss_Validation:  [[ 1420.7297026]]\n",
      "Loop  8647 :    Loss_Train:  [[ 4822.51501405]]    Loss_Validation:  [[ 1420.72976315]]\n",
      "Loop  8648 :    Loss_Train:  [[ 4822.51501351]]    Loss_Validation:  [[ 1420.72982367]]\n",
      "Loop  8649 :    Loss_Train:  [[ 4822.51501297]]    Loss_Validation:  [[ 1420.72988413]]\n",
      "Loop  8650 :    Loss_Train:  [[ 4822.51501244]]    Loss_Validation:  [[ 1420.72994456]]\n",
      "Loop  8651 :    Loss_Train:  [[ 4822.5150119]]    Loss_Validation:  [[ 1420.73000494]]\n",
      "Loop  8652 :    Loss_Train:  [[ 4822.51501137]]    Loss_Validation:  [[ 1420.73006528]]\n",
      "Loop  8653 :    Loss_Train:  [[ 4822.51501084]]    Loss_Validation:  [[ 1420.73012557]]\n",
      "Loop  8654 :    Loss_Train:  [[ 4822.5150103]]    Loss_Validation:  [[ 1420.73018583]]\n",
      "Loop  8655 :    Loss_Train:  [[ 4822.51500977]]    Loss_Validation:  [[ 1420.73024603]]\n",
      "Loop  8656 :    Loss_Train:  [[ 4822.51500924]]    Loss_Validation:  [[ 1420.7303062]]\n",
      "Loop  8657 :    Loss_Train:  [[ 4822.51500871]]    Loss_Validation:  [[ 1420.73036632]]\n",
      "Loop  8658 :    Loss_Train:  [[ 4822.51500818]]    Loss_Validation:  [[ 1420.7304264]]\n",
      "Loop  8659 :    Loss_Train:  [[ 4822.51500765]]    Loss_Validation:  [[ 1420.73048643]]\n",
      "Loop  8660 :    Loss_Train:  [[ 4822.51500713]]    Loss_Validation:  [[ 1420.73054643]]\n",
      "Loop  8661 :    Loss_Train:  [[ 4822.5150066]]    Loss_Validation:  [[ 1420.73060638]]\n",
      "Loop  8662 :    Loss_Train:  [[ 4822.51500607]]    Loss_Validation:  [[ 1420.73066628]]\n",
      "Loop  8663 :    Loss_Train:  [[ 4822.51500555]]    Loss_Validation:  [[ 1420.73072615]]\n",
      "Loop  8664 :    Loss_Train:  [[ 4822.51500502]]    Loss_Validation:  [[ 1420.73078597]]\n",
      "Loop  8665 :    Loss_Train:  [[ 4822.5150045]]    Loss_Validation:  [[ 1420.73084574]]\n",
      "Loop  8666 :    Loss_Train:  [[ 4822.51500398]]    Loss_Validation:  [[ 1420.73090548]]\n",
      "Loop  8667 :    Loss_Train:  [[ 4822.51500346]]    Loss_Validation:  [[ 1420.73096517]]\n",
      "Loop  8668 :    Loss_Train:  [[ 4822.51500294]]    Loss_Validation:  [[ 1420.73102482]]\n",
      "Loop  8669 :    Loss_Train:  [[ 4822.51500242]]    Loss_Validation:  [[ 1420.73108442]]\n",
      "Loop  8670 :    Loss_Train:  [[ 4822.5150019]]    Loss_Validation:  [[ 1420.73114399]]\n",
      "Loop  8671 :    Loss_Train:  [[ 4822.51500138]]    Loss_Validation:  [[ 1420.73120351]]\n",
      "Loop  8672 :    Loss_Train:  [[ 4822.51500086]]    Loss_Validation:  [[ 1420.73126298]]\n",
      "Loop  8673 :    Loss_Train:  [[ 4822.51500034]]    Loss_Validation:  [[ 1420.73132242]]\n",
      "Loop  8674 :    Loss_Train:  [[ 4822.51499983]]    Loss_Validation:  [[ 1420.73138181]]\n",
      "Loop  8675 :    Loss_Train:  [[ 4822.51499931]]    Loss_Validation:  [[ 1420.73144116]]\n",
      "Loop  8676 :    Loss_Train:  [[ 4822.5149988]]    Loss_Validation:  [[ 1420.73150047]]\n",
      "Loop  8677 :    Loss_Train:  [[ 4822.51499829]]    Loss_Validation:  [[ 1420.73155973]]\n",
      "Loop  8678 :    Loss_Train:  [[ 4822.51499777]]    Loss_Validation:  [[ 1420.73161895]]\n",
      "Loop  8679 :    Loss_Train:  [[ 4822.51499726]]    Loss_Validation:  [[ 1420.73167813]]\n",
      "Loop  8680 :    Loss_Train:  [[ 4822.51499675]]    Loss_Validation:  [[ 1420.73173727]]\n",
      "Loop  8681 :    Loss_Train:  [[ 4822.51499624]]    Loss_Validation:  [[ 1420.73179636]]\n",
      "Loop  8682 :    Loss_Train:  [[ 4822.51499573]]    Loss_Validation:  [[ 1420.73185541]]\n",
      "Loop  8683 :    Loss_Train:  [[ 4822.51499522]]    Loss_Validation:  [[ 1420.73191442]]\n",
      "Loop  8684 :    Loss_Train:  [[ 4822.51499471]]    Loss_Validation:  [[ 1420.73197339]]\n",
      "Loop  8685 :    Loss_Train:  [[ 4822.51499421]]    Loss_Validation:  [[ 1420.73203231]]\n",
      "Loop  8686 :    Loss_Train:  [[ 4822.5149937]]    Loss_Validation:  [[ 1420.7320912]]\n",
      "Loop  8687 :    Loss_Train:  [[ 4822.51499319]]    Loss_Validation:  [[ 1420.73215003]]\n",
      "Loop  8688 :    Loss_Train:  [[ 4822.51499269]]    Loss_Validation:  [[ 1420.73220883]]\n",
      "Loop  8689 :    Loss_Train:  [[ 4822.51499218]]    Loss_Validation:  [[ 1420.73226759]]\n",
      "Loop  8690 :    Loss_Train:  [[ 4822.51499168]]    Loss_Validation:  [[ 1420.7323263]]\n",
      "Loop  8691 :    Loss_Train:  [[ 4822.51499118]]    Loss_Validation:  [[ 1420.73238497]]\n",
      "Loop  8692 :    Loss_Train:  [[ 4822.51499068]]    Loss_Validation:  [[ 1420.7324436]]\n",
      "Loop  8693 :    Loss_Train:  [[ 4822.51499018]]    Loss_Validation:  [[ 1420.73250219]]\n",
      "Loop  8694 :    Loss_Train:  [[ 4822.51498968]]    Loss_Validation:  [[ 1420.73256073]]\n",
      "Loop  8695 :    Loss_Train:  [[ 4822.51498918]]    Loss_Validation:  [[ 1420.73261923]]\n",
      "Loop  8696 :    Loss_Train:  [[ 4822.51498868]]    Loss_Validation:  [[ 1420.73267769]]\n",
      "Loop  8697 :    Loss_Train:  [[ 4822.51498818]]    Loss_Validation:  [[ 1420.73273611]]\n",
      "Loop  8698 :    Loss_Train:  [[ 4822.51498768]]    Loss_Validation:  [[ 1420.73279449]]\n",
      "Loop  8699 :    Loss_Train:  [[ 4822.51498719]]    Loss_Validation:  [[ 1420.73285282]]\n",
      "Loop  8700 :    Loss_Train:  [[ 4822.51498669]]    Loss_Validation:  [[ 1420.73291112]]\n",
      "Loop  8701 :    Loss_Train:  [[ 4822.5149862]]    Loss_Validation:  [[ 1420.73296937]]\n",
      "Loop  8702 :    Loss_Train:  [[ 4822.5149857]]    Loss_Validation:  [[ 1420.73302758]]\n",
      "Loop  8703 :    Loss_Train:  [[ 4822.51498521]]    Loss_Validation:  [[ 1420.73308574]]\n",
      "Loop  8704 :    Loss_Train:  [[ 4822.51498472]]    Loss_Validation:  [[ 1420.73314387]]\n",
      "Loop  8705 :    Loss_Train:  [[ 4822.51498423]]    Loss_Validation:  [[ 1420.73320195]]\n",
      "Loop  8706 :    Loss_Train:  [[ 4822.51498374]]    Loss_Validation:  [[ 1420.73325999]]\n",
      "Loop  8707 :    Loss_Train:  [[ 4822.51498325]]    Loss_Validation:  [[ 1420.73331799]]\n",
      "Loop  8708 :    Loss_Train:  [[ 4822.51498276]]    Loss_Validation:  [[ 1420.73337595]]\n",
      "Loop  8709 :    Loss_Train:  [[ 4822.51498227]]    Loss_Validation:  [[ 1420.73343387]]\n",
      "Loop  8710 :    Loss_Train:  [[ 4822.51498178]]    Loss_Validation:  [[ 1420.73349174]]\n",
      "Loop  8711 :    Loss_Train:  [[ 4822.51498129]]    Loss_Validation:  [[ 1420.73354958]]\n",
      "Loop  8712 :    Loss_Train:  [[ 4822.51498081]]    Loss_Validation:  [[ 1420.73360737]]\n",
      "Loop  8713 :    Loss_Train:  [[ 4822.51498032]]    Loss_Validation:  [[ 1420.73366512]]\n",
      "Loop  8714 :    Loss_Train:  [[ 4822.51497984]]    Loss_Validation:  [[ 1420.73372283]]\n",
      "Loop  8715 :    Loss_Train:  [[ 4822.51497935]]    Loss_Validation:  [[ 1420.7337805]]\n",
      "Loop  8716 :    Loss_Train:  [[ 4822.51497887]]    Loss_Validation:  [[ 1420.73383812]]\n",
      "Loop  8717 :    Loss_Train:  [[ 4822.51497839]]    Loss_Validation:  [[ 1420.73389571]]\n",
      "Loop  8718 :    Loss_Train:  [[ 4822.5149779]]    Loss_Validation:  [[ 1420.73395325]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  8719 :    Loss_Train:  [[ 4822.51497742]]    Loss_Validation:  [[ 1420.73401075]]\n",
      "Loop  8720 :    Loss_Train:  [[ 4822.51497694]]    Loss_Validation:  [[ 1420.73406821]]\n",
      "Loop  8721 :    Loss_Train:  [[ 4822.51497646]]    Loss_Validation:  [[ 1420.73412563]]\n",
      "Loop  8722 :    Loss_Train:  [[ 4822.51497599]]    Loss_Validation:  [[ 1420.73418301]]\n",
      "Loop  8723 :    Loss_Train:  [[ 4822.51497551]]    Loss_Validation:  [[ 1420.73424035]]\n",
      "Loop  8724 :    Loss_Train:  [[ 4822.51497503]]    Loss_Validation:  [[ 1420.73429764]]\n",
      "Loop  8725 :    Loss_Train:  [[ 4822.51497455]]    Loss_Validation:  [[ 1420.7343549]]\n",
      "Loop  8726 :    Loss_Train:  [[ 4822.51497408]]    Loss_Validation:  [[ 1420.73441211]]\n",
      "Loop  8727 :    Loss_Train:  [[ 4822.5149736]]    Loss_Validation:  [[ 1420.73446928]]\n",
      "Loop  8728 :    Loss_Train:  [[ 4822.51497313]]    Loss_Validation:  [[ 1420.73452641]]\n",
      "Loop  8729 :    Loss_Train:  [[ 4822.51497266]]    Loss_Validation:  [[ 1420.7345835]]\n",
      "Loop  8730 :    Loss_Train:  [[ 4822.51497218]]    Loss_Validation:  [[ 1420.73464055]]\n",
      "Loop  8731 :    Loss_Train:  [[ 4822.51497171]]    Loss_Validation:  [[ 1420.73469756]]\n",
      "Loop  8732 :    Loss_Train:  [[ 4822.51497124]]    Loss_Validation:  [[ 1420.73475453]]\n",
      "Loop  8733 :    Loss_Train:  [[ 4822.51497077]]    Loss_Validation:  [[ 1420.73481145]]\n",
      "Loop  8734 :    Loss_Train:  [[ 4822.5149703]]    Loss_Validation:  [[ 1420.73486834]]\n",
      "Loop  8735 :    Loss_Train:  [[ 4822.51496983]]    Loss_Validation:  [[ 1420.73492518]]\n",
      "Loop  8736 :    Loss_Train:  [[ 4822.51496936]]    Loss_Validation:  [[ 1420.73498199]]\n",
      "Loop  8737 :    Loss_Train:  [[ 4822.51496889]]    Loss_Validation:  [[ 1420.73503875]]\n",
      "Loop  8738 :    Loss_Train:  [[ 4822.51496843]]    Loss_Validation:  [[ 1420.73509547]]\n",
      "Loop  8739 :    Loss_Train:  [[ 4822.51496796]]    Loss_Validation:  [[ 1420.73515215]]\n",
      "Loop  8740 :    Loss_Train:  [[ 4822.5149675]]    Loss_Validation:  [[ 1420.73520879]]\n",
      "Loop  8741 :    Loss_Train:  [[ 4822.51496703]]    Loss_Validation:  [[ 1420.73526539]]\n",
      "Loop  8742 :    Loss_Train:  [[ 4822.51496657]]    Loss_Validation:  [[ 1420.73532195]]\n",
      "Loop  8743 :    Loss_Train:  [[ 4822.5149661]]    Loss_Validation:  [[ 1420.73537847]]\n",
      "Loop  8744 :    Loss_Train:  [[ 4822.51496564]]    Loss_Validation:  [[ 1420.73543495]]\n",
      "Loop  8745 :    Loss_Train:  [[ 4822.51496518]]    Loss_Validation:  [[ 1420.73549138]]\n",
      "Loop  8746 :    Loss_Train:  [[ 4822.51496472]]    Loss_Validation:  [[ 1420.73554778]]\n",
      "Loop  8747 :    Loss_Train:  [[ 4822.51496426]]    Loss_Validation:  [[ 1420.73560414]]\n",
      "Loop  8748 :    Loss_Train:  [[ 4822.5149638]]    Loss_Validation:  [[ 1420.73566045]]\n",
      "Loop  8749 :    Loss_Train:  [[ 4822.51496334]]    Loss_Validation:  [[ 1420.73571673]]\n",
      "Loop  8750 :    Loss_Train:  [[ 4822.51496288]]    Loss_Validation:  [[ 1420.73577296]]\n",
      "Loop  8751 :    Loss_Train:  [[ 4822.51496242]]    Loss_Validation:  [[ 1420.73582916]]\n",
      "Loop  8752 :    Loss_Train:  [[ 4822.51496197]]    Loss_Validation:  [[ 1420.73588531]]\n",
      "Loop  8753 :    Loss_Train:  [[ 4822.51496151]]    Loss_Validation:  [[ 1420.73594142]]\n",
      "Loop  8754 :    Loss_Train:  [[ 4822.51496106]]    Loss_Validation:  [[ 1420.7359975]]\n",
      "Loop  8755 :    Loss_Train:  [[ 4822.5149606]]    Loss_Validation:  [[ 1420.73605353]]\n",
      "Loop  8756 :    Loss_Train:  [[ 4822.51496015]]    Loss_Validation:  [[ 1420.73610952]]\n",
      "Loop  8757 :    Loss_Train:  [[ 4822.51495969]]    Loss_Validation:  [[ 1420.73616548]]\n",
      "Loop  8758 :    Loss_Train:  [[ 4822.51495924]]    Loss_Validation:  [[ 1420.73622139]]\n",
      "Loop  8759 :    Loss_Train:  [[ 4822.51495879]]    Loss_Validation:  [[ 1420.73627726]]\n",
      "Loop  8760 :    Loss_Train:  [[ 4822.51495834]]    Loss_Validation:  [[ 1420.73633309]]\n",
      "Loop  8761 :    Loss_Train:  [[ 4822.51495789]]    Loss_Validation:  [[ 1420.73638888]]\n",
      "Loop  8762 :    Loss_Train:  [[ 4822.51495744]]    Loss_Validation:  [[ 1420.73644463]]\n",
      "Loop  8763 :    Loss_Train:  [[ 4822.51495699]]    Loss_Validation:  [[ 1420.73650035]]\n",
      "Loop  8764 :    Loss_Train:  [[ 4822.51495654]]    Loss_Validation:  [[ 1420.73655602]]\n",
      "Loop  8765 :    Loss_Train:  [[ 4822.51495609]]    Loss_Validation:  [[ 1420.73661165]]\n",
      "Loop  8766 :    Loss_Train:  [[ 4822.51495565]]    Loss_Validation:  [[ 1420.73666724]]\n",
      "Loop  8767 :    Loss_Train:  [[ 4822.5149552]]    Loss_Validation:  [[ 1420.73672279]]\n",
      "Loop  8768 :    Loss_Train:  [[ 4822.51495475]]    Loss_Validation:  [[ 1420.7367783]]\n",
      "Loop  8769 :    Loss_Train:  [[ 4822.51495431]]    Loss_Validation:  [[ 1420.73683378]]\n",
      "Loop  8770 :    Loss_Train:  [[ 4822.51495387]]    Loss_Validation:  [[ 1420.73688921]]\n",
      "Loop  8771 :    Loss_Train:  [[ 4822.51495342]]    Loss_Validation:  [[ 1420.7369446]]\n",
      "Loop  8772 :    Loss_Train:  [[ 4822.51495298]]    Loss_Validation:  [[ 1420.73699995]]\n",
      "Loop  8773 :    Loss_Train:  [[ 4822.51495254]]    Loss_Validation:  [[ 1420.73705526]]\n",
      "Loop  8774 :    Loss_Train:  [[ 4822.5149521]]    Loss_Validation:  [[ 1420.73711054]]\n",
      "Loop  8775 :    Loss_Train:  [[ 4822.51495165]]    Loss_Validation:  [[ 1420.73716577]]\n",
      "Loop  8776 :    Loss_Train:  [[ 4822.51495121]]    Loss_Validation:  [[ 1420.73722096]]\n",
      "Loop  8777 :    Loss_Train:  [[ 4822.51495078]]    Loss_Validation:  [[ 1420.73727612]]\n",
      "Loop  8778 :    Loss_Train:  [[ 4822.51495034]]    Loss_Validation:  [[ 1420.73733123]]\n",
      "Loop  8779 :    Loss_Train:  [[ 4822.5149499]]    Loss_Validation:  [[ 1420.7373863]]\n",
      "Loop  8780 :    Loss_Train:  [[ 4822.51494946]]    Loss_Validation:  [[ 1420.73744134]]\n",
      "Loop  8781 :    Loss_Train:  [[ 4822.51494903]]    Loss_Validation:  [[ 1420.73749633]]\n",
      "Loop  8782 :    Loss_Train:  [[ 4822.51494859]]    Loss_Validation:  [[ 1420.73755129]]\n",
      "Loop  8783 :    Loss_Train:  [[ 4822.51494815]]    Loss_Validation:  [[ 1420.7376062]]\n",
      "Loop  8784 :    Loss_Train:  [[ 4822.51494772]]    Loss_Validation:  [[ 1420.73766108]]\n",
      "Loop  8785 :    Loss_Train:  [[ 4822.51494729]]    Loss_Validation:  [[ 1420.73771592]]\n",
      "Loop  8786 :    Loss_Train:  [[ 4822.51494685]]    Loss_Validation:  [[ 1420.73777072]]\n",
      "Loop  8787 :    Loss_Train:  [[ 4822.51494642]]    Loss_Validation:  [[ 1420.73782547]]\n",
      "Loop  8788 :    Loss_Train:  [[ 4822.51494599]]    Loss_Validation:  [[ 1420.73788019]]\n",
      "Loop  8789 :    Loss_Train:  [[ 4822.51494556]]    Loss_Validation:  [[ 1420.73793487]]\n",
      "Loop  8790 :    Loss_Train:  [[ 4822.51494513]]    Loss_Validation:  [[ 1420.73798951]]\n",
      "Loop  8791 :    Loss_Train:  [[ 4822.5149447]]    Loss_Validation:  [[ 1420.73804411]]\n",
      "Loop  8792 :    Loss_Train:  [[ 4822.51494427]]    Loss_Validation:  [[ 1420.73809868]]\n",
      "Loop  8793 :    Loss_Train:  [[ 4822.51494384]]    Loss_Validation:  [[ 1420.7381532]]\n",
      "Loop  8794 :    Loss_Train:  [[ 4822.51494341]]    Loss_Validation:  [[ 1420.73820768]]\n",
      "Loop  8795 :    Loss_Train:  [[ 4822.51494298]]    Loss_Validation:  [[ 1420.73826213]]\n",
      "Loop  8796 :    Loss_Train:  [[ 4822.51494256]]    Loss_Validation:  [[ 1420.73831653]]\n",
      "Loop  8797 :    Loss_Train:  [[ 4822.51494213]]    Loss_Validation:  [[ 1420.7383709]]\n",
      "Loop  8798 :    Loss_Train:  [[ 4822.51494171]]    Loss_Validation:  [[ 1420.73842522]]\n",
      "Loop  8799 :    Loss_Train:  [[ 4822.51494128]]    Loss_Validation:  [[ 1420.73847951]]\n",
      "Loop  8800 :    Loss_Train:  [[ 4822.51494086]]    Loss_Validation:  [[ 1420.73853376]]\n",
      "Loop  8801 :    Loss_Train:  [[ 4822.51494044]]    Loss_Validation:  [[ 1420.73858797]]\n",
      "Loop  8802 :    Loss_Train:  [[ 4822.51494001]]    Loss_Validation:  [[ 1420.73864214]]\n",
      "Loop  8803 :    Loss_Train:  [[ 4822.51493959]]    Loss_Validation:  [[ 1420.73869627]]\n",
      "Loop  8804 :    Loss_Train:  [[ 4822.51493917]]    Loss_Validation:  [[ 1420.73875037]]\n",
      "Loop  8805 :    Loss_Train:  [[ 4822.51493875]]    Loss_Validation:  [[ 1420.73880442]]\n",
      "Loop  8806 :    Loss_Train:  [[ 4822.51493833]]    Loss_Validation:  [[ 1420.73885843]]\n",
      "Loop  8807 :    Loss_Train:  [[ 4822.51493791]]    Loss_Validation:  [[ 1420.73891241]]\n",
      "Loop  8808 :    Loss_Train:  [[ 4822.51493749]]    Loss_Validation:  [[ 1420.73896635]]\n",
      "Loop  8809 :    Loss_Train:  [[ 4822.51493707]]    Loss_Validation:  [[ 1420.73902025]]\n",
      "Loop  8810 :    Loss_Train:  [[ 4822.51493666]]    Loss_Validation:  [[ 1420.73907411]]\n",
      "Loop  8811 :    Loss_Train:  [[ 4822.51493624]]    Loss_Validation:  [[ 1420.73912793]]\n",
      "Loop  8812 :    Loss_Train:  [[ 4822.51493582]]    Loss_Validation:  [[ 1420.73918171]]\n",
      "Loop  8813 :    Loss_Train:  [[ 4822.51493541]]    Loss_Validation:  [[ 1420.73923545]]\n",
      "Loop  8814 :    Loss_Train:  [[ 4822.51493499]]    Loss_Validation:  [[ 1420.73928916]]\n",
      "Loop  8815 :    Loss_Train:  [[ 4822.51493458]]    Loss_Validation:  [[ 1420.73934283]]\n",
      "Loop  8816 :    Loss_Train:  [[ 4822.51493417]]    Loss_Validation:  [[ 1420.73939645]]\n",
      "Loop  8817 :    Loss_Train:  [[ 4822.51493375]]    Loss_Validation:  [[ 1420.73945004]]\n",
      "Loop  8818 :    Loss_Train:  [[ 4822.51493334]]    Loss_Validation:  [[ 1420.73950359]]\n",
      "Loop  8819 :    Loss_Train:  [[ 4822.51493293]]    Loss_Validation:  [[ 1420.73955711]]\n",
      "Loop  8820 :    Loss_Train:  [[ 4822.51493252]]    Loss_Validation:  [[ 1420.73961058]]\n",
      "Loop  8821 :    Loss_Train:  [[ 4822.51493211]]    Loss_Validation:  [[ 1420.73966402]]\n",
      "Loop  8822 :    Loss_Train:  [[ 4822.5149317]]    Loss_Validation:  [[ 1420.73971741]]\n",
      "Loop  8823 :    Loss_Train:  [[ 4822.51493129]]    Loss_Validation:  [[ 1420.73977077]]\n",
      "Loop  8824 :    Loss_Train:  [[ 4822.51493088]]    Loss_Validation:  [[ 1420.73982409]]\n",
      "Loop  8825 :    Loss_Train:  [[ 4822.51493048]]    Loss_Validation:  [[ 1420.73987737]]\n",
      "Loop  8826 :    Loss_Train:  [[ 4822.51493007]]    Loss_Validation:  [[ 1420.73993062]]\n",
      "Loop  8827 :    Loss_Train:  [[ 4822.51492966]]    Loss_Validation:  [[ 1420.73998382]]\n",
      "Loop  8828 :    Loss_Train:  [[ 4822.51492926]]    Loss_Validation:  [[ 1420.74003699]]\n",
      "Loop  8829 :    Loss_Train:  [[ 4822.51492885]]    Loss_Validation:  [[ 1420.74009012]]\n",
      "Loop  8830 :    Loss_Train:  [[ 4822.51492845]]    Loss_Validation:  [[ 1420.74014321]]\n",
      "Loop  8831 :    Loss_Train:  [[ 4822.51492804]]    Loss_Validation:  [[ 1420.74019626]]\n",
      "Loop  8832 :    Loss_Train:  [[ 4822.51492764]]    Loss_Validation:  [[ 1420.74024928]]\n",
      "Loop  8833 :    Loss_Train:  [[ 4822.51492724]]    Loss_Validation:  [[ 1420.74030225]]\n",
      "Loop  8834 :    Loss_Train:  [[ 4822.51492684]]    Loss_Validation:  [[ 1420.74035519]]\n",
      "Loop  8835 :    Loss_Train:  [[ 4822.51492643]]    Loss_Validation:  [[ 1420.74040809]]\n",
      "Loop  8836 :    Loss_Train:  [[ 4822.51492603]]    Loss_Validation:  [[ 1420.74046095]]\n",
      "Loop  8837 :    Loss_Train:  [[ 4822.51492563]]    Loss_Validation:  [[ 1420.74051378]]\n",
      "Loop  8838 :    Loss_Train:  [[ 4822.51492523]]    Loss_Validation:  [[ 1420.74056656]]\n",
      "Loop  8839 :    Loss_Train:  [[ 4822.51492484]]    Loss_Validation:  [[ 1420.74061931]]\n",
      "Loop  8840 :    Loss_Train:  [[ 4822.51492444]]    Loss_Validation:  [[ 1420.74067202]]\n",
      "Loop  8841 :    Loss_Train:  [[ 4822.51492404]]    Loss_Validation:  [[ 1420.74072469]]\n",
      "Loop  8842 :    Loss_Train:  [[ 4822.51492364]]    Loss_Validation:  [[ 1420.74077733]]\n",
      "Loop  8843 :    Loss_Train:  [[ 4822.51492325]]    Loss_Validation:  [[ 1420.74082992]]\n",
      "Loop  8844 :    Loss_Train:  [[ 4822.51492285]]    Loss_Validation:  [[ 1420.74088248]]\n",
      "Loop  8845 :    Loss_Train:  [[ 4822.51492246]]    Loss_Validation:  [[ 1420.740935]]\n",
      "Loop  8846 :    Loss_Train:  [[ 4822.51492206]]    Loss_Validation:  [[ 1420.74098749]]\n",
      "Loop  8847 :    Loss_Train:  [[ 4822.51492167]]    Loss_Validation:  [[ 1420.74103993]]\n",
      "Loop  8848 :    Loss_Train:  [[ 4822.51492128]]    Loss_Validation:  [[ 1420.74109234]]\n",
      "Loop  8849 :    Loss_Train:  [[ 4822.51492088]]    Loss_Validation:  [[ 1420.74114471]]\n",
      "Loop  8850 :    Loss_Train:  [[ 4822.51492049]]    Loss_Validation:  [[ 1420.74119704]]\n",
      "Loop  8851 :    Loss_Train:  [[ 4822.5149201]]    Loss_Validation:  [[ 1420.74124934]]\n",
      "Loop  8852 :    Loss_Train:  [[ 4822.51491971]]    Loss_Validation:  [[ 1420.74130159]]\n",
      "Loop  8853 :    Loss_Train:  [[ 4822.51491932]]    Loss_Validation:  [[ 1420.74135381]]\n",
      "Loop  8854 :    Loss_Train:  [[ 4822.51491893]]    Loss_Validation:  [[ 1420.74140599]]\n",
      "Loop  8855 :    Loss_Train:  [[ 4822.51491854]]    Loss_Validation:  [[ 1420.74145814]]\n",
      "Loop  8856 :    Loss_Train:  [[ 4822.51491815]]    Loss_Validation:  [[ 1420.74151025]]\n",
      "Loop  8857 :    Loss_Train:  [[ 4822.51491776]]    Loss_Validation:  [[ 1420.74156231]]\n",
      "Loop  8858 :    Loss_Train:  [[ 4822.51491738]]    Loss_Validation:  [[ 1420.74161435]]\n",
      "Loop  8859 :    Loss_Train:  [[ 4822.51491699]]    Loss_Validation:  [[ 1420.74166634]]\n",
      "Loop  8860 :    Loss_Train:  [[ 4822.5149166]]    Loss_Validation:  [[ 1420.7417183]]\n",
      "Loop  8861 :    Loss_Train:  [[ 4822.51491622]]    Loss_Validation:  [[ 1420.74177022]]\n",
      "Loop  8862 :    Loss_Train:  [[ 4822.51491583]]    Loss_Validation:  [[ 1420.7418221]]\n",
      "Loop  8863 :    Loss_Train:  [[ 4822.51491545]]    Loss_Validation:  [[ 1420.74187395]]\n",
      "Loop  8864 :    Loss_Train:  [[ 4822.51491507]]    Loss_Validation:  [[ 1420.74192575]]\n",
      "Loop  8865 :    Loss_Train:  [[ 4822.51491468]]    Loss_Validation:  [[ 1420.74197752]]\n",
      "Loop  8866 :    Loss_Train:  [[ 4822.5149143]]    Loss_Validation:  [[ 1420.74202926]]\n",
      "Loop  8867 :    Loss_Train:  [[ 4822.51491392]]    Loss_Validation:  [[ 1420.74208095]]\n",
      "Loop  8868 :    Loss_Train:  [[ 4822.51491354]]    Loss_Validation:  [[ 1420.74213261]]\n",
      "Loop  8869 :    Loss_Train:  [[ 4822.51491316]]    Loss_Validation:  [[ 1420.74218423]]\n",
      "Loop  8870 :    Loss_Train:  [[ 4822.51491278]]    Loss_Validation:  [[ 1420.74223582]]\n",
      "Loop  8871 :    Loss_Train:  [[ 4822.5149124]]    Loss_Validation:  [[ 1420.74228737]]\n",
      "Loop  8872 :    Loss_Train:  [[ 4822.51491202]]    Loss_Validation:  [[ 1420.74233888]]\n",
      "Loop  8873 :    Loss_Train:  [[ 4822.51491164]]    Loss_Validation:  [[ 1420.74239035]]\n",
      "Loop  8874 :    Loss_Train:  [[ 4822.51491126]]    Loss_Validation:  [[ 1420.74244179]]\n",
      "Loop  8875 :    Loss_Train:  [[ 4822.51491089]]    Loss_Validation:  [[ 1420.74249318]]\n",
      "Loop  8876 :    Loss_Train:  [[ 4822.51491051]]    Loss_Validation:  [[ 1420.74254455]]\n",
      "Loop  8877 :    Loss_Train:  [[ 4822.51491014]]    Loss_Validation:  [[ 1420.74259587]]\n",
      "Loop  8878 :    Loss_Train:  [[ 4822.51490976]]    Loss_Validation:  [[ 1420.74264716]]\n",
      "Loop  8879 :    Loss_Train:  [[ 4822.51490939]]    Loss_Validation:  [[ 1420.74269841]]\n",
      "Loop  8880 :    Loss_Train:  [[ 4822.51490901]]    Loss_Validation:  [[ 1420.74274963]]\n",
      "Loop  8881 :    Loss_Train:  [[ 4822.51490864]]    Loss_Validation:  [[ 1420.7428008]]\n",
      "Loop  8882 :    Loss_Train:  [[ 4822.51490827]]    Loss_Validation:  [[ 1420.74285195]]\n",
      "Loop  8883 :    Loss_Train:  [[ 4822.51490789]]    Loss_Validation:  [[ 1420.74290305]]\n",
      "Loop  8884 :    Loss_Train:  [[ 4822.51490752]]    Loss_Validation:  [[ 1420.74295412]]\n",
      "Loop  8885 :    Loss_Train:  [[ 4822.51490715]]    Loss_Validation:  [[ 1420.74300515]]\n",
      "Loop  8886 :    Loss_Train:  [[ 4822.51490678]]    Loss_Validation:  [[ 1420.74305614]]\n",
      "Loop  8887 :    Loss_Train:  [[ 4822.51490641]]    Loss_Validation:  [[ 1420.7431071]]\n",
      "Loop  8888 :    Loss_Train:  [[ 4822.51490604]]    Loss_Validation:  [[ 1420.74315802]]\n",
      "Loop  8889 :    Loss_Train:  [[ 4822.51490567]]    Loss_Validation:  [[ 1420.7432089]]\n",
      "Loop  8890 :    Loss_Train:  [[ 4822.5149053]]    Loss_Validation:  [[ 1420.74325975]]\n",
      "Loop  8891 :    Loss_Train:  [[ 4822.51490494]]    Loss_Validation:  [[ 1420.74331056]]\n",
      "Loop  8892 :    Loss_Train:  [[ 4822.51490457]]    Loss_Validation:  [[ 1420.74336134]]\n",
      "Loop  8893 :    Loss_Train:  [[ 4822.5149042]]    Loss_Validation:  [[ 1420.74341207]]\n",
      "Loop  8894 :    Loss_Train:  [[ 4822.51490384]]    Loss_Validation:  [[ 1420.74346278]]\n",
      "Loop  8895 :    Loss_Train:  [[ 4822.51490347]]    Loss_Validation:  [[ 1420.74351344]]\n",
      "Loop  8896 :    Loss_Train:  [[ 4822.51490311]]    Loss_Validation:  [[ 1420.74356407]]\n",
      "Loop  8897 :    Loss_Train:  [[ 4822.51490274]]    Loss_Validation:  [[ 1420.74361466]]\n",
      "Loop  8898 :    Loss_Train:  [[ 4822.51490238]]    Loss_Validation:  [[ 1420.74366522]]\n",
      "Loop  8899 :    Loss_Train:  [[ 4822.51490201]]    Loss_Validation:  [[ 1420.74371574]]\n",
      "Loop  8900 :    Loss_Train:  [[ 4822.51490165]]    Loss_Validation:  [[ 1420.74376622]]\n",
      "Loop  8901 :    Loss_Train:  [[ 4822.51490129]]    Loss_Validation:  [[ 1420.74381666]]\n",
      "Loop  8902 :    Loss_Train:  [[ 4822.51490093]]    Loss_Validation:  [[ 1420.74386707]]\n",
      "Loop  8903 :    Loss_Train:  [[ 4822.51490057]]    Loss_Validation:  [[ 1420.74391745]]\n",
      "Loop  8904 :    Loss_Train:  [[ 4822.51490021]]    Loss_Validation:  [[ 1420.74396779]]\n",
      "Loop  8905 :    Loss_Train:  [[ 4822.51489985]]    Loss_Validation:  [[ 1420.74401809]]\n",
      "Loop  8906 :    Loss_Train:  [[ 4822.51489949]]    Loss_Validation:  [[ 1420.74406835]]\n",
      "Loop  8907 :    Loss_Train:  [[ 4822.51489913]]    Loss_Validation:  [[ 1420.74411858]]\n",
      "Loop  8908 :    Loss_Train:  [[ 4822.51489877]]    Loss_Validation:  [[ 1420.74416878]]\n",
      "Loop  8909 :    Loss_Train:  [[ 4822.51489841]]    Loss_Validation:  [[ 1420.74421893]]\n",
      "Loop  8910 :    Loss_Train:  [[ 4822.51489806]]    Loss_Validation:  [[ 1420.74426905]]\n",
      "Loop  8911 :    Loss_Train:  [[ 4822.5148977]]    Loss_Validation:  [[ 1420.74431914]]\n",
      "Loop  8912 :    Loss_Train:  [[ 4822.51489735]]    Loss_Validation:  [[ 1420.74436919]]\n",
      "Loop  8913 :    Loss_Train:  [[ 4822.51489699]]    Loss_Validation:  [[ 1420.7444192]]\n",
      "Loop  8914 :    Loss_Train:  [[ 4822.51489664]]    Loss_Validation:  [[ 1420.74446918]]\n",
      "Loop  8915 :    Loss_Train:  [[ 4822.51489628]]    Loss_Validation:  [[ 1420.74451912]]\n",
      "Loop  8916 :    Loss_Train:  [[ 4822.51489593]]    Loss_Validation:  [[ 1420.74456902]]\n",
      "Loop  8917 :    Loss_Train:  [[ 4822.51489557]]    Loss_Validation:  [[ 1420.74461889]]\n",
      "Loop  8918 :    Loss_Train:  [[ 4822.51489522]]    Loss_Validation:  [[ 1420.74466872]]\n",
      "Loop  8919 :    Loss_Train:  [[ 4822.51489487]]    Loss_Validation:  [[ 1420.74471852]]\n",
      "Loop  8920 :    Loss_Train:  [[ 4822.51489452]]    Loss_Validation:  [[ 1420.74476828]]\n",
      "Loop  8921 :    Loss_Train:  [[ 4822.51489417]]    Loss_Validation:  [[ 1420.74481801]]\n",
      "Loop  8922 :    Loss_Train:  [[ 4822.51489382]]    Loss_Validation:  [[ 1420.7448677]]\n",
      "Loop  8923 :    Loss_Train:  [[ 4822.51489347]]    Loss_Validation:  [[ 1420.74491735]]\n",
      "Loop  8924 :    Loss_Train:  [[ 4822.51489312]]    Loss_Validation:  [[ 1420.74496697]]\n",
      "Loop  8925 :    Loss_Train:  [[ 4822.51489277]]    Loss_Validation:  [[ 1420.74501655]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  8926 :    Loss_Train:  [[ 4822.51489242]]    Loss_Validation:  [[ 1420.7450661]]\n",
      "Loop  8927 :    Loss_Train:  [[ 4822.51489207]]    Loss_Validation:  [[ 1420.74511561]]\n",
      "Loop  8928 :    Loss_Train:  [[ 4822.51489173]]    Loss_Validation:  [[ 1420.74516508]]\n",
      "Loop  8929 :    Loss_Train:  [[ 4822.51489138]]    Loss_Validation:  [[ 1420.74521452]]\n",
      "Loop  8930 :    Loss_Train:  [[ 4822.51489104]]    Loss_Validation:  [[ 1420.74526393]]\n",
      "Loop  8931 :    Loss_Train:  [[ 4822.51489069]]    Loss_Validation:  [[ 1420.7453133]]\n",
      "Loop  8932 :    Loss_Train:  [[ 4822.51489034]]    Loss_Validation:  [[ 1420.74536263]]\n",
      "Loop  8933 :    Loss_Train:  [[ 4822.51489]]    Loss_Validation:  [[ 1420.74541193]]\n",
      "Loop  8934 :    Loss_Train:  [[ 4822.51488966]]    Loss_Validation:  [[ 1420.74546119]]\n",
      "Loop  8935 :    Loss_Train:  [[ 4822.51488931]]    Loss_Validation:  [[ 1420.74551042]]\n",
      "Loop  8936 :    Loss_Train:  [[ 4822.51488897]]    Loss_Validation:  [[ 1420.74555961]]\n",
      "Loop  8937 :    Loss_Train:  [[ 4822.51488863]]    Loss_Validation:  [[ 1420.74560876]]\n",
      "Loop  8938 :    Loss_Train:  [[ 4822.51488829]]    Loss_Validation:  [[ 1420.74565789]]\n",
      "Loop  8939 :    Loss_Train:  [[ 4822.51488795]]    Loss_Validation:  [[ 1420.74570697]]\n",
      "Loop  8940 :    Loss_Train:  [[ 4822.51488761]]    Loss_Validation:  [[ 1420.74575602]]\n",
      "Loop  8941 :    Loss_Train:  [[ 4822.51488727]]    Loss_Validation:  [[ 1420.74580504]]\n",
      "Loop  8942 :    Loss_Train:  [[ 4822.51488693]]    Loss_Validation:  [[ 1420.74585401]]\n",
      "Loop  8943 :    Loss_Train:  [[ 4822.51488659]]    Loss_Validation:  [[ 1420.74590296]]\n",
      "Loop  8944 :    Loss_Train:  [[ 4822.51488625]]    Loss_Validation:  [[ 1420.74595187]]\n",
      "Loop  8945 :    Loss_Train:  [[ 4822.51488591]]    Loss_Validation:  [[ 1420.74600074]]\n",
      "Loop  8946 :    Loss_Train:  [[ 4822.51488557]]    Loss_Validation:  [[ 1420.74604958]]\n",
      "Loop  8947 :    Loss_Train:  [[ 4822.51488524]]    Loss_Validation:  [[ 1420.74609838]]\n",
      "Loop  8948 :    Loss_Train:  [[ 4822.5148849]]    Loss_Validation:  [[ 1420.74614715]]\n",
      "Loop  8949 :    Loss_Train:  [[ 4822.51488456]]    Loss_Validation:  [[ 1420.74619588]]\n",
      "Loop  8950 :    Loss_Train:  [[ 4822.51488423]]    Loss_Validation:  [[ 1420.74624458]]\n",
      "Loop  8951 :    Loss_Train:  [[ 4822.51488389]]    Loss_Validation:  [[ 1420.74629325]]\n",
      "Loop  8952 :    Loss_Train:  [[ 4822.51488356]]    Loss_Validation:  [[ 1420.74634187]]\n",
      "Loop  8953 :    Loss_Train:  [[ 4822.51488323]]    Loss_Validation:  [[ 1420.74639047]]\n",
      "Loop  8954 :    Loss_Train:  [[ 4822.51488289]]    Loss_Validation:  [[ 1420.74643903]]\n",
      "Loop  8955 :    Loss_Train:  [[ 4822.51488256]]    Loss_Validation:  [[ 1420.74648755]]\n",
      "Loop  8956 :    Loss_Train:  [[ 4822.51488223]]    Loss_Validation:  [[ 1420.74653604]]\n",
      "Loop  8957 :    Loss_Train:  [[ 4822.5148819]]    Loss_Validation:  [[ 1420.74658449]]\n",
      "Loop  8958 :    Loss_Train:  [[ 4822.51488156]]    Loss_Validation:  [[ 1420.74663291]]\n",
      "Loop  8959 :    Loss_Train:  [[ 4822.51488123]]    Loss_Validation:  [[ 1420.74668129]]\n",
      "Loop  8960 :    Loss_Train:  [[ 4822.5148809]]    Loss_Validation:  [[ 1420.74672964]]\n",
      "Loop  8961 :    Loss_Train:  [[ 4822.51488057]]    Loss_Validation:  [[ 1420.74677795]]\n",
      "Loop  8962 :    Loss_Train:  [[ 4822.51488024]]    Loss_Validation:  [[ 1420.74682623]]\n",
      "Loop  8963 :    Loss_Train:  [[ 4822.51487992]]    Loss_Validation:  [[ 1420.74687448]]\n",
      "Loop  8964 :    Loss_Train:  [[ 4822.51487959]]    Loss_Validation:  [[ 1420.74692269]]\n",
      "Loop  8965 :    Loss_Train:  [[ 4822.51487926]]    Loss_Validation:  [[ 1420.74697086]]\n",
      "Loop  8966 :    Loss_Train:  [[ 4822.51487893]]    Loss_Validation:  [[ 1420.747019]]\n",
      "Loop  8967 :    Loss_Train:  [[ 4822.51487861]]    Loss_Validation:  [[ 1420.74706711]]\n",
      "Loop  8968 :    Loss_Train:  [[ 4822.51487828]]    Loss_Validation:  [[ 1420.74711518]]\n",
      "Loop  8969 :    Loss_Train:  [[ 4822.51487796]]    Loss_Validation:  [[ 1420.74716322]]\n",
      "Loop  8970 :    Loss_Train:  [[ 4822.51487763]]    Loss_Validation:  [[ 1420.74721122]]\n",
      "Loop  8971 :    Loss_Train:  [[ 4822.51487731]]    Loss_Validation:  [[ 1420.74725918]]\n",
      "Loop  8972 :    Loss_Train:  [[ 4822.51487698]]    Loss_Validation:  [[ 1420.74730712]]\n",
      "Loop  8973 :    Loss_Train:  [[ 4822.51487666]]    Loss_Validation:  [[ 1420.74735502]]\n",
      "Loop  8974 :    Loss_Train:  [[ 4822.51487634]]    Loss_Validation:  [[ 1420.74740288]]\n",
      "Loop  8975 :    Loss_Train:  [[ 4822.51487601]]    Loss_Validation:  [[ 1420.74745071]]\n",
      "Loop  8976 :    Loss_Train:  [[ 4822.51487569]]    Loss_Validation:  [[ 1420.7474985]]\n",
      "Loop  8977 :    Loss_Train:  [[ 4822.51487537]]    Loss_Validation:  [[ 1420.74754626]]\n",
      "Loop  8978 :    Loss_Train:  [[ 4822.51487505]]    Loss_Validation:  [[ 1420.74759399]]\n",
      "Loop  8979 :    Loss_Train:  [[ 4822.51487473]]    Loss_Validation:  [[ 1420.74764168]]\n",
      "Loop  8980 :    Loss_Train:  [[ 4822.51487441]]    Loss_Validation:  [[ 1420.74768934]]\n",
      "Loop  8981 :    Loss_Train:  [[ 4822.51487409]]    Loss_Validation:  [[ 1420.74773696]]\n",
      "Loop  8982 :    Loss_Train:  [[ 4822.51487377]]    Loss_Validation:  [[ 1420.74778455]]\n",
      "Loop  8983 :    Loss_Train:  [[ 4822.51487345]]    Loss_Validation:  [[ 1420.74783211]]\n",
      "Loop  8984 :    Loss_Train:  [[ 4822.51487313]]    Loss_Validation:  [[ 1420.74787963]]\n",
      "Loop  8985 :    Loss_Train:  [[ 4822.51487282]]    Loss_Validation:  [[ 1420.74792711]]\n",
      "Loop  8986 :    Loss_Train:  [[ 4822.5148725]]    Loss_Validation:  [[ 1420.74797456]]\n",
      "Loop  8987 :    Loss_Train:  [[ 4822.51487218]]    Loss_Validation:  [[ 1420.74802198]]\n",
      "Loop  8988 :    Loss_Train:  [[ 4822.51487187]]    Loss_Validation:  [[ 1420.74806937]]\n",
      "Loop  8989 :    Loss_Train:  [[ 4822.51487155]]    Loss_Validation:  [[ 1420.74811672]]\n",
      "Loop  8990 :    Loss_Train:  [[ 4822.51487124]]    Loss_Validation:  [[ 1420.74816403]]\n",
      "Loop  8991 :    Loss_Train:  [[ 4822.51487092]]    Loss_Validation:  [[ 1420.74821131]]\n",
      "Loop  8992 :    Loss_Train:  [[ 4822.51487061]]    Loss_Validation:  [[ 1420.74825856]]\n",
      "Loop  8993 :    Loss_Train:  [[ 4822.51487029]]    Loss_Validation:  [[ 1420.74830577]]\n",
      "Loop  8994 :    Loss_Train:  [[ 4822.51486998]]    Loss_Validation:  [[ 1420.74835295]]\n",
      "Loop  8995 :    Loss_Train:  [[ 4822.51486967]]    Loss_Validation:  [[ 1420.7484001]]\n",
      "Loop  8996 :    Loss_Train:  [[ 4822.51486936]]    Loss_Validation:  [[ 1420.74844721]]\n",
      "Loop  8997 :    Loss_Train:  [[ 4822.51486904]]    Loss_Validation:  [[ 1420.74849429]]\n",
      "Loop  8998 :    Loss_Train:  [[ 4822.51486873]]    Loss_Validation:  [[ 1420.74854133]]\n",
      "Loop  8999 :    Loss_Train:  [[ 4822.51486842]]    Loss_Validation:  [[ 1420.74858834]]\n",
      "Loop  9000 :    Loss_Train:  [[ 4822.51486811]]    Loss_Validation:  [[ 1420.74863532]]\n",
      "Loop  9001 :    Loss_Train:  [[ 4822.5148678]]    Loss_Validation:  [[ 1420.74868226]]\n",
      "Loop  9002 :    Loss_Train:  [[ 4822.51486749]]    Loss_Validation:  [[ 1420.74872917]]\n",
      "Loop  9003 :    Loss_Train:  [[ 4822.51486718]]    Loss_Validation:  [[ 1420.74877604]]\n",
      "Loop  9004 :    Loss_Train:  [[ 4822.51486688]]    Loss_Validation:  [[ 1420.74882288]]\n",
      "Loop  9005 :    Loss_Train:  [[ 4822.51486657]]    Loss_Validation:  [[ 1420.74886969]]\n",
      "Loop  9006 :    Loss_Train:  [[ 4822.51486626]]    Loss_Validation:  [[ 1420.74891646]]\n",
      "Loop  9007 :    Loss_Train:  [[ 4822.51486595]]    Loss_Validation:  [[ 1420.7489632]]\n",
      "Loop  9008 :    Loss_Train:  [[ 4822.51486565]]    Loss_Validation:  [[ 1420.74900991]]\n",
      "Loop  9009 :    Loss_Train:  [[ 4822.51486534]]    Loss_Validation:  [[ 1420.74905658]]\n",
      "Loop  9010 :    Loss_Train:  [[ 4822.51486504]]    Loss_Validation:  [[ 1420.74910322]]\n",
      "Loop  9011 :    Loss_Train:  [[ 4822.51486473]]    Loss_Validation:  [[ 1420.74914982]]\n",
      "Loop  9012 :    Loss_Train:  [[ 4822.51486443]]    Loss_Validation:  [[ 1420.74919639]]\n",
      "Loop  9013 :    Loss_Train:  [[ 4822.51486412]]    Loss_Validation:  [[ 1420.74924293]]\n",
      "Loop  9014 :    Loss_Train:  [[ 4822.51486382]]    Loss_Validation:  [[ 1420.74928944]]\n",
      "Loop  9015 :    Loss_Train:  [[ 4822.51486352]]    Loss_Validation:  [[ 1420.74933591]]\n",
      "Loop  9016 :    Loss_Train:  [[ 4822.51486321]]    Loss_Validation:  [[ 1420.74938235]]\n",
      "Loop  9017 :    Loss_Train:  [[ 4822.51486291]]    Loss_Validation:  [[ 1420.74942875]]\n",
      "Loop  9018 :    Loss_Train:  [[ 4822.51486261]]    Loss_Validation:  [[ 1420.74947512]]\n",
      "Loop  9019 :    Loss_Train:  [[ 4822.51486231]]    Loss_Validation:  [[ 1420.74952146]]\n",
      "Loop  9020 :    Loss_Train:  [[ 4822.51486201]]    Loss_Validation:  [[ 1420.74956776]]\n",
      "Loop  9021 :    Loss_Train:  [[ 4822.51486171]]    Loss_Validation:  [[ 1420.74961403]]\n",
      "Loop  9022 :    Loss_Train:  [[ 4822.51486141]]    Loss_Validation:  [[ 1420.74966027]]\n",
      "Loop  9023 :    Loss_Train:  [[ 4822.51486111]]    Loss_Validation:  [[ 1420.74970647]]\n",
      "Loop  9024 :    Loss_Train:  [[ 4822.51486081]]    Loss_Validation:  [[ 1420.74975265]]\n",
      "Loop  9025 :    Loss_Train:  [[ 4822.51486051]]    Loss_Validation:  [[ 1420.74979878]]\n",
      "Loop  9026 :    Loss_Train:  [[ 4822.51486022]]    Loss_Validation:  [[ 1420.74984489]]\n",
      "Loop  9027 :    Loss_Train:  [[ 4822.51485992]]    Loss_Validation:  [[ 1420.74989096]]\n",
      "Loop  9028 :    Loss_Train:  [[ 4822.51485962]]    Loss_Validation:  [[ 1420.749937]]\n",
      "Loop  9029 :    Loss_Train:  [[ 4822.51485933]]    Loss_Validation:  [[ 1420.749983]]\n",
      "Loop  9030 :    Loss_Train:  [[ 4822.51485903]]    Loss_Validation:  [[ 1420.75002897]]\n",
      "Loop  9031 :    Loss_Train:  [[ 4822.51485873]]    Loss_Validation:  [[ 1420.75007491]]\n",
      "Loop  9032 :    Loss_Train:  [[ 4822.51485844]]    Loss_Validation:  [[ 1420.75012082]]\n",
      "Loop  9033 :    Loss_Train:  [[ 4822.51485814]]    Loss_Validation:  [[ 1420.75016669]]\n",
      "Loop  9034 :    Loss_Train:  [[ 4822.51485785]]    Loss_Validation:  [[ 1420.75021253]]\n",
      "Loop  9035 :    Loss_Train:  [[ 4822.51485756]]    Loss_Validation:  [[ 1420.75025833]]\n",
      "Loop  9036 :    Loss_Train:  [[ 4822.51485726]]    Loss_Validation:  [[ 1420.75030411]]\n",
      "Loop  9037 :    Loss_Train:  [[ 4822.51485697]]    Loss_Validation:  [[ 1420.75034985]]\n",
      "Loop  9038 :    Loss_Train:  [[ 4822.51485668]]    Loss_Validation:  [[ 1420.75039556]]\n",
      "Loop  9039 :    Loss_Train:  [[ 4822.51485639]]    Loss_Validation:  [[ 1420.75044123]]\n",
      "Loop  9040 :    Loss_Train:  [[ 4822.51485609]]    Loss_Validation:  [[ 1420.75048687]]\n",
      "Loop  9041 :    Loss_Train:  [[ 4822.5148558]]    Loss_Validation:  [[ 1420.75053248]]\n",
      "Loop  9042 :    Loss_Train:  [[ 4822.51485551]]    Loss_Validation:  [[ 1420.75057806]]\n",
      "Loop  9043 :    Loss_Train:  [[ 4822.51485522]]    Loss_Validation:  [[ 1420.7506236]]\n",
      "Loop  9044 :    Loss_Train:  [[ 4822.51485493]]    Loss_Validation:  [[ 1420.75066911]]\n",
      "Loop  9045 :    Loss_Train:  [[ 4822.51485464]]    Loss_Validation:  [[ 1420.75071459]]\n",
      "Loop  9046 :    Loss_Train:  [[ 4822.51485436]]    Loss_Validation:  [[ 1420.75076003]]\n",
      "Loop  9047 :    Loss_Train:  [[ 4822.51485407]]    Loss_Validation:  [[ 1420.75080544]]\n",
      "Loop  9048 :    Loss_Train:  [[ 4822.51485378]]    Loss_Validation:  [[ 1420.75085082]]\n",
      "Loop  9049 :    Loss_Train:  [[ 4822.51485349]]    Loss_Validation:  [[ 1420.75089617]]\n",
      "Loop  9050 :    Loss_Train:  [[ 4822.51485321]]    Loss_Validation:  [[ 1420.75094148]]\n",
      "Loop  9051 :    Loss_Train:  [[ 4822.51485292]]    Loss_Validation:  [[ 1420.75098677]]\n",
      "Loop  9052 :    Loss_Train:  [[ 4822.51485263]]    Loss_Validation:  [[ 1420.75103201]]\n",
      "Loop  9053 :    Loss_Train:  [[ 4822.51485235]]    Loss_Validation:  [[ 1420.75107723]]\n",
      "Loop  9054 :    Loss_Train:  [[ 4822.51485206]]    Loss_Validation:  [[ 1420.75112241]]\n",
      "Loop  9055 :    Loss_Train:  [[ 4822.51485178]]    Loss_Validation:  [[ 1420.75116757]]\n",
      "Loop  9056 :    Loss_Train:  [[ 4822.51485149]]    Loss_Validation:  [[ 1420.75121268]]\n",
      "Loop  9057 :    Loss_Train:  [[ 4822.51485121]]    Loss_Validation:  [[ 1420.75125777]]\n",
      "Loop  9058 :    Loss_Train:  [[ 4822.51485093]]    Loss_Validation:  [[ 1420.75130282]]\n",
      "Loop  9059 :    Loss_Train:  [[ 4822.51485064]]    Loss_Validation:  [[ 1420.75134784]]\n",
      "Loop  9060 :    Loss_Train:  [[ 4822.51485036]]    Loss_Validation:  [[ 1420.75139283]]\n",
      "Loop  9061 :    Loss_Train:  [[ 4822.51485008]]    Loss_Validation:  [[ 1420.75143779]]\n",
      "Loop  9062 :    Loss_Train:  [[ 4822.5148498]]    Loss_Validation:  [[ 1420.75148271]]\n",
      "Loop  9063 :    Loss_Train:  [[ 4822.51484952]]    Loss_Validation:  [[ 1420.7515276]]\n",
      "Loop  9064 :    Loss_Train:  [[ 4822.51484924]]    Loss_Validation:  [[ 1420.75157246]]\n",
      "Loop  9065 :    Loss_Train:  [[ 4822.51484896]]    Loss_Validation:  [[ 1420.75161729]]\n",
      "Loop  9066 :    Loss_Train:  [[ 4822.51484868]]    Loss_Validation:  [[ 1420.75166209]]\n",
      "Loop  9067 :    Loss_Train:  [[ 4822.5148484]]    Loss_Validation:  [[ 1420.75170685]]\n",
      "Loop  9068 :    Loss_Train:  [[ 4822.51484812]]    Loss_Validation:  [[ 1420.75175158]]\n",
      "Loop  9069 :    Loss_Train:  [[ 4822.51484784]]    Loss_Validation:  [[ 1420.75179628]]\n",
      "Loop  9070 :    Loss_Train:  [[ 4822.51484756]]    Loss_Validation:  [[ 1420.75184094]]\n",
      "Loop  9071 :    Loss_Train:  [[ 4822.51484728]]    Loss_Validation:  [[ 1420.75188557]]\n",
      "Loop  9072 :    Loss_Train:  [[ 4822.51484701]]    Loss_Validation:  [[ 1420.75193018]]\n",
      "Loop  9073 :    Loss_Train:  [[ 4822.51484673]]    Loss_Validation:  [[ 1420.75197475]]\n",
      "Loop  9074 :    Loss_Train:  [[ 4822.51484645]]    Loss_Validation:  [[ 1420.75201928]]\n",
      "Loop  9075 :    Loss_Train:  [[ 4822.51484618]]    Loss_Validation:  [[ 1420.75206379]]\n",
      "Loop  9076 :    Loss_Train:  [[ 4822.5148459]]    Loss_Validation:  [[ 1420.75210826]]\n",
      "Loop  9077 :    Loss_Train:  [[ 4822.51484563]]    Loss_Validation:  [[ 1420.7521527]]\n",
      "Loop  9078 :    Loss_Train:  [[ 4822.51484535]]    Loss_Validation:  [[ 1420.75219711]]\n",
      "Loop  9079 :    Loss_Train:  [[ 4822.51484508]]    Loss_Validation:  [[ 1420.75224149]]\n",
      "Loop  9080 :    Loss_Train:  [[ 4822.5148448]]    Loss_Validation:  [[ 1420.75228583]]\n",
      "Loop  9081 :    Loss_Train:  [[ 4822.51484453]]    Loss_Validation:  [[ 1420.75233015]]\n",
      "Loop  9082 :    Loss_Train:  [[ 4822.51484426]]    Loss_Validation:  [[ 1420.75237443]]\n",
      "Loop  9083 :    Loss_Train:  [[ 4822.51484399]]    Loss_Validation:  [[ 1420.75241868]]\n",
      "Loop  9084 :    Loss_Train:  [[ 4822.51484371]]    Loss_Validation:  [[ 1420.75246289]]\n",
      "Loop  9085 :    Loss_Train:  [[ 4822.51484344]]    Loss_Validation:  [[ 1420.75250708]]\n",
      "Loop  9086 :    Loss_Train:  [[ 4822.51484317]]    Loss_Validation:  [[ 1420.75255123]]\n",
      "Loop  9087 :    Loss_Train:  [[ 4822.5148429]]    Loss_Validation:  [[ 1420.75259535]]\n",
      "Loop  9088 :    Loss_Train:  [[ 4822.51484263]]    Loss_Validation:  [[ 1420.75263944]]\n",
      "Loop  9089 :    Loss_Train:  [[ 4822.51484236]]    Loss_Validation:  [[ 1420.7526835]]\n",
      "Loop  9090 :    Loss_Train:  [[ 4822.51484209]]    Loss_Validation:  [[ 1420.75272753]]\n",
      "Loop  9091 :    Loss_Train:  [[ 4822.51484182]]    Loss_Validation:  [[ 1420.75277152]]\n",
      "Loop  9092 :    Loss_Train:  [[ 4822.51484155]]    Loss_Validation:  [[ 1420.75281549]]\n",
      "Loop  9093 :    Loss_Train:  [[ 4822.51484128]]    Loss_Validation:  [[ 1420.75285942]]\n",
      "Loop  9094 :    Loss_Train:  [[ 4822.51484102]]    Loss_Validation:  [[ 1420.75290332]]\n",
      "Loop  9095 :    Loss_Train:  [[ 4822.51484075]]    Loss_Validation:  [[ 1420.75294719]]\n",
      "Loop  9096 :    Loss_Train:  [[ 4822.51484048]]    Loss_Validation:  [[ 1420.75299102]]\n",
      "Loop  9097 :    Loss_Train:  [[ 4822.51484021]]    Loss_Validation:  [[ 1420.75303483]]\n",
      "Loop  9098 :    Loss_Train:  [[ 4822.51483995]]    Loss_Validation:  [[ 1420.7530786]]\n",
      "Loop  9099 :    Loss_Train:  [[ 4822.51483968]]    Loss_Validation:  [[ 1420.75312234]]\n",
      "Loop  9100 :    Loss_Train:  [[ 4822.51483942]]    Loss_Validation:  [[ 1420.75316605]]\n",
      "Loop  9101 :    Loss_Train:  [[ 4822.51483915]]    Loss_Validation:  [[ 1420.75320973]]\n",
      "Loop  9102 :    Loss_Train:  [[ 4822.51483889]]    Loss_Validation:  [[ 1420.75325338]]\n",
      "Loop  9103 :    Loss_Train:  [[ 4822.51483862]]    Loss_Validation:  [[ 1420.753297]]\n",
      "Loop  9104 :    Loss_Train:  [[ 4822.51483836]]    Loss_Validation:  [[ 1420.75334058]]\n",
      "Loop  9105 :    Loss_Train:  [[ 4822.5148381]]    Loss_Validation:  [[ 1420.75338413]]\n",
      "Loop  9106 :    Loss_Train:  [[ 4822.51483783]]    Loss_Validation:  [[ 1420.75342765]]\n",
      "Loop  9107 :    Loss_Train:  [[ 4822.51483757]]    Loss_Validation:  [[ 1420.75347114]]\n",
      "Loop  9108 :    Loss_Train:  [[ 4822.51483731]]    Loss_Validation:  [[ 1420.7535146]]\n",
      "Loop  9109 :    Loss_Train:  [[ 4822.51483705]]    Loss_Validation:  [[ 1420.75355803]]\n",
      "Loop  9110 :    Loss_Train:  [[ 4822.51483679]]    Loss_Validation:  [[ 1420.75360143]]\n",
      "Loop  9111 :    Loss_Train:  [[ 4822.51483653]]    Loss_Validation:  [[ 1420.75364479]]\n",
      "Loop  9112 :    Loss_Train:  [[ 4822.51483627]]    Loss_Validation:  [[ 1420.75368813]]\n",
      "Loop  9113 :    Loss_Train:  [[ 4822.51483601]]    Loss_Validation:  [[ 1420.75373143]]\n",
      "Loop  9114 :    Loss_Train:  [[ 4822.51483575]]    Loss_Validation:  [[ 1420.7537747]]\n",
      "Loop  9115 :    Loss_Train:  [[ 4822.51483549]]    Loss_Validation:  [[ 1420.75381794]]\n",
      "Loop  9116 :    Loss_Train:  [[ 4822.51483523]]    Loss_Validation:  [[ 1420.75386115]]\n",
      "Loop  9117 :    Loss_Train:  [[ 4822.51483497]]    Loss_Validation:  [[ 1420.75390433]]\n",
      "Loop  9118 :    Loss_Train:  [[ 4822.51483471]]    Loss_Validation:  [[ 1420.75394748]]\n",
      "Loop  9119 :    Loss_Train:  [[ 4822.51483445]]    Loss_Validation:  [[ 1420.75399059]]\n",
      "Loop  9120 :    Loss_Train:  [[ 4822.5148342]]    Loss_Validation:  [[ 1420.75403368]]\n",
      "Loop  9121 :    Loss_Train:  [[ 4822.51483394]]    Loss_Validation:  [[ 1420.75407673]]\n",
      "Loop  9122 :    Loss_Train:  [[ 4822.51483368]]    Loss_Validation:  [[ 1420.75411975]]\n",
      "Loop  9123 :    Loss_Train:  [[ 4822.51483343]]    Loss_Validation:  [[ 1420.75416274]]\n",
      "Loop  9124 :    Loss_Train:  [[ 4822.51483317]]    Loss_Validation:  [[ 1420.75420571]]\n",
      "Loop  9125 :    Loss_Train:  [[ 4822.51483292]]    Loss_Validation:  [[ 1420.75424863]]\n",
      "Loop  9126 :    Loss_Train:  [[ 4822.51483266]]    Loss_Validation:  [[ 1420.75429153]]\n",
      "Loop  9127 :    Loss_Train:  [[ 4822.51483241]]    Loss_Validation:  [[ 1420.7543344]]\n",
      "Loop  9128 :    Loss_Train:  [[ 4822.51483215]]    Loss_Validation:  [[ 1420.75437724]]\n",
      "Loop  9129 :    Loss_Train:  [[ 4822.5148319]]    Loss_Validation:  [[ 1420.75442004]]\n",
      "Loop  9130 :    Loss_Train:  [[ 4822.51483165]]    Loss_Validation:  [[ 1420.75446282]]\n",
      "Loop  9131 :    Loss_Train:  [[ 4822.51483139]]    Loss_Validation:  [[ 1420.75450556]]\n",
      "Loop  9132 :    Loss_Train:  [[ 4822.51483114]]    Loss_Validation:  [[ 1420.75454828]]\n",
      "Loop  9133 :    Loss_Train:  [[ 4822.51483089]]    Loss_Validation:  [[ 1420.75459096]]\n",
      "Loop  9134 :    Loss_Train:  [[ 4822.51483064]]    Loss_Validation:  [[ 1420.75463361]]\n",
      "Loop  9135 :    Loss_Train:  [[ 4822.51483039]]    Loss_Validation:  [[ 1420.75467623]]\n",
      "Loop  9136 :    Loss_Train:  [[ 4822.51483014]]    Loss_Validation:  [[ 1420.75471882]]\n",
      "Loop  9137 :    Loss_Train:  [[ 4822.51482988]]    Loss_Validation:  [[ 1420.75476138]]\n",
      "Loop  9138 :    Loss_Train:  [[ 4822.51482963]]    Loss_Validation:  [[ 1420.75480391]]\n",
      "Loop  9139 :    Loss_Train:  [[ 4822.51482938]]    Loss_Validation:  [[ 1420.75484641]]\n",
      "Loop  9140 :    Loss_Train:  [[ 4822.51482914]]    Loss_Validation:  [[ 1420.75488888]]\n",
      "Loop  9141 :    Loss_Train:  [[ 4822.51482889]]    Loss_Validation:  [[ 1420.75493132]]\n",
      "Loop  9142 :    Loss_Train:  [[ 4822.51482864]]    Loss_Validation:  [[ 1420.75497373]]\n",
      "Loop  9143 :    Loss_Train:  [[ 4822.51482839]]    Loss_Validation:  [[ 1420.7550161]]\n",
      "Loop  9144 :    Loss_Train:  [[ 4822.51482814]]    Loss_Validation:  [[ 1420.75505845]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  9145 :    Loss_Train:  [[ 4822.51482789]]    Loss_Validation:  [[ 1420.75510076]]\n",
      "Loop  9146 :    Loss_Train:  [[ 4822.51482765]]    Loss_Validation:  [[ 1420.75514305]]\n",
      "Loop  9147 :    Loss_Train:  [[ 4822.5148274]]    Loss_Validation:  [[ 1420.7551853]]\n",
      "Loop  9148 :    Loss_Train:  [[ 4822.51482716]]    Loss_Validation:  [[ 1420.75522752]]\n",
      "Loop  9149 :    Loss_Train:  [[ 4822.51482691]]    Loss_Validation:  [[ 1420.75526972]]\n",
      "Loop  9150 :    Loss_Train:  [[ 4822.51482666]]    Loss_Validation:  [[ 1420.75531188]]\n",
      "Loop  9151 :    Loss_Train:  [[ 4822.51482642]]    Loss_Validation:  [[ 1420.75535401]]\n",
      "Loop  9152 :    Loss_Train:  [[ 4822.51482617]]    Loss_Validation:  [[ 1420.75539612]]\n",
      "Loop  9153 :    Loss_Train:  [[ 4822.51482593]]    Loss_Validation:  [[ 1420.75543819]]\n",
      "Loop  9154 :    Loss_Train:  [[ 4822.51482569]]    Loss_Validation:  [[ 1420.75548023]]\n",
      "Loop  9155 :    Loss_Train:  [[ 4822.51482544]]    Loss_Validation:  [[ 1420.75552224]]\n",
      "Loop  9156 :    Loss_Train:  [[ 4822.5148252]]    Loss_Validation:  [[ 1420.75556422]]\n",
      "Loop  9157 :    Loss_Train:  [[ 4822.51482496]]    Loss_Validation:  [[ 1420.75560617]]\n",
      "Loop  9158 :    Loss_Train:  [[ 4822.51482471]]    Loss_Validation:  [[ 1420.75564809]]\n",
      "Loop  9159 :    Loss_Train:  [[ 4822.51482447]]    Loss_Validation:  [[ 1420.75568998]]\n",
      "Loop  9160 :    Loss_Train:  [[ 4822.51482423]]    Loss_Validation:  [[ 1420.75573184]]\n",
      "Loop  9161 :    Loss_Train:  [[ 4822.51482399]]    Loss_Validation:  [[ 1420.75577367]]\n",
      "Loop  9162 :    Loss_Train:  [[ 4822.51482375]]    Loss_Validation:  [[ 1420.75581547]]\n",
      "Loop  9163 :    Loss_Train:  [[ 4822.51482351]]    Loss_Validation:  [[ 1420.75585724]]\n",
      "Loop  9164 :    Loss_Train:  [[ 4822.51482327]]    Loss_Validation:  [[ 1420.75589898]]\n",
      "Loop  9165 :    Loss_Train:  [[ 4822.51482303]]    Loss_Validation:  [[ 1420.75594069]]\n",
      "Loop  9166 :    Loss_Train:  [[ 4822.51482279]]    Loss_Validation:  [[ 1420.75598237]]\n",
      "Loop  9167 :    Loss_Train:  [[ 4822.51482255]]    Loss_Validation:  [[ 1420.75602402]]\n",
      "Loop  9168 :    Loss_Train:  [[ 4822.51482231]]    Loss_Validation:  [[ 1420.75606564]]\n",
      "Loop  9169 :    Loss_Train:  [[ 4822.51482207]]    Loss_Validation:  [[ 1420.75610723]]\n",
      "Loop  9170 :    Loss_Train:  [[ 4822.51482183]]    Loss_Validation:  [[ 1420.75614879]]\n",
      "Loop  9171 :    Loss_Train:  [[ 4822.5148216]]    Loss_Validation:  [[ 1420.75619032]]\n",
      "Loop  9172 :    Loss_Train:  [[ 4822.51482136]]    Loss_Validation:  [[ 1420.75623182]]\n",
      "Loop  9173 :    Loss_Train:  [[ 4822.51482112]]    Loss_Validation:  [[ 1420.75627328]]\n",
      "Loop  9174 :    Loss_Train:  [[ 4822.51482089]]    Loss_Validation:  [[ 1420.75631472]]\n",
      "Loop  9175 :    Loss_Train:  [[ 4822.51482065]]    Loss_Validation:  [[ 1420.75635613]]\n",
      "Loop  9176 :    Loss_Train:  [[ 4822.51482041]]    Loss_Validation:  [[ 1420.75639751]]\n",
      "Loop  9177 :    Loss_Train:  [[ 4822.51482018]]    Loss_Validation:  [[ 1420.75643886]]\n",
      "Loop  9178 :    Loss_Train:  [[ 4822.51481994]]    Loss_Validation:  [[ 1420.75648018]]\n",
      "Loop  9179 :    Loss_Train:  [[ 4822.51481971]]    Loss_Validation:  [[ 1420.75652147]]\n",
      "Loop  9180 :    Loss_Train:  [[ 4822.51481948]]    Loss_Validation:  [[ 1420.75656274]]\n",
      "Loop  9181 :    Loss_Train:  [[ 4822.51481924]]    Loss_Validation:  [[ 1420.75660397]]\n",
      "Loop  9182 :    Loss_Train:  [[ 4822.51481901]]    Loss_Validation:  [[ 1420.75664517]]\n",
      "Loop  9183 :    Loss_Train:  [[ 4822.51481877]]    Loss_Validation:  [[ 1420.75668634]]\n",
      "Loop  9184 :    Loss_Train:  [[ 4822.51481854]]    Loss_Validation:  [[ 1420.75672748]]\n",
      "Loop  9185 :    Loss_Train:  [[ 4822.51481831]]    Loss_Validation:  [[ 1420.75676859]]\n",
      "Loop  9186 :    Loss_Train:  [[ 4822.51481808]]    Loss_Validation:  [[ 1420.75680968]]\n",
      "Loop  9187 :    Loss_Train:  [[ 4822.51481785]]    Loss_Validation:  [[ 1420.75685073]]\n",
      "Loop  9188 :    Loss_Train:  [[ 4822.51481761]]    Loss_Validation:  [[ 1420.75689175]]\n",
      "Loop  9189 :    Loss_Train:  [[ 4822.51481738]]    Loss_Validation:  [[ 1420.75693274]]\n",
      "Loop  9190 :    Loss_Train:  [[ 4822.51481715]]    Loss_Validation:  [[ 1420.75697371]]\n",
      "Loop  9191 :    Loss_Train:  [[ 4822.51481692]]    Loss_Validation:  [[ 1420.75701464]]\n",
      "Loop  9192 :    Loss_Train:  [[ 4822.51481669]]    Loss_Validation:  [[ 1420.75705555]]\n",
      "Loop  9193 :    Loss_Train:  [[ 4822.51481646]]    Loss_Validation:  [[ 1420.75709642]]\n",
      "Loop  9194 :    Loss_Train:  [[ 4822.51481623]]    Loss_Validation:  [[ 1420.75713727]]\n",
      "Loop  9195 :    Loss_Train:  [[ 4822.51481601]]    Loss_Validation:  [[ 1420.75717809]]\n",
      "Loop  9196 :    Loss_Train:  [[ 4822.51481578]]    Loss_Validation:  [[ 1420.75721887]]\n",
      "Loop  9197 :    Loss_Train:  [[ 4822.51481555]]    Loss_Validation:  [[ 1420.75725963]]\n",
      "Loop  9198 :    Loss_Train:  [[ 4822.51481532]]    Loss_Validation:  [[ 1420.75730036]]\n",
      "Loop  9199 :    Loss_Train:  [[ 4822.51481509]]    Loss_Validation:  [[ 1420.75734106]]\n",
      "Loop  9200 :    Loss_Train:  [[ 4822.51481487]]    Loss_Validation:  [[ 1420.75738173]]\n",
      "Loop  9201 :    Loss_Train:  [[ 4822.51481464]]    Loss_Validation:  [[ 1420.75742237]]\n",
      "Loop  9202 :    Loss_Train:  [[ 4822.51481441]]    Loss_Validation:  [[ 1420.75746298]]\n",
      "Loop  9203 :    Loss_Train:  [[ 4822.51481419]]    Loss_Validation:  [[ 1420.75750356]]\n",
      "Loop  9204 :    Loss_Train:  [[ 4822.51481396]]    Loss_Validation:  [[ 1420.75754412]]\n",
      "Loop  9205 :    Loss_Train:  [[ 4822.51481374]]    Loss_Validation:  [[ 1420.75758464]]\n",
      "Loop  9206 :    Loss_Train:  [[ 4822.51481351]]    Loss_Validation:  [[ 1420.75762513]]\n",
      "Loop  9207 :    Loss_Train:  [[ 4822.51481329]]    Loss_Validation:  [[ 1420.7576656]]\n",
      "Loop  9208 :    Loss_Train:  [[ 4822.51481306]]    Loss_Validation:  [[ 1420.75770603]]\n",
      "Loop  9209 :    Loss_Train:  [[ 4822.51481284]]    Loss_Validation:  [[ 1420.75774644]]\n",
      "Loop  9210 :    Loss_Train:  [[ 4822.51481262]]    Loss_Validation:  [[ 1420.75778682]]\n",
      "Loop  9211 :    Loss_Train:  [[ 4822.51481239]]    Loss_Validation:  [[ 1420.75782717]]\n",
      "Loop  9212 :    Loss_Train:  [[ 4822.51481217]]    Loss_Validation:  [[ 1420.75786749]]\n",
      "Loop  9213 :    Loss_Train:  [[ 4822.51481195]]    Loss_Validation:  [[ 1420.75790778]]\n",
      "Loop  9214 :    Loss_Train:  [[ 4822.51481172]]    Loss_Validation:  [[ 1420.75794804]]\n",
      "Loop  9215 :    Loss_Train:  [[ 4822.5148115]]    Loss_Validation:  [[ 1420.75798827]]\n",
      "Loop  9216 :    Loss_Train:  [[ 4822.51481128]]    Loss_Validation:  [[ 1420.75802847]]\n",
      "Loop  9217 :    Loss_Train:  [[ 4822.51481106]]    Loss_Validation:  [[ 1420.75806865]]\n",
      "Loop  9218 :    Loss_Train:  [[ 4822.51481084]]    Loss_Validation:  [[ 1420.75810879]]\n",
      "Loop  9219 :    Loss_Train:  [[ 4822.51481062]]    Loss_Validation:  [[ 1420.75814891]]\n",
      "Loop  9220 :    Loss_Train:  [[ 4822.5148104]]    Loss_Validation:  [[ 1420.758189]]\n",
      "Loop  9221 :    Loss_Train:  [[ 4822.51481018]]    Loss_Validation:  [[ 1420.75822905]]\n",
      "Loop  9222 :    Loss_Train:  [[ 4822.51480996]]    Loss_Validation:  [[ 1420.75826908]]\n",
      "Loop  9223 :    Loss_Train:  [[ 4822.51480974]]    Loss_Validation:  [[ 1420.75830908]]\n",
      "Loop  9224 :    Loss_Train:  [[ 4822.51480952]]    Loss_Validation:  [[ 1420.75834906]]\n",
      "Loop  9225 :    Loss_Train:  [[ 4822.5148093]]    Loss_Validation:  [[ 1420.758389]]\n",
      "Loop  9226 :    Loss_Train:  [[ 4822.51480909]]    Loss_Validation:  [[ 1420.75842891]]\n",
      "Loop  9227 :    Loss_Train:  [[ 4822.51480887]]    Loss_Validation:  [[ 1420.7584688]]\n",
      "Loop  9228 :    Loss_Train:  [[ 4822.51480865]]    Loss_Validation:  [[ 1420.75850865]]\n",
      "Loop  9229 :    Loss_Train:  [[ 4822.51480843]]    Loss_Validation:  [[ 1420.75854848]]\n",
      "Loop  9230 :    Loss_Train:  [[ 4822.51480822]]    Loss_Validation:  [[ 1420.75858828]]\n",
      "Loop  9231 :    Loss_Train:  [[ 4822.514808]]    Loss_Validation:  [[ 1420.75862805]]\n",
      "Loop  9232 :    Loss_Train:  [[ 4822.51480778]]    Loss_Validation:  [[ 1420.75866779]]\n",
      "Loop  9233 :    Loss_Train:  [[ 4822.51480757]]    Loss_Validation:  [[ 1420.75870751]]\n",
      "Loop  9234 :    Loss_Train:  [[ 4822.51480735]]    Loss_Validation:  [[ 1420.75874719]]\n",
      "Loop  9235 :    Loss_Train:  [[ 4822.51480714]]    Loss_Validation:  [[ 1420.75878685]]\n",
      "Loop  9236 :    Loss_Train:  [[ 4822.51480692]]    Loss_Validation:  [[ 1420.75882647]]\n",
      "Loop  9237 :    Loss_Train:  [[ 4822.51480671]]    Loss_Validation:  [[ 1420.75886607]]\n",
      "Loop  9238 :    Loss_Train:  [[ 4822.5148065]]    Loss_Validation:  [[ 1420.75890564]]\n",
      "Loop  9239 :    Loss_Train:  [[ 4822.51480628]]    Loss_Validation:  [[ 1420.75894518]]\n",
      "Loop  9240 :    Loss_Train:  [[ 4822.51480607]]    Loss_Validation:  [[ 1420.7589847]]\n",
      "Loop  9241 :    Loss_Train:  [[ 4822.51480586]]    Loss_Validation:  [[ 1420.75902418]]\n",
      "Loop  9242 :    Loss_Train:  [[ 4822.51480564]]    Loss_Validation:  [[ 1420.75906364]]\n",
      "Loop  9243 :    Loss_Train:  [[ 4822.51480543]]    Loss_Validation:  [[ 1420.75910307]]\n",
      "Loop  9244 :    Loss_Train:  [[ 4822.51480522]]    Loss_Validation:  [[ 1420.75914247]]\n",
      "Loop  9245 :    Loss_Train:  [[ 4822.51480501]]    Loss_Validation:  [[ 1420.75918184]]\n",
      "Loop  9246 :    Loss_Train:  [[ 4822.5148048]]    Loss_Validation:  [[ 1420.75922118]]\n",
      "Loop  9247 :    Loss_Train:  [[ 4822.51480459]]    Loss_Validation:  [[ 1420.75926049]]\n",
      "Loop  9248 :    Loss_Train:  [[ 4822.51480437]]    Loss_Validation:  [[ 1420.75929978]]\n",
      "Loop  9249 :    Loss_Train:  [[ 4822.51480416]]    Loss_Validation:  [[ 1420.75933904]]\n",
      "Loop  9250 :    Loss_Train:  [[ 4822.51480395]]    Loss_Validation:  [[ 1420.75937826]]\n",
      "Loop  9251 :    Loss_Train:  [[ 4822.51480374]]    Loss_Validation:  [[ 1420.75941746]]\n",
      "Loop  9252 :    Loss_Train:  [[ 4822.51480354]]    Loss_Validation:  [[ 1420.75945664]]\n",
      "Loop  9253 :    Loss_Train:  [[ 4822.51480333]]    Loss_Validation:  [[ 1420.75949578]]\n",
      "Loop  9254 :    Loss_Train:  [[ 4822.51480312]]    Loss_Validation:  [[ 1420.7595349]]\n",
      "Loop  9255 :    Loss_Train:  [[ 4822.51480291]]    Loss_Validation:  [[ 1420.75957399]]\n",
      "Loop  9256 :    Loss_Train:  [[ 4822.5148027]]    Loss_Validation:  [[ 1420.75961304]]\n",
      "Loop  9257 :    Loss_Train:  [[ 4822.51480249]]    Loss_Validation:  [[ 1420.75965208]]\n",
      "Loop  9258 :    Loss_Train:  [[ 4822.51480229]]    Loss_Validation:  [[ 1420.75969108]]\n",
      "Loop  9259 :    Loss_Train:  [[ 4822.51480208]]    Loss_Validation:  [[ 1420.75973005]]\n",
      "Loop  9260 :    Loss_Train:  [[ 4822.51480187]]    Loss_Validation:  [[ 1420.759769]]\n",
      "Loop  9261 :    Loss_Train:  [[ 4822.51480167]]    Loss_Validation:  [[ 1420.75980792]]\n",
      "Loop  9262 :    Loss_Train:  [[ 4822.51480146]]    Loss_Validation:  [[ 1420.75984681]]\n",
      "Loop  9263 :    Loss_Train:  [[ 4822.51480125]]    Loss_Validation:  [[ 1420.75988567]]\n",
      "Loop  9264 :    Loss_Train:  [[ 4822.51480105]]    Loss_Validation:  [[ 1420.75992451]]\n",
      "Loop  9265 :    Loss_Train:  [[ 4822.51480084]]    Loss_Validation:  [[ 1420.75996332]]\n",
      "Loop  9266 :    Loss_Train:  [[ 4822.51480064]]    Loss_Validation:  [[ 1420.76000209]]\n",
      "Loop  9267 :    Loss_Train:  [[ 4822.51480043]]    Loss_Validation:  [[ 1420.76004084]]\n",
      "Loop  9268 :    Loss_Train:  [[ 4822.51480023]]    Loss_Validation:  [[ 1420.76007957]]\n",
      "Loop  9269 :    Loss_Train:  [[ 4822.51480003]]    Loss_Validation:  [[ 1420.76011826]]\n",
      "Loop  9270 :    Loss_Train:  [[ 4822.51479982]]    Loss_Validation:  [[ 1420.76015693]]\n",
      "Loop  9271 :    Loss_Train:  [[ 4822.51479962]]    Loss_Validation:  [[ 1420.76019557]]\n",
      "Loop  9272 :    Loss_Train:  [[ 4822.51479942]]    Loss_Validation:  [[ 1420.76023418]]\n",
      "Loop  9273 :    Loss_Train:  [[ 4822.51479921]]    Loss_Validation:  [[ 1420.76027276]]\n",
      "Loop  9274 :    Loss_Train:  [[ 4822.51479901]]    Loss_Validation:  [[ 1420.76031132]]\n",
      "Loop  9275 :    Loss_Train:  [[ 4822.51479881]]    Loss_Validation:  [[ 1420.76034985]]\n",
      "Loop  9276 :    Loss_Train:  [[ 4822.51479861]]    Loss_Validation:  [[ 1420.76038835]]\n",
      "Loop  9277 :    Loss_Train:  [[ 4822.51479841]]    Loss_Validation:  [[ 1420.76042682]]\n",
      "Loop  9278 :    Loss_Train:  [[ 4822.5147982]]    Loss_Validation:  [[ 1420.76046526]]\n",
      "Loop  9279 :    Loss_Train:  [[ 4822.514798]]    Loss_Validation:  [[ 1420.76050368]]\n",
      "Loop  9280 :    Loss_Train:  [[ 4822.5147978]]    Loss_Validation:  [[ 1420.76054207]]\n",
      "Loop  9281 :    Loss_Train:  [[ 4822.5147976]]    Loss_Validation:  [[ 1420.76058043]]\n",
      "Loop  9282 :    Loss_Train:  [[ 4822.5147974]]    Loss_Validation:  [[ 1420.76061876]]\n",
      "Loop  9283 :    Loss_Train:  [[ 4822.5147972]]    Loss_Validation:  [[ 1420.76065707]]\n",
      "Loop  9284 :    Loss_Train:  [[ 4822.514797]]    Loss_Validation:  [[ 1420.76069535]]\n",
      "Loop  9285 :    Loss_Train:  [[ 4822.51479681]]    Loss_Validation:  [[ 1420.7607336]]\n",
      "Loop  9286 :    Loss_Train:  [[ 4822.51479661]]    Loss_Validation:  [[ 1420.76077182]]\n",
      "Loop  9287 :    Loss_Train:  [[ 4822.51479641]]    Loss_Validation:  [[ 1420.76081002]]\n",
      "Loop  9288 :    Loss_Train:  [[ 4822.51479621]]    Loss_Validation:  [[ 1420.76084818]]\n",
      "Loop  9289 :    Loss_Train:  [[ 4822.51479601]]    Loss_Validation:  [[ 1420.76088632]]\n",
      "Loop  9290 :    Loss_Train:  [[ 4822.51479582]]    Loss_Validation:  [[ 1420.76092444]]\n",
      "Loop  9291 :    Loss_Train:  [[ 4822.51479562]]    Loss_Validation:  [[ 1420.76096252]]\n",
      "Loop  9292 :    Loss_Train:  [[ 4822.51479542]]    Loss_Validation:  [[ 1420.76100058]]\n",
      "Loop  9293 :    Loss_Train:  [[ 4822.51479523]]    Loss_Validation:  [[ 1420.76103861]]\n",
      "Loop  9294 :    Loss_Train:  [[ 4822.51479503]]    Loss_Validation:  [[ 1420.76107661]]\n",
      "Loop  9295 :    Loss_Train:  [[ 4822.51479483]]    Loss_Validation:  [[ 1420.76111459]]\n",
      "Loop  9296 :    Loss_Train:  [[ 4822.51479464]]    Loss_Validation:  [[ 1420.76115254]]\n",
      "Loop  9297 :    Loss_Train:  [[ 4822.51479444]]    Loss_Validation:  [[ 1420.76119046]]\n",
      "Loop  9298 :    Loss_Train:  [[ 4822.51479425]]    Loss_Validation:  [[ 1420.76122835]]\n",
      "Loop  9299 :    Loss_Train:  [[ 4822.51479405]]    Loss_Validation:  [[ 1420.76126622]]\n",
      "Loop  9300 :    Loss_Train:  [[ 4822.51479386]]    Loss_Validation:  [[ 1420.76130406]]\n",
      "Loop  9301 :    Loss_Train:  [[ 4822.51479367]]    Loss_Validation:  [[ 1420.76134187]]\n",
      "Loop  9302 :    Loss_Train:  [[ 4822.51479347]]    Loss_Validation:  [[ 1420.76137965]]\n",
      "Loop  9303 :    Loss_Train:  [[ 4822.51479328]]    Loss_Validation:  [[ 1420.76141741]]\n",
      "Loop  9304 :    Loss_Train:  [[ 4822.51479309]]    Loss_Validation:  [[ 1420.76145514]]\n",
      "Loop  9305 :    Loss_Train:  [[ 4822.51479289]]    Loss_Validation:  [[ 1420.76149284]]\n",
      "Loop  9306 :    Loss_Train:  [[ 4822.5147927]]    Loss_Validation:  [[ 1420.76153052]]\n",
      "Loop  9307 :    Loss_Train:  [[ 4822.51479251]]    Loss_Validation:  [[ 1420.76156816]]\n",
      "Loop  9308 :    Loss_Train:  [[ 4822.51479232]]    Loss_Validation:  [[ 1420.76160579]]\n",
      "Loop  9309 :    Loss_Train:  [[ 4822.51479212]]    Loss_Validation:  [[ 1420.76164338]]\n",
      "Loop  9310 :    Loss_Train:  [[ 4822.51479193]]    Loss_Validation:  [[ 1420.76168095]]\n",
      "Loop  9311 :    Loss_Train:  [[ 4822.51479174]]    Loss_Validation:  [[ 1420.76171849]]\n",
      "Loop  9312 :    Loss_Train:  [[ 4822.51479155]]    Loss_Validation:  [[ 1420.761756]]\n",
      "Loop  9313 :    Loss_Train:  [[ 4822.51479136]]    Loss_Validation:  [[ 1420.76179348]]\n",
      "Loop  9314 :    Loss_Train:  [[ 4822.51479117]]    Loss_Validation:  [[ 1420.76183094]]\n",
      "Loop  9315 :    Loss_Train:  [[ 4822.51479098]]    Loss_Validation:  [[ 1420.76186837]]\n",
      "Loop  9316 :    Loss_Train:  [[ 4822.51479079]]    Loss_Validation:  [[ 1420.76190578]]\n",
      "Loop  9317 :    Loss_Train:  [[ 4822.5147906]]    Loss_Validation:  [[ 1420.76194316]]\n",
      "Loop  9318 :    Loss_Train:  [[ 4822.51479041]]    Loss_Validation:  [[ 1420.76198051]]\n",
      "Loop  9319 :    Loss_Train:  [[ 4822.51479023]]    Loss_Validation:  [[ 1420.76201783]]\n",
      "Loop  9320 :    Loss_Train:  [[ 4822.51479004]]    Loss_Validation:  [[ 1420.76205513]]\n",
      "Loop  9321 :    Loss_Train:  [[ 4822.51478985]]    Loss_Validation:  [[ 1420.76209239]]\n",
      "Loop  9322 :    Loss_Train:  [[ 4822.51478966]]    Loss_Validation:  [[ 1420.76212964]]\n",
      "Loop  9323 :    Loss_Train:  [[ 4822.51478947]]    Loss_Validation:  [[ 1420.76216685]]\n",
      "Loop  9324 :    Loss_Train:  [[ 4822.51478929]]    Loss_Validation:  [[ 1420.76220404]]\n",
      "Loop  9325 :    Loss_Train:  [[ 4822.5147891]]    Loss_Validation:  [[ 1420.7622412]]\n",
      "Loop  9326 :    Loss_Train:  [[ 4822.51478891]]    Loss_Validation:  [[ 1420.76227834]]\n",
      "Loop  9327 :    Loss_Train:  [[ 4822.51478873]]    Loss_Validation:  [[ 1420.76231545]]\n",
      "Loop  9328 :    Loss_Train:  [[ 4822.51478854]]    Loss_Validation:  [[ 1420.76235253]]\n",
      "Loop  9329 :    Loss_Train:  [[ 4822.51478836]]    Loss_Validation:  [[ 1420.76238958]]\n",
      "Loop  9330 :    Loss_Train:  [[ 4822.51478817]]    Loss_Validation:  [[ 1420.76242661]]\n",
      "Loop  9331 :    Loss_Train:  [[ 4822.51478799]]    Loss_Validation:  [[ 1420.76246361]]\n",
      "Loop  9332 :    Loss_Train:  [[ 4822.5147878]]    Loss_Validation:  [[ 1420.76250059]]\n",
      "Loop  9333 :    Loss_Train:  [[ 4822.51478762]]    Loss_Validation:  [[ 1420.76253754]]\n",
      "Loop  9334 :    Loss_Train:  [[ 4822.51478743]]    Loss_Validation:  [[ 1420.76257446]]\n",
      "Loop  9335 :    Loss_Train:  [[ 4822.51478725]]    Loss_Validation:  [[ 1420.76261135]]\n",
      "Loop  9336 :    Loss_Train:  [[ 4822.51478706]]    Loss_Validation:  [[ 1420.76264822]]\n",
      "Loop  9337 :    Loss_Train:  [[ 4822.51478688]]    Loss_Validation:  [[ 1420.76268506]]\n",
      "Loop  9338 :    Loss_Train:  [[ 4822.5147867]]    Loss_Validation:  [[ 1420.76272188]]\n",
      "Loop  9339 :    Loss_Train:  [[ 4822.51478651]]    Loss_Validation:  [[ 1420.76275867]]\n",
      "Loop  9340 :    Loss_Train:  [[ 4822.51478633]]    Loss_Validation:  [[ 1420.76279543]]\n",
      "Loop  9341 :    Loss_Train:  [[ 4822.51478615]]    Loss_Validation:  [[ 1420.76283216]]\n",
      "Loop  9342 :    Loss_Train:  [[ 4822.51478597]]    Loss_Validation:  [[ 1420.76286887]]\n",
      "Loop  9343 :    Loss_Train:  [[ 4822.51478579]]    Loss_Validation:  [[ 1420.76290556]]\n",
      "Loop  9344 :    Loss_Train:  [[ 4822.5147856]]    Loss_Validation:  [[ 1420.76294221]]\n",
      "Loop  9345 :    Loss_Train:  [[ 4822.51478542]]    Loss_Validation:  [[ 1420.76297884]]\n",
      "Loop  9346 :    Loss_Train:  [[ 4822.51478524]]    Loss_Validation:  [[ 1420.76301544]]\n",
      "Loop  9347 :    Loss_Train:  [[ 4822.51478506]]    Loss_Validation:  [[ 1420.76305202]]\n",
      "Loop  9348 :    Loss_Train:  [[ 4822.51478488]]    Loss_Validation:  [[ 1420.76308857]]\n",
      "Loop  9349 :    Loss_Train:  [[ 4822.5147847]]    Loss_Validation:  [[ 1420.76312509]]\n",
      "Loop  9350 :    Loss_Train:  [[ 4822.51478452]]    Loss_Validation:  [[ 1420.76316159]]\n",
      "Loop  9351 :    Loss_Train:  [[ 4822.51478434]]    Loss_Validation:  [[ 1420.76319806]]\n",
      "Loop  9352 :    Loss_Train:  [[ 4822.51478416]]    Loss_Validation:  [[ 1420.76323451]]\n",
      "Loop  9353 :    Loss_Train:  [[ 4822.51478398]]    Loss_Validation:  [[ 1420.76327093]]\n",
      "Loop  9354 :    Loss_Train:  [[ 4822.51478381]]    Loss_Validation:  [[ 1420.76330732]]\n",
      "Loop  9355 :    Loss_Train:  [[ 4822.51478363]]    Loss_Validation:  [[ 1420.76334368]]\n",
      "Loop  9356 :    Loss_Train:  [[ 4822.51478345]]    Loss_Validation:  [[ 1420.76338002]]\n",
      "Loop  9357 :    Loss_Train:  [[ 4822.51478327]]    Loss_Validation:  [[ 1420.76341634]]\n",
      "Loop  9358 :    Loss_Train:  [[ 4822.51478309]]    Loss_Validation:  [[ 1420.76345262]]\n",
      "Loop  9359 :    Loss_Train:  [[ 4822.51478292]]    Loss_Validation:  [[ 1420.76348888]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  9360 :    Loss_Train:  [[ 4822.51478274]]    Loss_Validation:  [[ 1420.76352512]]\n",
      "Loop  9361 :    Loss_Train:  [[ 4822.51478256]]    Loss_Validation:  [[ 1420.76356133]]\n",
      "Loop  9362 :    Loss_Train:  [[ 4822.51478239]]    Loss_Validation:  [[ 1420.76359751]]\n",
      "Loop  9363 :    Loss_Train:  [[ 4822.51478221]]    Loss_Validation:  [[ 1420.76363367]]\n",
      "Loop  9364 :    Loss_Train:  [[ 4822.51478204]]    Loss_Validation:  [[ 1420.7636698]]\n",
      "Loop  9365 :    Loss_Train:  [[ 4822.51478186]]    Loss_Validation:  [[ 1420.7637059]]\n",
      "Loop  9366 :    Loss_Train:  [[ 4822.51478168]]    Loss_Validation:  [[ 1420.76374198]]\n",
      "Loop  9367 :    Loss_Train:  [[ 4822.51478151]]    Loss_Validation:  [[ 1420.76377803]]\n",
      "Loop  9368 :    Loss_Train:  [[ 4822.51478133]]    Loss_Validation:  [[ 1420.76381406]]\n",
      "Loop  9369 :    Loss_Train:  [[ 4822.51478116]]    Loss_Validation:  [[ 1420.76385006]]\n",
      "Loop  9370 :    Loss_Train:  [[ 4822.51478099]]    Loss_Validation:  [[ 1420.76388603]]\n",
      "Loop  9371 :    Loss_Train:  [[ 4822.51478081]]    Loss_Validation:  [[ 1420.76392198]]\n",
      "Loop  9372 :    Loss_Train:  [[ 4822.51478064]]    Loss_Validation:  [[ 1420.7639579]]\n",
      "Loop  9373 :    Loss_Train:  [[ 4822.51478047]]    Loss_Validation:  [[ 1420.7639938]]\n",
      "Loop  9374 :    Loss_Train:  [[ 4822.51478029]]    Loss_Validation:  [[ 1420.76402967]]\n",
      "Loop  9375 :    Loss_Train:  [[ 4822.51478012]]    Loss_Validation:  [[ 1420.76406551]]\n",
      "Loop  9376 :    Loss_Train:  [[ 4822.51477995]]    Loss_Validation:  [[ 1420.76410133]]\n",
      "Loop  9377 :    Loss_Train:  [[ 4822.51477977]]    Loss_Validation:  [[ 1420.76413713]]\n",
      "Loop  9378 :    Loss_Train:  [[ 4822.5147796]]    Loss_Validation:  [[ 1420.76417289]]\n",
      "Loop  9379 :    Loss_Train:  [[ 4822.51477943]]    Loss_Validation:  [[ 1420.76420863]]\n",
      "Loop  9380 :    Loss_Train:  [[ 4822.51477926]]    Loss_Validation:  [[ 1420.76424435]]\n",
      "Loop  9381 :    Loss_Train:  [[ 4822.51477909]]    Loss_Validation:  [[ 1420.76428004]]\n",
      "Loop  9382 :    Loss_Train:  [[ 4822.51477892]]    Loss_Validation:  [[ 1420.7643157]]\n",
      "Loop  9383 :    Loss_Train:  [[ 4822.51477875]]    Loss_Validation:  [[ 1420.76435134]]\n",
      "Loop  9384 :    Loss_Train:  [[ 4822.51477858]]    Loss_Validation:  [[ 1420.76438695]]\n",
      "Loop  9385 :    Loss_Train:  [[ 4822.51477841]]    Loss_Validation:  [[ 1420.76442254]]\n",
      "Loop  9386 :    Loss_Train:  [[ 4822.51477824]]    Loss_Validation:  [[ 1420.7644581]]\n",
      "Loop  9387 :    Loss_Train:  [[ 4822.51477807]]    Loss_Validation:  [[ 1420.76449363]]\n",
      "Loop  9388 :    Loss_Train:  [[ 4822.5147779]]    Loss_Validation:  [[ 1420.76452914]]\n",
      "Loop  9389 :    Loss_Train:  [[ 4822.51477773]]    Loss_Validation:  [[ 1420.76456463]]\n",
      "Loop  9390 :    Loss_Train:  [[ 4822.51477756]]    Loss_Validation:  [[ 1420.76460009]]\n",
      "Loop  9391 :    Loss_Train:  [[ 4822.51477739]]    Loss_Validation:  [[ 1420.76463552]]\n",
      "Loop  9392 :    Loss_Train:  [[ 4822.51477722]]    Loss_Validation:  [[ 1420.76467093]]\n",
      "Loop  9393 :    Loss_Train:  [[ 4822.51477705]]    Loss_Validation:  [[ 1420.76470631]]\n",
      "Loop  9394 :    Loss_Train:  [[ 4822.51477689]]    Loss_Validation:  [[ 1420.76474166]]\n",
      "Loop  9395 :    Loss_Train:  [[ 4822.51477672]]    Loss_Validation:  [[ 1420.76477699]]\n",
      "Loop  9396 :    Loss_Train:  [[ 4822.51477655]]    Loss_Validation:  [[ 1420.7648123]]\n",
      "Loop  9397 :    Loss_Train:  [[ 4822.51477638]]    Loss_Validation:  [[ 1420.76484758]]\n",
      "Loop  9398 :    Loss_Train:  [[ 4822.51477622]]    Loss_Validation:  [[ 1420.76488283]]\n",
      "Loop  9399 :    Loss_Train:  [[ 4822.51477605]]    Loss_Validation:  [[ 1420.76491806]]\n",
      "Loop  9400 :    Loss_Train:  [[ 4822.51477588]]    Loss_Validation:  [[ 1420.76495326]]\n",
      "Loop  9401 :    Loss_Train:  [[ 4822.51477572]]    Loss_Validation:  [[ 1420.76498844]]\n",
      "Loop  9402 :    Loss_Train:  [[ 4822.51477555]]    Loss_Validation:  [[ 1420.76502359]]\n",
      "Loop  9403 :    Loss_Train:  [[ 4822.51477539]]    Loss_Validation:  [[ 1420.76505872]]\n",
      "Loop  9404 :    Loss_Train:  [[ 4822.51477522]]    Loss_Validation:  [[ 1420.76509382]]\n",
      "Loop  9405 :    Loss_Train:  [[ 4822.51477506]]    Loss_Validation:  [[ 1420.7651289]]\n",
      "Loop  9406 :    Loss_Train:  [[ 4822.51477489]]    Loss_Validation:  [[ 1420.76516395]]\n",
      "Loop  9407 :    Loss_Train:  [[ 4822.51477473]]    Loss_Validation:  [[ 1420.76519898]]\n",
      "Loop  9408 :    Loss_Train:  [[ 4822.51477456]]    Loss_Validation:  [[ 1420.76523398]]\n",
      "Loop  9409 :    Loss_Train:  [[ 4822.5147744]]    Loss_Validation:  [[ 1420.76526895]]\n",
      "Loop  9410 :    Loss_Train:  [[ 4822.51477424]]    Loss_Validation:  [[ 1420.7653039]]\n",
      "Loop  9411 :    Loss_Train:  [[ 4822.51477407]]    Loss_Validation:  [[ 1420.76533882]]\n",
      "Loop  9412 :    Loss_Train:  [[ 4822.51477391]]    Loss_Validation:  [[ 1420.76537372]]\n",
      "Loop  9413 :    Loss_Train:  [[ 4822.51477375]]    Loss_Validation:  [[ 1420.7654086]]\n",
      "Loop  9414 :    Loss_Train:  [[ 4822.51477358]]    Loss_Validation:  [[ 1420.76544345]]\n",
      "Loop  9415 :    Loss_Train:  [[ 4822.51477342]]    Loss_Validation:  [[ 1420.76547827]]\n",
      "Loop  9416 :    Loss_Train:  [[ 4822.51477326]]    Loss_Validation:  [[ 1420.76551307]]\n",
      "Loop  9417 :    Loss_Train:  [[ 4822.5147731]]    Loss_Validation:  [[ 1420.76554784]]\n",
      "Loop  9418 :    Loss_Train:  [[ 4822.51477294]]    Loss_Validation:  [[ 1420.76558259]]\n",
      "Loop  9419 :    Loss_Train:  [[ 4822.51477277]]    Loss_Validation:  [[ 1420.76561731]]\n",
      "Loop  9420 :    Loss_Train:  [[ 4822.51477261]]    Loss_Validation:  [[ 1420.76565201]]\n",
      "Loop  9421 :    Loss_Train:  [[ 4822.51477245]]    Loss_Validation:  [[ 1420.76568669]]\n",
      "Loop  9422 :    Loss_Train:  [[ 4822.51477229]]    Loss_Validation:  [[ 1420.76572133]]\n",
      "Loop  9423 :    Loss_Train:  [[ 4822.51477213]]    Loss_Validation:  [[ 1420.76575596]]\n",
      "Loop  9424 :    Loss_Train:  [[ 4822.51477197]]    Loss_Validation:  [[ 1420.76579056]]\n",
      "Loop  9425 :    Loss_Train:  [[ 4822.51477181]]    Loss_Validation:  [[ 1420.76582513]]\n",
      "Loop  9426 :    Loss_Train:  [[ 4822.51477165]]    Loss_Validation:  [[ 1420.76585968]]\n",
      "Loop  9427 :    Loss_Train:  [[ 4822.51477149]]    Loss_Validation:  [[ 1420.7658942]]\n",
      "Loop  9428 :    Loss_Train:  [[ 4822.51477133]]    Loss_Validation:  [[ 1420.7659287]]\n",
      "Loop  9429 :    Loss_Train:  [[ 4822.51477117]]    Loss_Validation:  [[ 1420.76596317]]\n",
      "Loop  9430 :    Loss_Train:  [[ 4822.51477102]]    Loss_Validation:  [[ 1420.76599762]]\n",
      "Loop  9431 :    Loss_Train:  [[ 4822.51477086]]    Loss_Validation:  [[ 1420.76603204]]\n",
      "Loop  9432 :    Loss_Train:  [[ 4822.5147707]]    Loss_Validation:  [[ 1420.76606644]]\n",
      "Loop  9433 :    Loss_Train:  [[ 4822.51477054]]    Loss_Validation:  [[ 1420.76610082]]\n",
      "Loop  9434 :    Loss_Train:  [[ 4822.51477038]]    Loss_Validation:  [[ 1420.76613517]]\n",
      "Loop  9435 :    Loss_Train:  [[ 4822.51477023]]    Loss_Validation:  [[ 1420.76616949]]\n",
      "Loop  9436 :    Loss_Train:  [[ 4822.51477007]]    Loss_Validation:  [[ 1420.76620379]]\n",
      "Loop  9437 :    Loss_Train:  [[ 4822.51476991]]    Loss_Validation:  [[ 1420.76623806]]\n",
      "Loop  9438 :    Loss_Train:  [[ 4822.51476976]]    Loss_Validation:  [[ 1420.76627231]]\n",
      "Loop  9439 :    Loss_Train:  [[ 4822.5147696]]    Loss_Validation:  [[ 1420.76630654]]\n",
      "Loop  9440 :    Loss_Train:  [[ 4822.51476944]]    Loss_Validation:  [[ 1420.76634074]]\n",
      "Loop  9441 :    Loss_Train:  [[ 4822.51476929]]    Loss_Validation:  [[ 1420.76637492]]\n",
      "Loop  9442 :    Loss_Train:  [[ 4822.51476913]]    Loss_Validation:  [[ 1420.76640907]]\n",
      "Loop  9443 :    Loss_Train:  [[ 4822.51476898]]    Loss_Validation:  [[ 1420.76644319]]\n",
      "Loop  9444 :    Loss_Train:  [[ 4822.51476882]]    Loss_Validation:  [[ 1420.7664773]]\n",
      "Loop  9445 :    Loss_Train:  [[ 4822.51476867]]    Loss_Validation:  [[ 1420.76651137]]\n",
      "Loop  9446 :    Loss_Train:  [[ 4822.51476851]]    Loss_Validation:  [[ 1420.76654543]]\n",
      "Loop  9447 :    Loss_Train:  [[ 4822.51476836]]    Loss_Validation:  [[ 1420.76657945]]\n",
      "Loop  9448 :    Loss_Train:  [[ 4822.5147682]]    Loss_Validation:  [[ 1420.76661346]]\n",
      "Loop  9449 :    Loss_Train:  [[ 4822.51476805]]    Loss_Validation:  [[ 1420.76664744]]\n",
      "Loop  9450 :    Loss_Train:  [[ 4822.51476789]]    Loss_Validation:  [[ 1420.76668139]]\n",
      "Loop  9451 :    Loss_Train:  [[ 4822.51476774]]    Loss_Validation:  [[ 1420.76671532]]\n",
      "Loop  9452 :    Loss_Train:  [[ 4822.51476759]]    Loss_Validation:  [[ 1420.76674922]]\n",
      "Loop  9453 :    Loss_Train:  [[ 4822.51476743]]    Loss_Validation:  [[ 1420.76678311]]\n",
      "Loop  9454 :    Loss_Train:  [[ 4822.51476728]]    Loss_Validation:  [[ 1420.76681696]]\n",
      "Loop  9455 :    Loss_Train:  [[ 4822.51476713]]    Loss_Validation:  [[ 1420.76685079]]\n",
      "Loop  9456 :    Loss_Train:  [[ 4822.51476698]]    Loss_Validation:  [[ 1420.7668846]]\n",
      "Loop  9457 :    Loss_Train:  [[ 4822.51476682]]    Loss_Validation:  [[ 1420.76691838]]\n",
      "Loop  9458 :    Loss_Train:  [[ 4822.51476667]]    Loss_Validation:  [[ 1420.76695214]]\n",
      "Loop  9459 :    Loss_Train:  [[ 4822.51476652]]    Loss_Validation:  [[ 1420.76698588]]\n",
      "Loop  9460 :    Loss_Train:  [[ 4822.51476637]]    Loss_Validation:  [[ 1420.76701959]]\n",
      "Loop  9461 :    Loss_Train:  [[ 4822.51476622]]    Loss_Validation:  [[ 1420.76705327]]\n",
      "Loop  9462 :    Loss_Train:  [[ 4822.51476607]]    Loss_Validation:  [[ 1420.76708693]]\n",
      "Loop  9463 :    Loss_Train:  [[ 4822.51476592]]    Loss_Validation:  [[ 1420.76712057]]\n",
      "Loop  9464 :    Loss_Train:  [[ 4822.51476577]]    Loss_Validation:  [[ 1420.76715418]]\n",
      "Loop  9465 :    Loss_Train:  [[ 4822.51476562]]    Loss_Validation:  [[ 1420.76718777]]\n",
      "Loop  9466 :    Loss_Train:  [[ 4822.51476547]]    Loss_Validation:  [[ 1420.76722134]]\n",
      "Loop  9467 :    Loss_Train:  [[ 4822.51476532]]    Loss_Validation:  [[ 1420.76725488]]\n",
      "Loop  9468 :    Loss_Train:  [[ 4822.51476517]]    Loss_Validation:  [[ 1420.76728839]]\n",
      "Loop  9469 :    Loss_Train:  [[ 4822.51476502]]    Loss_Validation:  [[ 1420.76732188]]\n",
      "Loop  9470 :    Loss_Train:  [[ 4822.51476487]]    Loss_Validation:  [[ 1420.76735535]]\n",
      "Loop  9471 :    Loss_Train:  [[ 4822.51476472]]    Loss_Validation:  [[ 1420.76738879]]\n",
      "Loop  9472 :    Loss_Train:  [[ 4822.51476457]]    Loss_Validation:  [[ 1420.76742221]]\n",
      "Loop  9473 :    Loss_Train:  [[ 4822.51476442]]    Loss_Validation:  [[ 1420.76745561]]\n",
      "Loop  9474 :    Loss_Train:  [[ 4822.51476427]]    Loss_Validation:  [[ 1420.76748898]]\n",
      "Loop  9475 :    Loss_Train:  [[ 4822.51476413]]    Loss_Validation:  [[ 1420.76752232]]\n",
      "Loop  9476 :    Loss_Train:  [[ 4822.51476398]]    Loss_Validation:  [[ 1420.76755565]]\n",
      "Loop  9477 :    Loss_Train:  [[ 4822.51476383]]    Loss_Validation:  [[ 1420.76758894]]\n",
      "Loop  9478 :    Loss_Train:  [[ 4822.51476368]]    Loss_Validation:  [[ 1420.76762222]]\n",
      "Loop  9479 :    Loss_Train:  [[ 4822.51476354]]    Loss_Validation:  [[ 1420.76765547]]\n",
      "Loop  9480 :    Loss_Train:  [[ 4822.51476339]]    Loss_Validation:  [[ 1420.76768869]]\n",
      "Loop  9481 :    Loss_Train:  [[ 4822.51476324]]    Loss_Validation:  [[ 1420.7677219]]\n",
      "Loop  9482 :    Loss_Train:  [[ 4822.5147631]]    Loss_Validation:  [[ 1420.76775508]]\n",
      "Loop  9483 :    Loss_Train:  [[ 4822.51476295]]    Loss_Validation:  [[ 1420.76778823]]\n",
      "Loop  9484 :    Loss_Train:  [[ 4822.51476281]]    Loss_Validation:  [[ 1420.76782136]]\n",
      "Loop  9485 :    Loss_Train:  [[ 4822.51476266]]    Loss_Validation:  [[ 1420.76785447]]\n",
      "Loop  9486 :    Loss_Train:  [[ 4822.51476251]]    Loss_Validation:  [[ 1420.76788755]]\n",
      "Loop  9487 :    Loss_Train:  [[ 4822.51476237]]    Loss_Validation:  [[ 1420.76792061]]\n",
      "Loop  9488 :    Loss_Train:  [[ 4822.51476222]]    Loss_Validation:  [[ 1420.76795364]]\n",
      "Loop  9489 :    Loss_Train:  [[ 4822.51476208]]    Loss_Validation:  [[ 1420.76798665]]\n",
      "Loop  9490 :    Loss_Train:  [[ 4822.51476193]]    Loss_Validation:  [[ 1420.76801964]]\n",
      "Loop  9491 :    Loss_Train:  [[ 4822.51476179]]    Loss_Validation:  [[ 1420.7680526]]\n",
      "Loop  9492 :    Loss_Train:  [[ 4822.51476165]]    Loss_Validation:  [[ 1420.76808554]]\n",
      "Loop  9493 :    Loss_Train:  [[ 4822.5147615]]    Loss_Validation:  [[ 1420.76811846]]\n",
      "Loop  9494 :    Loss_Train:  [[ 4822.51476136]]    Loss_Validation:  [[ 1420.76815135]]\n",
      "Loop  9495 :    Loss_Train:  [[ 4822.51476122]]    Loss_Validation:  [[ 1420.76818422]]\n",
      "Loop  9496 :    Loss_Train:  [[ 4822.51476107]]    Loss_Validation:  [[ 1420.76821706]]\n",
      "Loop  9497 :    Loss_Train:  [[ 4822.51476093]]    Loss_Validation:  [[ 1420.76824988]]\n",
      "Loop  9498 :    Loss_Train:  [[ 4822.51476079]]    Loss_Validation:  [[ 1420.76828268]]\n",
      "Loop  9499 :    Loss_Train:  [[ 4822.51476064]]    Loss_Validation:  [[ 1420.76831545]]\n",
      "Loop  9500 :    Loss_Train:  [[ 4822.5147605]]    Loss_Validation:  [[ 1420.7683482]]\n",
      "Loop  9501 :    Loss_Train:  [[ 4822.51476036]]    Loss_Validation:  [[ 1420.76838093]]\n",
      "Loop  9502 :    Loss_Train:  [[ 4822.51476022]]    Loss_Validation:  [[ 1420.76841363]]\n",
      "Loop  9503 :    Loss_Train:  [[ 4822.51476008]]    Loss_Validation:  [[ 1420.76844631]]\n",
      "Loop  9504 :    Loss_Train:  [[ 4822.51475994]]    Loss_Validation:  [[ 1420.76847896]]\n",
      "Loop  9505 :    Loss_Train:  [[ 4822.51475979]]    Loss_Validation:  [[ 1420.76851159]]\n",
      "Loop  9506 :    Loss_Train:  [[ 4822.51475965]]    Loss_Validation:  [[ 1420.7685442]]\n",
      "Loop  9507 :    Loss_Train:  [[ 4822.51475951]]    Loss_Validation:  [[ 1420.76857679]]\n",
      "Loop  9508 :    Loss_Train:  [[ 4822.51475937]]    Loss_Validation:  [[ 1420.76860935]]\n",
      "Loop  9509 :    Loss_Train:  [[ 4822.51475923]]    Loss_Validation:  [[ 1420.76864188]]\n",
      "Loop  9510 :    Loss_Train:  [[ 4822.51475909]]    Loss_Validation:  [[ 1420.7686744]]\n",
      "Loop  9511 :    Loss_Train:  [[ 4822.51475895]]    Loss_Validation:  [[ 1420.76870689]]\n",
      "Loop  9512 :    Loss_Train:  [[ 4822.51475881]]    Loss_Validation:  [[ 1420.76873935]]\n",
      "Loop  9513 :    Loss_Train:  [[ 4822.51475867]]    Loss_Validation:  [[ 1420.7687718]]\n",
      "Loop  9514 :    Loss_Train:  [[ 4822.51475853]]    Loss_Validation:  [[ 1420.76880422]]\n",
      "Loop  9515 :    Loss_Train:  [[ 4822.51475839]]    Loss_Validation:  [[ 1420.76883661]]\n",
      "Loop  9516 :    Loss_Train:  [[ 4822.51475826]]    Loss_Validation:  [[ 1420.76886899]]\n",
      "Loop  9517 :    Loss_Train:  [[ 4822.51475812]]    Loss_Validation:  [[ 1420.76890133]]\n",
      "Loop  9518 :    Loss_Train:  [[ 4822.51475798]]    Loss_Validation:  [[ 1420.76893366]]\n",
      "Loop  9519 :    Loss_Train:  [[ 4822.51475784]]    Loss_Validation:  [[ 1420.76896596]]\n",
      "Loop  9520 :    Loss_Train:  [[ 4822.5147577]]    Loss_Validation:  [[ 1420.76899824]]\n",
      "Loop  9521 :    Loss_Train:  [[ 4822.51475756]]    Loss_Validation:  [[ 1420.7690305]]\n",
      "Loop  9522 :    Loss_Train:  [[ 4822.51475743]]    Loss_Validation:  [[ 1420.76906273]]\n",
      "Loop  9523 :    Loss_Train:  [[ 4822.51475729]]    Loss_Validation:  [[ 1420.76909494]]\n",
      "Loop  9524 :    Loss_Train:  [[ 4822.51475715]]    Loss_Validation:  [[ 1420.76912713]]\n",
      "Loop  9525 :    Loss_Train:  [[ 4822.51475702]]    Loss_Validation:  [[ 1420.76915929]]\n",
      "Loop  9526 :    Loss_Train:  [[ 4822.51475688]]    Loss_Validation:  [[ 1420.76919143]]\n",
      "Loop  9527 :    Loss_Train:  [[ 4822.51475674]]    Loss_Validation:  [[ 1420.76922355]]\n",
      "Loop  9528 :    Loss_Train:  [[ 4822.51475661]]    Loss_Validation:  [[ 1420.76925564]]\n",
      "Loop  9529 :    Loss_Train:  [[ 4822.51475647]]    Loss_Validation:  [[ 1420.76928771]]\n",
      "Loop  9530 :    Loss_Train:  [[ 4822.51475634]]    Loss_Validation:  [[ 1420.76931976]]\n",
      "Loop  9531 :    Loss_Train:  [[ 4822.5147562]]    Loss_Validation:  [[ 1420.76935178]]\n",
      "Loop  9532 :    Loss_Train:  [[ 4822.51475606]]    Loss_Validation:  [[ 1420.76938378]]\n",
      "Loop  9533 :    Loss_Train:  [[ 4822.51475593]]    Loss_Validation:  [[ 1420.76941576]]\n",
      "Loop  9534 :    Loss_Train:  [[ 4822.51475579]]    Loss_Validation:  [[ 1420.76944771]]\n",
      "Loop  9535 :    Loss_Train:  [[ 4822.51475566]]    Loss_Validation:  [[ 1420.76947964]]\n",
      "Loop  9536 :    Loss_Train:  [[ 4822.51475553]]    Loss_Validation:  [[ 1420.76951155]]\n",
      "Loop  9537 :    Loss_Train:  [[ 4822.51475539]]    Loss_Validation:  [[ 1420.76954344]]\n",
      "Loop  9538 :    Loss_Train:  [[ 4822.51475526]]    Loss_Validation:  [[ 1420.7695753]]\n",
      "Loop  9539 :    Loss_Train:  [[ 4822.51475512]]    Loss_Validation:  [[ 1420.76960714]]\n",
      "Loop  9540 :    Loss_Train:  [[ 4822.51475499]]    Loss_Validation:  [[ 1420.76963896]]\n",
      "Loop  9541 :    Loss_Train:  [[ 4822.51475486]]    Loss_Validation:  [[ 1420.76967075]]\n",
      "Loop  9542 :    Loss_Train:  [[ 4822.51475472]]    Loss_Validation:  [[ 1420.76970252]]\n",
      "Loop  9543 :    Loss_Train:  [[ 4822.51475459]]    Loss_Validation:  [[ 1420.76973427]]\n",
      "Loop  9544 :    Loss_Train:  [[ 4822.51475446]]    Loss_Validation:  [[ 1420.76976599]]\n",
      "Loop  9545 :    Loss_Train:  [[ 4822.51475432]]    Loss_Validation:  [[ 1420.76979769]]\n",
      "Loop  9546 :    Loss_Train:  [[ 4822.51475419]]    Loss_Validation:  [[ 1420.76982937]]\n",
      "Loop  9547 :    Loss_Train:  [[ 4822.51475406]]    Loss_Validation:  [[ 1420.76986102]]\n",
      "Loop  9548 :    Loss_Train:  [[ 4822.51475393]]    Loss_Validation:  [[ 1420.76989266]]\n",
      "Loop  9549 :    Loss_Train:  [[ 4822.5147538]]    Loss_Validation:  [[ 1420.76992427]]\n",
      "Loop  9550 :    Loss_Train:  [[ 4822.51475366]]    Loss_Validation:  [[ 1420.76995585]]\n",
      "Loop  9551 :    Loss_Train:  [[ 4822.51475353]]    Loss_Validation:  [[ 1420.76998742]]\n",
      "Loop  9552 :    Loss_Train:  [[ 4822.5147534]]    Loss_Validation:  [[ 1420.77001896]]\n",
      "Loop  9553 :    Loss_Train:  [[ 4822.51475327]]    Loss_Validation:  [[ 1420.77005048]]\n",
      "Loop  9554 :    Loss_Train:  [[ 4822.51475314]]    Loss_Validation:  [[ 1420.77008197]]\n",
      "Loop  9555 :    Loss_Train:  [[ 4822.51475301]]    Loss_Validation:  [[ 1420.77011345]]\n",
      "Loop  9556 :    Loss_Train:  [[ 4822.51475288]]    Loss_Validation:  [[ 1420.7701449]]\n",
      "Loop  9557 :    Loss_Train:  [[ 4822.51475275]]    Loss_Validation:  [[ 1420.77017632]]\n",
      "Loop  9558 :    Loss_Train:  [[ 4822.51475262]]    Loss_Validation:  [[ 1420.77020773]]\n",
      "Loop  9559 :    Loss_Train:  [[ 4822.51475249]]    Loss_Validation:  [[ 1420.77023911]]\n",
      "Loop  9560 :    Loss_Train:  [[ 4822.51475236]]    Loss_Validation:  [[ 1420.77027047]]\n",
      "Loop  9561 :    Loss_Train:  [[ 4822.51475223]]    Loss_Validation:  [[ 1420.77030181]]\n",
      "Loop  9562 :    Loss_Train:  [[ 4822.5147521]]    Loss_Validation:  [[ 1420.77033312]]\n",
      "Loop  9563 :    Loss_Train:  [[ 4822.51475197]]    Loss_Validation:  [[ 1420.77036441]]\n",
      "Loop  9564 :    Loss_Train:  [[ 4822.51475184]]    Loss_Validation:  [[ 1420.77039568]]\n",
      "Loop  9565 :    Loss_Train:  [[ 4822.51475171]]    Loss_Validation:  [[ 1420.77042693]]\n",
      "Loop  9566 :    Loss_Train:  [[ 4822.51475159]]    Loss_Validation:  [[ 1420.77045815]]\n",
      "Loop  9567 :    Loss_Train:  [[ 4822.51475146]]    Loss_Validation:  [[ 1420.77048935]]\n",
      "Loop  9568 :    Loss_Train:  [[ 4822.51475133]]    Loss_Validation:  [[ 1420.77052053]]\n",
      "Loop  9569 :    Loss_Train:  [[ 4822.5147512]]    Loss_Validation:  [[ 1420.77055169]]\n",
      "Loop  9570 :    Loss_Train:  [[ 4822.51475107]]    Loss_Validation:  [[ 1420.77058282]]\n",
      "Loop  9571 :    Loss_Train:  [[ 4822.51475095]]    Loss_Validation:  [[ 1420.77061393]]\n",
      "Loop  9572 :    Loss_Train:  [[ 4822.51475082]]    Loss_Validation:  [[ 1420.77064502]]\n",
      "Loop  9573 :    Loss_Train:  [[ 4822.51475069]]    Loss_Validation:  [[ 1420.77067608]]\n",
      "Loop  9574 :    Loss_Train:  [[ 4822.51475057]]    Loss_Validation:  [[ 1420.77070713]]\n",
      "Loop  9575 :    Loss_Train:  [[ 4822.51475044]]    Loss_Validation:  [[ 1420.77073815]]\n",
      "Loop  9576 :    Loss_Train:  [[ 4822.51475031]]    Loss_Validation:  [[ 1420.77076915]]\n",
      "Loop  9577 :    Loss_Train:  [[ 4822.51475019]]    Loss_Validation:  [[ 1420.77080012]]\n",
      "Loop  9578 :    Loss_Train:  [[ 4822.51475006]]    Loss_Validation:  [[ 1420.77083108]]\n",
      "Loop  9579 :    Loss_Train:  [[ 4822.51474993]]    Loss_Validation:  [[ 1420.77086201]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  9580 :    Loss_Train:  [[ 4822.51474981]]    Loss_Validation:  [[ 1420.77089292]]\n",
      "Loop  9581 :    Loss_Train:  [[ 4822.51474968]]    Loss_Validation:  [[ 1420.77092381]]\n",
      "Loop  9582 :    Loss_Train:  [[ 4822.51474956]]    Loss_Validation:  [[ 1420.77095467]]\n",
      "Loop  9583 :    Loss_Train:  [[ 4822.51474943]]    Loss_Validation:  [[ 1420.77098551]]\n",
      "Loop  9584 :    Loss_Train:  [[ 4822.51474931]]    Loss_Validation:  [[ 1420.77101633]]\n",
      "Loop  9585 :    Loss_Train:  [[ 4822.51474918]]    Loss_Validation:  [[ 1420.77104713]]\n",
      "Loop  9586 :    Loss_Train:  [[ 4822.51474906]]    Loss_Validation:  [[ 1420.7710779]]\n",
      "Loop  9587 :    Loss_Train:  [[ 4822.51474894]]    Loss_Validation:  [[ 1420.77110866]]\n",
      "Loop  9588 :    Loss_Train:  [[ 4822.51474881]]    Loss_Validation:  [[ 1420.77113939]]\n",
      "Loop  9589 :    Loss_Train:  [[ 4822.51474869]]    Loss_Validation:  [[ 1420.7711701]]\n",
      "Loop  9590 :    Loss_Train:  [[ 4822.51474856]]    Loss_Validation:  [[ 1420.77120078]]\n",
      "Loop  9591 :    Loss_Train:  [[ 4822.51474844]]    Loss_Validation:  [[ 1420.77123145]]\n",
      "Loop  9592 :    Loss_Train:  [[ 4822.51474832]]    Loss_Validation:  [[ 1420.77126209]]\n",
      "Loop  9593 :    Loss_Train:  [[ 4822.51474819]]    Loss_Validation:  [[ 1420.77129271]]\n",
      "Loop  9594 :    Loss_Train:  [[ 4822.51474807]]    Loss_Validation:  [[ 1420.77132331]]\n",
      "Loop  9595 :    Loss_Train:  [[ 4822.51474795]]    Loss_Validation:  [[ 1420.77135388]]\n",
      "Loop  9596 :    Loss_Train:  [[ 4822.51474783]]    Loss_Validation:  [[ 1420.77138444]]\n",
      "Loop  9597 :    Loss_Train:  [[ 4822.5147477]]    Loss_Validation:  [[ 1420.77141497]]\n",
      "Loop  9598 :    Loss_Train:  [[ 4822.51474758]]    Loss_Validation:  [[ 1420.77144548]]\n",
      "Loop  9599 :    Loss_Train:  [[ 4822.51474746]]    Loss_Validation:  [[ 1420.77147596]]\n",
      "Loop  9600 :    Loss_Train:  [[ 4822.51474734]]    Loss_Validation:  [[ 1420.77150643]]\n",
      "Loop  9601 :    Loss_Train:  [[ 4822.51474722]]    Loss_Validation:  [[ 1420.77153687]]\n",
      "Loop  9602 :    Loss_Train:  [[ 4822.51474709]]    Loss_Validation:  [[ 1420.77156729]]\n",
      "Loop  9603 :    Loss_Train:  [[ 4822.51474697]]    Loss_Validation:  [[ 1420.77159769]]\n",
      "Loop  9604 :    Loss_Train:  [[ 4822.51474685]]    Loss_Validation:  [[ 1420.77162807]]\n",
      "Loop  9605 :    Loss_Train:  [[ 4822.51474673]]    Loss_Validation:  [[ 1420.77165843]]\n",
      "Loop  9606 :    Loss_Train:  [[ 4822.51474661]]    Loss_Validation:  [[ 1420.77168876]]\n",
      "Loop  9607 :    Loss_Train:  [[ 4822.51474649]]    Loss_Validation:  [[ 1420.77171907]]\n",
      "Loop  9608 :    Loss_Train:  [[ 4822.51474637]]    Loss_Validation:  [[ 1420.77174936]]\n",
      "Loop  9609 :    Loss_Train:  [[ 4822.51474625]]    Loss_Validation:  [[ 1420.77177963]]\n",
      "Loop  9610 :    Loss_Train:  [[ 4822.51474613]]    Loss_Validation:  [[ 1420.77180987]]\n",
      "Loop  9611 :    Loss_Train:  [[ 4822.51474601]]    Loss_Validation:  [[ 1420.7718401]]\n",
      "Loop  9612 :    Loss_Train:  [[ 4822.51474589]]    Loss_Validation:  [[ 1420.7718703]]\n",
      "Loop  9613 :    Loss_Train:  [[ 4822.51474577]]    Loss_Validation:  [[ 1420.77190048]]\n",
      "Loop  9614 :    Loss_Train:  [[ 4822.51474565]]    Loss_Validation:  [[ 1420.77193064]]\n",
      "Loop  9615 :    Loss_Train:  [[ 4822.51474553]]    Loss_Validation:  [[ 1420.77196077]]\n",
      "Loop  9616 :    Loss_Train:  [[ 4822.51474542]]    Loss_Validation:  [[ 1420.77199089]]\n",
      "Loop  9617 :    Loss_Train:  [[ 4822.5147453]]    Loss_Validation:  [[ 1420.77202098]]\n",
      "Loop  9618 :    Loss_Train:  [[ 4822.51474518]]    Loss_Validation:  [[ 1420.77205105]]\n",
      "Loop  9619 :    Loss_Train:  [[ 4822.51474506]]    Loss_Validation:  [[ 1420.7720811]]\n",
      "Loop  9620 :    Loss_Train:  [[ 4822.51474494]]    Loss_Validation:  [[ 1420.77211113]]\n",
      "Loop  9621 :    Loss_Train:  [[ 4822.51474482]]    Loss_Validation:  [[ 1420.77214114]]\n",
      "Loop  9622 :    Loss_Train:  [[ 4822.51474471]]    Loss_Validation:  [[ 1420.77217112]]\n",
      "Loop  9623 :    Loss_Train:  [[ 4822.51474459]]    Loss_Validation:  [[ 1420.77220108]]\n",
      "Loop  9624 :    Loss_Train:  [[ 4822.51474447]]    Loss_Validation:  [[ 1420.77223102]]\n",
      "Loop  9625 :    Loss_Train:  [[ 4822.51474435]]    Loss_Validation:  [[ 1420.77226094]]\n",
      "Loop  9626 :    Loss_Train:  [[ 4822.51474424]]    Loss_Validation:  [[ 1420.77229084]]\n",
      "Loop  9627 :    Loss_Train:  [[ 4822.51474412]]    Loss_Validation:  [[ 1420.77232072]]\n",
      "Loop  9628 :    Loss_Train:  [[ 4822.514744]]    Loss_Validation:  [[ 1420.77235057]]\n",
      "Loop  9629 :    Loss_Train:  [[ 4822.51474389]]    Loss_Validation:  [[ 1420.7723804]]\n",
      "Loop  9630 :    Loss_Train:  [[ 4822.51474377]]    Loss_Validation:  [[ 1420.77241022]]\n",
      "Loop  9631 :    Loss_Train:  [[ 4822.51474366]]    Loss_Validation:  [[ 1420.77244001]]\n",
      "Loop  9632 :    Loss_Train:  [[ 4822.51474354]]    Loss_Validation:  [[ 1420.77246977]]\n",
      "Loop  9633 :    Loss_Train:  [[ 4822.51474342]]    Loss_Validation:  [[ 1420.77249952]]\n",
      "Loop  9634 :    Loss_Train:  [[ 4822.51474331]]    Loss_Validation:  [[ 1420.77252925]]\n",
      "Loop  9635 :    Loss_Train:  [[ 4822.51474319]]    Loss_Validation:  [[ 1420.77255895]]\n",
      "Loop  9636 :    Loss_Train:  [[ 4822.51474308]]    Loss_Validation:  [[ 1420.77258863]]\n",
      "Loop  9637 :    Loss_Train:  [[ 4822.51474296]]    Loss_Validation:  [[ 1420.77261829]]\n",
      "Loop  9638 :    Loss_Train:  [[ 4822.51474285]]    Loss_Validation:  [[ 1420.77264793]]\n",
      "Loop  9639 :    Loss_Train:  [[ 4822.51474273]]    Loss_Validation:  [[ 1420.77267755]]\n",
      "Loop  9640 :    Loss_Train:  [[ 4822.51474262]]    Loss_Validation:  [[ 1420.77270715]]\n",
      "Loop  9641 :    Loss_Train:  [[ 4822.51474251]]    Loss_Validation:  [[ 1420.77273672]]\n",
      "Loop  9642 :    Loss_Train:  [[ 4822.51474239]]    Loss_Validation:  [[ 1420.77276627]]\n",
      "Loop  9643 :    Loss_Train:  [[ 4822.51474228]]    Loss_Validation:  [[ 1420.77279581]]\n",
      "Loop  9644 :    Loss_Train:  [[ 4822.51474216]]    Loss_Validation:  [[ 1420.77282532]]\n",
      "Loop  9645 :    Loss_Train:  [[ 4822.51474205]]    Loss_Validation:  [[ 1420.77285481]]\n",
      "Loop  9646 :    Loss_Train:  [[ 4822.51474194]]    Loss_Validation:  [[ 1420.77288428]]\n",
      "Loop  9647 :    Loss_Train:  [[ 4822.51474182]]    Loss_Validation:  [[ 1420.77291372]]\n",
      "Loop  9648 :    Loss_Train:  [[ 4822.51474171]]    Loss_Validation:  [[ 1420.77294315]]\n",
      "Loop  9649 :    Loss_Train:  [[ 4822.5147416]]    Loss_Validation:  [[ 1420.77297255]]\n",
      "Loop  9650 :    Loss_Train:  [[ 4822.51474149]]    Loss_Validation:  [[ 1420.77300193]]\n",
      "Loop  9651 :    Loss_Train:  [[ 4822.51474137]]    Loss_Validation:  [[ 1420.7730313]]\n",
      "Loop  9652 :    Loss_Train:  [[ 4822.51474126]]    Loss_Validation:  [[ 1420.77306064]]\n",
      "Loop  9653 :    Loss_Train:  [[ 4822.51474115]]    Loss_Validation:  [[ 1420.77308996]]\n",
      "Loop  9654 :    Loss_Train:  [[ 4822.51474104]]    Loss_Validation:  [[ 1420.77311925]]\n",
      "Loop  9655 :    Loss_Train:  [[ 4822.51474092]]    Loss_Validation:  [[ 1420.77314853]]\n",
      "Loop  9656 :    Loss_Train:  [[ 4822.51474081]]    Loss_Validation:  [[ 1420.77317779]]\n",
      "Loop  9657 :    Loss_Train:  [[ 4822.5147407]]    Loss_Validation:  [[ 1420.77320702]]\n",
      "Loop  9658 :    Loss_Train:  [[ 4822.51474059]]    Loss_Validation:  [[ 1420.77323624]]\n",
      "Loop  9659 :    Loss_Train:  [[ 4822.51474048]]    Loss_Validation:  [[ 1420.77326543]]\n",
      "Loop  9660 :    Loss_Train:  [[ 4822.51474037]]    Loss_Validation:  [[ 1420.7732946]]\n",
      "Loop  9661 :    Loss_Train:  [[ 4822.51474026]]    Loss_Validation:  [[ 1420.77332375]]\n",
      "Loop  9662 :    Loss_Train:  [[ 4822.51474015]]    Loss_Validation:  [[ 1420.77335288]]\n",
      "Loop  9663 :    Loss_Train:  [[ 4822.51474004]]    Loss_Validation:  [[ 1420.77338199]]\n",
      "Loop  9664 :    Loss_Train:  [[ 4822.51473993]]    Loss_Validation:  [[ 1420.77341107]]\n",
      "Loop  9665 :    Loss_Train:  [[ 4822.51473982]]    Loss_Validation:  [[ 1420.77344014]]\n",
      "Loop  9666 :    Loss_Train:  [[ 4822.51473971]]    Loss_Validation:  [[ 1420.77346918]]\n",
      "Loop  9667 :    Loss_Train:  [[ 4822.5147396]]    Loss_Validation:  [[ 1420.77349821]]\n",
      "Loop  9668 :    Loss_Train:  [[ 4822.51473949]]    Loss_Validation:  [[ 1420.77352721]]\n",
      "Loop  9669 :    Loss_Train:  [[ 4822.51473938]]    Loss_Validation:  [[ 1420.77355619]]\n",
      "Loop  9670 :    Loss_Train:  [[ 4822.51473927]]    Loss_Validation:  [[ 1420.77358515]]\n",
      "Loop  9671 :    Loss_Train:  [[ 4822.51473916]]    Loss_Validation:  [[ 1420.77361409]]\n",
      "Loop  9672 :    Loss_Train:  [[ 4822.51473905]]    Loss_Validation:  [[ 1420.77364301]]\n",
      "Loop  9673 :    Loss_Train:  [[ 4822.51473894]]    Loss_Validation:  [[ 1420.77367191]]\n",
      "Loop  9674 :    Loss_Train:  [[ 4822.51473883]]    Loss_Validation:  [[ 1420.77370079]]\n",
      "Loop  9675 :    Loss_Train:  [[ 4822.51473873]]    Loss_Validation:  [[ 1420.77372965]]\n",
      "Loop  9676 :    Loss_Train:  [[ 4822.51473862]]    Loss_Validation:  [[ 1420.77375848]]\n",
      "Loop  9677 :    Loss_Train:  [[ 4822.51473851]]    Loss_Validation:  [[ 1420.7737873]]\n",
      "Loop  9678 :    Loss_Train:  [[ 4822.5147384]]    Loss_Validation:  [[ 1420.77381609]]\n",
      "Loop  9679 :    Loss_Train:  [[ 4822.51473829]]    Loss_Validation:  [[ 1420.77384486]]\n",
      "Loop  9680 :    Loss_Train:  [[ 4822.51473819]]    Loss_Validation:  [[ 1420.77387361]]\n",
      "Loop  9681 :    Loss_Train:  [[ 4822.51473808]]    Loss_Validation:  [[ 1420.77390235]]\n",
      "Loop  9682 :    Loss_Train:  [[ 4822.51473797]]    Loss_Validation:  [[ 1420.77393106]]\n",
      "Loop  9683 :    Loss_Train:  [[ 4822.51473787]]    Loss_Validation:  [[ 1420.77395975]]\n",
      "Loop  9684 :    Loss_Train:  [[ 4822.51473776]]    Loss_Validation:  [[ 1420.77398841]]\n",
      "Loop  9685 :    Loss_Train:  [[ 4822.51473765]]    Loss_Validation:  [[ 1420.77401706]]\n",
      "Loop  9686 :    Loss_Train:  [[ 4822.51473755]]    Loss_Validation:  [[ 1420.77404569]]\n",
      "Loop  9687 :    Loss_Train:  [[ 4822.51473744]]    Loss_Validation:  [[ 1420.7740743]]\n",
      "Loop  9688 :    Loss_Train:  [[ 4822.51473733]]    Loss_Validation:  [[ 1420.77410288]]\n",
      "Loop  9689 :    Loss_Train:  [[ 4822.51473723]]    Loss_Validation:  [[ 1420.77413145]]\n",
      "Loop  9690 :    Loss_Train:  [[ 4822.51473712]]    Loss_Validation:  [[ 1420.77415999]]\n",
      "Loop  9691 :    Loss_Train:  [[ 4822.51473702]]    Loss_Validation:  [[ 1420.77418852]]\n",
      "Loop  9692 :    Loss_Train:  [[ 4822.51473691]]    Loss_Validation:  [[ 1420.77421702]]\n",
      "Loop  9693 :    Loss_Train:  [[ 4822.5147368]]    Loss_Validation:  [[ 1420.7742455]]\n",
      "Loop  9694 :    Loss_Train:  [[ 4822.5147367]]    Loss_Validation:  [[ 1420.77427397]]\n",
      "Loop  9695 :    Loss_Train:  [[ 4822.51473659]]    Loss_Validation:  [[ 1420.77430241]]\n",
      "Loop  9696 :    Loss_Train:  [[ 4822.51473649]]    Loss_Validation:  [[ 1420.77433083]]\n",
      "Loop  9697 :    Loss_Train:  [[ 4822.51473638]]    Loss_Validation:  [[ 1420.77435923]]\n",
      "Loop  9698 :    Loss_Train:  [[ 4822.51473628]]    Loss_Validation:  [[ 1420.77438761]]\n",
      "Loop  9699 :    Loss_Train:  [[ 4822.51473618]]    Loss_Validation:  [[ 1420.77441597]]\n",
      "Loop  9700 :    Loss_Train:  [[ 4822.51473607]]    Loss_Validation:  [[ 1420.77444431]]\n",
      "Loop  9701 :    Loss_Train:  [[ 4822.51473597]]    Loss_Validation:  [[ 1420.77447263]]\n",
      "Loop  9702 :    Loss_Train:  [[ 4822.51473586]]    Loss_Validation:  [[ 1420.77450093]]\n",
      "Loop  9703 :    Loss_Train:  [[ 4822.51473576]]    Loss_Validation:  [[ 1420.7745292]]\n",
      "Loop  9704 :    Loss_Train:  [[ 4822.51473566]]    Loss_Validation:  [[ 1420.77455746]]\n",
      "Loop  9705 :    Loss_Train:  [[ 4822.51473555]]    Loss_Validation:  [[ 1420.7745857]]\n",
      "Loop  9706 :    Loss_Train:  [[ 4822.51473545]]    Loss_Validation:  [[ 1420.77461391]]\n",
      "Loop  9707 :    Loss_Train:  [[ 4822.51473535]]    Loss_Validation:  [[ 1420.77464211]]\n",
      "Loop  9708 :    Loss_Train:  [[ 4822.51473524]]    Loss_Validation:  [[ 1420.77467028]]\n",
      "Loop  9709 :    Loss_Train:  [[ 4822.51473514]]    Loss_Validation:  [[ 1420.77469844]]\n",
      "Loop  9710 :    Loss_Train:  [[ 4822.51473504]]    Loss_Validation:  [[ 1420.77472657]]\n",
      "Loop  9711 :    Loss_Train:  [[ 4822.51473494]]    Loss_Validation:  [[ 1420.77475469]]\n",
      "Loop  9712 :    Loss_Train:  [[ 4822.51473483]]    Loss_Validation:  [[ 1420.77478278]]\n",
      "Loop  9713 :    Loss_Train:  [[ 4822.51473473]]    Loss_Validation:  [[ 1420.77481086]]\n",
      "Loop  9714 :    Loss_Train:  [[ 4822.51473463]]    Loss_Validation:  [[ 1420.77483891]]\n",
      "Loop  9715 :    Loss_Train:  [[ 4822.51473453]]    Loss_Validation:  [[ 1420.77486694]]\n",
      "Loop  9716 :    Loss_Train:  [[ 4822.51473443]]    Loss_Validation:  [[ 1420.77489496]]\n",
      "Loop  9717 :    Loss_Train:  [[ 4822.51473432]]    Loss_Validation:  [[ 1420.77492295]]\n",
      "Loop  9718 :    Loss_Train:  [[ 4822.51473422]]    Loss_Validation:  [[ 1420.77495092]]\n",
      "Loop  9719 :    Loss_Train:  [[ 4822.51473412]]    Loss_Validation:  [[ 1420.77497887]]\n",
      "Loop  9720 :    Loss_Train:  [[ 4822.51473402]]    Loss_Validation:  [[ 1420.7750068]]\n",
      "Loop  9721 :    Loss_Train:  [[ 4822.51473392]]    Loss_Validation:  [[ 1420.77503472]]\n",
      "Loop  9722 :    Loss_Train:  [[ 4822.51473382]]    Loss_Validation:  [[ 1420.77506261]]\n",
      "Loop  9723 :    Loss_Train:  [[ 4822.51473372]]    Loss_Validation:  [[ 1420.77509048]]\n",
      "Loop  9724 :    Loss_Train:  [[ 4822.51473362]]    Loss_Validation:  [[ 1420.77511833]]\n",
      "Loop  9725 :    Loss_Train:  [[ 4822.51473352]]    Loss_Validation:  [[ 1420.77514616]]\n",
      "Loop  9726 :    Loss_Train:  [[ 4822.51473342]]    Loss_Validation:  [[ 1420.77517397]]\n",
      "Loop  9727 :    Loss_Train:  [[ 4822.51473332]]    Loss_Validation:  [[ 1420.77520176]]\n",
      "Loop  9728 :    Loss_Train:  [[ 4822.51473322]]    Loss_Validation:  [[ 1420.77522953]]\n",
      "Loop  9729 :    Loss_Train:  [[ 4822.51473312]]    Loss_Validation:  [[ 1420.77525728]]\n",
      "Loop  9730 :    Loss_Train:  [[ 4822.51473302]]    Loss_Validation:  [[ 1420.77528501]]\n",
      "Loop  9731 :    Loss_Train:  [[ 4822.51473292]]    Loss_Validation:  [[ 1420.77531272]]\n",
      "Loop  9732 :    Loss_Train:  [[ 4822.51473282]]    Loss_Validation:  [[ 1420.77534041]]\n",
      "Loop  9733 :    Loss_Train:  [[ 4822.51473272]]    Loss_Validation:  [[ 1420.77536808]]\n",
      "Loop  9734 :    Loss_Train:  [[ 4822.51473262]]    Loss_Validation:  [[ 1420.77539573]]\n",
      "Loop  9735 :    Loss_Train:  [[ 4822.51473252]]    Loss_Validation:  [[ 1420.77542336]]\n",
      "Loop  9736 :    Loss_Train:  [[ 4822.51473243]]    Loss_Validation:  [[ 1420.77545097]]\n",
      "Loop  9737 :    Loss_Train:  [[ 4822.51473233]]    Loss_Validation:  [[ 1420.77547856]]\n",
      "Loop  9738 :    Loss_Train:  [[ 4822.51473223]]    Loss_Validation:  [[ 1420.77550613]]\n",
      "Loop  9739 :    Loss_Train:  [[ 4822.51473213]]    Loss_Validation:  [[ 1420.77553368]]\n",
      "Loop  9740 :    Loss_Train:  [[ 4822.51473203]]    Loss_Validation:  [[ 1420.77556121]]\n",
      "Loop  9741 :    Loss_Train:  [[ 4822.51473194]]    Loss_Validation:  [[ 1420.77558872]]\n",
      "Loop  9742 :    Loss_Train:  [[ 4822.51473184]]    Loss_Validation:  [[ 1420.77561621]]\n",
      "Loop  9743 :    Loss_Train:  [[ 4822.51473174]]    Loss_Validation:  [[ 1420.77564369]]\n",
      "Loop  9744 :    Loss_Train:  [[ 4822.51473164]]    Loss_Validation:  [[ 1420.77567114]]\n",
      "Loop  9745 :    Loss_Train:  [[ 4822.51473155]]    Loss_Validation:  [[ 1420.77569857]]\n",
      "Loop  9746 :    Loss_Train:  [[ 4822.51473145]]    Loss_Validation:  [[ 1420.77572598]]\n",
      "Loop  9747 :    Loss_Train:  [[ 4822.51473135]]    Loss_Validation:  [[ 1420.77575337]]\n",
      "Loop  9748 :    Loss_Train:  [[ 4822.51473126]]    Loss_Validation:  [[ 1420.77578074]]\n",
      "Loop  9749 :    Loss_Train:  [[ 4822.51473116]]    Loss_Validation:  [[ 1420.77580809]]\n",
      "Loop  9750 :    Loss_Train:  [[ 4822.51473106]]    Loss_Validation:  [[ 1420.77583542]]\n",
      "Loop  9751 :    Loss_Train:  [[ 4822.51473097]]    Loss_Validation:  [[ 1420.77586274]]\n",
      "Loop  9752 :    Loss_Train:  [[ 4822.51473087]]    Loss_Validation:  [[ 1420.77589003]]\n",
      "Loop  9753 :    Loss_Train:  [[ 4822.51473077]]    Loss_Validation:  [[ 1420.7759173]]\n",
      "Loop  9754 :    Loss_Train:  [[ 4822.51473068]]    Loss_Validation:  [[ 1420.77594455]]\n",
      "Loop  9755 :    Loss_Train:  [[ 4822.51473058]]    Loss_Validation:  [[ 1420.77597179]]\n",
      "Loop  9756 :    Loss_Train:  [[ 4822.51473049]]    Loss_Validation:  [[ 1420.775999]]\n",
      "Loop  9757 :    Loss_Train:  [[ 4822.51473039]]    Loss_Validation:  [[ 1420.77602619]]\n",
      "Loop  9758 :    Loss_Train:  [[ 4822.5147303]]    Loss_Validation:  [[ 1420.77605337]]\n",
      "Loop  9759 :    Loss_Train:  [[ 4822.5147302]]    Loss_Validation:  [[ 1420.77608052]]\n",
      "Loop  9760 :    Loss_Train:  [[ 4822.51473011]]    Loss_Validation:  [[ 1420.77610765]]\n",
      "Loop  9761 :    Loss_Train:  [[ 4822.51473001]]    Loss_Validation:  [[ 1420.77613477]]\n",
      "Loop  9762 :    Loss_Train:  [[ 4822.51472992]]    Loss_Validation:  [[ 1420.77616186]]\n",
      "Loop  9763 :    Loss_Train:  [[ 4822.51472982]]    Loss_Validation:  [[ 1420.77618894]]\n",
      "Loop  9764 :    Loss_Train:  [[ 4822.51472973]]    Loss_Validation:  [[ 1420.776216]]\n",
      "Loop  9765 :    Loss_Train:  [[ 4822.51472963]]    Loss_Validation:  [[ 1420.77624303]]\n",
      "Loop  9766 :    Loss_Train:  [[ 4822.51472954]]    Loss_Validation:  [[ 1420.77627005]]\n",
      "Loop  9767 :    Loss_Train:  [[ 4822.51472945]]    Loss_Validation:  [[ 1420.77629705]]\n",
      "Loop  9768 :    Loss_Train:  [[ 4822.51472935]]    Loss_Validation:  [[ 1420.77632403]]\n",
      "Loop  9769 :    Loss_Train:  [[ 4822.51472926]]    Loss_Validation:  [[ 1420.77635098]]\n",
      "Loop  9770 :    Loss_Train:  [[ 4822.51472917]]    Loss_Validation:  [[ 1420.77637792]]\n",
      "Loop  9771 :    Loss_Train:  [[ 4822.51472907]]    Loss_Validation:  [[ 1420.77640484]]\n",
      "Loop  9772 :    Loss_Train:  [[ 4822.51472898]]    Loss_Validation:  [[ 1420.77643174]]\n",
      "Loop  9773 :    Loss_Train:  [[ 4822.51472889]]    Loss_Validation:  [[ 1420.77645862]]\n",
      "Loop  9774 :    Loss_Train:  [[ 4822.51472879]]    Loss_Validation:  [[ 1420.77648548]]\n",
      "Loop  9775 :    Loss_Train:  [[ 4822.5147287]]    Loss_Validation:  [[ 1420.77651232]]\n",
      "Loop  9776 :    Loss_Train:  [[ 4822.51472861]]    Loss_Validation:  [[ 1420.77653915]]\n",
      "Loop  9777 :    Loss_Train:  [[ 4822.51472852]]    Loss_Validation:  [[ 1420.77656595]]\n",
      "Loop  9778 :    Loss_Train:  [[ 4822.51472842]]    Loss_Validation:  [[ 1420.77659273]]\n",
      "Loop  9779 :    Loss_Train:  [[ 4822.51472833]]    Loss_Validation:  [[ 1420.7766195]]\n",
      "Loop  9780 :    Loss_Train:  [[ 4822.51472824]]    Loss_Validation:  [[ 1420.77664624]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  9781 :    Loss_Train:  [[ 4822.51472815]]    Loss_Validation:  [[ 1420.77667297]]\n",
      "Loop  9782 :    Loss_Train:  [[ 4822.51472806]]    Loss_Validation:  [[ 1420.77669967]]\n",
      "Loop  9783 :    Loss_Train:  [[ 4822.51472796]]    Loss_Validation:  [[ 1420.77672636]]\n",
      "Loop  9784 :    Loss_Train:  [[ 4822.51472787]]    Loss_Validation:  [[ 1420.77675302]]\n",
      "Loop  9785 :    Loss_Train:  [[ 4822.51472778]]    Loss_Validation:  [[ 1420.77677967]]\n",
      "Loop  9786 :    Loss_Train:  [[ 4822.51472769]]    Loss_Validation:  [[ 1420.7768063]]\n",
      "Loop  9787 :    Loss_Train:  [[ 4822.5147276]]    Loss_Validation:  [[ 1420.77683291]]\n",
      "Loop  9788 :    Loss_Train:  [[ 4822.51472751]]    Loss_Validation:  [[ 1420.7768595]]\n",
      "Loop  9789 :    Loss_Train:  [[ 4822.51472742]]    Loss_Validation:  [[ 1420.77688607]]\n",
      "Loop  9790 :    Loss_Train:  [[ 4822.51472733]]    Loss_Validation:  [[ 1420.77691262]]\n",
      "Loop  9791 :    Loss_Train:  [[ 4822.51472724]]    Loss_Validation:  [[ 1420.77693915]]\n",
      "Loop  9792 :    Loss_Train:  [[ 4822.51472715]]    Loss_Validation:  [[ 1420.77696567]]\n",
      "Loop  9793 :    Loss_Train:  [[ 4822.51472706]]    Loss_Validation:  [[ 1420.77699216]]\n",
      "Loop  9794 :    Loss_Train:  [[ 4822.51472697]]    Loss_Validation:  [[ 1420.77701864]]\n",
      "Loop  9795 :    Loss_Train:  [[ 4822.51472688]]    Loss_Validation:  [[ 1420.77704509]]\n",
      "Loop  9796 :    Loss_Train:  [[ 4822.51472679]]    Loss_Validation:  [[ 1420.77707153]]\n",
      "Loop  9797 :    Loss_Train:  [[ 4822.5147267]]    Loss_Validation:  [[ 1420.77709795]]\n",
      "Loop  9798 :    Loss_Train:  [[ 4822.51472661]]    Loss_Validation:  [[ 1420.77712434]]\n",
      "Loop  9799 :    Loss_Train:  [[ 4822.51472652]]    Loss_Validation:  [[ 1420.77715072]]\n",
      "Loop  9800 :    Loss_Train:  [[ 4822.51472643]]    Loss_Validation:  [[ 1420.77717708]]\n",
      "Loop  9801 :    Loss_Train:  [[ 4822.51472634]]    Loss_Validation:  [[ 1420.77720342]]\n",
      "Loop  9802 :    Loss_Train:  [[ 4822.51472625]]    Loss_Validation:  [[ 1420.77722974]]\n",
      "Loop  9803 :    Loss_Train:  [[ 4822.51472616]]    Loss_Validation:  [[ 1420.77725605]]\n",
      "Loop  9804 :    Loss_Train:  [[ 4822.51472607]]    Loss_Validation:  [[ 1420.77728233]]\n",
      "Loop  9805 :    Loss_Train:  [[ 4822.51472598]]    Loss_Validation:  [[ 1420.7773086]]\n",
      "Loop  9806 :    Loss_Train:  [[ 4822.5147259]]    Loss_Validation:  [[ 1420.77733484]]\n",
      "Loop  9807 :    Loss_Train:  [[ 4822.51472581]]    Loss_Validation:  [[ 1420.77736107]]\n",
      "Loop  9808 :    Loss_Train:  [[ 4822.51472572]]    Loss_Validation:  [[ 1420.77738728]]\n",
      "Loop  9809 :    Loss_Train:  [[ 4822.51472563]]    Loss_Validation:  [[ 1420.77741346]]\n",
      "Loop  9810 :    Loss_Train:  [[ 4822.51472554]]    Loss_Validation:  [[ 1420.77743963]]\n",
      "Loop  9811 :    Loss_Train:  [[ 4822.51472546]]    Loss_Validation:  [[ 1420.77746578]]\n",
      "Loop  9812 :    Loss_Train:  [[ 4822.51472537]]    Loss_Validation:  [[ 1420.77749192]]\n",
      "Loop  9813 :    Loss_Train:  [[ 4822.51472528]]    Loss_Validation:  [[ 1420.77751803]]\n",
      "Loop  9814 :    Loss_Train:  [[ 4822.51472519]]    Loss_Validation:  [[ 1420.77754412]]\n",
      "Loop  9815 :    Loss_Train:  [[ 4822.51472511]]    Loss_Validation:  [[ 1420.7775702]]\n",
      "Loop  9816 :    Loss_Train:  [[ 4822.51472502]]    Loss_Validation:  [[ 1420.77759625]]\n",
      "Loop  9817 :    Loss_Train:  [[ 4822.51472493]]    Loss_Validation:  [[ 1420.77762229]]\n",
      "Loop  9818 :    Loss_Train:  [[ 4822.51472485]]    Loss_Validation:  [[ 1420.77764831]]\n",
      "Loop  9819 :    Loss_Train:  [[ 4822.51472476]]    Loss_Validation:  [[ 1420.77767431]]\n",
      "Loop  9820 :    Loss_Train:  [[ 4822.51472467]]    Loss_Validation:  [[ 1420.77770029]]\n",
      "Loop  9821 :    Loss_Train:  [[ 4822.51472459]]    Loss_Validation:  [[ 1420.77772625]]\n",
      "Loop  9822 :    Loss_Train:  [[ 4822.5147245]]    Loss_Validation:  [[ 1420.7777522]]\n",
      "Loop  9823 :    Loss_Train:  [[ 4822.51472441]]    Loss_Validation:  [[ 1420.77777812]]\n",
      "Loop  9824 :    Loss_Train:  [[ 4822.51472433]]    Loss_Validation:  [[ 1420.77780403]]\n",
      "Loop  9825 :    Loss_Train:  [[ 4822.51472424]]    Loss_Validation:  [[ 1420.77782991]]\n",
      "Loop  9826 :    Loss_Train:  [[ 4822.51472416]]    Loss_Validation:  [[ 1420.77785578]]\n",
      "Loop  9827 :    Loss_Train:  [[ 4822.51472407]]    Loss_Validation:  [[ 1420.77788163]]\n",
      "Loop  9828 :    Loss_Train:  [[ 4822.51472399]]    Loss_Validation:  [[ 1420.77790746]]\n",
      "Loop  9829 :    Loss_Train:  [[ 4822.5147239]]    Loss_Validation:  [[ 1420.77793327]]\n",
      "Loop  9830 :    Loss_Train:  [[ 4822.51472382]]    Loss_Validation:  [[ 1420.77795907]]\n",
      "Loop  9831 :    Loss_Train:  [[ 4822.51472373]]    Loss_Validation:  [[ 1420.77798484]]\n",
      "Loop  9832 :    Loss_Train:  [[ 4822.51472365]]    Loss_Validation:  [[ 1420.7780106]]\n",
      "Loop  9833 :    Loss_Train:  [[ 4822.51472356]]    Loss_Validation:  [[ 1420.77803633]]\n",
      "Loop  9834 :    Loss_Train:  [[ 4822.51472348]]    Loss_Validation:  [[ 1420.77806205]]\n",
      "Loop  9835 :    Loss_Train:  [[ 4822.51472339]]    Loss_Validation:  [[ 1420.77808775]]\n",
      "Loop  9836 :    Loss_Train:  [[ 4822.51472331]]    Loss_Validation:  [[ 1420.77811343]]\n",
      "Loop  9837 :    Loss_Train:  [[ 4822.51472322]]    Loss_Validation:  [[ 1420.7781391]]\n",
      "Loop  9838 :    Loss_Train:  [[ 4822.51472314]]    Loss_Validation:  [[ 1420.77816474]]\n",
      "Loop  9839 :    Loss_Train:  [[ 4822.51472306]]    Loss_Validation:  [[ 1420.77819037]]\n",
      "Loop  9840 :    Loss_Train:  [[ 4822.51472297]]    Loss_Validation:  [[ 1420.77821598]]\n",
      "Loop  9841 :    Loss_Train:  [[ 4822.51472289]]    Loss_Validation:  [[ 1420.77824156]]\n",
      "Loop  9842 :    Loss_Train:  [[ 4822.51472281]]    Loss_Validation:  [[ 1420.77826713]]\n",
      "Loop  9843 :    Loss_Train:  [[ 4822.51472272]]    Loss_Validation:  [[ 1420.77829269]]\n",
      "Loop  9844 :    Loss_Train:  [[ 4822.51472264]]    Loss_Validation:  [[ 1420.77831822]]\n",
      "Loop  9845 :    Loss_Train:  [[ 4822.51472256]]    Loss_Validation:  [[ 1420.77834373]]\n",
      "Loop  9846 :    Loss_Train:  [[ 4822.51472247]]    Loss_Validation:  [[ 1420.77836923]]\n",
      "Loop  9847 :    Loss_Train:  [[ 4822.51472239]]    Loss_Validation:  [[ 1420.77839471]]\n",
      "Loop  9848 :    Loss_Train:  [[ 4822.51472231]]    Loss_Validation:  [[ 1420.77842017]]\n",
      "Loop  9849 :    Loss_Train:  [[ 4822.51472222]]    Loss_Validation:  [[ 1420.77844561]]\n",
      "Loop  9850 :    Loss_Train:  [[ 4822.51472214]]    Loss_Validation:  [[ 1420.77847103]]\n",
      "Loop  9851 :    Loss_Train:  [[ 4822.51472206]]    Loss_Validation:  [[ 1420.77849643]]\n",
      "Loop  9852 :    Loss_Train:  [[ 4822.51472198]]    Loss_Validation:  [[ 1420.77852182]]\n",
      "Loop  9853 :    Loss_Train:  [[ 4822.51472189]]    Loss_Validation:  [[ 1420.77854719]]\n",
      "Loop  9854 :    Loss_Train:  [[ 4822.51472181]]    Loss_Validation:  [[ 1420.77857253]]\n",
      "Loop  9855 :    Loss_Train:  [[ 4822.51472173]]    Loss_Validation:  [[ 1420.77859786]]\n",
      "Loop  9856 :    Loss_Train:  [[ 4822.51472165]]    Loss_Validation:  [[ 1420.77862318]]\n",
      "Loop  9857 :    Loss_Train:  [[ 4822.51472157]]    Loss_Validation:  [[ 1420.77864847]]\n",
      "Loop  9858 :    Loss_Train:  [[ 4822.51472149]]    Loss_Validation:  [[ 1420.77867375]]\n",
      "Loop  9859 :    Loss_Train:  [[ 4822.5147214]]    Loss_Validation:  [[ 1420.778699]]\n",
      "Loop  9860 :    Loss_Train:  [[ 4822.51472132]]    Loss_Validation:  [[ 1420.77872424]]\n",
      "Loop  9861 :    Loss_Train:  [[ 4822.51472124]]    Loss_Validation:  [[ 1420.77874946]]\n",
      "Loop  9862 :    Loss_Train:  [[ 4822.51472116]]    Loss_Validation:  [[ 1420.77877466]]\n",
      "Loop  9863 :    Loss_Train:  [[ 4822.51472108]]    Loss_Validation:  [[ 1420.77879985]]\n",
      "Loop  9864 :    Loss_Train:  [[ 4822.514721]]    Loss_Validation:  [[ 1420.77882501]]\n",
      "Loop  9865 :    Loss_Train:  [[ 4822.51472092]]    Loss_Validation:  [[ 1420.77885016]]\n",
      "Loop  9866 :    Loss_Train:  [[ 4822.51472084]]    Loss_Validation:  [[ 1420.77887529]]\n",
      "Loop  9867 :    Loss_Train:  [[ 4822.51472076]]    Loss_Validation:  [[ 1420.7789004]]\n",
      "Loop  9868 :    Loss_Train:  [[ 4822.51472068]]    Loss_Validation:  [[ 1420.7789255]]\n",
      "Loop  9869 :    Loss_Train:  [[ 4822.5147206]]    Loss_Validation:  [[ 1420.77895057]]\n",
      "Loop  9870 :    Loss_Train:  [[ 4822.51472052]]    Loss_Validation:  [[ 1420.77897563]]\n",
      "Loop  9871 :    Loss_Train:  [[ 4822.51472044]]    Loss_Validation:  [[ 1420.77900067]]\n",
      "Loop  9872 :    Loss_Train:  [[ 4822.51472036]]    Loss_Validation:  [[ 1420.77902569]]\n",
      "Loop  9873 :    Loss_Train:  [[ 4822.51472028]]    Loss_Validation:  [[ 1420.77905069]]\n",
      "Loop  9874 :    Loss_Train:  [[ 4822.5147202]]    Loss_Validation:  [[ 1420.77907567]]\n",
      "Loop  9875 :    Loss_Train:  [[ 4822.51472012]]    Loss_Validation:  [[ 1420.77910064]]\n",
      "Loop  9876 :    Loss_Train:  [[ 4822.51472004]]    Loss_Validation:  [[ 1420.77912559]]\n",
      "Loop  9877 :    Loss_Train:  [[ 4822.51471996]]    Loss_Validation:  [[ 1420.77915052]]\n",
      "Loop  9878 :    Loss_Train:  [[ 4822.51471988]]    Loss_Validation:  [[ 1420.77917543]]\n",
      "Loop  9879 :    Loss_Train:  [[ 4822.5147198]]    Loss_Validation:  [[ 1420.77920032]]\n",
      "Loop  9880 :    Loss_Train:  [[ 4822.51471972]]    Loss_Validation:  [[ 1420.7792252]]\n",
      "Loop  9881 :    Loss_Train:  [[ 4822.51471965]]    Loss_Validation:  [[ 1420.77925005]]\n",
      "Loop  9882 :    Loss_Train:  [[ 4822.51471957]]    Loss_Validation:  [[ 1420.77927489]]\n",
      "Loop  9883 :    Loss_Train:  [[ 4822.51471949]]    Loss_Validation:  [[ 1420.77929972]]\n",
      "Loop  9884 :    Loss_Train:  [[ 4822.51471941]]    Loss_Validation:  [[ 1420.77932452]]\n",
      "Loop  9885 :    Loss_Train:  [[ 4822.51471933]]    Loss_Validation:  [[ 1420.77934931]]\n",
      "Loop  9886 :    Loss_Train:  [[ 4822.51471925]]    Loss_Validation:  [[ 1420.77937407]]\n",
      "Loop  9887 :    Loss_Train:  [[ 4822.51471918]]    Loss_Validation:  [[ 1420.77939882]]\n",
      "Loop  9888 :    Loss_Train:  [[ 4822.5147191]]    Loss_Validation:  [[ 1420.77942356]]\n",
      "Loop  9889 :    Loss_Train:  [[ 4822.51471902]]    Loss_Validation:  [[ 1420.77944827]]\n",
      "Loop  9890 :    Loss_Train:  [[ 4822.51471894]]    Loss_Validation:  [[ 1420.77947297]]\n",
      "Loop  9891 :    Loss_Train:  [[ 4822.51471887]]    Loss_Validation:  [[ 1420.77949764]]\n",
      "Loop  9892 :    Loss_Train:  [[ 4822.51471879]]    Loss_Validation:  [[ 1420.7795223]]\n",
      "Loop  9893 :    Loss_Train:  [[ 4822.51471871]]    Loss_Validation:  [[ 1420.77954695]]\n",
      "Loop  9894 :    Loss_Train:  [[ 4822.51471863]]    Loss_Validation:  [[ 1420.77957157]]\n",
      "Loop  9895 :    Loss_Train:  [[ 4822.51471856]]    Loss_Validation:  [[ 1420.77959618]]\n",
      "Loop  9896 :    Loss_Train:  [[ 4822.51471848]]    Loss_Validation:  [[ 1420.77962077]]\n",
      "Loop  9897 :    Loss_Train:  [[ 4822.5147184]]    Loss_Validation:  [[ 1420.77964534]]\n",
      "Loop  9898 :    Loss_Train:  [[ 4822.51471833]]    Loss_Validation:  [[ 1420.77966989]]\n",
      "Loop  9899 :    Loss_Train:  [[ 4822.51471825]]    Loss_Validation:  [[ 1420.77969443]]\n",
      "Loop  9900 :    Loss_Train:  [[ 4822.51471817]]    Loss_Validation:  [[ 1420.77971895]]\n",
      "Loop  9901 :    Loss_Train:  [[ 4822.5147181]]    Loss_Validation:  [[ 1420.77974345]]\n",
      "Loop  9902 :    Loss_Train:  [[ 4822.51471802]]    Loss_Validation:  [[ 1420.77976793]]\n",
      "Loop  9903 :    Loss_Train:  [[ 4822.51471795]]    Loss_Validation:  [[ 1420.77979239]]\n",
      "Loop  9904 :    Loss_Train:  [[ 4822.51471787]]    Loss_Validation:  [[ 1420.77981684]]\n",
      "Loop  9905 :    Loss_Train:  [[ 4822.5147178]]    Loss_Validation:  [[ 1420.77984127]]\n",
      "Loop  9906 :    Loss_Train:  [[ 4822.51471772]]    Loss_Validation:  [[ 1420.77986568]]\n",
      "Loop  9907 :    Loss_Train:  [[ 4822.51471764]]    Loss_Validation:  [[ 1420.77989007]]\n",
      "Loop  9908 :    Loss_Train:  [[ 4822.51471757]]    Loss_Validation:  [[ 1420.77991445]]\n",
      "Loop  9909 :    Loss_Train:  [[ 4822.51471749]]    Loss_Validation:  [[ 1420.77993881]]\n",
      "Loop  9910 :    Loss_Train:  [[ 4822.51471742]]    Loss_Validation:  [[ 1420.77996315]]\n",
      "Loop  9911 :    Loss_Train:  [[ 4822.51471734]]    Loss_Validation:  [[ 1420.77998747]]\n",
      "Loop  9912 :    Loss_Train:  [[ 4822.51471727]]    Loss_Validation:  [[ 1420.78001178]]\n",
      "Loop  9913 :    Loss_Train:  [[ 4822.51471719]]    Loss_Validation:  [[ 1420.78003607]]\n",
      "Loop  9914 :    Loss_Train:  [[ 4822.51471712]]    Loss_Validation:  [[ 1420.78006034]]\n",
      "Loop  9915 :    Loss_Train:  [[ 4822.51471704]]    Loss_Validation:  [[ 1420.78008459]]\n",
      "Loop  9916 :    Loss_Train:  [[ 4822.51471697]]    Loss_Validation:  [[ 1420.78010882]]\n",
      "Loop  9917 :    Loss_Train:  [[ 4822.5147169]]    Loss_Validation:  [[ 1420.78013304]]\n",
      "Loop  9918 :    Loss_Train:  [[ 4822.51471682]]    Loss_Validation:  [[ 1420.78015724]]\n",
      "Loop  9919 :    Loss_Train:  [[ 4822.51471675]]    Loss_Validation:  [[ 1420.78018142]]\n",
      "Loop  9920 :    Loss_Train:  [[ 4822.51471667]]    Loss_Validation:  [[ 1420.78020559]]\n",
      "Loop  9921 :    Loss_Train:  [[ 4822.5147166]]    Loss_Validation:  [[ 1420.78022974]]\n",
      "Loop  9922 :    Loss_Train:  [[ 4822.51471653]]    Loss_Validation:  [[ 1420.78025387]]\n",
      "Loop  9923 :    Loss_Train:  [[ 4822.51471645]]    Loss_Validation:  [[ 1420.78027798]]\n",
      "Loop  9924 :    Loss_Train:  [[ 4822.51471638]]    Loss_Validation:  [[ 1420.78030207]]\n",
      "Loop  9925 :    Loss_Train:  [[ 4822.5147163]]    Loss_Validation:  [[ 1420.78032615]]\n",
      "Loop  9926 :    Loss_Train:  [[ 4822.51471623]]    Loss_Validation:  [[ 1420.78035021]]\n",
      "Loop  9927 :    Loss_Train:  [[ 4822.51471616]]    Loss_Validation:  [[ 1420.78037425]]\n",
      "Loop  9928 :    Loss_Train:  [[ 4822.51471608]]    Loss_Validation:  [[ 1420.78039828]]\n",
      "Loop  9929 :    Loss_Train:  [[ 4822.51471601]]    Loss_Validation:  [[ 1420.78042229]]\n",
      "Loop  9930 :    Loss_Train:  [[ 4822.51471594]]    Loss_Validation:  [[ 1420.78044628]]\n",
      "Loop  9931 :    Loss_Train:  [[ 4822.51471587]]    Loss_Validation:  [[ 1420.78047025]]\n",
      "Loop  9932 :    Loss_Train:  [[ 4822.51471579]]    Loss_Validation:  [[ 1420.78049421]]\n",
      "Loop  9933 :    Loss_Train:  [[ 4822.51471572]]    Loss_Validation:  [[ 1420.78051815]]\n",
      "Loop  9934 :    Loss_Train:  [[ 4822.51471565]]    Loss_Validation:  [[ 1420.78054207]]\n",
      "Loop  9935 :    Loss_Train:  [[ 4822.51471558]]    Loss_Validation:  [[ 1420.78056597]]\n",
      "Loop  9936 :    Loss_Train:  [[ 4822.5147155]]    Loss_Validation:  [[ 1420.78058986]]\n",
      "Loop  9937 :    Loss_Train:  [[ 4822.51471543]]    Loss_Validation:  [[ 1420.78061373]]\n",
      "Loop  9938 :    Loss_Train:  [[ 4822.51471536]]    Loss_Validation:  [[ 1420.78063758]]\n",
      "Loop  9939 :    Loss_Train:  [[ 4822.51471529]]    Loss_Validation:  [[ 1420.78066141]]\n",
      "Loop  9940 :    Loss_Train:  [[ 4822.51471522]]    Loss_Validation:  [[ 1420.78068523]]\n",
      "Loop  9941 :    Loss_Train:  [[ 4822.51471514]]    Loss_Validation:  [[ 1420.78070903]]\n",
      "Loop  9942 :    Loss_Train:  [[ 4822.51471507]]    Loss_Validation:  [[ 1420.78073281]]\n",
      "Loop  9943 :    Loss_Train:  [[ 4822.514715]]    Loss_Validation:  [[ 1420.78075658]]\n",
      "Loop  9944 :    Loss_Train:  [[ 4822.51471493]]    Loss_Validation:  [[ 1420.78078033]]\n",
      "Loop  9945 :    Loss_Train:  [[ 4822.51471486]]    Loss_Validation:  [[ 1420.78080406]]\n",
      "Loop  9946 :    Loss_Train:  [[ 4822.51471479]]    Loss_Validation:  [[ 1420.78082777]]\n",
      "Loop  9947 :    Loss_Train:  [[ 4822.51471472]]    Loss_Validation:  [[ 1420.78085147]]\n",
      "Loop  9948 :    Loss_Train:  [[ 4822.51471465]]    Loss_Validation:  [[ 1420.78087515]]\n",
      "Loop  9949 :    Loss_Train:  [[ 4822.51471458]]    Loss_Validation:  [[ 1420.78089881]]\n",
      "Loop  9950 :    Loss_Train:  [[ 4822.51471451]]    Loss_Validation:  [[ 1420.78092245]]\n",
      "Loop  9951 :    Loss_Train:  [[ 4822.51471443]]    Loss_Validation:  [[ 1420.78094608]]\n",
      "Loop  9952 :    Loss_Train:  [[ 4822.51471436]]    Loss_Validation:  [[ 1420.78096969]]\n",
      "Loop  9953 :    Loss_Train:  [[ 4822.51471429]]    Loss_Validation:  [[ 1420.78099329]]\n",
      "Loop  9954 :    Loss_Train:  [[ 4822.51471422]]    Loss_Validation:  [[ 1420.78101686]]\n",
      "Loop  9955 :    Loss_Train:  [[ 4822.51471415]]    Loss_Validation:  [[ 1420.78104042]]\n",
      "Loop  9956 :    Loss_Train:  [[ 4822.51471408]]    Loss_Validation:  [[ 1420.78106397]]\n",
      "Loop  9957 :    Loss_Train:  [[ 4822.51471401]]    Loss_Validation:  [[ 1420.78108749]]\n",
      "Loop  9958 :    Loss_Train:  [[ 4822.51471394]]    Loss_Validation:  [[ 1420.781111]]\n",
      "Loop  9959 :    Loss_Train:  [[ 4822.51471387]]    Loss_Validation:  [[ 1420.78113449]]\n",
      "Loop  9960 :    Loss_Train:  [[ 4822.5147138]]    Loss_Validation:  [[ 1420.78115797]]\n",
      "Loop  9961 :    Loss_Train:  [[ 4822.51471374]]    Loss_Validation:  [[ 1420.78118142]]\n",
      "Loop  9962 :    Loss_Train:  [[ 4822.51471367]]    Loss_Validation:  [[ 1420.78120486]]\n",
      "Loop  9963 :    Loss_Train:  [[ 4822.5147136]]    Loss_Validation:  [[ 1420.78122829]]\n",
      "Loop  9964 :    Loss_Train:  [[ 4822.51471353]]    Loss_Validation:  [[ 1420.78125169]]\n",
      "Loop  9965 :    Loss_Train:  [[ 4822.51471346]]    Loss_Validation:  [[ 1420.78127508]]\n",
      "Loop  9966 :    Loss_Train:  [[ 4822.51471339]]    Loss_Validation:  [[ 1420.78129846]]\n",
      "Loop  9967 :    Loss_Train:  [[ 4822.51471332]]    Loss_Validation:  [[ 1420.78132181]]\n",
      "Loop  9968 :    Loss_Train:  [[ 4822.51471325]]    Loss_Validation:  [[ 1420.78134515]]\n",
      "Loop  9969 :    Loss_Train:  [[ 4822.51471318]]    Loss_Validation:  [[ 1420.78136847]]\n",
      "Loop  9970 :    Loss_Train:  [[ 4822.51471312]]    Loss_Validation:  [[ 1420.78139178]]\n",
      "Loop  9971 :    Loss_Train:  [[ 4822.51471305]]    Loss_Validation:  [[ 1420.78141506]]\n",
      "Loop  9972 :    Loss_Train:  [[ 4822.51471298]]    Loss_Validation:  [[ 1420.78143834]]\n",
      "Loop  9973 :    Loss_Train:  [[ 4822.51471291]]    Loss_Validation:  [[ 1420.78146159]]\n",
      "Loop  9974 :    Loss_Train:  [[ 4822.51471284]]    Loss_Validation:  [[ 1420.78148483]]\n",
      "Loop  9975 :    Loss_Train:  [[ 4822.51471277]]    Loss_Validation:  [[ 1420.78150805]]\n",
      "Loop  9976 :    Loss_Train:  [[ 4822.51471271]]    Loss_Validation:  [[ 1420.78153125]]\n",
      "Loop  9977 :    Loss_Train:  [[ 4822.51471264]]    Loss_Validation:  [[ 1420.78155444]]\n",
      "Loop  9978 :    Loss_Train:  [[ 4822.51471257]]    Loss_Validation:  [[ 1420.78157761]]\n",
      "Loop  9979 :    Loss_Train:  [[ 4822.5147125]]    Loss_Validation:  [[ 1420.78160076]]\n",
      "Loop  9980 :    Loss_Train:  [[ 4822.51471244]]    Loss_Validation:  [[ 1420.7816239]]\n",
      "Loop  9981 :    Loss_Train:  [[ 4822.51471237]]    Loss_Validation:  [[ 1420.78164702]]\n",
      "Loop  9982 :    Loss_Train:  [[ 4822.5147123]]    Loss_Validation:  [[ 1420.78167012]]\n",
      "Loop  9983 :    Loss_Train:  [[ 4822.51471223]]    Loss_Validation:  [[ 1420.78169321]]\n",
      "Loop  9984 :    Loss_Train:  [[ 4822.51471217]]    Loss_Validation:  [[ 1420.78171628]]\n",
      "Loop  9985 :    Loss_Train:  [[ 4822.5147121]]    Loss_Validation:  [[ 1420.78173933]]\n",
      "Loop  9986 :    Loss_Train:  [[ 4822.51471203]]    Loss_Validation:  [[ 1420.78176237]]\n",
      "Loop  9987 :    Loss_Train:  [[ 4822.51471197]]    Loss_Validation:  [[ 1420.78178538]]\n",
      "Loop  9988 :    Loss_Train:  [[ 4822.5147119]]    Loss_Validation:  [[ 1420.78180839]]\n",
      "Loop  9989 :    Loss_Train:  [[ 4822.51471183]]    Loss_Validation:  [[ 1420.78183137]]\n",
      "Loop  9990 :    Loss_Train:  [[ 4822.51471177]]    Loss_Validation:  [[ 1420.78185434]]\n",
      "Loop  9991 :    Loss_Train:  [[ 4822.5147117]]    Loss_Validation:  [[ 1420.7818773]]\n",
      "Loop  9992 :    Loss_Train:  [[ 4822.51471164]]    Loss_Validation:  [[ 1420.78190023]]\n",
      "Loop  9993 :    Loss_Train:  [[ 4822.51471157]]    Loss_Validation:  [[ 1420.78192315]]\n",
      "Loop  9994 :    Loss_Train:  [[ 4822.5147115]]    Loss_Validation:  [[ 1420.78194605]]\n",
      "Loop  9995 :    Loss_Train:  [[ 4822.51471144]]    Loss_Validation:  [[ 1420.78196894]]\n",
      "Loop  9996 :    Loss_Train:  [[ 4822.51471137]]    Loss_Validation:  [[ 1420.78199181]]\n",
      "Loop  9997 :    Loss_Train:  [[ 4822.51471131]]    Loss_Validation:  [[ 1420.78201466]]\n",
      "Loop  9998 :    Loss_Train:  [[ 4822.51471124]]    Loss_Validation:  [[ 1420.7820375]]\n",
      "Loop  9999 :    Loss_Train:  [[ 4822.51471118]]    Loss_Validation:  [[ 1420.78206032]]\n",
      "Loop  10000 :    Loss_Train:  [[ 4822.51471111]]    Loss_Validation:  [[ 1420.78208312]]\n",
      "Loop  10001 :    Loss_Train:  [[ 4822.51471104]]    Loss_Validation:  [[ 1420.78210591]]\n",
      "Loop  10002 :    Loss_Train:  [[ 4822.51471098]]    Loss_Validation:  [[ 1420.78212868]]\n",
      "Loop  10003 :    Loss_Train:  [[ 4822.51471091]]    Loss_Validation:  [[ 1420.78215143]]\n",
      "Loop  10004 :    Loss_Train:  [[ 4822.51471085]]    Loss_Validation:  [[ 1420.78217417]]\n",
      "Loop  10005 :    Loss_Train:  [[ 4822.51471078]]    Loss_Validation:  [[ 1420.78219689]]\n",
      "Loop  10006 :    Loss_Train:  [[ 4822.51471072]]    Loss_Validation:  [[ 1420.7822196]]\n",
      "Loop  10007 :    Loss_Train:  [[ 4822.51471066]]    Loss_Validation:  [[ 1420.78224228]]\n",
      "Loop  10008 :    Loss_Train:  [[ 4822.51471059]]    Loss_Validation:  [[ 1420.78226496]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  10009 :    Loss_Train:  [[ 4822.51471053]]    Loss_Validation:  [[ 1420.78228761]]\n",
      "Loop  10010 :    Loss_Train:  [[ 4822.51471046]]    Loss_Validation:  [[ 1420.78231025]]\n",
      "Loop  10011 :    Loss_Train:  [[ 4822.5147104]]    Loss_Validation:  [[ 1420.78233287]]\n",
      "Loop  10012 :    Loss_Train:  [[ 4822.51471033]]    Loss_Validation:  [[ 1420.78235548]]\n",
      "Loop  10013 :    Loss_Train:  [[ 4822.51471027]]    Loss_Validation:  [[ 1420.78237807]]\n",
      "Loop  10014 :    Loss_Train:  [[ 4822.51471021]]    Loss_Validation:  [[ 1420.78240064]]\n",
      "Loop  10015 :    Loss_Train:  [[ 4822.51471014]]    Loss_Validation:  [[ 1420.7824232]]\n",
      "Loop  10016 :    Loss_Train:  [[ 4822.51471008]]    Loss_Validation:  [[ 1420.78244574]]\n",
      "Loop  10017 :    Loss_Train:  [[ 4822.51471001]]    Loss_Validation:  [[ 1420.78246826]]\n",
      "Loop  10018 :    Loss_Train:  [[ 4822.51470995]]    Loss_Validation:  [[ 1420.78249077]]\n",
      "Loop  10019 :    Loss_Train:  [[ 4822.51470989]]    Loss_Validation:  [[ 1420.78251326]]\n",
      "Loop  10020 :    Loss_Train:  [[ 4822.51470982]]    Loss_Validation:  [[ 1420.78253573]]\n",
      "Loop  10021 :    Loss_Train:  [[ 4822.51470976]]    Loss_Validation:  [[ 1420.78255819]]\n",
      "Loop  10022 :    Loss_Train:  [[ 4822.5147097]]    Loss_Validation:  [[ 1420.78258064]]\n",
      "Loop  10023 :    Loss_Train:  [[ 4822.51470963]]    Loss_Validation:  [[ 1420.78260306]]\n",
      "Loop  10024 :    Loss_Train:  [[ 4822.51470957]]    Loss_Validation:  [[ 1420.78262547]]\n",
      "Loop  10025 :    Loss_Train:  [[ 4822.51470951]]    Loss_Validation:  [[ 1420.78264787]]\n",
      "Loop  10026 :    Loss_Train:  [[ 4822.51470945]]    Loss_Validation:  [[ 1420.78267024]]\n",
      "Loop  10027 :    Loss_Train:  [[ 4822.51470938]]    Loss_Validation:  [[ 1420.7826926]]\n",
      "Loop  10028 :    Loss_Train:  [[ 4822.51470932]]    Loss_Validation:  [[ 1420.78271495]]\n",
      "Loop  10029 :    Loss_Train:  [[ 4822.51470926]]    Loss_Validation:  [[ 1420.78273728]]\n",
      "Loop  10030 :    Loss_Train:  [[ 4822.5147092]]    Loss_Validation:  [[ 1420.78275959]]\n",
      "Loop  10031 :    Loss_Train:  [[ 4822.51470913]]    Loss_Validation:  [[ 1420.78278189]]\n",
      "Loop  10032 :    Loss_Train:  [[ 4822.51470907]]    Loss_Validation:  [[ 1420.78280417]]\n",
      "Loop  10033 :    Loss_Train:  [[ 4822.51470901]]    Loss_Validation:  [[ 1420.78282643]]\n",
      "Loop  10034 :    Loss_Train:  [[ 4822.51470895]]    Loss_Validation:  [[ 1420.78284868]]\n",
      "Loop  10035 :    Loss_Train:  [[ 4822.51470889]]    Loss_Validation:  [[ 1420.78287091]]\n",
      "Loop  10036 :    Loss_Train:  [[ 4822.51470882]]    Loss_Validation:  [[ 1420.78289313]]\n",
      "Loop  10037 :    Loss_Train:  [[ 4822.51470876]]    Loss_Validation:  [[ 1420.78291533]]\n",
      "Loop  10038 :    Loss_Train:  [[ 4822.5147087]]    Loss_Validation:  [[ 1420.78293751]]\n",
      "Loop  10039 :    Loss_Train:  [[ 4822.51470864]]    Loss_Validation:  [[ 1420.78295968]]\n",
      "Loop  10040 :    Loss_Train:  [[ 4822.51470858]]    Loss_Validation:  [[ 1420.78298183]]\n",
      "Loop  10041 :    Loss_Train:  [[ 4822.51470852]]    Loss_Validation:  [[ 1420.78300396]]\n",
      "Loop  10042 :    Loss_Train:  [[ 4822.51470846]]    Loss_Validation:  [[ 1420.78302608]]\n",
      "Loop  10043 :    Loss_Train:  [[ 4822.51470839]]    Loss_Validation:  [[ 1420.78304819]]\n",
      "Loop  10044 :    Loss_Train:  [[ 4822.51470833]]    Loss_Validation:  [[ 1420.78307027]]\n",
      "Loop  10045 :    Loss_Train:  [[ 4822.51470827]]    Loss_Validation:  [[ 1420.78309235]]\n",
      "Loop  10046 :    Loss_Train:  [[ 4822.51470821]]    Loss_Validation:  [[ 1420.7831144]]\n",
      "Loop  10047 :    Loss_Train:  [[ 4822.51470815]]    Loss_Validation:  [[ 1420.78313644]]\n",
      "Loop  10048 :    Loss_Train:  [[ 4822.51470809]]    Loss_Validation:  [[ 1420.78315846]]\n",
      "Loop  10049 :    Loss_Train:  [[ 4822.51470803]]    Loss_Validation:  [[ 1420.78318047]]\n",
      "Loop  10050 :    Loss_Train:  [[ 4822.51470797]]    Loss_Validation:  [[ 1420.78320246]]\n",
      "Loop  10051 :    Loss_Train:  [[ 4822.51470791]]    Loss_Validation:  [[ 1420.78322444]]\n",
      "Loop  10052 :    Loss_Train:  [[ 4822.51470785]]    Loss_Validation:  [[ 1420.7832464]]\n",
      "Loop  10053 :    Loss_Train:  [[ 4822.51470779]]    Loss_Validation:  [[ 1420.78326834]]\n",
      "Loop  10054 :    Loss_Train:  [[ 4822.51470773]]    Loss_Validation:  [[ 1420.78329027]]\n",
      "Loop  10055 :    Loss_Train:  [[ 4822.51470767]]    Loss_Validation:  [[ 1420.78331218]]\n",
      "Loop  10056 :    Loss_Train:  [[ 4822.51470761]]    Loss_Validation:  [[ 1420.78333407]]\n",
      "Loop  10057 :    Loss_Train:  [[ 4822.51470755]]    Loss_Validation:  [[ 1420.78335595]]\n",
      "Loop  10058 :    Loss_Train:  [[ 4822.51470749]]    Loss_Validation:  [[ 1420.78337782]]\n",
      "Loop  10059 :    Loss_Train:  [[ 4822.51470743]]    Loss_Validation:  [[ 1420.78339967]]\n",
      "Loop  10060 :    Loss_Train:  [[ 4822.51470737]]    Loss_Validation:  [[ 1420.7834215]]\n",
      "Loop  10061 :    Loss_Train:  [[ 4822.51470731]]    Loss_Validation:  [[ 1420.78344332]]\n",
      "Loop  10062 :    Loss_Train:  [[ 4822.51470725]]    Loss_Validation:  [[ 1420.78346512]]\n",
      "Loop  10063 :    Loss_Train:  [[ 4822.51470719]]    Loss_Validation:  [[ 1420.7834869]]\n",
      "Loop  10064 :    Loss_Train:  [[ 4822.51470713]]    Loss_Validation:  [[ 1420.78350867]]\n",
      "Loop  10065 :    Loss_Train:  [[ 4822.51470707]]    Loss_Validation:  [[ 1420.78353042]]\n",
      "Loop  10066 :    Loss_Train:  [[ 4822.51470701]]    Loss_Validation:  [[ 1420.78355216]]\n",
      "Loop  10067 :    Loss_Train:  [[ 4822.51470696]]    Loss_Validation:  [[ 1420.78357388]]\n",
      "Loop  10068 :    Loss_Train:  [[ 4822.5147069]]    Loss_Validation:  [[ 1420.78359559]]\n",
      "Loop  10069 :    Loss_Train:  [[ 4822.51470684]]    Loss_Validation:  [[ 1420.78361728]]\n",
      "Loop  10070 :    Loss_Train:  [[ 4822.51470678]]    Loss_Validation:  [[ 1420.78363895]]\n",
      "Loop  10071 :    Loss_Train:  [[ 4822.51470672]]    Loss_Validation:  [[ 1420.78366061]]\n",
      "Loop  10072 :    Loss_Train:  [[ 4822.51470666]]    Loss_Validation:  [[ 1420.78368226]]\n",
      "Loop  10073 :    Loss_Train:  [[ 4822.5147066]]    Loss_Validation:  [[ 1420.78370388]]\n",
      "Loop  10074 :    Loss_Train:  [[ 4822.51470655]]    Loss_Validation:  [[ 1420.78372549]]\n",
      "Loop  10075 :    Loss_Train:  [[ 4822.51470649]]    Loss_Validation:  [[ 1420.78374709]]\n",
      "Loop  10076 :    Loss_Train:  [[ 4822.51470643]]    Loss_Validation:  [[ 1420.78376867]]\n",
      "Loop  10077 :    Loss_Train:  [[ 4822.51470637]]    Loss_Validation:  [[ 1420.78379024]]\n",
      "Loop  10078 :    Loss_Train:  [[ 4822.51470631]]    Loss_Validation:  [[ 1420.78381178]]\n",
      "Loop  10079 :    Loss_Train:  [[ 4822.51470626]]    Loss_Validation:  [[ 1420.78383332]]\n",
      "Loop  10080 :    Loss_Train:  [[ 4822.5147062]]    Loss_Validation:  [[ 1420.78385484]]\n",
      "Loop  10081 :    Loss_Train:  [[ 4822.51470614]]    Loss_Validation:  [[ 1420.78387634]]\n",
      "Loop  10082 :    Loss_Train:  [[ 4822.51470608]]    Loss_Validation:  [[ 1420.78389782]]\n",
      "Loop  10083 :    Loss_Train:  [[ 4822.51470603]]    Loss_Validation:  [[ 1420.7839193]]\n",
      "Loop  10084 :    Loss_Train:  [[ 4822.51470597]]    Loss_Validation:  [[ 1420.78394075]]\n",
      "Loop  10085 :    Loss_Train:  [[ 4822.51470591]]    Loss_Validation:  [[ 1420.78396219]]\n",
      "Loop  10086 :    Loss_Train:  [[ 4822.51470585]]    Loss_Validation:  [[ 1420.78398362]]\n",
      "Loop  10087 :    Loss_Train:  [[ 4822.5147058]]    Loss_Validation:  [[ 1420.78400502]]\n",
      "Loop  10088 :    Loss_Train:  [[ 4822.51470574]]    Loss_Validation:  [[ 1420.78402642]]\n",
      "Loop  10089 :    Loss_Train:  [[ 4822.51470568]]    Loss_Validation:  [[ 1420.7840478]]\n",
      "Loop  10090 :    Loss_Train:  [[ 4822.51470563]]    Loss_Validation:  [[ 1420.78406916]]\n",
      "Loop  10091 :    Loss_Train:  [[ 4822.51470557]]    Loss_Validation:  [[ 1420.7840905]]\n",
      "Loop  10092 :    Loss_Train:  [[ 4822.51470551]]    Loss_Validation:  [[ 1420.78411184]]\n",
      "Loop  10093 :    Loss_Train:  [[ 4822.51470546]]    Loss_Validation:  [[ 1420.78413315]]\n",
      "Loop  10094 :    Loss_Train:  [[ 4822.5147054]]    Loss_Validation:  [[ 1420.78415445]]\n",
      "Loop  10095 :    Loss_Train:  [[ 4822.51470534]]    Loss_Validation:  [[ 1420.78417574]]\n",
      "Loop  10096 :    Loss_Train:  [[ 4822.51470529]]    Loss_Validation:  [[ 1420.78419701]]\n",
      "Loop  10097 :    Loss_Train:  [[ 4822.51470523]]    Loss_Validation:  [[ 1420.78421826]]\n",
      "Loop  10098 :    Loss_Train:  [[ 4822.51470517]]    Loss_Validation:  [[ 1420.7842395]]\n",
      "Loop  10099 :    Loss_Train:  [[ 4822.51470512]]    Loss_Validation:  [[ 1420.78426072]]\n",
      "Loop  10100 :    Loss_Train:  [[ 4822.51470506]]    Loss_Validation:  [[ 1420.78428193]]\n",
      "Loop  10101 :    Loss_Train:  [[ 4822.51470501]]    Loss_Validation:  [[ 1420.78430312]]\n",
      "Loop  10102 :    Loss_Train:  [[ 4822.51470495]]    Loss_Validation:  [[ 1420.7843243]]\n",
      "Loop  10103 :    Loss_Train:  [[ 4822.5147049]]    Loss_Validation:  [[ 1420.78434546]]\n",
      "Loop  10104 :    Loss_Train:  [[ 4822.51470484]]    Loss_Validation:  [[ 1420.78436661]]\n",
      "Loop  10105 :    Loss_Train:  [[ 4822.51470478]]    Loss_Validation:  [[ 1420.78438774]]\n",
      "Loop  10106 :    Loss_Train:  [[ 4822.51470473]]    Loss_Validation:  [[ 1420.78440885]]\n",
      "Loop  10107 :    Loss_Train:  [[ 4822.51470467]]    Loss_Validation:  [[ 1420.78442995]]\n",
      "Loop  10108 :    Loss_Train:  [[ 4822.51470462]]    Loss_Validation:  [[ 1420.78445104]]\n",
      "Loop  10109 :    Loss_Train:  [[ 4822.51470456]]    Loss_Validation:  [[ 1420.78447211]]\n",
      "Loop  10110 :    Loss_Train:  [[ 4822.51470451]]    Loss_Validation:  [[ 1420.78449316]]\n",
      "Loop  10111 :    Loss_Train:  [[ 4822.51470445]]    Loss_Validation:  [[ 1420.7845142]]\n",
      "Loop  10112 :    Loss_Train:  [[ 4822.5147044]]    Loss_Validation:  [[ 1420.78453523]]\n",
      "Loop  10113 :    Loss_Train:  [[ 4822.51470434]]    Loss_Validation:  [[ 1420.78455624]]\n",
      "Loop  10114 :    Loss_Train:  [[ 4822.51470429]]    Loss_Validation:  [[ 1420.78457723]]\n",
      "Loop  10115 :    Loss_Train:  [[ 4822.51470423]]    Loss_Validation:  [[ 1420.78459821]]\n",
      "Loop  10116 :    Loss_Train:  [[ 4822.51470418]]    Loss_Validation:  [[ 1420.78461917]]\n",
      "Loop  10117 :    Loss_Train:  [[ 4822.51470412]]    Loss_Validation:  [[ 1420.78464012]]\n",
      "Loop  10118 :    Loss_Train:  [[ 4822.51470407]]    Loss_Validation:  [[ 1420.78466105]]\n",
      "Loop  10119 :    Loss_Train:  [[ 4822.51470402]]    Loss_Validation:  [[ 1420.78468197]]\n",
      "Loop  10120 :    Loss_Train:  [[ 4822.51470396]]    Loss_Validation:  [[ 1420.78470287]]\n",
      "Loop  10121 :    Loss_Train:  [[ 4822.51470391]]    Loss_Validation:  [[ 1420.78472376]]\n",
      "Loop  10122 :    Loss_Train:  [[ 4822.51470385]]    Loss_Validation:  [[ 1420.78474463]]\n",
      "Loop  10123 :    Loss_Train:  [[ 4822.5147038]]    Loss_Validation:  [[ 1420.78476549]]\n",
      "Loop  10124 :    Loss_Train:  [[ 4822.51470375]]    Loss_Validation:  [[ 1420.78478633]]\n",
      "Loop  10125 :    Loss_Train:  [[ 4822.51470369]]    Loss_Validation:  [[ 1420.78480716]]\n",
      "Loop  10126 :    Loss_Train:  [[ 4822.51470364]]    Loss_Validation:  [[ 1420.78482797]]\n",
      "Loop  10127 :    Loss_Train:  [[ 4822.51470358]]    Loss_Validation:  [[ 1420.78484876]]\n",
      "Loop  10128 :    Loss_Train:  [[ 4822.51470353]]    Loss_Validation:  [[ 1420.78486954]]\n",
      "Loop  10129 :    Loss_Train:  [[ 4822.51470348]]    Loss_Validation:  [[ 1420.78489031]]\n",
      "Loop  10130 :    Loss_Train:  [[ 4822.51470342]]    Loss_Validation:  [[ 1420.78491106]]\n",
      "Loop  10131 :    Loss_Train:  [[ 4822.51470337]]    Loss_Validation:  [[ 1420.7849318]]\n",
      "Loop  10132 :    Loss_Train:  [[ 4822.51470332]]    Loss_Validation:  [[ 1420.78495252]]\n",
      "Loop  10133 :    Loss_Train:  [[ 4822.51470326]]    Loss_Validation:  [[ 1420.78497322]]\n",
      "Loop  10134 :    Loss_Train:  [[ 4822.51470321]]    Loss_Validation:  [[ 1420.78499392]]\n",
      "Loop  10135 :    Loss_Train:  [[ 4822.51470316]]    Loss_Validation:  [[ 1420.78501459]]\n",
      "Loop  10136 :    Loss_Train:  [[ 4822.51470311]]    Loss_Validation:  [[ 1420.78503525]]\n",
      "Loop  10137 :    Loss_Train:  [[ 4822.51470305]]    Loss_Validation:  [[ 1420.7850559]]\n",
      "Loop  10138 :    Loss_Train:  [[ 4822.514703]]    Loss_Validation:  [[ 1420.78507653]]\n",
      "Loop  10139 :    Loss_Train:  [[ 4822.51470295]]    Loss_Validation:  [[ 1420.78509715]]\n",
      "Loop  10140 :    Loss_Train:  [[ 4822.51470289]]    Loss_Validation:  [[ 1420.78511775]]\n",
      "Loop  10141 :    Loss_Train:  [[ 4822.51470284]]    Loss_Validation:  [[ 1420.78513833]]\n",
      "Loop  10142 :    Loss_Train:  [[ 4822.51470279]]    Loss_Validation:  [[ 1420.7851589]]\n",
      "Loop  10143 :    Loss_Train:  [[ 4822.51470274]]    Loss_Validation:  [[ 1420.78517946]]\n",
      "Loop  10144 :    Loss_Train:  [[ 4822.51470269]]    Loss_Validation:  [[ 1420.7852]]\n",
      "Loop  10145 :    Loss_Train:  [[ 4822.51470263]]    Loss_Validation:  [[ 1420.78522053]]\n",
      "Loop  10146 :    Loss_Train:  [[ 4822.51470258]]    Loss_Validation:  [[ 1420.78524104]]\n",
      "Loop  10147 :    Loss_Train:  [[ 4822.51470253]]    Loss_Validation:  [[ 1420.78526154]]\n",
      "Loop  10148 :    Loss_Train:  [[ 4822.51470248]]    Loss_Validation:  [[ 1420.78528202]]\n",
      "Loop  10149 :    Loss_Train:  [[ 4822.51470243]]    Loss_Validation:  [[ 1420.78530248]]\n",
      "Loop  10150 :    Loss_Train:  [[ 4822.51470237]]    Loss_Validation:  [[ 1420.78532294]]\n",
      "Loop  10151 :    Loss_Train:  [[ 4822.51470232]]    Loss_Validation:  [[ 1420.78534337]]\n",
      "Loop  10152 :    Loss_Train:  [[ 4822.51470227]]    Loss_Validation:  [[ 1420.7853638]]\n",
      "Loop  10153 :    Loss_Train:  [[ 4822.51470222]]    Loss_Validation:  [[ 1420.7853842]]\n",
      "Loop  10154 :    Loss_Train:  [[ 4822.51470217]]    Loss_Validation:  [[ 1420.7854046]]\n",
      "Loop  10155 :    Loss_Train:  [[ 4822.51470212]]    Loss_Validation:  [[ 1420.78542497]]\n",
      "Loop  10156 :    Loss_Train:  [[ 4822.51470206]]    Loss_Validation:  [[ 1420.78544534]]\n",
      "Loop  10157 :    Loss_Train:  [[ 4822.51470201]]    Loss_Validation:  [[ 1420.78546569]]\n",
      "Loop  10158 :    Loss_Train:  [[ 4822.51470196]]    Loss_Validation:  [[ 1420.78548602]]\n",
      "Loop  10159 :    Loss_Train:  [[ 4822.51470191]]    Loss_Validation:  [[ 1420.78550634]]\n",
      "Loop  10160 :    Loss_Train:  [[ 4822.51470186]]    Loss_Validation:  [[ 1420.78552664]]\n",
      "Loop  10161 :    Loss_Train:  [[ 4822.51470181]]    Loss_Validation:  [[ 1420.78554693]]\n",
      "Loop  10162 :    Loss_Train:  [[ 4822.51470176]]    Loss_Validation:  [[ 1420.78556721]]\n",
      "Loop  10163 :    Loss_Train:  [[ 4822.51470171]]    Loss_Validation:  [[ 1420.78558747]]\n",
      "Loop  10164 :    Loss_Train:  [[ 4822.51470166]]    Loss_Validation:  [[ 1420.78560771]]\n",
      "Loop  10165 :    Loss_Train:  [[ 4822.51470161]]    Loss_Validation:  [[ 1420.78562794]]\n",
      "Loop  10166 :    Loss_Train:  [[ 4822.51470156]]    Loss_Validation:  [[ 1420.78564816]]\n",
      "Loop  10167 :    Loss_Train:  [[ 4822.51470151]]    Loss_Validation:  [[ 1420.78566836]]\n",
      "Loop  10168 :    Loss_Train:  [[ 4822.51470146]]    Loss_Validation:  [[ 1420.78568855]]\n",
      "Loop  10169 :    Loss_Train:  [[ 4822.51470141]]    Loss_Validation:  [[ 1420.78570872]]\n",
      "Loop  10170 :    Loss_Train:  [[ 4822.51470136]]    Loss_Validation:  [[ 1420.78572888]]\n",
      "Loop  10171 :    Loss_Train:  [[ 4822.5147013]]    Loss_Validation:  [[ 1420.78574902]]\n",
      "Loop  10172 :    Loss_Train:  [[ 4822.51470125]]    Loss_Validation:  [[ 1420.78576915]]\n",
      "Loop  10173 :    Loss_Train:  [[ 4822.5147012]]    Loss_Validation:  [[ 1420.78578926]]\n",
      "Loop  10174 :    Loss_Train:  [[ 4822.51470116]]    Loss_Validation:  [[ 1420.78580936]]\n",
      "Loop  10175 :    Loss_Train:  [[ 4822.51470111]]    Loss_Validation:  [[ 1420.78582944]]\n",
      "Loop  10176 :    Loss_Train:  [[ 4822.51470106]]    Loss_Validation:  [[ 1420.78584951]]\n",
      "Loop  10177 :    Loss_Train:  [[ 4822.51470101]]    Loss_Validation:  [[ 1420.78586957]]\n",
      "Loop  10178 :    Loss_Train:  [[ 4822.51470096]]    Loss_Validation:  [[ 1420.78588961]]\n",
      "Loop  10179 :    Loss_Train:  [[ 4822.51470091]]    Loss_Validation:  [[ 1420.78590963]]\n",
      "Loop  10180 :    Loss_Train:  [[ 4822.51470086]]    Loss_Validation:  [[ 1420.78592965]]\n",
      "Loop  10181 :    Loss_Train:  [[ 4822.51470081]]    Loss_Validation:  [[ 1420.78594964]]\n",
      "Loop  10182 :    Loss_Train:  [[ 4822.51470076]]    Loss_Validation:  [[ 1420.78596963]]\n",
      "Loop  10183 :    Loss_Train:  [[ 4822.51470071]]    Loss_Validation:  [[ 1420.78598959]]\n",
      "Loop  10184 :    Loss_Train:  [[ 4822.51470066]]    Loss_Validation:  [[ 1420.78600955]]\n",
      "Loop  10185 :    Loss_Train:  [[ 4822.51470061]]    Loss_Validation:  [[ 1420.78602949]]\n",
      "Loop  10186 :    Loss_Train:  [[ 4822.51470056]]    Loss_Validation:  [[ 1420.78604941]]\n",
      "Loop  10187 :    Loss_Train:  [[ 4822.51470051]]    Loss_Validation:  [[ 1420.78606932]]\n",
      "Loop  10188 :    Loss_Train:  [[ 4822.51470047]]    Loss_Validation:  [[ 1420.78608922]]\n",
      "Loop  10189 :    Loss_Train:  [[ 4822.51470042]]    Loss_Validation:  [[ 1420.7861091]]\n",
      "Loop  10190 :    Loss_Train:  [[ 4822.51470037]]    Loss_Validation:  [[ 1420.78612896]]\n",
      "Loop  10191 :    Loss_Train:  [[ 4822.51470032]]    Loss_Validation:  [[ 1420.78614882]]\n",
      "Loop  10192 :    Loss_Train:  [[ 4822.51470027]]    Loss_Validation:  [[ 1420.78616865]]\n",
      "Loop  10193 :    Loss_Train:  [[ 4822.51470022]]    Loss_Validation:  [[ 1420.78618848]]\n",
      "Loop  10194 :    Loss_Train:  [[ 4822.51470017]]    Loss_Validation:  [[ 1420.78620829]]\n",
      "Loop  10195 :    Loss_Train:  [[ 4822.51470013]]    Loss_Validation:  [[ 1420.78622808]]\n",
      "Loop  10196 :    Loss_Train:  [[ 4822.51470008]]    Loss_Validation:  [[ 1420.78624786]]\n",
      "Loop  10197 :    Loss_Train:  [[ 4822.51470003]]    Loss_Validation:  [[ 1420.78626763]]\n",
      "Loop  10198 :    Loss_Train:  [[ 4822.51469998]]    Loss_Validation:  [[ 1420.78628738]]\n",
      "Loop  10199 :    Loss_Train:  [[ 4822.51469993]]    Loss_Validation:  [[ 1420.78630712]]\n",
      "Loop  10200 :    Loss_Train:  [[ 4822.51469989]]    Loss_Validation:  [[ 1420.78632684]]\n",
      "Loop  10201 :    Loss_Train:  [[ 4822.51469984]]    Loss_Validation:  [[ 1420.78634655]]\n",
      "Loop  10202 :    Loss_Train:  [[ 4822.51469979]]    Loss_Validation:  [[ 1420.78636624]]\n",
      "Loop  10203 :    Loss_Train:  [[ 4822.51469974]]    Loss_Validation:  [[ 1420.78638592]]\n",
      "Loop  10204 :    Loss_Train:  [[ 4822.51469969]]    Loss_Validation:  [[ 1420.78640559]]\n",
      "Loop  10205 :    Loss_Train:  [[ 4822.51469965]]    Loss_Validation:  [[ 1420.78642524]]\n",
      "Loop  10206 :    Loss_Train:  [[ 4822.5146996]]    Loss_Validation:  [[ 1420.78644488]]\n",
      "Loop  10207 :    Loss_Train:  [[ 4822.51469955]]    Loss_Validation:  [[ 1420.7864645]]\n",
      "Loop  10208 :    Loss_Train:  [[ 4822.51469951]]    Loss_Validation:  [[ 1420.78648411]]\n",
      "Loop  10209 :    Loss_Train:  [[ 4822.51469946]]    Loss_Validation:  [[ 1420.7865037]]\n",
      "Loop  10210 :    Loss_Train:  [[ 4822.51469941]]    Loss_Validation:  [[ 1420.78652328]]\n",
      "Loop  10211 :    Loss_Train:  [[ 4822.51469936]]    Loss_Validation:  [[ 1420.78654285]]\n",
      "Loop  10212 :    Loss_Train:  [[ 4822.51469932]]    Loss_Validation:  [[ 1420.7865624]]\n",
      "Loop  10213 :    Loss_Train:  [[ 4822.51469927]]    Loss_Validation:  [[ 1420.78658194]]\n",
      "Loop  10214 :    Loss_Train:  [[ 4822.51469922]]    Loss_Validation:  [[ 1420.78660146]]\n",
      "Loop  10215 :    Loss_Train:  [[ 4822.51469918]]    Loss_Validation:  [[ 1420.78662097]]\n",
      "Loop  10216 :    Loss_Train:  [[ 4822.51469913]]    Loss_Validation:  [[ 1420.78664047]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  10217 :    Loss_Train:  [[ 4822.51469908]]    Loss_Validation:  [[ 1420.78665995]]\n",
      "Loop  10218 :    Loss_Train:  [[ 4822.51469904]]    Loss_Validation:  [[ 1420.78667942]]\n",
      "Loop  10219 :    Loss_Train:  [[ 4822.51469899]]    Loss_Validation:  [[ 1420.78669887]]\n",
      "Loop  10220 :    Loss_Train:  [[ 4822.51469894]]    Loss_Validation:  [[ 1420.78671831]]\n",
      "Loop  10221 :    Loss_Train:  [[ 4822.5146989]]    Loss_Validation:  [[ 1420.78673773]]\n",
      "Loop  10222 :    Loss_Train:  [[ 4822.51469885]]    Loss_Validation:  [[ 1420.78675714]]\n",
      "Loop  10223 :    Loss_Train:  [[ 4822.5146988]]    Loss_Validation:  [[ 1420.78677654]]\n",
      "Loop  10224 :    Loss_Train:  [[ 4822.51469876]]    Loss_Validation:  [[ 1420.78679592]]\n",
      "Loop  10225 :    Loss_Train:  [[ 4822.51469871]]    Loss_Validation:  [[ 1420.78681529]]\n",
      "Loop  10226 :    Loss_Train:  [[ 4822.51469867]]    Loss_Validation:  [[ 1420.78683464]]\n",
      "Loop  10227 :    Loss_Train:  [[ 4822.51469862]]    Loss_Validation:  [[ 1420.78685398]]\n",
      "Loop  10228 :    Loss_Train:  [[ 4822.51469857]]    Loss_Validation:  [[ 1420.78687331]]\n",
      "Loop  10229 :    Loss_Train:  [[ 4822.51469853]]    Loss_Validation:  [[ 1420.78689262]]\n",
      "Loop  10230 :    Loss_Train:  [[ 4822.51469848]]    Loss_Validation:  [[ 1420.78691192]]\n",
      "Loop  10231 :    Loss_Train:  [[ 4822.51469844]]    Loss_Validation:  [[ 1420.7869312]]\n",
      "Loop  10232 :    Loss_Train:  [[ 4822.51469839]]    Loss_Validation:  [[ 1420.78695047]]\n",
      "Loop  10233 :    Loss_Train:  [[ 4822.51469835]]    Loss_Validation:  [[ 1420.78696973]]\n",
      "Loop  10234 :    Loss_Train:  [[ 4822.5146983]]    Loss_Validation:  [[ 1420.78698897]]\n",
      "Loop  10235 :    Loss_Train:  [[ 4822.51469826]]    Loss_Validation:  [[ 1420.7870082]]\n",
      "Loop  10236 :    Loss_Train:  [[ 4822.51469821]]    Loss_Validation:  [[ 1420.78702741]]\n",
      "Loop  10237 :    Loss_Train:  [[ 4822.51469816]]    Loss_Validation:  [[ 1420.78704661]]\n",
      "Loop  10238 :    Loss_Train:  [[ 4822.51469812]]    Loss_Validation:  [[ 1420.7870658]]\n",
      "Loop  10239 :    Loss_Train:  [[ 4822.51469807]]    Loss_Validation:  [[ 1420.78708497]]\n",
      "Loop  10240 :    Loss_Train:  [[ 4822.51469803]]    Loss_Validation:  [[ 1420.78710413]]\n",
      "Loop  10241 :    Loss_Train:  [[ 4822.51469798]]    Loss_Validation:  [[ 1420.78712328]]\n",
      "Loop  10242 :    Loss_Train:  [[ 4822.51469794]]    Loss_Validation:  [[ 1420.78714241]]\n",
      "Loop  10243 :    Loss_Train:  [[ 4822.5146979]]    Loss_Validation:  [[ 1420.78716152]]\n",
      "Loop  10244 :    Loss_Train:  [[ 4822.51469785]]    Loss_Validation:  [[ 1420.78718063]]\n",
      "Loop  10245 :    Loss_Train:  [[ 4822.51469781]]    Loss_Validation:  [[ 1420.78719971]]\n",
      "Loop  10246 :    Loss_Train:  [[ 4822.51469776]]    Loss_Validation:  [[ 1420.78721879]]\n",
      "Loop  10247 :    Loss_Train:  [[ 4822.51469772]]    Loss_Validation:  [[ 1420.78723785]]\n",
      "Loop  10248 :    Loss_Train:  [[ 4822.51469767]]    Loss_Validation:  [[ 1420.7872569]]\n",
      "Loop  10249 :    Loss_Train:  [[ 4822.51469763]]    Loss_Validation:  [[ 1420.78727593]]\n",
      "Loop  10250 :    Loss_Train:  [[ 4822.51469758]]    Loss_Validation:  [[ 1420.78729495]]\n",
      "Loop  10251 :    Loss_Train:  [[ 4822.51469754]]    Loss_Validation:  [[ 1420.78731396]]\n",
      "Loop  10252 :    Loss_Train:  [[ 4822.5146975]]    Loss_Validation:  [[ 1420.78733295]]\n",
      "Loop  10253 :    Loss_Train:  [[ 4822.51469745]]    Loss_Validation:  [[ 1420.78735193]]\n",
      "Loop  10254 :    Loss_Train:  [[ 4822.51469741]]    Loss_Validation:  [[ 1420.78737089]]\n",
      "Loop  10255 :    Loss_Train:  [[ 4822.51469736]]    Loss_Validation:  [[ 1420.78738984]]\n",
      "Loop  10256 :    Loss_Train:  [[ 4822.51469732]]    Loss_Validation:  [[ 1420.78740878]]\n",
      "Loop  10257 :    Loss_Train:  [[ 4822.51469728]]    Loss_Validation:  [[ 1420.7874277]]\n",
      "Loop  10258 :    Loss_Train:  [[ 4822.51469723]]    Loss_Validation:  [[ 1420.78744661]]\n",
      "Loop  10259 :    Loss_Train:  [[ 4822.51469719]]    Loss_Validation:  [[ 1420.78746551]]\n",
      "Loop  10260 :    Loss_Train:  [[ 4822.51469714]]    Loss_Validation:  [[ 1420.78748439]]\n",
      "Loop  10261 :    Loss_Train:  [[ 4822.5146971]]    Loss_Validation:  [[ 1420.78750326]]\n",
      "Loop  10262 :    Loss_Train:  [[ 4822.51469706]]    Loss_Validation:  [[ 1420.78752211]]\n",
      "Loop  10263 :    Loss_Train:  [[ 4822.51469701]]    Loss_Validation:  [[ 1420.78754095]]\n",
      "Loop  10264 :    Loss_Train:  [[ 4822.51469697]]    Loss_Validation:  [[ 1420.78755978]]\n",
      "Loop  10265 :    Loss_Train:  [[ 4822.51469693]]    Loss_Validation:  [[ 1420.7875786]]\n",
      "Loop  10266 :    Loss_Train:  [[ 4822.51469688]]    Loss_Validation:  [[ 1420.7875974]]\n",
      "Loop  10267 :    Loss_Train:  [[ 4822.51469684]]    Loss_Validation:  [[ 1420.78761618]]\n",
      "Loop  10268 :    Loss_Train:  [[ 4822.5146968]]    Loss_Validation:  [[ 1420.78763495]]\n",
      "Loop  10269 :    Loss_Train:  [[ 4822.51469675]]    Loss_Validation:  [[ 1420.78765371]]\n",
      "Loop  10270 :    Loss_Train:  [[ 4822.51469671]]    Loss_Validation:  [[ 1420.78767246]]\n",
      "Loop  10271 :    Loss_Train:  [[ 4822.51469667]]    Loss_Validation:  [[ 1420.78769119]]\n",
      "Loop  10272 :    Loss_Train:  [[ 4822.51469663]]    Loss_Validation:  [[ 1420.78770991]]\n",
      "Loop  10273 :    Loss_Train:  [[ 4822.51469658]]    Loss_Validation:  [[ 1420.78772861]]\n",
      "Loop  10274 :    Loss_Train:  [[ 4822.51469654]]    Loss_Validation:  [[ 1420.7877473]]\n",
      "Loop  10275 :    Loss_Train:  [[ 4822.5146965]]    Loss_Validation:  [[ 1420.78776598]]\n",
      "Loop  10276 :    Loss_Train:  [[ 4822.51469646]]    Loss_Validation:  [[ 1420.78778465]]\n",
      "Loop  10277 :    Loss_Train:  [[ 4822.51469641]]    Loss_Validation:  [[ 1420.7878033]]\n",
      "Loop  10278 :    Loss_Train:  [[ 4822.51469637]]    Loss_Validation:  [[ 1420.78782193]]\n",
      "Loop  10279 :    Loss_Train:  [[ 4822.51469633]]    Loss_Validation:  [[ 1420.78784056]]\n",
      "Loop  10280 :    Loss_Train:  [[ 4822.51469629]]    Loss_Validation:  [[ 1420.78785917]]\n",
      "Loop  10281 :    Loss_Train:  [[ 4822.51469624]]    Loss_Validation:  [[ 1420.78787776]]\n",
      "Loop  10282 :    Loss_Train:  [[ 4822.5146962]]    Loss_Validation:  [[ 1420.78789634]]\n",
      "Loop  10283 :    Loss_Train:  [[ 4822.51469616]]    Loss_Validation:  [[ 1420.78791491]]\n",
      "Loop  10284 :    Loss_Train:  [[ 4822.51469612]]    Loss_Validation:  [[ 1420.78793347]]\n",
      "Loop  10285 :    Loss_Train:  [[ 4822.51469608]]    Loss_Validation:  [[ 1420.78795201]]\n",
      "Loop  10286 :    Loss_Train:  [[ 4822.51469603]]    Loss_Validation:  [[ 1420.78797054]]\n",
      "Loop  10287 :    Loss_Train:  [[ 4822.51469599]]    Loss_Validation:  [[ 1420.78798906]]\n",
      "Loop  10288 :    Loss_Train:  [[ 4822.51469595]]    Loss_Validation:  [[ 1420.78800756]]\n",
      "Loop  10289 :    Loss_Train:  [[ 4822.51469591]]    Loss_Validation:  [[ 1420.78802605]]\n",
      "Loop  10290 :    Loss_Train:  [[ 4822.51469587]]    Loss_Validation:  [[ 1420.78804452]]\n",
      "Loop  10291 :    Loss_Train:  [[ 4822.51469582]]    Loss_Validation:  [[ 1420.78806298]]\n",
      "Loop  10292 :    Loss_Train:  [[ 4822.51469578]]    Loss_Validation:  [[ 1420.78808143]]\n",
      "Loop  10293 :    Loss_Train:  [[ 4822.51469574]]    Loss_Validation:  [[ 1420.78809987]]\n",
      "Loop  10294 :    Loss_Train:  [[ 4822.5146957]]    Loss_Validation:  [[ 1420.78811829]]\n",
      "Loop  10295 :    Loss_Train:  [[ 4822.51469566]]    Loss_Validation:  [[ 1420.7881367]]\n",
      "Loop  10296 :    Loss_Train:  [[ 4822.51469562]]    Loss_Validation:  [[ 1420.78815509]]\n",
      "Loop  10297 :    Loss_Train:  [[ 4822.51469558]]    Loss_Validation:  [[ 1420.78817347]]\n",
      "Loop  10298 :    Loss_Train:  [[ 4822.51469554]]    Loss_Validation:  [[ 1420.78819184]]\n",
      "Loop  10299 :    Loss_Train:  [[ 4822.51469549]]    Loss_Validation:  [[ 1420.78821019]]\n",
      "Loop  10300 :    Loss_Train:  [[ 4822.51469545]]    Loss_Validation:  [[ 1420.78822854]]\n",
      "Loop  10301 :    Loss_Train:  [[ 4822.51469541]]    Loss_Validation:  [[ 1420.78824686]]\n",
      "Loop  10302 :    Loss_Train:  [[ 4822.51469537]]    Loss_Validation:  [[ 1420.78826518]]\n",
      "Loop  10303 :    Loss_Train:  [[ 4822.51469533]]    Loss_Validation:  [[ 1420.78828348]]\n",
      "Loop  10304 :    Loss_Train:  [[ 4822.51469529]]    Loss_Validation:  [[ 1420.78830177]]\n",
      "Loop  10305 :    Loss_Train:  [[ 4822.51469525]]    Loss_Validation:  [[ 1420.78832004]]\n",
      "Loop  10306 :    Loss_Train:  [[ 4822.51469521]]    Loss_Validation:  [[ 1420.7883383]]\n",
      "Loop  10307 :    Loss_Train:  [[ 4822.51469517]]    Loss_Validation:  [[ 1420.78835655]]\n",
      "Loop  10308 :    Loss_Train:  [[ 4822.51469513]]    Loss_Validation:  [[ 1420.78837479]]\n",
      "Loop  10309 :    Loss_Train:  [[ 4822.51469509]]    Loss_Validation:  [[ 1420.78839301]]\n",
      "Loop  10310 :    Loss_Train:  [[ 4822.51469505]]    Loss_Validation:  [[ 1420.78841122]]\n",
      "Loop  10311 :    Loss_Train:  [[ 4822.51469501]]    Loss_Validation:  [[ 1420.78842941]]\n",
      "Loop  10312 :    Loss_Train:  [[ 4822.51469497]]    Loss_Validation:  [[ 1420.78844759]]\n",
      "Loop  10313 :    Loss_Train:  [[ 4822.51469493]]    Loss_Validation:  [[ 1420.78846576]]\n",
      "Loop  10314 :    Loss_Train:  [[ 4822.51469489]]    Loss_Validation:  [[ 1420.78848392]]\n",
      "Loop  10315 :    Loss_Train:  [[ 4822.51469485]]    Loss_Validation:  [[ 1420.78850206]]\n",
      "Loop  10316 :    Loss_Train:  [[ 4822.51469481]]    Loss_Validation:  [[ 1420.78852019]]\n",
      "Loop  10317 :    Loss_Train:  [[ 4822.51469477]]    Loss_Validation:  [[ 1420.78853831]]\n",
      "Loop  10318 :    Loss_Train:  [[ 4822.51469473]]    Loss_Validation:  [[ 1420.78855641]]\n",
      "Loop  10319 :    Loss_Train:  [[ 4822.51469469]]    Loss_Validation:  [[ 1420.7885745]]\n",
      "Loop  10320 :    Loss_Train:  [[ 4822.51469465]]    Loss_Validation:  [[ 1420.78859258]]\n",
      "Loop  10321 :    Loss_Train:  [[ 4822.51469461]]    Loss_Validation:  [[ 1420.78861064]]\n",
      "Loop  10322 :    Loss_Train:  [[ 4822.51469457]]    Loss_Validation:  [[ 1420.78862869]]\n",
      "Loop  10323 :    Loss_Train:  [[ 4822.51469453]]    Loss_Validation:  [[ 1420.78864673]]\n",
      "Loop  10324 :    Loss_Train:  [[ 4822.51469449]]    Loss_Validation:  [[ 1420.78866475]]\n",
      "Loop  10325 :    Loss_Train:  [[ 4822.51469445]]    Loss_Validation:  [[ 1420.78868276]]\n",
      "Loop  10326 :    Loss_Train:  [[ 4822.51469441]]    Loss_Validation:  [[ 1420.78870076]]\n",
      "Loop  10327 :    Loss_Train:  [[ 4822.51469437]]    Loss_Validation:  [[ 1420.78871875]]\n",
      "Loop  10328 :    Loss_Train:  [[ 4822.51469433]]    Loss_Validation:  [[ 1420.78873672]]\n",
      "Loop  10329 :    Loss_Train:  [[ 4822.51469429]]    Loss_Validation:  [[ 1420.78875468]]\n",
      "Loop  10330 :    Loss_Train:  [[ 4822.51469425]]    Loss_Validation:  [[ 1420.78877262]]\n",
      "Loop  10331 :    Loss_Train:  [[ 4822.51469421]]    Loss_Validation:  [[ 1420.78879056]]\n",
      "Loop  10332 :    Loss_Train:  [[ 4822.51469417]]    Loss_Validation:  [[ 1420.78880848]]\n",
      "Loop  10333 :    Loss_Train:  [[ 4822.51469414]]    Loss_Validation:  [[ 1420.78882638]]\n",
      "Loop  10334 :    Loss_Train:  [[ 4822.5146941]]    Loss_Validation:  [[ 1420.78884428]]\n",
      "Loop  10335 :    Loss_Train:  [[ 4822.51469406]]    Loss_Validation:  [[ 1420.78886216]]\n",
      "Loop  10336 :    Loss_Train:  [[ 4822.51469402]]    Loss_Validation:  [[ 1420.78888002]]\n",
      "Loop  10337 :    Loss_Train:  [[ 4822.51469398]]    Loss_Validation:  [[ 1420.78889788]]\n",
      "Loop  10338 :    Loss_Train:  [[ 4822.51469394]]    Loss_Validation:  [[ 1420.78891572]]\n",
      "Loop  10339 :    Loss_Train:  [[ 4822.5146939]]    Loss_Validation:  [[ 1420.78893355]]\n",
      "Loop  10340 :    Loss_Train:  [[ 4822.51469386]]    Loss_Validation:  [[ 1420.78895137]]\n",
      "Loop  10341 :    Loss_Train:  [[ 4822.51469383]]    Loss_Validation:  [[ 1420.78896917]]\n",
      "Loop  10342 :    Loss_Train:  [[ 4822.51469379]]    Loss_Validation:  [[ 1420.78898696]]\n",
      "Loop  10343 :    Loss_Train:  [[ 4822.51469375]]    Loss_Validation:  [[ 1420.78900474]]\n",
      "Loop  10344 :    Loss_Train:  [[ 4822.51469371]]    Loss_Validation:  [[ 1420.7890225]]\n",
      "Loop  10345 :    Loss_Train:  [[ 4822.51469367]]    Loss_Validation:  [[ 1420.78904025]]\n",
      "Loop  10346 :    Loss_Train:  [[ 4822.51469363]]    Loss_Validation:  [[ 1420.78905799]]\n",
      "Loop  10347 :    Loss_Train:  [[ 4822.5146936]]    Loss_Validation:  [[ 1420.78907571]]\n",
      "Loop  10348 :    Loss_Train:  [[ 4822.51469356]]    Loss_Validation:  [[ 1420.78909343]]\n",
      "Loop  10349 :    Loss_Train:  [[ 4822.51469352]]    Loss_Validation:  [[ 1420.78911113]]\n",
      "Loop  10350 :    Loss_Train:  [[ 4822.51469348]]    Loss_Validation:  [[ 1420.78912881]]\n",
      "Loop  10351 :    Loss_Train:  [[ 4822.51469344]]    Loss_Validation:  [[ 1420.78914649]]\n",
      "Loop  10352 :    Loss_Train:  [[ 4822.51469341]]    Loss_Validation:  [[ 1420.78916415]]\n",
      "Loop  10353 :    Loss_Train:  [[ 4822.51469337]]    Loss_Validation:  [[ 1420.7891818]]\n",
      "Loop  10354 :    Loss_Train:  [[ 4822.51469333]]    Loss_Validation:  [[ 1420.78919943]]\n",
      "Loop  10355 :    Loss_Train:  [[ 4822.51469329]]    Loss_Validation:  [[ 1420.78921706]]\n",
      "Loop  10356 :    Loss_Train:  [[ 4822.51469326]]    Loss_Validation:  [[ 1420.78923467]]\n",
      "Loop  10357 :    Loss_Train:  [[ 4822.51469322]]    Loss_Validation:  [[ 1420.78925226]]\n",
      "Loop  10358 :    Loss_Train:  [[ 4822.51469318]]    Loss_Validation:  [[ 1420.78926985]]\n",
      "Loop  10359 :    Loss_Train:  [[ 4822.51469314]]    Loss_Validation:  [[ 1420.78928742]]\n",
      "Loop  10360 :    Loss_Train:  [[ 4822.51469311]]    Loss_Validation:  [[ 1420.78930498]]\n",
      "Loop  10361 :    Loss_Train:  [[ 4822.51469307]]    Loss_Validation:  [[ 1420.78932252]]\n",
      "Loop  10362 :    Loss_Train:  [[ 4822.51469303]]    Loss_Validation:  [[ 1420.78934006]]\n",
      "Loop  10363 :    Loss_Train:  [[ 4822.51469299]]    Loss_Validation:  [[ 1420.78935758]]\n",
      "Loop  10364 :    Loss_Train:  [[ 4822.51469296]]    Loss_Validation:  [[ 1420.78937508]]\n",
      "Loop  10365 :    Loss_Train:  [[ 4822.51469292]]    Loss_Validation:  [[ 1420.78939258]]\n",
      "Loop  10366 :    Loss_Train:  [[ 4822.51469288]]    Loss_Validation:  [[ 1420.78941006]]\n",
      "Loop  10367 :    Loss_Train:  [[ 4822.51469285]]    Loss_Validation:  [[ 1420.78942753]]\n",
      "Loop  10368 :    Loss_Train:  [[ 4822.51469281]]    Loss_Validation:  [[ 1420.78944499]]\n",
      "Loop  10369 :    Loss_Train:  [[ 4822.51469277]]    Loss_Validation:  [[ 1420.78946243]]\n",
      "Loop  10370 :    Loss_Train:  [[ 4822.51469274]]    Loss_Validation:  [[ 1420.78947986]]\n",
      "Loop  10371 :    Loss_Train:  [[ 4822.5146927]]    Loss_Validation:  [[ 1420.78949728]]\n",
      "Loop  10372 :    Loss_Train:  [[ 4822.51469266]]    Loss_Validation:  [[ 1420.78951469]]\n",
      "Loop  10373 :    Loss_Train:  [[ 4822.51469263]]    Loss_Validation:  [[ 1420.78953208]]\n",
      "Loop  10374 :    Loss_Train:  [[ 4822.51469259]]    Loss_Validation:  [[ 1420.78954946]]\n",
      "Loop  10375 :    Loss_Train:  [[ 4822.51469255]]    Loss_Validation:  [[ 1420.78956683]]\n",
      "Loop  10376 :    Loss_Train:  [[ 4822.51469252]]    Loss_Validation:  [[ 1420.78958419]]\n",
      "Loop  10377 :    Loss_Train:  [[ 4822.51469248]]    Loss_Validation:  [[ 1420.78960153]]\n",
      "Loop  10378 :    Loss_Train:  [[ 4822.51469244]]    Loss_Validation:  [[ 1420.78961886]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  10379 :    Loss_Train:  [[ 4822.51469241]]    Loss_Validation:  [[ 1420.78963618]]\n",
      "Loop  10380 :    Loss_Train:  [[ 4822.51469237]]    Loss_Validation:  [[ 1420.78965349]]\n",
      "Loop  10381 :    Loss_Train:  [[ 4822.51469234]]    Loss_Validation:  [[ 1420.78967078]]\n",
      "Loop  10382 :    Loss_Train:  [[ 4822.5146923]]    Loss_Validation:  [[ 1420.78968806]]\n",
      "Loop  10383 :    Loss_Train:  [[ 4822.51469226]]    Loss_Validation:  [[ 1420.78970533]]\n",
      "Loop  10384 :    Loss_Train:  [[ 4822.51469223]]    Loss_Validation:  [[ 1420.78972258]]\n",
      "Loop  10385 :    Loss_Train:  [[ 4822.51469219]]    Loss_Validation:  [[ 1420.78973982]]\n",
      "Loop  10386 :    Loss_Train:  [[ 4822.51469216]]    Loss_Validation:  [[ 1420.78975705]]\n",
      "Loop  10387 :    Loss_Train:  [[ 4822.51469212]]    Loss_Validation:  [[ 1420.78977427]]\n",
      "Loop  10388 :    Loss_Train:  [[ 4822.51469208]]    Loss_Validation:  [[ 1420.78979148]]\n",
      "Loop  10389 :    Loss_Train:  [[ 4822.51469205]]    Loss_Validation:  [[ 1420.78980867]]\n",
      "Loop  10390 :    Loss_Train:  [[ 4822.51469201]]    Loss_Validation:  [[ 1420.78982585]]\n",
      "Loop  10391 :    Loss_Train:  [[ 4822.51469198]]    Loss_Validation:  [[ 1420.78984302]]\n",
      "Loop  10392 :    Loss_Train:  [[ 4822.51469194]]    Loss_Validation:  [[ 1420.78986017]]\n",
      "Loop  10393 :    Loss_Train:  [[ 4822.51469191]]    Loss_Validation:  [[ 1420.78987731]]\n",
      "Loop  10394 :    Loss_Train:  [[ 4822.51469187]]    Loss_Validation:  [[ 1420.78989444]]\n",
      "Loop  10395 :    Loss_Train:  [[ 4822.51469184]]    Loss_Validation:  [[ 1420.78991156]]\n",
      "Loop  10396 :    Loss_Train:  [[ 4822.5146918]]    Loss_Validation:  [[ 1420.78992867]]\n",
      "Loop  10397 :    Loss_Train:  [[ 4822.51469176]]    Loss_Validation:  [[ 1420.78994576]]\n",
      "Loop  10398 :    Loss_Train:  [[ 4822.51469173]]    Loss_Validation:  [[ 1420.78996284]]\n",
      "Loop  10399 :    Loss_Train:  [[ 4822.51469169]]    Loss_Validation:  [[ 1420.78997991]]\n",
      "Loop  10400 :    Loss_Train:  [[ 4822.51469166]]    Loss_Validation:  [[ 1420.78999696]]\n",
      "Loop  10401 :    Loss_Train:  [[ 4822.51469162]]    Loss_Validation:  [[ 1420.79001401]]\n",
      "Loop  10402 :    Loss_Train:  [[ 4822.51469159]]    Loss_Validation:  [[ 1420.79003104]]\n",
      "Loop  10403 :    Loss_Train:  [[ 4822.51469155]]    Loss_Validation:  [[ 1420.79004806]]\n",
      "Loop  10404 :    Loss_Train:  [[ 4822.51469152]]    Loss_Validation:  [[ 1420.79006506]]\n",
      "Loop  10405 :    Loss_Train:  [[ 4822.51469148]]    Loss_Validation:  [[ 1420.79008206]]\n",
      "Loop  10406 :    Loss_Train:  [[ 4822.51469145]]    Loss_Validation:  [[ 1420.79009904]]\n",
      "Loop  10407 :    Loss_Train:  [[ 4822.51469141]]    Loss_Validation:  [[ 1420.79011601]]\n",
      "Loop  10408 :    Loss_Train:  [[ 4822.51469138]]    Loss_Validation:  [[ 1420.79013296]]\n",
      "Loop  10409 :    Loss_Train:  [[ 4822.51469135]]    Loss_Validation:  [[ 1420.79014991]]\n",
      "Loop  10410 :    Loss_Train:  [[ 4822.51469131]]    Loss_Validation:  [[ 1420.79016684]]\n",
      "Loop  10411 :    Loss_Train:  [[ 4822.51469128]]    Loss_Validation:  [[ 1420.79018376]]\n",
      "Loop  10412 :    Loss_Train:  [[ 4822.51469124]]    Loss_Validation:  [[ 1420.79020067]]\n",
      "Loop  10413 :    Loss_Train:  [[ 4822.51469121]]    Loss_Validation:  [[ 1420.79021756]]\n",
      "Loop  10414 :    Loss_Train:  [[ 4822.51469117]]    Loss_Validation:  [[ 1420.79023444]]\n",
      "Loop  10415 :    Loss_Train:  [[ 4822.51469114]]    Loss_Validation:  [[ 1420.79025132]]\n",
      "Loop  10416 :    Loss_Train:  [[ 4822.5146911]]    Loss_Validation:  [[ 1420.79026817]]\n",
      "Loop  10417 :    Loss_Train:  [[ 4822.51469107]]    Loss_Validation:  [[ 1420.79028502]]\n",
      "Loop  10418 :    Loss_Train:  [[ 4822.51469104]]    Loss_Validation:  [[ 1420.79030185]]\n",
      "Loop  10419 :    Loss_Train:  [[ 4822.514691]]    Loss_Validation:  [[ 1420.79031868]]\n",
      "Loop  10420 :    Loss_Train:  [[ 4822.51469097]]    Loss_Validation:  [[ 1420.79033548]]\n",
      "Loop  10421 :    Loss_Train:  [[ 4822.51469093]]    Loss_Validation:  [[ 1420.79035228]]\n",
      "Loop  10422 :    Loss_Train:  [[ 4822.5146909]]    Loss_Validation:  [[ 1420.79036907]]\n",
      "Loop  10423 :    Loss_Train:  [[ 4822.51469087]]    Loss_Validation:  [[ 1420.79038584]]\n",
      "Loop  10424 :    Loss_Train:  [[ 4822.51469083]]    Loss_Validation:  [[ 1420.7904026]]\n",
      "Loop  10425 :    Loss_Train:  [[ 4822.5146908]]    Loss_Validation:  [[ 1420.79041935]]\n",
      "Loop  10426 :    Loss_Train:  [[ 4822.51469077]]    Loss_Validation:  [[ 1420.79043608]]\n",
      "Loop  10427 :    Loss_Train:  [[ 4822.51469073]]    Loss_Validation:  [[ 1420.79045281]]\n",
      "Loop  10428 :    Loss_Train:  [[ 4822.5146907]]    Loss_Validation:  [[ 1420.79046952]]\n",
      "Loop  10429 :    Loss_Train:  [[ 4822.51469066]]    Loss_Validation:  [[ 1420.79048622]]\n",
      "Loop  10430 :    Loss_Train:  [[ 4822.51469063]]    Loss_Validation:  [[ 1420.79050291]]\n",
      "Loop  10431 :    Loss_Train:  [[ 4822.5146906]]    Loss_Validation:  [[ 1420.79051958]]\n",
      "Loop  10432 :    Loss_Train:  [[ 4822.51469056]]    Loss_Validation:  [[ 1420.79053625]]\n",
      "Loop  10433 :    Loss_Train:  [[ 4822.51469053]]    Loss_Validation:  [[ 1420.7905529]]\n",
      "Loop  10434 :    Loss_Train:  [[ 4822.5146905]]    Loss_Validation:  [[ 1420.79056954]]\n",
      "Loop  10435 :    Loss_Train:  [[ 4822.51469046]]    Loss_Validation:  [[ 1420.79058616]]\n",
      "Loop  10436 :    Loss_Train:  [[ 4822.51469043]]    Loss_Validation:  [[ 1420.79060278]]\n",
      "Loop  10437 :    Loss_Train:  [[ 4822.5146904]]    Loss_Validation:  [[ 1420.79061938]]\n",
      "Loop  10438 :    Loss_Train:  [[ 4822.51469036]]    Loss_Validation:  [[ 1420.79063597]]\n",
      "Loop  10439 :    Loss_Train:  [[ 4822.51469033]]    Loss_Validation:  [[ 1420.79065255]]\n",
      "Loop  10440 :    Loss_Train:  [[ 4822.5146903]]    Loss_Validation:  [[ 1420.79066912]]\n",
      "Loop  10441 :    Loss_Train:  [[ 4822.51469027]]    Loss_Validation:  [[ 1420.79068567]]\n",
      "Loop  10442 :    Loss_Train:  [[ 4822.51469023]]    Loss_Validation:  [[ 1420.79070222]]\n",
      "Loop  10443 :    Loss_Train:  [[ 4822.5146902]]    Loss_Validation:  [[ 1420.79071875]]\n",
      "Loop  10444 :    Loss_Train:  [[ 4822.51469017]]    Loss_Validation:  [[ 1420.79073526]]\n",
      "Loop  10445 :    Loss_Train:  [[ 4822.51469013]]    Loss_Validation:  [[ 1420.79075177]]\n",
      "Loop  10446 :    Loss_Train:  [[ 4822.5146901]]    Loss_Validation:  [[ 1420.79076827]]\n",
      "Loop  10447 :    Loss_Train:  [[ 4822.51469007]]    Loss_Validation:  [[ 1420.79078475]]\n",
      "Loop  10448 :    Loss_Train:  [[ 4822.51469004]]    Loss_Validation:  [[ 1420.79080122]]\n",
      "Loop  10449 :    Loss_Train:  [[ 4822.51469]]    Loss_Validation:  [[ 1420.79081768]]\n",
      "Loop  10450 :    Loss_Train:  [[ 4822.51468997]]    Loss_Validation:  [[ 1420.79083412]]\n",
      "Loop  10451 :    Loss_Train:  [[ 4822.51468994]]    Loss_Validation:  [[ 1420.79085056]]\n",
      "Loop  10452 :    Loss_Train:  [[ 4822.51468991]]    Loss_Validation:  [[ 1420.79086698]]\n",
      "Loop  10453 :    Loss_Train:  [[ 4822.51468987]]    Loss_Validation:  [[ 1420.79088339]]\n",
      "Loop  10454 :    Loss_Train:  [[ 4822.51468984]]    Loss_Validation:  [[ 1420.79089979]]\n",
      "Loop  10455 :    Loss_Train:  [[ 4822.51468981]]    Loss_Validation:  [[ 1420.79091618]]\n",
      "Loop  10456 :    Loss_Train:  [[ 4822.51468978]]    Loss_Validation:  [[ 1420.79093255]]\n",
      "Loop  10457 :    Loss_Train:  [[ 4822.51468975]]    Loss_Validation:  [[ 1420.79094892]]\n",
      "Loop  10458 :    Loss_Train:  [[ 4822.51468971]]    Loss_Validation:  [[ 1420.79096527]]\n",
      "Loop  10459 :    Loss_Train:  [[ 4822.51468968]]    Loss_Validation:  [[ 1420.79098161]]\n",
      "Loop  10460 :    Loss_Train:  [[ 4822.51468965]]    Loss_Validation:  [[ 1420.79099793]]\n",
      "Loop  10461 :    Loss_Train:  [[ 4822.51468962]]    Loss_Validation:  [[ 1420.79101425]]\n",
      "Loop  10462 :    Loss_Train:  [[ 4822.51468959]]    Loss_Validation:  [[ 1420.79103055]]\n",
      "Loop  10463 :    Loss_Train:  [[ 4822.51468955]]    Loss_Validation:  [[ 1420.79104685]]\n",
      "Loop  10464 :    Loss_Train:  [[ 4822.51468952]]    Loss_Validation:  [[ 1420.79106313]]\n",
      "Loop  10465 :    Loss_Train:  [[ 4822.51468949]]    Loss_Validation:  [[ 1420.79107939]]\n",
      "Loop  10466 :    Loss_Train:  [[ 4822.51468946]]    Loss_Validation:  [[ 1420.79109565]]\n",
      "Loop  10467 :    Loss_Train:  [[ 4822.51468943]]    Loss_Validation:  [[ 1420.79111189]]\n",
      "Loop  10468 :    Loss_Train:  [[ 4822.5146894]]    Loss_Validation:  [[ 1420.79112813]]\n",
      "Loop  10469 :    Loss_Train:  [[ 4822.51468936]]    Loss_Validation:  [[ 1420.79114435]]\n",
      "Loop  10470 :    Loss_Train:  [[ 4822.51468933]]    Loss_Validation:  [[ 1420.79116056]]\n",
      "Loop  10471 :    Loss_Train:  [[ 4822.5146893]]    Loss_Validation:  [[ 1420.79117675]]\n",
      "Loop  10472 :    Loss_Train:  [[ 4822.51468927]]    Loss_Validation:  [[ 1420.79119294]]\n",
      "Loop  10473 :    Loss_Train:  [[ 4822.51468924]]    Loss_Validation:  [[ 1420.79120911]]\n",
      "Loop  10474 :    Loss_Train:  [[ 4822.51468921]]    Loss_Validation:  [[ 1420.79122528]]\n",
      "Loop  10475 :    Loss_Train:  [[ 4822.51468918]]    Loss_Validation:  [[ 1420.79124143]]\n",
      "Loop  10476 :    Loss_Train:  [[ 4822.51468914]]    Loss_Validation:  [[ 1420.79125757]]\n",
      "Loop  10477 :    Loss_Train:  [[ 4822.51468911]]    Loss_Validation:  [[ 1420.79127369]]\n",
      "Loop  10478 :    Loss_Train:  [[ 4822.51468908]]    Loss_Validation:  [[ 1420.79128981]]\n",
      "Loop  10479 :    Loss_Train:  [[ 4822.51468905]]    Loss_Validation:  [[ 1420.79130591]]\n",
      "Loop  10480 :    Loss_Train:  [[ 4822.51468902]]    Loss_Validation:  [[ 1420.791322]]\n",
      "Loop  10481 :    Loss_Train:  [[ 4822.51468899]]    Loss_Validation:  [[ 1420.79133808]]\n",
      "Loop  10482 :    Loss_Train:  [[ 4822.51468896]]    Loss_Validation:  [[ 1420.79135415]]\n",
      "Loop  10483 :    Loss_Train:  [[ 4822.51468893]]    Loss_Validation:  [[ 1420.79137021]]\n",
      "Loop  10484 :    Loss_Train:  [[ 4822.5146889]]    Loss_Validation:  [[ 1420.79138625]]\n",
      "Loop  10485 :    Loss_Train:  [[ 4822.51468887]]    Loss_Validation:  [[ 1420.79140229]]\n",
      "Loop  10486 :    Loss_Train:  [[ 4822.51468884]]    Loss_Validation:  [[ 1420.79141831]]\n",
      "Loop  10487 :    Loss_Train:  [[ 4822.5146888]]    Loss_Validation:  [[ 1420.79143432]]\n",
      "Loop  10488 :    Loss_Train:  [[ 4822.51468877]]    Loss_Validation:  [[ 1420.79145032]]\n",
      "Loop  10489 :    Loss_Train:  [[ 4822.51468874]]    Loss_Validation:  [[ 1420.7914663]]\n",
      "Loop  10490 :    Loss_Train:  [[ 4822.51468871]]    Loss_Validation:  [[ 1420.79148228]]\n",
      "Loop  10491 :    Loss_Train:  [[ 4822.51468868]]    Loss_Validation:  [[ 1420.79149824]]\n",
      "Loop  10492 :    Loss_Train:  [[ 4822.51468865]]    Loss_Validation:  [[ 1420.79151419]]\n",
      "Loop  10493 :    Loss_Train:  [[ 4822.51468862]]    Loss_Validation:  [[ 1420.79153013]]\n",
      "Loop  10494 :    Loss_Train:  [[ 4822.51468859]]    Loss_Validation:  [[ 1420.79154606]]\n",
      "Loop  10495 :    Loss_Train:  [[ 4822.51468856]]    Loss_Validation:  [[ 1420.79156198]]\n",
      "Loop  10496 :    Loss_Train:  [[ 4822.51468853]]    Loss_Validation:  [[ 1420.79157788]]\n",
      "Loop  10497 :    Loss_Train:  [[ 4822.5146885]]    Loss_Validation:  [[ 1420.79159378]]\n",
      "Loop  10498 :    Loss_Train:  [[ 4822.51468847]]    Loss_Validation:  [[ 1420.79160966]]\n",
      "Loop  10499 :    Loss_Train:  [[ 4822.51468844]]    Loss_Validation:  [[ 1420.79162553]]\n",
      "Loop  10500 :    Loss_Train:  [[ 4822.51468841]]    Loss_Validation:  [[ 1420.79164139]]\n",
      "Loop  10501 :    Loss_Train:  [[ 4822.51468838]]    Loss_Validation:  [[ 1420.79165724]]\n",
      "Loop  10502 :    Loss_Train:  [[ 4822.51468835]]    Loss_Validation:  [[ 1420.79167307]]\n",
      "Loop  10503 :    Loss_Train:  [[ 4822.51468832]]    Loss_Validation:  [[ 1420.7916889]]\n",
      "Loop  10504 :    Loss_Train:  [[ 4822.51468829]]    Loss_Validation:  [[ 1420.79170471]]\n",
      "Loop  10505 :    Loss_Train:  [[ 4822.51468826]]    Loss_Validation:  [[ 1420.79172051]]\n",
      "Loop  10506 :    Loss_Train:  [[ 4822.51468823]]    Loss_Validation:  [[ 1420.7917363]]\n",
      "Loop  10507 :    Loss_Train:  [[ 4822.5146882]]    Loss_Validation:  [[ 1420.79175208]]\n",
      "Loop  10508 :    Loss_Train:  [[ 4822.51468817]]    Loss_Validation:  [[ 1420.79176785]]\n",
      "Loop  10509 :    Loss_Train:  [[ 4822.51468814]]    Loss_Validation:  [[ 1420.79178361]]\n",
      "Loop  10510 :    Loss_Train:  [[ 4822.51468811]]    Loss_Validation:  [[ 1420.79179935]]\n",
      "Loop  10511 :    Loss_Train:  [[ 4822.51468808]]    Loss_Validation:  [[ 1420.79181508]]\n",
      "Loop  10512 :    Loss_Train:  [[ 4822.51468805]]    Loss_Validation:  [[ 1420.7918308]]\n",
      "Loop  10513 :    Loss_Train:  [[ 4822.51468802]]    Loss_Validation:  [[ 1420.79184651]]\n",
      "Loop  10514 :    Loss_Train:  [[ 4822.51468799]]    Loss_Validation:  [[ 1420.79186221]]\n",
      "Loop  10515 :    Loss_Train:  [[ 4822.51468797]]    Loss_Validation:  [[ 1420.7918779]]\n",
      "Loop  10516 :    Loss_Train:  [[ 4822.51468794]]    Loss_Validation:  [[ 1420.79189358]]\n",
      "Loop  10517 :    Loss_Train:  [[ 4822.51468791]]    Loss_Validation:  [[ 1420.79190924]]\n",
      "Loop  10518 :    Loss_Train:  [[ 4822.51468788]]    Loss_Validation:  [[ 1420.79192489]]\n",
      "Loop  10519 :    Loss_Train:  [[ 4822.51468785]]    Loss_Validation:  [[ 1420.79194053]]\n",
      "Loop  10520 :    Loss_Train:  [[ 4822.51468782]]    Loss_Validation:  [[ 1420.79195616]]\n",
      "Loop  10521 :    Loss_Train:  [[ 4822.51468779]]    Loss_Validation:  [[ 1420.79197178]]\n",
      "Loop  10522 :    Loss_Train:  [[ 4822.51468776]]    Loss_Validation:  [[ 1420.79198739]]\n",
      "Loop  10523 :    Loss_Train:  [[ 4822.51468773]]    Loss_Validation:  [[ 1420.79200299]]\n",
      "Loop  10524 :    Loss_Train:  [[ 4822.5146877]]    Loss_Validation:  [[ 1420.79201857]]\n",
      "Loop  10525 :    Loss_Train:  [[ 4822.51468767]]    Loss_Validation:  [[ 1420.79203415]]\n",
      "Loop  10526 :    Loss_Train:  [[ 4822.51468765]]    Loss_Validation:  [[ 1420.79204971]]\n",
      "Loop  10527 :    Loss_Train:  [[ 4822.51468762]]    Loss_Validation:  [[ 1420.79206526]]\n",
      "Loop  10528 :    Loss_Train:  [[ 4822.51468759]]    Loss_Validation:  [[ 1420.7920808]]\n",
      "Loop  10529 :    Loss_Train:  [[ 4822.51468756]]    Loss_Validation:  [[ 1420.79209633]]\n",
      "Loop  10530 :    Loss_Train:  [[ 4822.51468753]]    Loss_Validation:  [[ 1420.79211184]]\n",
      "Loop  10531 :    Loss_Train:  [[ 4822.5146875]]    Loss_Validation:  [[ 1420.79212735]]\n",
      "Loop  10532 :    Loss_Train:  [[ 4822.51468747]]    Loss_Validation:  [[ 1420.79214284]]\n",
      "Loop  10533 :    Loss_Train:  [[ 4822.51468744]]    Loss_Validation:  [[ 1420.79215833]]\n",
      "Loop  10534 :    Loss_Train:  [[ 4822.51468742]]    Loss_Validation:  [[ 1420.7921738]]\n",
      "Loop  10535 :    Loss_Train:  [[ 4822.51468739]]    Loss_Validation:  [[ 1420.79218926]]\n",
      "Loop  10536 :    Loss_Train:  [[ 4822.51468736]]    Loss_Validation:  [[ 1420.79220471]]\n",
      "Loop  10537 :    Loss_Train:  [[ 4822.51468733]]    Loss_Validation:  [[ 1420.79222015]]\n",
      "Loop  10538 :    Loss_Train:  [[ 4822.5146873]]    Loss_Validation:  [[ 1420.79223557]]\n",
      "Loop  10539 :    Loss_Train:  [[ 4822.51468727]]    Loss_Validation:  [[ 1420.79225099]]\n",
      "Loop  10540 :    Loss_Train:  [[ 4822.51468725]]    Loss_Validation:  [[ 1420.79226639]]\n",
      "Loop  10541 :    Loss_Train:  [[ 4822.51468722]]    Loss_Validation:  [[ 1420.79228179]]\n",
      "Loop  10542 :    Loss_Train:  [[ 4822.51468719]]    Loss_Validation:  [[ 1420.79229717]]\n",
      "Loop  10543 :    Loss_Train:  [[ 4822.51468716]]    Loss_Validation:  [[ 1420.79231254]]\n",
      "Loop  10544 :    Loss_Train:  [[ 4822.51468713]]    Loss_Validation:  [[ 1420.7923279]]\n",
      "Loop  10545 :    Loss_Train:  [[ 4822.51468711]]    Loss_Validation:  [[ 1420.79234325]]\n",
      "Loop  10546 :    Loss_Train:  [[ 4822.51468708]]    Loss_Validation:  [[ 1420.79235858]]\n",
      "Loop  10547 :    Loss_Train:  [[ 4822.51468705]]    Loss_Validation:  [[ 1420.79237391]]\n",
      "Loop  10548 :    Loss_Train:  [[ 4822.51468702]]    Loss_Validation:  [[ 1420.79238922]]\n",
      "Loop  10549 :    Loss_Train:  [[ 4822.51468699]]    Loss_Validation:  [[ 1420.79240453]]\n",
      "Loop  10550 :    Loss_Train:  [[ 4822.51468697]]    Loss_Validation:  [[ 1420.79241982]]\n",
      "Loop  10551 :    Loss_Train:  [[ 4822.51468694]]    Loss_Validation:  [[ 1420.7924351]]\n",
      "Loop  10552 :    Loss_Train:  [[ 4822.51468691]]    Loss_Validation:  [[ 1420.79245037]]\n",
      "Loop  10553 :    Loss_Train:  [[ 4822.51468688]]    Loss_Validation:  [[ 1420.79246563]]\n",
      "Loop  10554 :    Loss_Train:  [[ 4822.51468685]]    Loss_Validation:  [[ 1420.79248088]]\n",
      "Loop  10555 :    Loss_Train:  [[ 4822.51468683]]    Loss_Validation:  [[ 1420.79249612]]\n",
      "Loop  10556 :    Loss_Train:  [[ 4822.5146868]]    Loss_Validation:  [[ 1420.79251134]]\n",
      "Loop  10557 :    Loss_Train:  [[ 4822.51468677]]    Loss_Validation:  [[ 1420.79252656]]\n",
      "Loop  10558 :    Loss_Train:  [[ 4822.51468674]]    Loss_Validation:  [[ 1420.79254176]]\n",
      "Loop  10559 :    Loss_Train:  [[ 4822.51468672]]    Loss_Validation:  [[ 1420.79255696]]\n",
      "Loop  10560 :    Loss_Train:  [[ 4822.51468669]]    Loss_Validation:  [[ 1420.79257214]]\n",
      "Loop  10561 :    Loss_Train:  [[ 4822.51468666]]    Loss_Validation:  [[ 1420.79258731]]\n",
      "Loop  10562 :    Loss_Train:  [[ 4822.51468664]]    Loss_Validation:  [[ 1420.79260247]]\n",
      "Loop  10563 :    Loss_Train:  [[ 4822.51468661]]    Loss_Validation:  [[ 1420.79261762]]\n",
      "Loop  10564 :    Loss_Train:  [[ 4822.51468658]]    Loss_Validation:  [[ 1420.79263275]]\n",
      "Loop  10565 :    Loss_Train:  [[ 4822.51468655]]    Loss_Validation:  [[ 1420.79264788]]\n",
      "Loop  10566 :    Loss_Train:  [[ 4822.51468653]]    Loss_Validation:  [[ 1420.792663]]\n",
      "Loop  10567 :    Loss_Train:  [[ 4822.5146865]]    Loss_Validation:  [[ 1420.7926781]]\n",
      "Loop  10568 :    Loss_Train:  [[ 4822.51468647]]    Loss_Validation:  [[ 1420.7926932]]\n",
      "Loop  10569 :    Loss_Train:  [[ 4822.51468645]]    Loss_Validation:  [[ 1420.79270828]]\n",
      "Loop  10570 :    Loss_Train:  [[ 4822.51468642]]    Loss_Validation:  [[ 1420.79272335]]\n",
      "Loop  10571 :    Loss_Train:  [[ 4822.51468639]]    Loss_Validation:  [[ 1420.79273841]]\n",
      "Loop  10572 :    Loss_Train:  [[ 4822.51468636]]    Loss_Validation:  [[ 1420.79275346]]\n",
      "Loop  10573 :    Loss_Train:  [[ 4822.51468634]]    Loss_Validation:  [[ 1420.7927685]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  10574 :    Loss_Train:  [[ 4822.51468631]]    Loss_Validation:  [[ 1420.79278353]]\n",
      "Loop  10575 :    Loss_Train:  [[ 4822.51468628]]    Loss_Validation:  [[ 1420.79279854]]\n",
      "Loop  10576 :    Loss_Train:  [[ 4822.51468626]]    Loss_Validation:  [[ 1420.79281355]]\n",
      "Loop  10577 :    Loss_Train:  [[ 4822.51468623]]    Loss_Validation:  [[ 1420.79282855]]\n",
      "Loop  10578 :    Loss_Train:  [[ 4822.5146862]]    Loss_Validation:  [[ 1420.79284353]]\n",
      "Loop  10579 :    Loss_Train:  [[ 4822.51468618]]    Loss_Validation:  [[ 1420.7928585]]\n",
      "Loop  10580 :    Loss_Train:  [[ 4822.51468615]]    Loss_Validation:  [[ 1420.79287347]]\n",
      "Loop  10581 :    Loss_Train:  [[ 4822.51468612]]    Loss_Validation:  [[ 1420.79288842]]\n",
      "Loop  10582 :    Loss_Train:  [[ 4822.5146861]]    Loss_Validation:  [[ 1420.79290336]]\n",
      "Loop  10583 :    Loss_Train:  [[ 4822.51468607]]    Loss_Validation:  [[ 1420.79291829]]\n",
      "Loop  10584 :    Loss_Train:  [[ 4822.51468605]]    Loss_Validation:  [[ 1420.79293321]]\n",
      "Loop  10585 :    Loss_Train:  [[ 4822.51468602]]    Loss_Validation:  [[ 1420.79294811]]\n",
      "Loop  10586 :    Loss_Train:  [[ 4822.51468599]]    Loss_Validation:  [[ 1420.79296301]]\n",
      "Loop  10587 :    Loss_Train:  [[ 4822.51468597]]    Loss_Validation:  [[ 1420.7929779]]\n",
      "Loop  10588 :    Loss_Train:  [[ 4822.51468594]]    Loss_Validation:  [[ 1420.79299277]]\n",
      "Loop  10589 :    Loss_Train:  [[ 4822.51468591]]    Loss_Validation:  [[ 1420.79300764]]\n",
      "Loop  10590 :    Loss_Train:  [[ 4822.51468589]]    Loss_Validation:  [[ 1420.79302249]]\n",
      "Loop  10591 :    Loss_Train:  [[ 4822.51468586]]    Loss_Validation:  [[ 1420.79303734]]\n",
      "Loop  10592 :    Loss_Train:  [[ 4822.51468584]]    Loss_Validation:  [[ 1420.79305217]]\n",
      "Loop  10593 :    Loss_Train:  [[ 4822.51468581]]    Loss_Validation:  [[ 1420.79306699]]\n",
      "Loop  10594 :    Loss_Train:  [[ 4822.51468578]]    Loss_Validation:  [[ 1420.7930818]]\n",
      "Loop  10595 :    Loss_Train:  [[ 4822.51468576]]    Loss_Validation:  [[ 1420.7930966]]\n",
      "Loop  10596 :    Loss_Train:  [[ 4822.51468573]]    Loss_Validation:  [[ 1420.79311139]]\n",
      "Loop  10597 :    Loss_Train:  [[ 4822.51468571]]    Loss_Validation:  [[ 1420.79312617]]\n",
      "Loop  10598 :    Loss_Train:  [[ 4822.51468568]]    Loss_Validation:  [[ 1420.79314094]]\n",
      "Loop  10599 :    Loss_Train:  [[ 4822.51468565]]    Loss_Validation:  [[ 1420.79315569]]\n",
      "Loop  10600 :    Loss_Train:  [[ 4822.51468563]]    Loss_Validation:  [[ 1420.79317044]]\n",
      "Loop  10601 :    Loss_Train:  [[ 4822.5146856]]    Loss_Validation:  [[ 1420.79318517]]\n",
      "Loop  10602 :    Loss_Train:  [[ 4822.51468558]]    Loss_Validation:  [[ 1420.7931999]]\n",
      "Loop  10603 :    Loss_Train:  [[ 4822.51468555]]    Loss_Validation:  [[ 1420.79321461]]\n",
      "Loop  10604 :    Loss_Train:  [[ 4822.51468553]]    Loss_Validation:  [[ 1420.79322932]]\n",
      "Loop  10605 :    Loss_Train:  [[ 4822.5146855]]    Loss_Validation:  [[ 1420.79324401]]\n",
      "Loop  10606 :    Loss_Train:  [[ 4822.51468548]]    Loss_Validation:  [[ 1420.79325869]]\n",
      "Loop  10607 :    Loss_Train:  [[ 4822.51468545]]    Loss_Validation:  [[ 1420.79327336]]\n",
      "Loop  10608 :    Loss_Train:  [[ 4822.51468542]]    Loss_Validation:  [[ 1420.79328802]]\n",
      "Loop  10609 :    Loss_Train:  [[ 4822.5146854]]    Loss_Validation:  [[ 1420.79330267]]\n",
      "Loop  10610 :    Loss_Train:  [[ 4822.51468537]]    Loss_Validation:  [[ 1420.79331731]]\n",
      "Loop  10611 :    Loss_Train:  [[ 4822.51468535]]    Loss_Validation:  [[ 1420.79333194]]\n",
      "Loop  10612 :    Loss_Train:  [[ 4822.51468532]]    Loss_Validation:  [[ 1420.79334656]]\n",
      "Loop  10613 :    Loss_Train:  [[ 4822.5146853]]    Loss_Validation:  [[ 1420.79336117]]\n",
      "Loop  10614 :    Loss_Train:  [[ 4822.51468527]]    Loss_Validation:  [[ 1420.79337576]]\n",
      "Loop  10615 :    Loss_Train:  [[ 4822.51468525]]    Loss_Validation:  [[ 1420.79339035]]\n",
      "Loop  10616 :    Loss_Train:  [[ 4822.51468522]]    Loss_Validation:  [[ 1420.79340492]]\n",
      "Loop  10617 :    Loss_Train:  [[ 4822.5146852]]    Loss_Validation:  [[ 1420.79341949]]\n",
      "Loop  10618 :    Loss_Train:  [[ 4822.51468517]]    Loss_Validation:  [[ 1420.79343404]]\n",
      "Loop  10619 :    Loss_Train:  [[ 4822.51468515]]    Loss_Validation:  [[ 1420.79344859]]\n",
      "Loop  10620 :    Loss_Train:  [[ 4822.51468512]]    Loss_Validation:  [[ 1420.79346312]]\n",
      "Loop  10621 :    Loss_Train:  [[ 4822.5146851]]    Loss_Validation:  [[ 1420.79347764]]\n",
      "Loop  10622 :    Loss_Train:  [[ 4822.51468507]]    Loss_Validation:  [[ 1420.79349215]]\n",
      "Loop  10623 :    Loss_Train:  [[ 4822.51468505]]    Loss_Validation:  [[ 1420.79350666]]\n",
      "Loop  10624 :    Loss_Train:  [[ 4822.51468502]]    Loss_Validation:  [[ 1420.79352115]]\n",
      "Loop  10625 :    Loss_Train:  [[ 4822.514685]]    Loss_Validation:  [[ 1420.79353563]]\n",
      "Loop  10626 :    Loss_Train:  [[ 4822.51468497]]    Loss_Validation:  [[ 1420.7935501]]\n",
      "Loop  10627 :    Loss_Train:  [[ 4822.51468495]]    Loss_Validation:  [[ 1420.79356456]]\n",
      "Loop  10628 :    Loss_Train:  [[ 4822.51468492]]    Loss_Validation:  [[ 1420.793579]]\n",
      "Loop  10629 :    Loss_Train:  [[ 4822.5146849]]    Loss_Validation:  [[ 1420.79359344]]\n",
      "Loop  10630 :    Loss_Train:  [[ 4822.51468488]]    Loss_Validation:  [[ 1420.79360787]]\n",
      "Loop  10631 :    Loss_Train:  [[ 4822.51468485]]    Loss_Validation:  [[ 1420.79362229]]\n",
      "Loop  10632 :    Loss_Train:  [[ 4822.51468483]]    Loss_Validation:  [[ 1420.79363669]]\n",
      "Loop  10633 :    Loss_Train:  [[ 4822.5146848]]    Loss_Validation:  [[ 1420.79365109]]\n",
      "Loop  10634 :    Loss_Train:  [[ 4822.51468478]]    Loss_Validation:  [[ 1420.79366548]]\n",
      "Loop  10635 :    Loss_Train:  [[ 4822.51468475]]    Loss_Validation:  [[ 1420.79367985]]\n",
      "Loop  10636 :    Loss_Train:  [[ 4822.51468473]]    Loss_Validation:  [[ 1420.79369422]]\n",
      "Loop  10637 :    Loss_Train:  [[ 4822.5146847]]    Loss_Validation:  [[ 1420.79370857]]\n",
      "Loop  10638 :    Loss_Train:  [[ 4822.51468468]]    Loss_Validation:  [[ 1420.79372291]]\n",
      "Loop  10639 :    Loss_Train:  [[ 4822.51468466]]    Loss_Validation:  [[ 1420.79373725]]\n",
      "Loop  10640 :    Loss_Train:  [[ 4822.51468463]]    Loss_Validation:  [[ 1420.79375157]]\n",
      "Loop  10641 :    Loss_Train:  [[ 4822.51468461]]    Loss_Validation:  [[ 1420.79376588]]\n",
      "Loop  10642 :    Loss_Train:  [[ 4822.51468458]]    Loss_Validation:  [[ 1420.79378019]]\n",
      "Loop  10643 :    Loss_Train:  [[ 4822.51468456]]    Loss_Validation:  [[ 1420.79379448]]\n",
      "Loop  10644 :    Loss_Train:  [[ 4822.51468454]]    Loss_Validation:  [[ 1420.79380876]]\n",
      "Loop  10645 :    Loss_Train:  [[ 4822.51468451]]    Loss_Validation:  [[ 1420.79382303]]\n",
      "Loop  10646 :    Loss_Train:  [[ 4822.51468449]]    Loss_Validation:  [[ 1420.79383729]]\n",
      "Loop  10647 :    Loss_Train:  [[ 4822.51468446]]    Loss_Validation:  [[ 1420.79385154]]\n",
      "Loop  10648 :    Loss_Train:  [[ 4822.51468444]]    Loss_Validation:  [[ 1420.79386578]]\n",
      "Loop  10649 :    Loss_Train:  [[ 4822.51468442]]    Loss_Validation:  [[ 1420.79388001]]\n",
      "Loop  10650 :    Loss_Train:  [[ 4822.51468439]]    Loss_Validation:  [[ 1420.79389423]]\n",
      "Loop  10651 :    Loss_Train:  [[ 4822.51468437]]    Loss_Validation:  [[ 1420.79390844]]\n",
      "Loop  10652 :    Loss_Train:  [[ 4822.51468434]]    Loss_Validation:  [[ 1420.79392264]]\n",
      "Loop  10653 :    Loss_Train:  [[ 4822.51468432]]    Loss_Validation:  [[ 1420.79393682]]\n",
      "Loop  10654 :    Loss_Train:  [[ 4822.5146843]]    Loss_Validation:  [[ 1420.793951]]\n",
      "Loop  10655 :    Loss_Train:  [[ 4822.51468427]]    Loss_Validation:  [[ 1420.79396517]]\n",
      "Loop  10656 :    Loss_Train:  [[ 4822.51468425]]    Loss_Validation:  [[ 1420.79397933]]\n",
      "Loop  10657 :    Loss_Train:  [[ 4822.51468423]]    Loss_Validation:  [[ 1420.79399347]]\n",
      "Loop  10658 :    Loss_Train:  [[ 4822.5146842]]    Loss_Validation:  [[ 1420.79400761]]\n",
      "Loop  10659 :    Loss_Train:  [[ 4822.51468418]]    Loss_Validation:  [[ 1420.79402174]]\n",
      "Loop  10660 :    Loss_Train:  [[ 4822.51468416]]    Loss_Validation:  [[ 1420.79403585]]\n",
      "Loop  10661 :    Loss_Train:  [[ 4822.51468413]]    Loss_Validation:  [[ 1420.79404996]]\n",
      "Loop  10662 :    Loss_Train:  [[ 4822.51468411]]    Loss_Validation:  [[ 1420.79406405]]\n",
      "Loop  10663 :    Loss_Train:  [[ 4822.51468409]]    Loss_Validation:  [[ 1420.79407814]]\n",
      "Loop  10664 :    Loss_Train:  [[ 4822.51468406]]    Loss_Validation:  [[ 1420.79409221]]\n",
      "Loop  10665 :    Loss_Train:  [[ 4822.51468404]]    Loss_Validation:  [[ 1420.79410628]]\n",
      "Loop  10666 :    Loss_Train:  [[ 4822.51468402]]    Loss_Validation:  [[ 1420.79412033]]\n",
      "Loop  10667 :    Loss_Train:  [[ 4822.51468399]]    Loss_Validation:  [[ 1420.79413438]]\n",
      "Loop  10668 :    Loss_Train:  [[ 4822.51468397]]    Loss_Validation:  [[ 1420.79414841]]\n",
      "Loop  10669 :    Loss_Train:  [[ 4822.51468395]]    Loss_Validation:  [[ 1420.79416243]]\n",
      "Loop  10670 :    Loss_Train:  [[ 4822.51468392]]    Loss_Validation:  [[ 1420.79417645]]\n",
      "Loop  10671 :    Loss_Train:  [[ 4822.5146839]]    Loss_Validation:  [[ 1420.79419045]]\n",
      "Loop  10672 :    Loss_Train:  [[ 4822.51468388]]    Loss_Validation:  [[ 1420.79420444]]\n",
      "Loop  10673 :    Loss_Train:  [[ 4822.51468385]]    Loss_Validation:  [[ 1420.79421843]]\n",
      "Loop  10674 :    Loss_Train:  [[ 4822.51468383]]    Loss_Validation:  [[ 1420.7942324]]\n",
      "Loop  10675 :    Loss_Train:  [[ 4822.51468381]]    Loss_Validation:  [[ 1420.79424636]]\n",
      "Loop  10676 :    Loss_Train:  [[ 4822.51468379]]    Loss_Validation:  [[ 1420.79426031]]\n",
      "Loop  10677 :    Loss_Train:  [[ 4822.51468376]]    Loss_Validation:  [[ 1420.79427426]]\n",
      "Loop  10678 :    Loss_Train:  [[ 4822.51468374]]    Loss_Validation:  [[ 1420.79428819]]\n",
      "Loop  10679 :    Loss_Train:  [[ 4822.51468372]]    Loss_Validation:  [[ 1420.79430211]]\n",
      "Loop  10680 :    Loss_Train:  [[ 4822.51468369]]    Loss_Validation:  [[ 1420.79431602]]\n",
      "Loop  10681 :    Loss_Train:  [[ 4822.51468367]]    Loss_Validation:  [[ 1420.79432992]]\n",
      "Loop  10682 :    Loss_Train:  [[ 4822.51468365]]    Loss_Validation:  [[ 1420.79434382]]\n",
      "Loop  10683 :    Loss_Train:  [[ 4822.51468363]]    Loss_Validation:  [[ 1420.7943577]]\n",
      "Loop  10684 :    Loss_Train:  [[ 4822.5146836]]    Loss_Validation:  [[ 1420.79437157]]\n",
      "Loop  10685 :    Loss_Train:  [[ 4822.51468358]]    Loss_Validation:  [[ 1420.79438543]]\n",
      "Loop  10686 :    Loss_Train:  [[ 4822.51468356]]    Loss_Validation:  [[ 1420.79439928]]\n",
      "Loop  10687 :    Loss_Train:  [[ 4822.51468354]]    Loss_Validation:  [[ 1420.79441312]]\n",
      "Loop  10688 :    Loss_Train:  [[ 4822.51468351]]    Loss_Validation:  [[ 1420.79442695]]\n",
      "Loop  10689 :    Loss_Train:  [[ 4822.51468349]]    Loss_Validation:  [[ 1420.79444077]]\n",
      "Loop  10690 :    Loss_Train:  [[ 4822.51468347]]    Loss_Validation:  [[ 1420.79445458]]\n",
      "Loop  10691 :    Loss_Train:  [[ 4822.51468345]]    Loss_Validation:  [[ 1420.79446839]]\n",
      "Loop  10692 :    Loss_Train:  [[ 4822.51468342]]    Loss_Validation:  [[ 1420.79448218]]\n",
      "Loop  10693 :    Loss_Train:  [[ 4822.5146834]]    Loss_Validation:  [[ 1420.79449596]]\n",
      "Loop  10694 :    Loss_Train:  [[ 4822.51468338]]    Loss_Validation:  [[ 1420.79450973]]\n",
      "Loop  10695 :    Loss_Train:  [[ 4822.51468336]]    Loss_Validation:  [[ 1420.79452349]]\n",
      "Loop  10696 :    Loss_Train:  [[ 4822.51468334]]    Loss_Validation:  [[ 1420.79453724]]\n",
      "Loop  10697 :    Loss_Train:  [[ 4822.51468331]]    Loss_Validation:  [[ 1420.79455098]]\n",
      "Loop  10698 :    Loss_Train:  [[ 4822.51468329]]    Loss_Validation:  [[ 1420.79456471]]\n",
      "Loop  10699 :    Loss_Train:  [[ 4822.51468327]]    Loss_Validation:  [[ 1420.79457843]]\n",
      "Loop  10700 :    Loss_Train:  [[ 4822.51468325]]    Loss_Validation:  [[ 1420.79459214]]\n",
      "Loop  10701 :    Loss_Train:  [[ 4822.51468323]]    Loss_Validation:  [[ 1420.79460584]]\n",
      "Loop  10702 :    Loss_Train:  [[ 4822.5146832]]    Loss_Validation:  [[ 1420.79461953]]\n",
      "Loop  10703 :    Loss_Train:  [[ 4822.51468318]]    Loss_Validation:  [[ 1420.79463321]]\n",
      "Loop  10704 :    Loss_Train:  [[ 4822.51468316]]    Loss_Validation:  [[ 1420.79464688]]\n",
      "Loop  10705 :    Loss_Train:  [[ 4822.51468314]]    Loss_Validation:  [[ 1420.79466055]]\n",
      "Loop  10706 :    Loss_Train:  [[ 4822.51468312]]    Loss_Validation:  [[ 1420.7946742]]\n",
      "Loop  10707 :    Loss_Train:  [[ 4822.51468309]]    Loss_Validation:  [[ 1420.79468784]]\n",
      "Loop  10708 :    Loss_Train:  [[ 4822.51468307]]    Loss_Validation:  [[ 1420.79470147]]\n",
      "Loop  10709 :    Loss_Train:  [[ 4822.51468305]]    Loss_Validation:  [[ 1420.79471509]]\n",
      "Loop  10710 :    Loss_Train:  [[ 4822.51468303]]    Loss_Validation:  [[ 1420.7947287]]\n",
      "Loop  10711 :    Loss_Train:  [[ 4822.51468301]]    Loss_Validation:  [[ 1420.7947423]]\n",
      "Loop  10712 :    Loss_Train:  [[ 4822.51468299]]    Loss_Validation:  [[ 1420.79475589]]\n",
      "Loop  10713 :    Loss_Train:  [[ 4822.51468296]]    Loss_Validation:  [[ 1420.79476947]]\n",
      "Loop  10714 :    Loss_Train:  [[ 4822.51468294]]    Loss_Validation:  [[ 1420.79478305]]\n",
      "Loop  10715 :    Loss_Train:  [[ 4822.51468292]]    Loss_Validation:  [[ 1420.79479661]]\n",
      "Loop  10716 :    Loss_Train:  [[ 4822.5146829]]    Loss_Validation:  [[ 1420.79481016]]\n",
      "Loop  10717 :    Loss_Train:  [[ 4822.51468288]]    Loss_Validation:  [[ 1420.7948237]]\n",
      "Loop  10718 :    Loss_Train:  [[ 4822.51468286]]    Loss_Validation:  [[ 1420.79483723]]\n",
      "Loop  10719 :    Loss_Train:  [[ 4822.51468284]]    Loss_Validation:  [[ 1420.79485076]]\n",
      "Loop  10720 :    Loss_Train:  [[ 4822.51468281]]    Loss_Validation:  [[ 1420.79486427]]\n",
      "Loop  10721 :    Loss_Train:  [[ 4822.51468279]]    Loss_Validation:  [[ 1420.79487777]]\n",
      "Loop  10722 :    Loss_Train:  [[ 4822.51468277]]    Loss_Validation:  [[ 1420.79489126]]\n",
      "Loop  10723 :    Loss_Train:  [[ 4822.51468275]]    Loss_Validation:  [[ 1420.79490475]]\n",
      "Loop  10724 :    Loss_Train:  [[ 4822.51468273]]    Loss_Validation:  [[ 1420.79491822]]\n",
      "Loop  10725 :    Loss_Train:  [[ 4822.51468271]]    Loss_Validation:  [[ 1420.79493168]]\n",
      "Loop  10726 :    Loss_Train:  [[ 4822.51468269]]    Loss_Validation:  [[ 1420.79494514]]\n",
      "Loop  10727 :    Loss_Train:  [[ 4822.51468267]]    Loss_Validation:  [[ 1420.79495858]]\n",
      "Loop  10728 :    Loss_Train:  [[ 4822.51468264]]    Loss_Validation:  [[ 1420.79497201]]\n",
      "Loop  10729 :    Loss_Train:  [[ 4822.51468262]]    Loss_Validation:  [[ 1420.79498544]]\n",
      "Loop  10730 :    Loss_Train:  [[ 4822.5146826]]    Loss_Validation:  [[ 1420.79499885]]\n",
      "Loop  10731 :    Loss_Train:  [[ 4822.51468258]]    Loss_Validation:  [[ 1420.79501226]]\n",
      "Loop  10732 :    Loss_Train:  [[ 4822.51468256]]    Loss_Validation:  [[ 1420.79502565]]\n",
      "Loop  10733 :    Loss_Train:  [[ 4822.51468254]]    Loss_Validation:  [[ 1420.79503904]]\n",
      "Loop  10734 :    Loss_Train:  [[ 4822.51468252]]    Loss_Validation:  [[ 1420.79505241]]\n",
      "Loop  10735 :    Loss_Train:  [[ 4822.5146825]]    Loss_Validation:  [[ 1420.79506578]]\n",
      "Loop  10736 :    Loss_Train:  [[ 4822.51468248]]    Loss_Validation:  [[ 1420.79507913]]\n",
      "Loop  10737 :    Loss_Train:  [[ 4822.51468246]]    Loss_Validation:  [[ 1420.79509248]]\n",
      "Loop  10738 :    Loss_Train:  [[ 4822.51468244]]    Loss_Validation:  [[ 1420.79510582]]\n",
      "Loop  10739 :    Loss_Train:  [[ 4822.51468241]]    Loss_Validation:  [[ 1420.79511914]]\n",
      "Loop  10740 :    Loss_Train:  [[ 4822.51468239]]    Loss_Validation:  [[ 1420.79513246]]\n",
      "Loop  10741 :    Loss_Train:  [[ 4822.51468237]]    Loss_Validation:  [[ 1420.79514577]]\n",
      "Loop  10742 :    Loss_Train:  [[ 4822.51468235]]    Loss_Validation:  [[ 1420.79515906]]\n",
      "Loop  10743 :    Loss_Train:  [[ 4822.51468233]]    Loss_Validation:  [[ 1420.79517235]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  10744 :    Loss_Train:  [[ 4822.51468231]]    Loss_Validation:  [[ 1420.79518563]]\n",
      "Loop  10745 :    Loss_Train:  [[ 4822.51468229]]    Loss_Validation:  [[ 1420.7951989]]\n",
      "Loop  10746 :    Loss_Train:  [[ 4822.51468227]]    Loss_Validation:  [[ 1420.79521216]]\n",
      "Loop  10747 :    Loss_Train:  [[ 4822.51468225]]    Loss_Validation:  [[ 1420.79522541]]\n",
      "Loop  10748 :    Loss_Train:  [[ 4822.51468223]]    Loss_Validation:  [[ 1420.79523865]]\n",
      "Loop  10749 :    Loss_Train:  [[ 4822.51468221]]    Loss_Validation:  [[ 1420.79525188]]\n",
      "Loop  10750 :    Loss_Train:  [[ 4822.51468219]]    Loss_Validation:  [[ 1420.7952651]]\n",
      "Loop  10751 :    Loss_Train:  [[ 4822.51468217]]    Loss_Validation:  [[ 1420.79527831]]\n",
      "Loop  10752 :    Loss_Train:  [[ 4822.51468215]]    Loss_Validation:  [[ 1420.79529151]]\n",
      "Loop  10753 :    Loss_Train:  [[ 4822.51468213]]    Loss_Validation:  [[ 1420.7953047]]\n",
      "Loop  10754 :    Loss_Train:  [[ 4822.51468211]]    Loss_Validation:  [[ 1420.79531788]]\n",
      "Loop  10755 :    Loss_Train:  [[ 4822.51468209]]    Loss_Validation:  [[ 1420.79533105]]\n",
      "Loop  10756 :    Loss_Train:  [[ 4822.51468207]]    Loss_Validation:  [[ 1420.79534422]]\n",
      "Loop  10757 :    Loss_Train:  [[ 4822.51468205]]    Loss_Validation:  [[ 1420.79535737]]\n",
      "Loop  10758 :    Loss_Train:  [[ 4822.51468203]]    Loss_Validation:  [[ 1420.79537051]]\n",
      "Loop  10759 :    Loss_Train:  [[ 4822.51468201]]    Loss_Validation:  [[ 1420.79538365]]\n",
      "Loop  10760 :    Loss_Train:  [[ 4822.51468199]]    Loss_Validation:  [[ 1420.79539677]]\n",
      "Loop  10761 :    Loss_Train:  [[ 4822.51468197]]    Loss_Validation:  [[ 1420.79540988]]\n",
      "Loop  10762 :    Loss_Train:  [[ 4822.51468195]]    Loss_Validation:  [[ 1420.79542299]]\n",
      "Loop  10763 :    Loss_Train:  [[ 4822.51468193]]    Loss_Validation:  [[ 1420.79543609]]\n",
      "Loop  10764 :    Loss_Train:  [[ 4822.51468191]]    Loss_Validation:  [[ 1420.79544917]]\n",
      "Loop  10765 :    Loss_Train:  [[ 4822.51468189]]    Loss_Validation:  [[ 1420.79546225]]\n",
      "Loop  10766 :    Loss_Train:  [[ 4822.51468187]]    Loss_Validation:  [[ 1420.79547532]]\n",
      "Loop  10767 :    Loss_Train:  [[ 4822.51468185]]    Loss_Validation:  [[ 1420.79548837]]\n",
      "Loop  10768 :    Loss_Train:  [[ 4822.51468183]]    Loss_Validation:  [[ 1420.79550142]]\n",
      "Loop  10769 :    Loss_Train:  [[ 4822.51468181]]    Loss_Validation:  [[ 1420.79551446]]\n",
      "Loop  10770 :    Loss_Train:  [[ 4822.51468179]]    Loss_Validation:  [[ 1420.79552749]]\n",
      "Loop  10771 :    Loss_Train:  [[ 4822.51468177]]    Loss_Validation:  [[ 1420.79554051]]\n",
      "Loop  10772 :    Loss_Train:  [[ 4822.51468175]]    Loss_Validation:  [[ 1420.79555352]]\n",
      "Loop  10773 :    Loss_Train:  [[ 4822.51468173]]    Loss_Validation:  [[ 1420.79556652]]\n",
      "Loop  10774 :    Loss_Train:  [[ 4822.51468171]]    Loss_Validation:  [[ 1420.79557951]]\n",
      "Loop  10775 :    Loss_Train:  [[ 4822.51468169]]    Loss_Validation:  [[ 1420.79559249]]\n",
      "Loop  10776 :    Loss_Train:  [[ 4822.51468167]]    Loss_Validation:  [[ 1420.79560546]]\n",
      "Loop  10777 :    Loss_Train:  [[ 4822.51468165]]    Loss_Validation:  [[ 1420.79561843]]\n",
      "Loop  10778 :    Loss_Train:  [[ 4822.51468163]]    Loss_Validation:  [[ 1420.79563138]]\n",
      "Loop  10779 :    Loss_Train:  [[ 4822.51468161]]    Loss_Validation:  [[ 1420.79564432]]\n",
      "Loop  10780 :    Loss_Train:  [[ 4822.51468159]]    Loss_Validation:  [[ 1420.79565726]]\n",
      "Loop  10781 :    Loss_Train:  [[ 4822.51468157]]    Loss_Validation:  [[ 1420.79567018]]\n",
      "Loop  10782 :    Loss_Train:  [[ 4822.51468155]]    Loss_Validation:  [[ 1420.7956831]]\n",
      "Loop  10783 :    Loss_Train:  [[ 4822.51468153]]    Loss_Validation:  [[ 1420.795696]]\n",
      "Loop  10784 :    Loss_Train:  [[ 4822.51468151]]    Loss_Validation:  [[ 1420.7957089]]\n",
      "Loop  10785 :    Loss_Train:  [[ 4822.51468149]]    Loss_Validation:  [[ 1420.79572179]]\n",
      "Loop  10786 :    Loss_Train:  [[ 4822.51468148]]    Loss_Validation:  [[ 1420.79573467]]\n",
      "Loop  10787 :    Loss_Train:  [[ 4822.51468146]]    Loss_Validation:  [[ 1420.79574754]]\n",
      "Loop  10788 :    Loss_Train:  [[ 4822.51468144]]    Loss_Validation:  [[ 1420.79576039]]\n",
      "Loop  10789 :    Loss_Train:  [[ 4822.51468142]]    Loss_Validation:  [[ 1420.79577324]]\n",
      "Loop  10790 :    Loss_Train:  [[ 4822.5146814]]    Loss_Validation:  [[ 1420.79578608]]\n",
      "Loop  10791 :    Loss_Train:  [[ 4822.51468138]]    Loss_Validation:  [[ 1420.79579892]]\n",
      "Loop  10792 :    Loss_Train:  [[ 4822.51468136]]    Loss_Validation:  [[ 1420.79581174]]\n",
      "Loop  10793 :    Loss_Train:  [[ 4822.51468134]]    Loss_Validation:  [[ 1420.79582455]]\n",
      "Loop  10794 :    Loss_Train:  [[ 4822.51468132]]    Loss_Validation:  [[ 1420.79583735]]\n",
      "Loop  10795 :    Loss_Train:  [[ 4822.5146813]]    Loss_Validation:  [[ 1420.79585015]]\n",
      "Loop  10796 :    Loss_Train:  [[ 4822.51468128]]    Loss_Validation:  [[ 1420.79586293]]\n",
      "Loop  10797 :    Loss_Train:  [[ 4822.51468126]]    Loss_Validation:  [[ 1420.79587571]]\n",
      "Loop  10798 :    Loss_Train:  [[ 4822.51468125]]    Loss_Validation:  [[ 1420.79588847]]\n",
      "Loop  10799 :    Loss_Train:  [[ 4822.51468123]]    Loss_Validation:  [[ 1420.79590123]]\n",
      "Loop  10800 :    Loss_Train:  [[ 4822.51468121]]    Loss_Validation:  [[ 1420.79591398]]\n",
      "Loop  10801 :    Loss_Train:  [[ 4822.51468119]]    Loss_Validation:  [[ 1420.79592671]]\n",
      "Loop  10802 :    Loss_Train:  [[ 4822.51468117]]    Loss_Validation:  [[ 1420.79593944]]\n",
      "Loop  10803 :    Loss_Train:  [[ 4822.51468115]]    Loss_Validation:  [[ 1420.79595216]]\n",
      "Loop  10804 :    Loss_Train:  [[ 4822.51468113]]    Loss_Validation:  [[ 1420.79596487]]\n",
      "Loop  10805 :    Loss_Train:  [[ 4822.51468111]]    Loss_Validation:  [[ 1420.79597757]]\n",
      "Loop  10806 :    Loss_Train:  [[ 4822.5146811]]    Loss_Validation:  [[ 1420.79599027]]\n",
      "Loop  10807 :    Loss_Train:  [[ 4822.51468108]]    Loss_Validation:  [[ 1420.79600295]]\n",
      "Loop  10808 :    Loss_Train:  [[ 4822.51468106]]    Loss_Validation:  [[ 1420.79601562]]\n",
      "Loop  10809 :    Loss_Train:  [[ 4822.51468104]]    Loss_Validation:  [[ 1420.79602828]]\n",
      "Loop  10810 :    Loss_Train:  [[ 4822.51468102]]    Loss_Validation:  [[ 1420.79604094]]\n",
      "Loop  10811 :    Loss_Train:  [[ 4822.514681]]    Loss_Validation:  [[ 1420.79605358]]\n",
      "Loop  10812 :    Loss_Train:  [[ 4822.51468098]]    Loss_Validation:  [[ 1420.79606622]]\n",
      "Loop  10813 :    Loss_Train:  [[ 4822.51468097]]    Loss_Validation:  [[ 1420.79607885]]\n",
      "Loop  10814 :    Loss_Train:  [[ 4822.51468095]]    Loss_Validation:  [[ 1420.79609147]]\n",
      "Loop  10815 :    Loss_Train:  [[ 4822.51468093]]    Loss_Validation:  [[ 1420.79610407]]\n",
      "Loop  10816 :    Loss_Train:  [[ 4822.51468091]]    Loss_Validation:  [[ 1420.79611667]]\n",
      "Loop  10817 :    Loss_Train:  [[ 4822.51468089]]    Loss_Validation:  [[ 1420.79612926]]\n",
      "Loop  10818 :    Loss_Train:  [[ 4822.51468087]]    Loss_Validation:  [[ 1420.79614185]]\n",
      "Loop  10819 :    Loss_Train:  [[ 4822.51468086]]    Loss_Validation:  [[ 1420.79615442]]\n",
      "Loop  10820 :    Loss_Train:  [[ 4822.51468084]]    Loss_Validation:  [[ 1420.79616698]]\n",
      "Loop  10821 :    Loss_Train:  [[ 4822.51468082]]    Loss_Validation:  [[ 1420.79617953]]\n",
      "Loop  10822 :    Loss_Train:  [[ 4822.5146808]]    Loss_Validation:  [[ 1420.79619208]]\n",
      "Loop  10823 :    Loss_Train:  [[ 4822.51468078]]    Loss_Validation:  [[ 1420.79620461]]\n",
      "Loop  10824 :    Loss_Train:  [[ 4822.51468076]]    Loss_Validation:  [[ 1420.79621714]]\n",
      "Loop  10825 :    Loss_Train:  [[ 4822.51468075]]    Loss_Validation:  [[ 1420.79622966]]\n",
      "Loop  10826 :    Loss_Train:  [[ 4822.51468073]]    Loss_Validation:  [[ 1420.79624216]]\n",
      "Loop  10827 :    Loss_Train:  [[ 4822.51468071]]    Loss_Validation:  [[ 1420.79625466]]\n",
      "Loop  10828 :    Loss_Train:  [[ 4822.51468069]]    Loss_Validation:  [[ 1420.79626715]]\n",
      "Loop  10829 :    Loss_Train:  [[ 4822.51468067]]    Loss_Validation:  [[ 1420.79627963]]\n",
      "Loop  10830 :    Loss_Train:  [[ 4822.51468066]]    Loss_Validation:  [[ 1420.79629211]]\n",
      "Loop  10831 :    Loss_Train:  [[ 4822.51468064]]    Loss_Validation:  [[ 1420.79630457]]\n",
      "Loop  10832 :    Loss_Train:  [[ 4822.51468062]]    Loss_Validation:  [[ 1420.79631702]]\n",
      "Loop  10833 :    Loss_Train:  [[ 4822.5146806]]    Loss_Validation:  [[ 1420.79632947]]\n",
      "Loop  10834 :    Loss_Train:  [[ 4822.51468058]]    Loss_Validation:  [[ 1420.7963419]]\n",
      "Loop  10835 :    Loss_Train:  [[ 4822.51468057]]    Loss_Validation:  [[ 1420.79635433]]\n",
      "Loop  10836 :    Loss_Train:  [[ 4822.51468055]]    Loss_Validation:  [[ 1420.79636674]]\n",
      "Loop  10837 :    Loss_Train:  [[ 4822.51468053]]    Loss_Validation:  [[ 1420.79637915]]\n",
      "Loop  10838 :    Loss_Train:  [[ 4822.51468051]]    Loss_Validation:  [[ 1420.79639155]]\n",
      "Loop  10839 :    Loss_Train:  [[ 4822.51468049]]    Loss_Validation:  [[ 1420.79640394]]\n",
      "Loop  10840 :    Loss_Train:  [[ 4822.51468048]]    Loss_Validation:  [[ 1420.79641632]]\n",
      "Loop  10841 :    Loss_Train:  [[ 4822.51468046]]    Loss_Validation:  [[ 1420.79642869]]\n",
      "Loop  10842 :    Loss_Train:  [[ 4822.51468044]]    Loss_Validation:  [[ 1420.79644106]]\n",
      "Loop  10843 :    Loss_Train:  [[ 4822.51468042]]    Loss_Validation:  [[ 1420.79645341]]\n",
      "Loop  10844 :    Loss_Train:  [[ 4822.51468041]]    Loss_Validation:  [[ 1420.79646576]]\n",
      "Loop  10845 :    Loss_Train:  [[ 4822.51468039]]    Loss_Validation:  [[ 1420.79647809]]\n",
      "Loop  10846 :    Loss_Train:  [[ 4822.51468037]]    Loss_Validation:  [[ 1420.79649042]]\n",
      "Loop  10847 :    Loss_Train:  [[ 4822.51468035]]    Loss_Validation:  [[ 1420.79650274]]\n",
      "Loop  10848 :    Loss_Train:  [[ 4822.51468034]]    Loss_Validation:  [[ 1420.79651505]]\n",
      "Loop  10849 :    Loss_Train:  [[ 4822.51468032]]    Loss_Validation:  [[ 1420.79652735]]\n",
      "Loop  10850 :    Loss_Train:  [[ 4822.5146803]]    Loss_Validation:  [[ 1420.79653964]]\n",
      "Loop  10851 :    Loss_Train:  [[ 4822.51468028]]    Loss_Validation:  [[ 1420.79655192]]\n",
      "Loop  10852 :    Loss_Train:  [[ 4822.51468027]]    Loss_Validation:  [[ 1420.79656419]]\n",
      "Loop  10853 :    Loss_Train:  [[ 4822.51468025]]    Loss_Validation:  [[ 1420.79657646]]\n",
      "Loop  10854 :    Loss_Train:  [[ 4822.51468023]]    Loss_Validation:  [[ 1420.79658871]]\n",
      "Loop  10855 :    Loss_Train:  [[ 4822.51468021]]    Loss_Validation:  [[ 1420.79660096]]\n",
      "Loop  10856 :    Loss_Train:  [[ 4822.5146802]]    Loss_Validation:  [[ 1420.7966132]]\n",
      "Loop  10857 :    Loss_Train:  [[ 4822.51468018]]    Loss_Validation:  [[ 1420.79662542]]\n",
      "Loop  10858 :    Loss_Train:  [[ 4822.51468016]]    Loss_Validation:  [[ 1420.79663764]]\n",
      "Loop  10859 :    Loss_Train:  [[ 4822.51468015]]    Loss_Validation:  [[ 1420.79664985]]\n",
      "Loop  10860 :    Loss_Train:  [[ 4822.51468013]]    Loss_Validation:  [[ 1420.79666206]]\n",
      "Loop  10861 :    Loss_Train:  [[ 4822.51468011]]    Loss_Validation:  [[ 1420.79667425]]\n",
      "Loop  10862 :    Loss_Train:  [[ 4822.51468009]]    Loss_Validation:  [[ 1420.79668643]]\n",
      "Loop  10863 :    Loss_Train:  [[ 4822.51468008]]    Loss_Validation:  [[ 1420.79669861]]\n",
      "Loop  10864 :    Loss_Train:  [[ 4822.51468006]]    Loss_Validation:  [[ 1420.79671077]]\n",
      "Loop  10865 :    Loss_Train:  [[ 4822.51468004]]    Loss_Validation:  [[ 1420.79672293]]\n",
      "Loop  10866 :    Loss_Train:  [[ 4822.51468003]]    Loss_Validation:  [[ 1420.79673508]]\n",
      "Loop  10867 :    Loss_Train:  [[ 4822.51468001]]    Loss_Validation:  [[ 1420.79674722]]\n",
      "Loop  10868 :    Loss_Train:  [[ 4822.51467999]]    Loss_Validation:  [[ 1420.79675935]]\n",
      "Loop  10869 :    Loss_Train:  [[ 4822.51467997]]    Loss_Validation:  [[ 1420.79677147]]\n",
      "Loop  10870 :    Loss_Train:  [[ 4822.51467996]]    Loss_Validation:  [[ 1420.79678359]]\n",
      "Loop  10871 :    Loss_Train:  [[ 4822.51467994]]    Loss_Validation:  [[ 1420.79679569]]\n",
      "Loop  10872 :    Loss_Train:  [[ 4822.51467992]]    Loss_Validation:  [[ 1420.79680779]]\n",
      "Loop  10873 :    Loss_Train:  [[ 4822.51467991]]    Loss_Validation:  [[ 1420.79681987]]\n",
      "Loop  10874 :    Loss_Train:  [[ 4822.51467989]]    Loss_Validation:  [[ 1420.79683195]]\n",
      "Loop  10875 :    Loss_Train:  [[ 4822.51467987]]    Loss_Validation:  [[ 1420.79684402]]\n",
      "Loop  10876 :    Loss_Train:  [[ 4822.51467986]]    Loss_Validation:  [[ 1420.79685608]]\n",
      "Loop  10877 :    Loss_Train:  [[ 4822.51467984]]    Loss_Validation:  [[ 1420.79686813]]\n",
      "Loop  10878 :    Loss_Train:  [[ 4822.51467982]]    Loss_Validation:  [[ 1420.79688017]]\n",
      "Loop  10879 :    Loss_Train:  [[ 4822.51467981]]    Loss_Validation:  [[ 1420.79689221]]\n",
      "Loop  10880 :    Loss_Train:  [[ 4822.51467979]]    Loss_Validation:  [[ 1420.79690423]]\n",
      "Loop  10881 :    Loss_Train:  [[ 4822.51467977]]    Loss_Validation:  [[ 1420.79691625]]\n",
      "Loop  10882 :    Loss_Train:  [[ 4822.51467976]]    Loss_Validation:  [[ 1420.79692826]]\n",
      "Loop  10883 :    Loss_Train:  [[ 4822.51467974]]    Loss_Validation:  [[ 1420.79694026]]\n",
      "Loop  10884 :    Loss_Train:  [[ 4822.51467972]]    Loss_Validation:  [[ 1420.79695225]]\n",
      "Loop  10885 :    Loss_Train:  [[ 4822.51467971]]    Loss_Validation:  [[ 1420.79696423]]\n",
      "Loop  10886 :    Loss_Train:  [[ 4822.51467969]]    Loss_Validation:  [[ 1420.7969762]]\n",
      "Loop  10887 :    Loss_Train:  [[ 4822.51467967]]    Loss_Validation:  [[ 1420.79698816]]\n",
      "Loop  10888 :    Loss_Train:  [[ 4822.51467966]]    Loss_Validation:  [[ 1420.79700012]]\n",
      "Loop  10889 :    Loss_Train:  [[ 4822.51467964]]    Loss_Validation:  [[ 1420.79701207]]\n",
      "Loop  10890 :    Loss_Train:  [[ 4822.51467962]]    Loss_Validation:  [[ 1420.797024]]\n",
      "Loop  10891 :    Loss_Train:  [[ 4822.51467961]]    Loss_Validation:  [[ 1420.79703593]]\n",
      "Loop  10892 :    Loss_Train:  [[ 4822.51467959]]    Loss_Validation:  [[ 1420.79704785]]\n",
      "Loop  10893 :    Loss_Train:  [[ 4822.51467958]]    Loss_Validation:  [[ 1420.79705976]]\n",
      "Loop  10894 :    Loss_Train:  [[ 4822.51467956]]    Loss_Validation:  [[ 1420.79707167]]\n",
      "Loop  10895 :    Loss_Train:  [[ 4822.51467954]]    Loss_Validation:  [[ 1420.79708356]]\n",
      "Loop  10896 :    Loss_Train:  [[ 4822.51467953]]    Loss_Validation:  [[ 1420.79709545]]\n",
      "Loop  10897 :    Loss_Train:  [[ 4822.51467951]]    Loss_Validation:  [[ 1420.79710732]]\n",
      "Loop  10898 :    Loss_Train:  [[ 4822.51467949]]    Loss_Validation:  [[ 1420.79711919]]\n",
      "Loop  10899 :    Loss_Train:  [[ 4822.51467948]]    Loss_Validation:  [[ 1420.79713105]]\n",
      "Loop  10900 :    Loss_Train:  [[ 4822.51467946]]    Loss_Validation:  [[ 1420.7971429]]\n",
      "Loop  10901 :    Loss_Train:  [[ 4822.51467945]]    Loss_Validation:  [[ 1420.79715475]]\n",
      "Loop  10902 :    Loss_Train:  [[ 4822.51467943]]    Loss_Validation:  [[ 1420.79716658]]\n",
      "Loop  10903 :    Loss_Train:  [[ 4822.51467941]]    Loss_Validation:  [[ 1420.7971784]]\n",
      "Loop  10904 :    Loss_Train:  [[ 4822.5146794]]    Loss_Validation:  [[ 1420.79719022]]\n",
      "Loop  10905 :    Loss_Train:  [[ 4822.51467938]]    Loss_Validation:  [[ 1420.79720203]]\n",
      "Loop  10906 :    Loss_Train:  [[ 4822.51467937]]    Loss_Validation:  [[ 1420.79721383]]\n",
      "Loop  10907 :    Loss_Train:  [[ 4822.51467935]]    Loss_Validation:  [[ 1420.79722562]]\n",
      "Loop  10908 :    Loss_Train:  [[ 4822.51467933]]    Loss_Validation:  [[ 1420.7972374]]\n",
      "Loop  10909 :    Loss_Train:  [[ 4822.51467932]]    Loss_Validation:  [[ 1420.79724917]]\n",
      "Loop  10910 :    Loss_Train:  [[ 4822.5146793]]    Loss_Validation:  [[ 1420.79726094]]\n",
      "Loop  10911 :    Loss_Train:  [[ 4822.51467929]]    Loss_Validation:  [[ 1420.7972727]]\n",
      "Loop  10912 :    Loss_Train:  [[ 4822.51467927]]    Loss_Validation:  [[ 1420.79728444]]\n",
      "Loop  10913 :    Loss_Train:  [[ 4822.51467925]]    Loss_Validation:  [[ 1420.79729618]]\n",
      "Loop  10914 :    Loss_Train:  [[ 4822.51467924]]    Loss_Validation:  [[ 1420.79730791]]\n",
      "Loop  10915 :    Loss_Train:  [[ 4822.51467922]]    Loss_Validation:  [[ 1420.79731964]]\n",
      "Loop  10916 :    Loss_Train:  [[ 4822.51467921]]    Loss_Validation:  [[ 1420.79733135]]\n",
      "Loop  10917 :    Loss_Train:  [[ 4822.51467919]]    Loss_Validation:  [[ 1420.79734305]]\n",
      "Loop  10918 :    Loss_Train:  [[ 4822.51467918]]    Loss_Validation:  [[ 1420.79735475]]\n",
      "Loop  10919 :    Loss_Train:  [[ 4822.51467916]]    Loss_Validation:  [[ 1420.79736644]]\n",
      "Loop  10920 :    Loss_Train:  [[ 4822.51467914]]    Loss_Validation:  [[ 1420.79737812]]\n",
      "Loop  10921 :    Loss_Train:  [[ 4822.51467913]]    Loss_Validation:  [[ 1420.79738979]]\n",
      "Loop  10922 :    Loss_Train:  [[ 4822.51467911]]    Loss_Validation:  [[ 1420.79740145]]\n",
      "Loop  10923 :    Loss_Train:  [[ 4822.5146791]]    Loss_Validation:  [[ 1420.7974131]]\n",
      "Loop  10924 :    Loss_Train:  [[ 4822.51467908]]    Loss_Validation:  [[ 1420.79742475]]\n",
      "Loop  10925 :    Loss_Train:  [[ 4822.51467907]]    Loss_Validation:  [[ 1420.79743639]]\n",
      "Loop  10926 :    Loss_Train:  [[ 4822.51467905]]    Loss_Validation:  [[ 1420.79744802]]\n",
      "Loop  10927 :    Loss_Train:  [[ 4822.51467904]]    Loss_Validation:  [[ 1420.79745964]]\n",
      "Loop  10928 :    Loss_Train:  [[ 4822.51467902]]    Loss_Validation:  [[ 1420.79747125]]\n",
      "Loop  10929 :    Loss_Train:  [[ 4822.514679]]    Loss_Validation:  [[ 1420.79748285]]\n",
      "Loop  10930 :    Loss_Train:  [[ 4822.51467899]]    Loss_Validation:  [[ 1420.79749444]]\n",
      "Loop  10931 :    Loss_Train:  [[ 4822.51467897]]    Loss_Validation:  [[ 1420.79750603]]\n",
      "Loop  10932 :    Loss_Train:  [[ 4822.51467896]]    Loss_Validation:  [[ 1420.79751761]]\n",
      "Loop  10933 :    Loss_Train:  [[ 4822.51467894]]    Loss_Validation:  [[ 1420.79752918]]\n",
      "Loop  10934 :    Loss_Train:  [[ 4822.51467893]]    Loss_Validation:  [[ 1420.79754074]]\n",
      "Loop  10935 :    Loss_Train:  [[ 4822.51467891]]    Loss_Validation:  [[ 1420.79755229]]\n",
      "Loop  10936 :    Loss_Train:  [[ 4822.5146789]]    Loss_Validation:  [[ 1420.79756383]]\n",
      "Loop  10937 :    Loss_Train:  [[ 4822.51467888]]    Loss_Validation:  [[ 1420.79757537]]\n",
      "Loop  10938 :    Loss_Train:  [[ 4822.51467887]]    Loss_Validation:  [[ 1420.7975869]]\n",
      "Loop  10939 :    Loss_Train:  [[ 4822.51467885]]    Loss_Validation:  [[ 1420.79759842]]\n",
      "Loop  10940 :    Loss_Train:  [[ 4822.51467884]]    Loss_Validation:  [[ 1420.79760993]]\n",
      "Loop  10941 :    Loss_Train:  [[ 4822.51467882]]    Loss_Validation:  [[ 1420.79762143]]\n",
      "Loop  10942 :    Loss_Train:  [[ 4822.51467881]]    Loss_Validation:  [[ 1420.79763292]]\n",
      "Loop  10943 :    Loss_Train:  [[ 4822.51467879]]    Loss_Validation:  [[ 1420.79764441]]\n",
      "Loop  10944 :    Loss_Train:  [[ 4822.51467878]]    Loss_Validation:  [[ 1420.79765588]]\n",
      "Loop  10945 :    Loss_Train:  [[ 4822.51467876]]    Loss_Validation:  [[ 1420.79766735]]\n",
      "Loop  10946 :    Loss_Train:  [[ 4822.51467875]]    Loss_Validation:  [[ 1420.79767881]]\n",
      "Loop  10947 :    Loss_Train:  [[ 4822.51467873]]    Loss_Validation:  [[ 1420.79769026]]\n",
      "Loop  10948 :    Loss_Train:  [[ 4822.51467872]]    Loss_Validation:  [[ 1420.79770171]]\n",
      "Loop  10949 :    Loss_Train:  [[ 4822.5146787]]    Loss_Validation:  [[ 1420.79771314]]\n",
      "Loop  10950 :    Loss_Train:  [[ 4822.51467869]]    Loss_Validation:  [[ 1420.79772457]]\n",
      "Loop  10951 :    Loss_Train:  [[ 4822.51467867]]    Loss_Validation:  [[ 1420.79773599]]\n",
      "Loop  10952 :    Loss_Train:  [[ 4822.51467866]]    Loss_Validation:  [[ 1420.7977474]]\n",
      "Loop  10953 :    Loss_Train:  [[ 4822.51467864]]    Loss_Validation:  [[ 1420.7977588]]\n",
      "Loop  10954 :    Loss_Train:  [[ 4822.51467863]]    Loss_Validation:  [[ 1420.79777019]]\n",
      "Loop  10955 :    Loss_Train:  [[ 4822.51467861]]    Loss_Validation:  [[ 1420.79778158]]\n",
      "Loop  10956 :    Loss_Train:  [[ 4822.5146786]]    Loss_Validation:  [[ 1420.79779295]]\n",
      "Loop  10957 :    Loss_Train:  [[ 4822.51467858]]    Loss_Validation:  [[ 1420.79780432]]\n",
      "Loop  10958 :    Loss_Train:  [[ 4822.51467857]]    Loss_Validation:  [[ 1420.79781568]]\n",
      "Loop  10959 :    Loss_Train:  [[ 4822.51467855]]    Loss_Validation:  [[ 1420.79782703]]\n",
      "Loop  10960 :    Loss_Train:  [[ 4822.51467854]]    Loss_Validation:  [[ 1420.79783838]]\n",
      "Loop  10961 :    Loss_Train:  [[ 4822.51467852]]    Loss_Validation:  [[ 1420.79784971]]\n",
      "Loop  10962 :    Loss_Train:  [[ 4822.51467851]]    Loss_Validation:  [[ 1420.79786104]]\n",
      "Loop  10963 :    Loss_Train:  [[ 4822.51467849]]    Loss_Validation:  [[ 1420.79787236]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop  10964 :    Loss_Train:  [[ 4822.51467848]]    Loss_Validation:  [[ 1420.79788367]]\n",
      "Loop  10965 :    Loss_Train:  [[ 4822.51467846]]    Loss_Validation:  [[ 1420.79789497]]\n",
      "Loop  10966 :    Loss_Train:  [[ 4822.51467845]]    Loss_Validation:  [[ 1420.79790627]]\n",
      "Loop  10967 :    Loss_Train:  [[ 4822.51467843]]    Loss_Validation:  [[ 1420.79791755]]\n",
      "Loop  10968 :    Loss_Train:  [[ 4822.51467842]]    Loss_Validation:  [[ 1420.79792883]]\n",
      "Loop  10969 :    Loss_Train:  [[ 4822.51467841]]    Loss_Validation:  [[ 1420.7979401]]\n",
      "Loop  10970 :    Loss_Train:  [[ 4822.51467839]]    Loss_Validation:  [[ 1420.79795136]]\n",
      "Loop  10971 :    Loss_Train:  [[ 4822.51467838]]    Loss_Validation:  [[ 1420.79796261]]\n",
      "Loop  10972 :    Loss_Train:  [[ 4822.51467836]]    Loss_Validation:  [[ 1420.79797386]]\n",
      "Loop  10973 :    Loss_Train:  [[ 4822.51467835]]    Loss_Validation:  [[ 1420.79798509]]\n",
      "Loop  10974 :    Loss_Train:  [[ 4822.51467833]]    Loss_Validation:  [[ 1420.79799632]]\n",
      "Loop  10975 :    Loss_Train:  [[ 4822.51467832]]    Loss_Validation:  [[ 1420.79800754]]\n",
      "Loop  10976 :    Loss_Train:  [[ 4822.5146783]]    Loss_Validation:  [[ 1420.79801875]]\n",
      "Loop  10977 :    Loss_Train:  [[ 4822.51467829]]    Loss_Validation:  [[ 1420.79802996]]\n",
      "Loop  10978 :    Loss_Train:  [[ 4822.51467828]]    Loss_Validation:  [[ 1420.79804115]]\n",
      "Loop  10979 :    Loss_Train:  [[ 4822.51467826]]    Loss_Validation:  [[ 1420.79805234]]\n",
      "Loop  10980 :    Loss_Train:  [[ 4822.51467825]]    Loss_Validation:  [[ 1420.79806352]]\n",
      "Loop  10981 :    Loss_Train:  [[ 4822.51467823]]    Loss_Validation:  [[ 1420.79807469]]\n",
      "Loop  10982 :    Loss_Train:  [[ 4822.51467822]]    Loss_Validation:  [[ 1420.79808585]]\n",
      "Loop  10983 :    Loss_Train:  [[ 4822.5146782]]    Loss_Validation:  [[ 1420.79809701]]\n",
      "Loop  10984 :    Loss_Train:  [[ 4822.51467819]]    Loss_Validation:  [[ 1420.79810816]]\n",
      "Loop  10985 :    Loss_Train:  [[ 4822.51467818]]    Loss_Validation:  [[ 1420.79811929]]\n",
      "Loop  10986 :    Loss_Train:  [[ 4822.51467816]]    Loss_Validation:  [[ 1420.79813043]]\n",
      "Loop  10987 :    Loss_Train:  [[ 4822.51467815]]    Loss_Validation:  [[ 1420.79814155]]\n",
      "Loop  10988 :    Loss_Train:  [[ 4822.51467813]]    Loss_Validation:  [[ 1420.79815266]]\n",
      "Loop  10989 :    Loss_Train:  [[ 4822.51467812]]    Loss_Validation:  [[ 1420.79816377]]\n",
      "Loop  10990 :    Loss_Train:  [[ 4822.51467811]]    Loss_Validation:  [[ 1420.79817487]]\n",
      "Loop  10991 :    Loss_Train:  [[ 4822.51467809]]    Loss_Validation:  [[ 1420.79818596]]\n",
      "Loop  10992 :    Loss_Train:  [[ 4822.51467808]]    Loss_Validation:  [[ 1420.79819704]]\n",
      "Loop  10993 :    Loss_Train:  [[ 4822.51467806]]    Loss_Validation:  [[ 1420.79820811]]\n",
      "Loop  10994 :    Loss_Train:  [[ 4822.51467805]]    Loss_Validation:  [[ 1420.79821918]]\n",
      "Loop  10995 :    Loss_Train:  [[ 4822.51467804]]    Loss_Validation:  [[ 1420.79823023]]\n",
      "Loop  10996 :    Loss_Train:  [[ 4822.51467802]]    Loss_Validation:  [[ 1420.79824128]]\n",
      "Loop  10997 :    Loss_Train:  [[ 4822.51467801]]    Loss_Validation:  [[ 1420.79825233]]\n",
      "Loop  10998 :    Loss_Train:  [[ 4822.51467799]]    Loss_Validation:  [[ 1420.79826336]]\n",
      "Loop  10999 :    Loss_Train:  [[ 4822.51467798]]    Loss_Validation:  [[ 1420.79827438]]\n",
      "Loop  11000 :    Loss_Train:  [[ 4822.51467797]]    Loss_Validation:  [[ 1420.7982854]]\n",
      "Loop  11001 :    Loss_Train:  [[ 4822.51467795]]    Loss_Validation:  [[ 1420.79829641]]\n",
      "Loop  11002 :    Loss_Train:  [[ 4822.51467794]]    Loss_Validation:  [[ 1420.79830741]]\n",
      "Loop  11003 :    Loss_Train:  [[ 4822.51467793]]    Loss_Validation:  [[ 1420.79831841]]\n",
      "Loop  11004 :    Loss_Train:  [[ 4822.51467791]]    Loss_Validation:  [[ 1420.79832939]]\n",
      "Loop  11005 :    Loss_Train:  [[ 4822.5146779]]    Loss_Validation:  [[ 1420.79834037]]\n",
      "Loop  11006 :    Loss_Train:  [[ 4822.51467788]]    Loss_Validation:  [[ 1420.79835134]]\n",
      "Loop  11007 :    Loss_Train:  [[ 4822.51467787]]    Loss_Validation:  [[ 1420.7983623]]\n",
      "Loop  11008 :    Loss_Train:  [[ 4822.51467786]]    Loss_Validation:  [[ 1420.79837325]]\n",
      "Loop  11009 :    Loss_Train:  [[ 4822.51467784]]    Loss_Validation:  [[ 1420.7983842]]\n",
      "Loop  11010 :    Loss_Train:  [[ 4822.51467783]]    Loss_Validation:  [[ 1420.79839513]]\n",
      "Loop  11011 :    Loss_Train:  [[ 4822.51467782]]    Loss_Validation:  [[ 1420.79840606]]\n",
      "Loop  11012 :    Loss_Train:  [[ 4822.5146778]]    Loss_Validation:  [[ 1420.79841698]]\n",
      "Loop  11013 :    Loss_Train:  [[ 4822.51467779]]    Loss_Validation:  [[ 1420.7984279]]\n",
      "Loop  11014 :    Loss_Train:  [[ 4822.51467778]]    Loss_Validation:  [[ 1420.7984388]]\n",
      "Loop  11015 :    Loss_Train:  [[ 4822.51467776]]    Loss_Validation:  [[ 1420.7984497]]\n",
      "Loop  11016 :    Loss_Train:  [[ 4822.51467775]]    Loss_Validation:  [[ 1420.79846059]]\n",
      "Loop  11017 :    Loss_Train:  [[ 4822.51467773]]    Loss_Validation:  [[ 1420.79847147]]\n",
      "Loop  11018 :    Loss_Train:  [[ 4822.51467772]]    Loss_Validation:  [[ 1420.79848235]]\n",
      "Loop  11019 :    Loss_Train:  [[ 4822.51467771]]    Loss_Validation:  [[ 1420.79849321]]\n",
      "Loop  11020 :    Loss_Train:  [[ 4822.51467769]]    Loss_Validation:  [[ 1420.79850407]]\n",
      "Loop  11021 :    Loss_Train:  [[ 4822.51467768]]    Loss_Validation:  [[ 1420.79851492]]\n",
      "Loop  11022 :    Loss_Train:  [[ 4822.51467767]]    Loss_Validation:  [[ 1420.79852576]]\n",
      "Loop  11023 :    Loss_Train:  [[ 4822.51467765]]    Loss_Validation:  [[ 1420.79853659]]\n",
      "Loop  11024 :    Loss_Train:  [[ 4822.51467764]]    Loss_Validation:  [[ 1420.79854742]]\n",
      "Loop  11025 :    Loss_Train:  [[ 4822.51467763]]    Loss_Validation:  [[ 1420.79855824]]\n",
      "Loop  11026 :    Loss_Train:  [[ 4822.51467761]]    Loss_Validation:  [[ 1420.79856905]]\n",
      "Loop  11027 :    Loss_Train:  [[ 4822.5146776]]    Loss_Validation:  [[ 1420.79857985]]\n",
      "Loop  11028 :    Loss_Train:  [[ 4822.51467759]]    Loss_Validation:  [[ 1420.79859065]]\n",
      "Loop  11029 :    Loss_Train:  [[ 4822.51467757]]    Loss_Validation:  [[ 1420.79860143]]\n",
      "Loop  11030 :    Loss_Train:  [[ 4822.51467756]]    Loss_Validation:  [[ 1420.79861221]]\n",
      "Loop  11031 :    Loss_Train:  [[ 4822.51467755]]    Loss_Validation:  [[ 1420.79862298]]\n",
      "Loop  11032 :    Loss_Train:  [[ 4822.51467754]]    Loss_Validation:  [[ 1420.79863375]]\n",
      "Loop  11033 :    Loss_Train:  [[ 4822.51467752]]    Loss_Validation:  [[ 1420.7986445]]\n",
      "Loop  11034 :    Loss_Train:  [[ 4822.51467751]]    Loss_Validation:  [[ 1420.79865525]]\n",
      "Loop  11035 :    Loss_Train:  [[ 4822.5146775]]    Loss_Validation:  [[ 1420.79866599]]\n",
      "Loop  11036 :    Loss_Train:  [[ 4822.51467748]]    Loss_Validation:  [[ 1420.79867672]]\n",
      "Loop  11037 :    Loss_Train:  [[ 4822.51467747]]    Loss_Validation:  [[ 1420.79868744]]\n",
      "Loop  11038 :    Loss_Train:  [[ 4822.51467746]]    Loss_Validation:  [[ 1420.79869816]]\n",
      "Loop  11039 :    Loss_Train:  [[ 4822.51467744]]    Loss_Validation:  [[ 1420.79870887]]\n",
      "Loop  11040 :    Loss_Train:  [[ 4822.51467743]]    Loss_Validation:  [[ 1420.79871957]]\n",
      "Loop  11041 :    Loss_Train:  [[ 4822.51467742]]    Loss_Validation:  [[ 1420.79873026]]\n",
      "Loop  11042 :    Loss_Train:  [[ 4822.5146774]]    Loss_Validation:  [[ 1420.79874094]]\n",
      "Loop  11043 :    Loss_Train:  [[ 4822.51467739]]    Loss_Validation:  [[ 1420.79875162]]\n",
      "Loop  11044 :    Loss_Train:  [[ 4822.51467738]]    Loss_Validation:  [[ 1420.79876229]]\n",
      "Loop  11045 :    Loss_Train:  [[ 4822.51467737]]    Loss_Validation:  [[ 1420.79877295]]\n",
      "Loop  11046 :    Loss_Train:  [[ 4822.51467735]]    Loss_Validation:  [[ 1420.79878361]]\n",
      "Loop  11047 :    Loss_Train:  [[ 4822.51467734]]    Loss_Validation:  [[ 1420.79879425]]\n",
      "Loop  11048 :    Loss_Train:  [[ 4822.51467733]]    Loss_Validation:  [[ 1420.79880489]]\n",
      "Loop  11049 :    Loss_Train:  [[ 4822.51467731]]    Loss_Validation:  [[ 1420.79881552]]\n",
      "Loop  11050 :    Loss_Train:  [[ 4822.5146773]]    Loss_Validation:  [[ 1420.79882614]]\n",
      "Loop  11051 :    Loss_Train:  [[ 4822.51467729]]    Loss_Validation:  [[ 1420.79883676]]\n",
      "Loop  11052 :    Loss_Train:  [[ 4822.51467728]]    Loss_Validation:  [[ 1420.79884736]]\n",
      "Loop  11053 :    Loss_Train:  [[ 4822.51467726]]    Loss_Validation:  [[ 1420.79885796]]\n",
      "Loop  11054 :    Loss_Train:  [[ 4822.51467725]]    Loss_Validation:  [[ 1420.79886856]]\n",
      "Loop  11055 :    Loss_Train:  [[ 4822.51467724]]    Loss_Validation:  [[ 1420.79887914]]\n",
      "Loop  11056 :    Loss_Train:  [[ 4822.51467723]]    Loss_Validation:  [[ 1420.79888972]]\n",
      "Loop  11057 :    Loss_Train:  [[ 4822.51467721]]    Loss_Validation:  [[ 1420.79890028]]\n",
      "Loop  11058 :    Loss_Train:  [[ 4822.5146772]]    Loss_Validation:  [[ 1420.79891084]]\n",
      "Loop  11059 :    Loss_Train:  [[ 4822.51467719]]    Loss_Validation:  [[ 1420.7989214]]\n",
      "Loop  11060 :    Loss_Train:  [[ 4822.51467717]]    Loss_Validation:  [[ 1420.79893194]]\n",
      "Loop  11061 :    Loss_Train:  [[ 4822.51467716]]    Loss_Validation:  [[ 1420.79894248]]\n",
      "Loop  11062 :    Loss_Train:  [[ 4822.51467715]]    Loss_Validation:  [[ 1420.79895301]]\n",
      "Loop  11063 :    Loss_Train:  [[ 4822.51467714]]    Loss_Validation:  [[ 1420.79896353]]\n",
      "Loop  11064 :    Loss_Train:  [[ 4822.51467712]]    Loss_Validation:  [[ 1420.79897405]]\n",
      "Loop  11065 :    Loss_Train:  [[ 4822.51467711]]    Loss_Validation:  [[ 1420.79898455]]\n",
      "Loop  11066 :    Loss_Train:  [[ 4822.5146771]]    Loss_Validation:  [[ 1420.79899505]]\n",
      "Loop  11067 :    Loss_Train:  [[ 4822.51467709]]    Loss_Validation:  [[ 1420.79900555]]\n",
      "Loop  11068 :    Loss_Train:  [[ 4822.51467707]]    Loss_Validation:  [[ 1420.79901603]]\n",
      "Loop  11069 :    Loss_Train:  [[ 4822.51467706]]    Loss_Validation:  [[ 1420.79902651]]\n",
      "Loop  11070 :    Loss_Train:  [[ 4822.51467705]]    Loss_Validation:  [[ 1420.79903697]]\n",
      "Loop  11071 :    Loss_Train:  [[ 4822.51467704]]    Loss_Validation:  [[ 1420.79904744]]\n",
      "Loop  11072 :    Loss_Train:  [[ 4822.51467703]]    Loss_Validation:  [[ 1420.79905789]]\n",
      "Loop  11073 :    Loss_Train:  [[ 4822.51467701]]    Loss_Validation:  [[ 1420.79906833]]\n",
      "Loop  11074 :    Loss_Train:  [[ 4822.514677]]    Loss_Validation:  [[ 1420.79907877]]\n",
      "Loop  11075 :    Loss_Train:  [[ 4822.51467699]]    Loss_Validation:  [[ 1420.7990892]]\n",
      "Loop  11076 :    Loss_Train:  [[ 4822.51467698]]    Loss_Validation:  [[ 1420.79909963]]\n",
      "Loop  11077 :    Loss_Train:  [[ 4822.51467696]]    Loss_Validation:  [[ 1420.79911004]]\n",
      "Loop  11078 :    Loss_Train:  [[ 4822.51467695]]    Loss_Validation:  [[ 1420.79912045]]\n",
      "Loop  11079 :    Loss_Train:  [[ 4822.51467694]]    Loss_Validation:  [[ 1420.79913085]]\n",
      "Loop  11080 :    Loss_Train:  [[ 4822.51467693]]    Loss_Validation:  [[ 1420.79914124]]\n",
      "Loop  11081 :    Loss_Train:  [[ 4822.51467691]]    Loss_Validation:  [[ 1420.79915163]]\n",
      "Loop  11082 :    Loss_Train:  [[ 4822.5146769]]    Loss_Validation:  [[ 1420.799162]]\n",
      "Loop  11083 :    Loss_Train:  [[ 4822.51467689]]    Loss_Validation:  [[ 1420.79917237]]\n",
      "Loop  11084 :    Loss_Train:  [[ 4822.51467688]]    Loss_Validation:  [[ 1420.79918274]]\n",
      "Loop  11085 :    Loss_Train:  [[ 4822.51467687]]    Loss_Validation:  [[ 1420.79919309]]\n",
      "Loop  11086 :    Loss_Train:  [[ 4822.51467685]]    Loss_Validation:  [[ 1420.79920344]]\n",
      "Loop  11087 :    Loss_Train:  [[ 4822.51467684]]    Loss_Validation:  [[ 1420.79921378]]\n",
      "Loop  11088 :    Loss_Train:  [[ 4822.51467683]]    Loss_Validation:  [[ 1420.79922411]]\n",
      "Loop  11089 :    Loss_Train:  [[ 4822.51467682]]    Loss_Validation:  [[ 1420.79923443]]\n",
      "Loop  11090 :    Loss_Train:  [[ 4822.51467681]]    Loss_Validation:  [[ 1420.79924475]]\n",
      "Loop  11091 :    Loss_Train:  [[ 4822.51467679]]    Loss_Validation:  [[ 1420.79925506]]\n",
      "Loop  11092 :    Loss_Train:  [[ 4822.51467678]]    Loss_Validation:  [[ 1420.79926536]]\n",
      "Loop  11093 :    Loss_Train:  [[ 4822.51467677]]    Loss_Validation:  [[ 1420.79927566]]\n",
      "Loop  11094 :    Loss_Train:  [[ 4822.51467676]]    Loss_Validation:  [[ 1420.79928594]]\n",
      "Loop  11095 :    Loss_Train:  [[ 4822.51467675]]    Loss_Validation:  [[ 1420.79929622]]\n",
      "Loop  11096 :    Loss_Train:  [[ 4822.51467673]]    Loss_Validation:  [[ 1420.79930649]]\n",
      "Loop  11097 :    Loss_Train:  [[ 4822.51467672]]    Loss_Validation:  [[ 1420.79931676]]\n",
      "Loop  11098 :    Loss_Train:  [[ 4822.51467671]]    Loss_Validation:  [[ 1420.79932701]]\n",
      "Loop  11099 :    Loss_Train:  [[ 4822.5146767]]    Loss_Validation:  [[ 1420.79933726]]\n",
      "Loop  11100 :    Loss_Train:  [[ 4822.51467669]]    Loss_Validation:  [[ 1420.79934751]]\n",
      "Loop  11101 :    Loss_Train:  [[ 4822.51467667]]    Loss_Validation:  [[ 1420.79935774]]\n",
      "Loop  11102 :    Loss_Train:  [[ 4822.51467666]]    Loss_Validation:  [[ 1420.79936797]]\n",
      "Loop  11103 :    Loss_Train:  [[ 4822.51467665]]    Loss_Validation:  [[ 1420.79937819]]\n",
      "Loop  11104 :    Loss_Train:  [[ 4822.51467664]]    Loss_Validation:  [[ 1420.7993884]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nASEiIkUpIEREpCgFhIiIFPX/AVGuW4FDnIA1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1545b43cbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# read data\n",
    "def get_data():\n",
    "    data = load_svmlight_file(\"D://test.txt\")\n",
    "    return data\n",
    "\n",
    "# Draw\n",
    "def Draw(loops, Loss_train, Loss_Validation):\n",
    "    plt.plot(np.arange(0,100,1), Loss_train[0:100], label='Loss Train ')\n",
    "    plt.plot(np.arange(0,100,1), Loss_Validation[0:100], label='Loss Validation')\n",
    "    plt.xlabel('loops')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# grad\n",
    "def Grad(Lambda, theta, X_train):\n",
    "    grad = Lambda * theta + (np.dot(X_train.transpose(), np.dot(X_train, theta)))\n",
    "    return grad\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    X = get_data()[0]\n",
    "    y = get_data()[1]\n",
    "\n",
    "    X = X.toarray()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "    train_row = X_train.shape[0]\n",
    "    test_row = X_test.shape[0]\n",
    "    col = X_train.shape[1]\n",
    "\n",
    "    \n",
    "    y_train = y_train.reshape(train_row, 1)\n",
    "    y_test = y_test.reshape(test_row, 1) \n",
    "    \n",
    "    theta = np.random.random(size = (col, 1))\n",
    "    Lambda = 0.01\n",
    "    Eta = 0.000085\n",
    "    \n",
    "    # batch grandient descent \n",
    "    loops = 100000 # 循环总次数\n",
    "    epsilon = 0.000001 # 收敛精度\n",
    "    count = 0 # loop的次数\n",
    "    error = np.zeros((col, 1)) # 上次theta的值，初始为0向量\n",
    "    finish = 0 # 完成标志位\n",
    "    \n",
    "    lossTrain = []\n",
    "    lossValidation = []\n",
    "\n",
    "    Tensor = np.dot(-X_train.transpose(), y_train)\n",
    "    \n",
    "    while count < loops:\n",
    "        count += 1\n",
    "        # 所有训练数据的期望更新一次theta\n",
    "        theta = theta - Eta * (Grad(Lambda, theta, X_train) + Tensor)\n",
    "        if (np.linalg.norm(theta - error) < epsilon):\n",
    "            finish = 1\n",
    "            break\n",
    "        else:\n",
    "            error = theta # 没有则将当前theta向量赋值给error，作为下次判断收敛的参数之一\n",
    "            Loss_Train = (1.0/2) * Lambda * theta.transpose().dot(theta) + (1.0/2) * (y_train - X_train.dot(theta)).transpose().dot((y_train - X_train.dot(theta)))\n",
    "            Loss_Validation = (1.0/2) * Lambda * theta.transpose().dot(theta) + (1.0/2) * (y_test-X_test.dot(theta)).transpose().dot((y_test - X_test.dot(theta)))\n",
    "            lossTrain.append(Loss_Train[0] / train_row)\n",
    "            lossValidation.append(Loss_Validation[0] / test_row)\n",
    "            print('Loop '.format(count), count, ':',  '   Loss_Train: ',Loss_Train, '   Loss_Validation: ',Loss_Validation)\n",
    "\n",
    "    Draw(count, lossTrain, lossValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
